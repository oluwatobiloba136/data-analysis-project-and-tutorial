% This file was created with JabRef 2.7b.
% Encoding: UTF-8

@STRING{addison = {Addison-Wesley}}

@STRING{AMS = {Annals of Mathematical Statistics}}

@STRING{article = {Journal Papers}}

@STRING{bioinf = {Bioinformatics}}

@STRING{bmcbioinf = {BMC Bioinformatics}}

@STRING{book = {Books}}

@STRING{cancerres = {Cancer Research}}

@STRING{collection = {Volumes of Collected Papers}}

@STRING{CSL = {Computer Speech and Language}}

@STRING{cup = {Cambridge University Press}}

@STRING{DOKLADY = {Doklady Akademiia Nauk SSSR}}

@STRING{eccv = {European Conference on Computer Vision}}

@STRING{EPL = {Europhysics Letters}}

@STRING{icann = {International Conference on Artificial Neural Networks}}

@STRING{iccv = {IEEE International Conference on Computer Vision (ICCV)}}

@STRING{icml = {Proceedings of the International Conference in Machine Learning}}

@STRING{IEEE = {IEEE Transactions on Neural Networks}}

@STRING{ieeecomp = {IEEE Computer Society Press}}

@STRING{ijcnn = {Proceedings of the International Joint Conference on Neural Networks}}

@STRING{ijcv = {International Journal of Computer Vision}}

@STRING{IJNS = {International Journal of Neural Systems}}

@STRING{incollection = {In Collected Volumes}}

@STRING{inproceedings = {Refereed Conference Papers}}

@STRING{jair = {Journal of Artificial Intelligence Research}}

@STRING{jasa = {Journal of the American Statistical Association}}

@STRING{JMB = {Journal of Molecular Biology}}

@STRING{jmbcell = {Mol. Biol. Cell.}}

@STRING{jmlr = {Journal of Machine Learning Research}}

@STRING{JPhysChem = {J. Phys Chem.}}

@STRING{JPhysChemA = {J. Phys Chem. A}}

@STRING{JRSSa = {Journal of the Royal Statistical Society, A}}

@STRING{JRSSb = {Journal of the Royal Statistical Society, B}}

@STRING{jtheoretbio = {Journal of Theoretical Biology}}

@STRING{lnai = {Lecture Notes in Artificial Intelligence}}

@STRING{lncs = {Lecture Notes in Computer Science}}

@STRING{mainheading = {Machine Learning Publications}}

@STRING{mcgraw = {McGraw-Hill}}

@STRING{misc = {Miscellaneous}}

@STRING{mit = {MIT Press}}

@STRING{mk = {Morgan Kauffman}}

@STRING{ML = {Machine Learning}}

@STRING{myftp = {http://www.thelawrences.net/neil/}}

@STRING{nar = {Nucleic Acids Research}}

@STRING{NC = {Neural Computation}}

@STRING{network = {Network: Computation in Neural Systems}}

@STRING{nholland = {North Holland}}

@STRING{nips = {Advances in Neural Information Processing Systems}}

@STRING{nle = {Natural Language Engineering}}

@STRING{NN = {Neural Networks}}

@STRING{NW = {Network: Computation in Neural Systems}}

@STRING{PAMI = {IEEE Transactions on Pattern Analysis and Machine Intelligence}}

@STRING{patent = {Patents}}

@STRING{pCVPR = {Proceedings of the {IEEE} Computer Society Conference on Computer Vision
	and Pattern Recognition}}

@STRING{phdthesis = {PhD Theses}}

@STRING{pnasusa = {Proc. Natl. Acad. Sci. USA}}

@STRING{PRa = {Physical Review A}}

@STRING{PRe = {Physical Review E}}

@STRING{PRL = {Physical Review Letters}}

@STRING{RMP = {Reviews of Modern Physics}}

@STRING{shefftp = {ftp://ftp.dcs.shef.ac.uk/home/neil/}}

@STRING{springer = {Springer-Verlag}}

@STRING{statmod = {Statistical Modelling}}

@STRING{talk = {Talks}}

@STRING{techreport = {Technical Reports}}

@STRING{TIT = {IEEE Transactions on Information Theory}}

@STRING{TKDE = {IEEE Transactions on Knowledge and Data Engineering}}

@STRING{trendsbio = {Trends in Biochemical Sciences}}
@STRING{trendscog = {Trends in Cognitive Sciences}}

@STRING{uai = {Uncertainty in Artificial Intelligence}}

@STRING{unpublished = {Submitted Papers}}

@STRING{wiley = {John Wiley and Sons}}
@article{Kahneman:prospect79,
 author = {Daniel Kahneman and Amos Tversky},
 title = {Prospect Theory: An Analysis of Decision under Risk},
 ISSN = {00129682, 14680262},
 jstor = 1914185,
 URL = {http://www.jstor.org/stable/1914185},
 abstract = {This paper presents a critique of expected utility theory as a descriptive model of decision making under risk, and develops an alternative model, called prospect theory. Choices among risky prospects exhibit several pervasive effects that are inconsistent with the basic tenets of utility theory. In particular, people underweight outcomes that are merely probable in comparison with outcomes that are obtained with certainty. This tendency, called the certainty effect, contributes to risk aversion in choices involving sure gains and to risk seeking in choices involving sure losses. In addition, people generally discard components that are shared by all prospects under consideration. This tendency, called the isolation effect, leads to inconsistent preferences when the same choice is presented in different forms. An alternative theory of choice is developed, in which value is assigned to gains and losses rather than to final assets and in which probabilities are replaced by decision weights. The value function is normally concave for gains, commonly convex for losses, and is generally steeper for losses than for gains. Decision weights are generally lower than the corresponding probabilities, except in the range of low probabilities. Overweighting of low probabilities may contribute to the attractiveness of both insurance and gambling.},
 journal = {Econometrica},
 number = {2},
 pages = {263--291},
 publisher = {[Wiley, Econometric Society]},
 volume = {47},
 doi = {10.2307/1914185},
 year = {1979}
}

@InCollection{,
  author = 	 {},
  title = 	 {},
  booktitle = 	 {},
  OPTcrossref =  {},
  OPTkey = 	 {},
  OPTpages = 	 {},
  OPTpublisher = {},
  OPTyear = 	 {},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTtype = 	 {},
  OPTchapter = 	 {},
  OPTaddress = 	 {},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@InCollection{Piazzi:monatliche1801,
  author = 	 {Giuseppe Piazzi},
  title = 	 {Fortgesetzte Nachrichten über den Längst vermutheten neuen Haupt-Planeten unseres Sonnen-Systems},
  crossref =	 1801monatliche,
  month = {September},
  pages =	 {279--283},
  OPTgroup = 	 {}
}

@InCollection{Gauss:monatliche1801,
  author = 	 {Carl Friederich Gauss},
  title = 	 {Fortgesetzte Nachrichten über den Längst vermutheten neuen Haupt-Planeten unseres Sonnen-Systems},
  crossref =	 1801monatliche,
  month = {December},
  pages =	 {638--649},
  OPTgroup = 	 {}
}

@Article{Turner:pad11,
  author = 	 {Richard E. Turner and Maneesh Sahani},
  title = 	 {Demodulation as Probabilistic Inference},
  journal = 	 {IEEE Transactions on Audio, Speech, and Language Processing},
  year = 	 {2011},
  OPTkey = 	 {},
  volume =	 {19},
  number =	 {},
  pages = {2398-2411},
  OPTpages = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Turner:time14,
  author = 	 {Richard E. Turner and Maneesh Sahani},
  title = 	 {Time-frequency Analysis as Probabilistic Inference},
  journal = 	 {IEEE Transactions on Signal Processing},
  year = 	 {2014},
  OPTkey = 	 {},
  volume =	 {62},
  number =	 {23},
  pages =	 {6171--6181},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@techreport{Stoica:systemsml17,
    Author = {Stoica, Ion and Song, Dawn and Popa, Raluca Ada and Patterson, David A. and Mahoney, Michael W. and Katz, Randy H. and Joseph, Anthony D. and Jordan, Michael and Hellerstein, Joseph M. and Gonzalez, Joseph and Goldberg, Ken and Ghodsi, Ali and Culler, David E. and Abbeel, Pieter},
    Title = {A Berkeley View of Systems Challenges for AI},
    Institution = {EECS Department, University of California, Berkeley},
    Year = {2017},
    Month = {Oct},
    URL = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2017/EECS-2017-159.html},
    Number = {UCB/EECS-2017-159},
    Abstract = {With the increasing commoditization of computer vision, speech recognition and machine translation systems and the widespread deployment of learning-based back-end technologies such as digital advertising and intelligent infrastructures, AI (Artificial Intelligence) has moved from research labs to production. These changes have been made possible by unprecedented levels of data and computation, by methodological advances in machine learning, by innovations in systems software and architectures, and by the broad accessibility of these technologies.

The next generation of AI systems promises to accelerate these developments and increasingly impact our lives via frequent interactions and making (often mission-critical) decisions on our behalf, often in highly personalized contexts. Realizing this promise, however, raises daunting challenges. In particular, we need AI systems that make timely and safe decisions in unpredictable environments, that are robust against sophisticated adversaries, and that can process ever increasing amounts of data across organizations and individuals without compromising confidentiality. These challenges will be exacerbated by the end of the Moore’s Law, which will constrain the amount of data these technologies can store and process. In this paper, we propose several open research directions in systems, architectures, and security that can address these challenges and help unlock AI’s potential to improve lives and society.}
}


@Article{Heider:experimental44,
  author = 	 {F. Heider and M. Simmel},
  title = 	 {An Experimental Study of Apparent Behavior},
  journal = 	 {The American Journal of Psychology},
  year = 	 1944,
  OPTkey = 	 {},
  volume =	 {57},
  OPTnumber = 	 {},
  pages =	 {243--259},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {10.2307/1416950},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  abstract =	 {A motion picture which shows movements of three geometrical figures was the material of the investigation. It was presented to a first group of 34 Ss with the instruction to describe it; to a second group (36 Ss) with the instruction to interpret the movements as actions of persons and to answer a number of questions relating to them. A third group (44 Ss) was treated like the second, except that the picture was shown in reverse and with fewer questions. The reports show that all but one S of Group I, all of Group II, and all but two of Group III interpreted the picture in terms of actions of animated beings, chiefly of persons. A characteristic feature of this organization in terms of actions is the attribution of the origin of movements to figural units and to motives. It has been shown that this attribution of the origin influences the interpretation of the movements, and that it depends in some cases on the characteristics of the movements themselves, in others on surrounding objects. The way in which the actors are judged is closely connected with this attribution of origin. It is held that this method is useful in investigating the way the behavior of other persons is perceived.},
  OPTgroup = 	 {}
}

@incollection{Sculley:debt15,
title = {Hidden Technical Debt in Machine Learning Systems},
author = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-Fran\c{c}ois and Dennison, Dan},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {Corinna Cortes and Neil D. Lawrence and Daniel D. Lee and Masashi Sugiyama and Roman Garnett},
pages = {2503--2511},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf}
}


@InProceedings{Klami:local07,
  author = 	 {Aarto Klami and Sami Kaski},
  title = 	 {Local Dependent Components Analysis},
  crossref =	 {Ghahramani:icml07}
}

@Article{Klami:probabilistic08,
  author = 	 {Aarto Klami and Sami Kaski},
  title = 	 {Probabilistic approach to detecting dependencies between data sets},
  journal = 	 {Neurocomputing},
  year = 	 2008,
  OPTkey = 	 {},
  volume =	 {72},
  OPTnumber = 	 {},
  pages =	 {39--46},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}
@ARTICLE{Hinton:fast06,
    author = {Geoffrey E. Hinton and Simon Osindero},
    title = {A fast learning algorithm for deep belief nets},
    journal = {Neural Computation},
    year = {2006},
    volume = {18},
    pages = {2006}
}

@article{Bengio:deep09,
 author = {Yoshua Bengio},
 title = {{Learning Deep Architectures for AI}},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {January 2009},
 volume = {2},
 number = {1},
 month = jan,
 year = {2009},
 issn = {1935-8237},
 pages = {1--127},
 numpages = {127},
 doi = {10.1561/2200000006},
 acmid = {1658424},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 


@InProceedings{Klami:group11,
  author = 	 {S. Virtanen and Aarto Klami and Sami Kaski},
  title = 	 {Bayesian {CCA} via Group Sparsity},
  crossref = 	 {Getoor:icml11}
}

@Misc{Unknown:ref,
  key =		 {},
  author =	 {Giorgia Foder\`a Serio},
  title =	 {On the History of the Palermo Observatory},
  howpublished = {Online},
  OPTmonth = 	 {},
  OPTyear = 	 {},
  url =	 {http://www.astropa.unipa.it/HISTORY/history.htm},
  OPTnote = 	 {Retrieved 2012/08/28},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}
@TechReport{Hoffman:stochastic12,
  title={Stochastic Variational Inference},
  author={Matthew Hoffman and David M. Blei and Chong Wang and John Paisley},
  journal={arXiv preprint arXiv:1206.7051},
  year={2012}
}


@InProceedings{Ananthanarayanan:cat09,
  author = 	 {Rajagopal Ananthanarayanan and Steven K. Esser and Horst D. Simon and Dharmendra S. Modha},
  title = 	 {The Cat is Out of The Bag: Cortical Simulations with $10^9$ neurons and $10^13$ synapses},
  booktitle = 	 {Proceedings of the ACM/IEEE SC2009 Conference on High Performance Networking and Computing},
  year = 	 {2009},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTpages = 	 {},
  month =	 {Nov 14--20},
  address = 	 {Portland, OR},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Reed:information98,
  author = 	 {Charlotte Reed and Nathaniel I. Durlach},
  title = 	 {Note on Information Transfer Rates in Human Communication},
  journal = 	 {Presence Teleoperators \& Virtual Environments},
  year = 	 {1998},
  OPTkey = 	 {},
  volume =	 {7},
  number =	 {5},
  pages =	 {509--518},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {10.1162/105474698565893},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

Note on Information Transfer Rates in Human Communication
@ARTICLE{Listgarten:improved12,
  author = {Jennifer Listgarten and Christoph Lippert and Carl M. Kadie and Robert I. Davidson and Eleazar Eskin and David Heckerman},
  title = {Improved linear mixed models for genome-wide association studies
},
  journal = {Nature Methods},
  year = {2012},
  volume = {9},
  pages = {525--526},
  OPTabstract = {},
  doi = {10.1038/nmeth.2037},
  OPTfile = {},
  OPTgroup = {}
}

@InProceedings{Krizhevsky:imagenet12,
  author = 	 {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  title = 	 {ImageNet Classification with Deep Convolutional Neural Networks},
  crossref =	 {Bartlett:nips12},
  pages =	 {1097--1105},
  linkpdf =	 {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
  abstract =	 {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\% and 18.9\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  OPTgroup = 	 {}
}

@InProceedings{Duvenaud:pathologies14,
  author = 	 {David Duvenaud and Oren Rippel and Ryan Adams and Zoubin Ghahramani
},
  title = 	 {Avoiding Pathologies in Very Deep Networks},
  crossref =	 {Kaski:aistats14},
  pages =	 {},
  year =	 2014,
  OPTeditor =	 {},
  OPTcrossref =  {},
  OPTkey = 	 {},
  OPTbooktitle = {},
  OPTpages = 	 {},
  OPTyear = 	 {},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Defreitas:variational01,
  author = {Nando G {de Freitas} and Pedro {H{\oe}jen-S{\oe}rensen} and Michael
	I. Jordan and Stuart Russell},
  title = {Variational {MCMC}},
  pages = {120--127},
  abstract = {We propose a new class of learning algorithms that combines variational
	approximation and Markov chain Monte Carlo (MCMC) simulation. Naive
	algorithms that use the variational approximation as proposal distribution
	can perform poorly because this approximation tends to underestimate
	the true variance and other features of the data. We solve this problem
	by introducing more sophisticated MCMC algorithms. One of these algorithms
	is a mixture of two MCMC kernels: a random walk Metropolis kernel
	and a block Metropolis-Hastings (MH) kernel with a variational approximation
	as proposal distribution. The MH kernel allows one to locate regions
	of high probability efficiently. The Metropolis kernel allows us
	to explore the vicinity of these regions. This algorithm outperforms
	variational approximations because it yields slightly better estimates
	of the mean and considerably better estimates of higher moments,
	such as covariances. It also outperforms standard MCMC algorithms
	because it locates the regions of high probability quickly, thus
	speeding up convergence. We demonstrate this algorithm on the problem
	of Bayesian parameter estimation for logistic (sigmoid) belief networks.},
  crossref = {Breese:uai01},
  file = {varmcuai.ps:http\://www.cs.berkeley.edu/~jordan/papers/varmcuai.ps:PostScript},
  group = {variational, mcmc},
  linkpsgz = {http://www.cs.ubc.ca/~nando/papers/varmcuai.ps.gz}
}

@INPROCEEDINGS{Ahmad:missing93,
  author = {Subutai Ahmad and Volker Tresp},
  title = {Some Solutions to the Missing Feature Problem in Vision},
  year = {1993},
  pages = {393--400},
  crossref = {Hanson:nips92},
  linkdjvu = {http://nips.djvuzone.org/djvu/nips05/0393.djvu}
}

@INPROCEEDINGS{Lu:surpassing14,
  title={Surpassing Human-Level Face Verification Performance on {LFW} with {GaussianFace}},
  author={Chaochao Lu and Xiaoou Tang},
  booktitle = {Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI)},
  address = {Austin, Texas},
  year={2015}
}
@INPROCEEDINGS{Amari:BSS96,
  author = {Shun-Ichi Amari and Andrzej Cichocki and Howard H. Yang},
  title = {A New Learning Algorithm for Blind Signal Separation},
  pages = {757--763},
  crossref = {Touretzky:nips95}
}
@article{Opper:variational09,
  title={The variational {G}aussian approximation revisited},
  author={Manfred Opper and Cedric Archambeau},
  journal=NC,
  volume={21},
  number={3},
  pages={786--792},
  year={2009},
  publisher={MIT Press}
}
@ARTICLE{Archambeau:gpsde07,
  author = {Cedric Archambeau and Dan Cornford and Manfred Opper and John Shawe-Taylor},
  title = {Gaussian Process Approximations of Stochastic Differential Equations},
  journal = {JMLR Workshop and Conference Proceedings},
  year = {2007},
  volume = {1},
  pages = {1--16},
  abstract = {Stochastic differential equations arise naturally in a range of contexts,
	from financial to environmental modeling. Current solution methods
	are limited in their representation of the posterior process in the
	presence of data. In this work, we present a novel Gaussian process
	approximation to the posterior measure over paths for a general class
	of stochastic differential equations in the presence of observations.
	The method is applied to two simple problems: the Ornstein-Uhlenbeck
	process, of which the exact solution is known and can be compared
	to, and the double-well system, for which standard approaches such
	as the ensemble Kalman smoother fail to provide a satisfactory result.
	Experiments show that our variational approximation is viable and
	that the results are very promising as the variational approximate
	solution outperforms standard Gaussian process regression for non-Gaussian
	Markov processes.},
  crossref = {Lawrence:gpip07},
  file = {archambeau07a.pdf:http\://jmlr.csail.mit.edu/proceedings/papers/v1/archambeau07a/archambeau07a.pdf:PDF},
  group = {gp, sde}
}
@article{Gal:dropout15,
  author = {Yarin Gal and Zoubin Ghahramani},
  title = {Dropout as a {B}ayesian Approximation: Representing Model Uncertainty in Deep Learning},
  year = {2015},
  journal = {arXiv:1506.02142},
}

@INPROCEEDINGS{Attias:latent99,
  author = {Hagai Attias},
  title = {Inferring Parameters and Structure of Latent Variable Models by Variational
	{B}ayes},
  crossref = {Laskey:uai99}
}

@INPROCEEDINGS{Attias:variational00,
  author = {Hagai Attias},
  title = {A Variational {B}ayesian framework for Graphical Models},
  crossref = {Solla:nips99}
}

@INPROCEEDINGS{Augusto:smarthomes04,
  author = {Juan C. Augusto and Chris D. Nugent},
  title = {The Use of Temporal Reasoning and Mangement of Complex Events in
	Smart Homes},
  booktitle = {Proceedings of the 16th European Conference on Artifical Intelligence},
  pages = {778--782},
  abstract = {Technological advancements have and will revolutionise the support
	offered to persons in their home environment. As the population continues
	to grow and in addition the percentage of elderly within the population
	increases we now face the challenge of improving individual autonomy
	and quality of life. Smart home technology offering intelligent appliances
	and remote alarm-based monitoring are moving close towards addressing
	these issues. To date the research efforts on smart home technology
	have focused on communications and intelligent user interfaces. The
	trends in these areas must now, however, focus on the analysis on
	the data which is generated from the devices within the house as
	a means of producing 'profiles' of the users and providing intelligent
	interaction to support their daily activities. A key element in the
	implementation of these systems is the capability to handle time-related
	concepts. Here we report about one experience using Active Databases
	in connection with temporal reasoning in the form of complex event
	detection to accommodate prevention of hazardous situations.},
  crossref = {Lopez:ECAI04},
  file = {ecai2004.pdf:http\://www.infj.ulst.ac.uk/~jcaug/ecai2004.pdf:PDF},
  group = {alms}
}

@INPROCEEDINGS{Bach:blind04,
  author = {Francis R. Bach and Michael I. Jordan},
  title = {Blind One-microphone Speech Separation: A Spectral Learning Approach},
  crossref = {Saul:nips04}
}

@INPROCEEDINGS{Bach:learning03,
  author = {Francis R. Bach and Michael I. Jordan},
  title = {Learning Spectral Clustering},
  pages = {305--312},
  crossref = {Thrun:nips03},
  linkpsgz = {http://www.cs.berkeley.edu/~fbach/nips03_cluster.ps.gz}
}

@INPROCEEDINGS{Barber:ensemble98,
  author = {David Barber and Christopher M. Bishop},
  title = {Ensemble Learning in {B}ayesian Neural Networks},
  pages = {215--237},
  crossref = {Bishop:neural98}
}

@INPROCEEDINGS{Barber:variational98,
  author = {David Barber and Wim Wiegerinck},
  title = {Variational Approximations of Graphical Models using Undirected Graphs},
  crossref = {Kearns:nips98}
}

@INPROCEEDINGS{Barber:Gaussian97,
  author = {David Barber and Christopher K. I. Williams},
  title = {{G}aussian Processes for {B}ayesian Classification via Hybrid {M}onte
	{C}arlo},
  crossref = {Mozer:nips96},
  group = {gp},
  trnumber = {NCRG/96/027}
}

@INPROCEEDINGS{Bengio:outofsample03,
  author = {Yoshua Bengio and Jean-Francois Paiement and Pascal Vincent and Olivier
	Delalleau and Nicolas {Le Roux} and Marie Ouimet},
  title = {Out-of-Sample Extensions for {LLE}, Isomap, {MDS}, Eigenmaps, and
	Spectral Clustering},
  year = {2004},
  pages = {177--184},
  crossref = {Thrun:nips03},
  file = {tr1238.pdf:http\://www.iro.umontreal.ca/~lisa/pointeurs/tr1238.pdf:PDF}
}

@INPROCEEDINGS{Bishop:bayesPCA98,
  author = {Christopher M. Bishop},
  title = {{B}ayesian {PCA}},
  pages = {482--388},
  crossref = {Kearns:nips98},
  group = {pca, dimensionality reduction}
}

@INCOLLECTION{Bishop:erice97,
  author = {Christopher M. Bishop},
  title = {Latent Variable Models},
  booktitle = {Learning in Graphical Models},
  pages = {371--403},
  crossref = {Jordan:learning98}
}

@INPROCEEDINGS{Bishop:nips_tokamak95,
  author = {Christopher M. Bishop and P. S. Haynes and M. E. U. Smith and T.
	N. Todd and D. L. Trotman and C. G. Windsor},
  title = {Real-time control of a tokamak plasma using neural networks},
  year = {1995},
  pages = {1007--1014},
  crossref = {Tesauro:nips94}
}

@INPROCEEDINGS{Bishop:nips_periodic95,
  author = {Christopher M. Bishop and C. Legleye},
  title = {Estimating conditional probability densities for periodic variables},
  year = {1995},
  pages = {641--648},
  crossref = {Tesauro:nips94}
}

@INPROCEEDINGS{Bishop:beta_nips97,
  author = {Christopher M. Bishop and Cazhaow S. Qazaz},
  title = {Regression with Input-Dependent Noise: A {B}ayesian Treatment},
  booktitle = nips,
  year = {1997},
  publisher = mit,
  crossref = {Mozer:nips96}
}

@INPROCEEDINGS{Bishop:emdn95,
  author = {Christopher M. Bishop and Marcus Svens\'{e}n and Christopher K. I.
	Williams},
  title = {A fast {EM} algorithm for latent variable density models},
  booktitle = nips,
  pages = {465--471},
  crossref = {Touretzky:nips95},
  group = {dimensionality reduction},
  linkpszip = {http://www.ncrg.aston.ac.uk/Papers/postscript/NCRG_96_011.ps.zip}
}

@INPROCEEDINGS{Blanz:3dmodels96,
  author = {V. Blanz and Bernhard Sch\"olkopf and H. Bulthoff and Christopher
	J. C. Burges and Vladimir N. Vapnik and T. Vetter},
  title = {Comparison of View-based Object Recognition Algorithms Using Realistic
	3{D} Models},
  crossref = {vonderMalsburg:icann96}
}

@INPROCEEDINGS{Bonilla:preference11,
  author = {Edwin Bonilla and Shengbo Guo and Scott Sanner},
  title = {Gaussian Process Preference Elicitation},
  pages = {262--270},
  crossref = {Taylor:nips11}
}

@INPROCEEDINGS{Bonilla:multitask08,
  author = {Edwin V. Bonilla and Kian Ming A. Chai and Christopher K. I. Williams},
  title = {Multi-task {G}aussian Process Prediction},
  year = {2008},
  abstract = {In this paper we investigate multi-task learning in the context of
	Gaussian Processes (GP). We propose a model that learns a shared
	covariance function on input-dependent features and a `free-form'
	covariance matrix over tasks. This allows for good flexibility when
	modelling inter-task dependencies while avoiding the need for large
	amounts of data for training. We show that under the assumption of
	noise-free observations and a block design, predictions for a given
	task only depend on its target values and therefore a cancellation
	of inter-task transfer occurs. We evaluate the benefits of our model
	on two practical applications: a compiler performance prediction
	problem and an exam score prediction task. Additionally, we make
	use of GP approximations and properties of our model in order to
	provide scalability to large data sets.},
  crossref = {Platt:nips07},
  file = {multitaskGP_v22.pdf:http\://www.dai.ed.ac.uk/homes/ckiw/postscript/multitaskGP_v22.pdf:PDF},
  group = {gp, multitask}
}

@TechReport{Ge:calibrating15,
  author = 	 {Hong Ge and Max Welling and Zoubin Ghahramani},
  title = 	 {A {B}ayesian Model for Calibrating Reviewer Scores},
  institution =  {University of Cambridge},
  year = 	 {2015},
  OPTkey = 	 {},
  OPTtype = 	 {},
  OPTnumber = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {Model used for NIPS 2013, but write up posted on line in 2015. Write up available from \url{http://mlg.eng.cam.ac.uk/hong/nipsrevcal.pdf}.},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@TechReport{Platt:regularized12,
  author = 	 {John C. Platt and Chris J. C. Burges},
  title = 	 {Regularized Least Squares to Remove Reviewer Bias},
  institution =  {},
  year = 	 {2012},
  OPTkey = 	 {},
  OPTtype = 	 {},
  OPTnumber = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  note =	 {First used in 2002. Description available from \url{http://research.microsoft.com/en-us/um/people/cburges/papers/ReviewerBias.pdf}.},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Bonilla:multi07,
  author = {Edwin V. Bonilla and Kian Ming Chai and Christopher K. I. Williams},
  title = {Multi-task {G}aussian Process Prediction},
  abstract = {In this paper we investigate multi-task learning in the context of
	Gaussian Processes (GP). We propose a model that learns a shared
	covariance function on input-dependent features and a “free-form”
	covariance matrix over tasks. This allows for good flexibility when
	modelling inter-task dependencies while avoiding the need for large
	amounts of data for training. We show that under the assumption of
	noise-free observations and a block design, predictions for a given
	task only depend on its target values and therefore a cancellation
	of inter-task transfer occurs. We evaluate the benefits of our model
	on two practical applications: a compiler performance prediction
	problem and an exam score prediction task. Additionally, we make
	use of GP approximations and properties of our model in order to
	provide scalability to large data sets.},
  crossref = {Platt:nips07},
  file = {NIPS2007_0431.pdf:http\://books.nips.cc/papers/files/nips20/NIPS2007_0431.pdf:PDF},
  group = {gp,multi-task}
}

@INPROCEEDINGS{Bourlard:speech90,
  author = {H. Bourlard and N. Morgan},
  title = {A continuous speech recognition system embedding {MLP} into {HMM}},
  year = {1990},
  pages = {186--193},
  crossref = {Touretzky:nips89}
}

@INPROCEEDINGS{Boyle:dependent04,
  author = {Phillip Boyle and Marcus Frean},
  title = {Dependent {G}aussian Processes},
  pages = {217--224},
  abstract = {Gaussian processes are usually parameterised in terms of their covariance
	functions. However, this makes it difficult to deal with multiple
	outputs, because ensuring that the covariance matrix is positive
	definite is problematic. An alternative formulation is to treat Gaussian
	processes as white noise sources convolved with smoothing kernels,
	and to parameterise the kernel instead. Using this, we extend Gaussian
	processes to handle multiple, coupled outputs.},
  crossref = {Saul:nips04},
  file = {NIPS2004_0225.pdf:http\://books.nips.cc/papers/files/nips17/NIPS2004_0225.pdf:PDF},
  group = {gp}
}

@INPROCEEDINGS{Campbell:query00,
  author = {Colin Campbell and Nello Cristianini and Alex J. Smola},
  title = {Query Learning with Large Margin Classifiers},
  pages = {111--118},
  crossref = {Langley:icml00}
}

@INPROCEEDINGS{Chai:generalization09,
  author = {Kian Ming Chai},
  title = {Generalization Errors and Learning Curves for Regression with Multi-task
	{G}aussian Processes},
  pages = {279--287},
  crossref = {Bengio:nips09}
}

@INCOLLECTION{Chai:inverse09,
  author = {Kian Ming A. Chai and Christopher K. I. Williams and Stefan Klanke
	and Sethu Vijayakumar},
  title = {Multi-task {G}aussian Process Learning of Robot Inverse Dynamics},
  pages = {265--272},
  crossref = {Koller:nips08}
}

@INPROCEEDINGS{Chapelle:invariances01,
  author = {Olivier Chapelle and Bernhard Sch\"olkopf},
  title = {Incorporating Invariances in Nonlinear Support Vector Machines},
  pages = {609--616},
  crossref = {Dietterich:nips01},
  linkdjvu = {http://www-2.cs.cmu.edu/Groups/NIPS/NIPS2001/papers/djvu/AA32.djvu},
  linkpsgz = {http://www-2.cs.cmu.edu/Groups/NIPS/NIPS2001/papers/psgz/AA32.ps.gz}
}

@INPROCEEDINGS{Chapelle:cluster02,
  author = {Olivier Chapelle and Jason Weston and Bernhard Sch\"olkopf},
  title = {Cluster kernels for semi-supervised learning},
  pages = {601--608},
  crossref = {Becker:nips02}
}

@INCOLLECTION{Cheeseman:autoclass96,
  author = {Peter Cheeseman and John Stutz},
  title = {{B}ayesian Classification ({AutoClass}): Theory and Results},
  pages = {153--180},
  crossref = {Fayyad:kddm96}
}

@INPROCEEDINGS{Chickering:efficient96,
  author = {D. M. Chickering and David Heckerman},
  title = {Efficient Approximations for the Marginal Likelihood of {B}ayesian
	Networks with Hidden Variables},
  pages = {158--168},
  crossref = {Horvitz:uai96}
}

@INPROCEEDINGS{Chudova:clustering03,
  author = {Darya Chudova and Christopher Hart and Eric Mjolsness and Padhraic
	Smyth},
  title = {Gene Expression Clustering with Functional Mixture Models},
  pages = {683--690},
  abstract = {We propose a functional mixture model for simultaneous clustering
	and alignment of sets of curves measured on a discrete time grid.
	The model is specifically tailored to gene expression time course
	data. Each functional cluster center is a nonlinear combination of
	solutions of a simple linear differential equation that describes
	the change of individual mRNA levels when the synthesis and decay
	rates are constant. The mixture of continuous time parametric functional
	forms allows one to (a) account for the heterogeneity in the observed
	profiles, (b) align the profiles in time by estimating real-valued
	time shifts, (c) capture the synthesis and decay of mRNA in the course
	of an experiment, and (d) regularize noisy profiles by enforcing
	smoothness in the mean curves. We derive an EM algorithm for estimating
	the parameters of the model, and apply the proposed approach to the
	set of cycling genes in yeast. The experiments show consistent improvement
	in predictive power and within cluster variance compared to regular
	Gaussian mixtures.},
  crossref = {Thrun:nips03},
  file = {NIPS2003_AP15.pdf:http\://books.nips.cc/papers/files/nips16/NIPS2003_AP15.pdf:PDF},
  group = {clustering, gene expression}
}

@Article{Halevy:unreasonable09,
  author = 	 {Alon Y. Halevy and Peter Norvig and Fernando Pereira},
  title = 	 {The Unreasonable Effectiveness of Data},
  journal = 	 {IEEE Intelligent Systems},
  year = 	 {2009},
  OPTkey = 	 {},
  volume =	 {24},
  number =	 {2},
  pages =	 {8--12},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1109/MIS.2009.36},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Wigner:unreasonable60,
  author = 	 {Eugene P. Wigner},
  title = 	 {The Unreasonable Effectiveness of Mathematics in the Natural Sciences},
  journal = 	 {Communications on Pure and Applied Mathematics},
  year = 	 {1960},
  OPTkey = 	 {},
  volume =	 {13},
  number =	 {1},
  pages =	 {1--14},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1002/cpa.3160130102},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INCOLLECTION{Cowell:inference98,
  author = {Robert Cowell},
  title = {Introduction to Inference for {B}ayesian Networks},
  year = {1998},
  pages = {9--26},
  crossref = {Jordan:learning98}
}

@INPROCEEDINGS{Cristianini:spectral01,
  author = {Nello Cristianini and John Shawe-Taylor and Jaz S. Kandola},
  title = {Spectral Kernel Methods for Clustering},
  crossref = {Dietterich:nips01},
  linkps = {http://www.support-vector.net/papers/nips01_spectral.ps}
}

@INPROCEEDINGS{Csato:sparse00,
  author = {Lehel Csat\'o and Manfred Opper},
  title = {Sparse Representation for {G}aussian Process Models},
  pages = {444--450},
  abstract = {We develop an approach for a sparse representation for Gaussian Process
	(GP) models in order to overcome the limitations of GPs caused by
	large data sets. The method is based on a combination of a Bayesian
	online algorithm together with a sequential construction of a relevant
	subsample of the data which fully specifies the prediction of the
	model. Experimental results on toy examples and large real-world
	datasets indicate the efficiency of the approach.},
  crossref = {Leen:nips00},
  group = {spgp},
  linkpsgz = {http://www.nips.cc/NIPS2000/00papers-pub-on-web/CsatoOpper.ps.gz}
}

@INPROCEEDINGS{DeCoste:collab06,
  author = {Dennis DeCoste},
  title = {Collaborative Prediction Using Ensembles of Maximum Margin Matrix
	Factorization},
  pages = {249--256},
  crossref = {Cohen:icml06}
}

@INPROCEEDINGS{Engel:octopus05,
  author = {Yaakov Engel and Peter Szabo and Dmitry Volkinshtein},
  title = {Learning to Control an {O}ctopus Arm with {G}aussian Process Temporal
	Difference Methods},
  abstract = {The Octopus arm is a highly versatile and complex limb. How the Octopus
	controls such a hyper-redundant arm (not to mention eight of them!)
	is as yet unknown. Robotic arms based on the same mechanical principles
	may render present day robotic arms obsolete. In this paper, we tackle
	this control problem using an online reinforcement learning algorithm,
	based on a Bayesian approach to policy evaluation known as Gaussian
	process temporal difference (GPTD) learning. Our substitute for the
	real arm is a computer simulation of a 2-dimensional model of an
	Octopus arm. Even with the simplifications inherent to this model,
	the state space we face is a high-dimensional one. We apply a GPTD-based
	algorithm to this domain, and demonstrate its operation on several
	learning tasks of varying degrees of difficulty.},
  crossref = {Weiss:nips05},
  file = {gprl_icml05_camera.pdf:http\://www.cs.ualberta.ca/~yaki/papers/gprl_icml05_camera.pdf:PDF},
  group = {gp},
  linkps = {http://www.cs.ualberta.ca/~yaki/papers/gprl_icml05_camera.ps}
}

@INPROCEEDINGS{Fahlman:quickprop88,
  author = {S. E. Fahlman},
  title = {Faster-learning Variations on Back-propagation: An Empirical Study},
  pages = {38--51},
  crossref = {Touretzky:connectionist88}
}

@INPROCEEDINGS{Fahlman:cascade90,
  author = {S. E. Fahlman and C. Lebiere},
  title = {The cascade-correlation learning architecture},
  pages = {524--532},
  crossref = {Touretzky:nips89}
}

@INPROCEEDINGS{Freund:unsupervised91,
  author = {Yoav Freund and David Haussler},
  title = {Unsupervised Learning of Distributions on Binary Vectors Using Two
	Layer Networks},
  pages = {912--919},
  crossref = {Moody:nips91}
}

@INPROCEEDINGS{Frey:density96,
  author = {Brendan J. Frey and Geoffrey E. Hinton and Peter Dayan},
  title = {Does the Wake-Sleep Algorithm Learn Good Density Estimators?},
  pages = {661--670},
  crossref = {Touretzky:nips95}
}

@INPROCEEDINGS{Friess:kaa98,
  author = {Thilo-Thomas Frie\ss and Nello Cristianini and Colin Campbell},
  title = {The Kernel-Adatron Algorithm: A Fast and Simple Learning Procedure
	for Support Vector Machines},
  crossref = {Shavlik:icml98}
}

@INPROCEEDINGS{Friedman:belief97,
  author = {Nir Friedman},
  title = {Learning belief networks in the presence of missing values and hidden
	variables},
  crossref = {Fisher:icml97}
}

@INPROCEEDINGS{Friedman:structuralem98,
  author = {Nir Friedman},
  title = {The Bayesian Structural EM Algorithm},
  year = {1998},
  abstract = {In recent years there has been a flurry of works on learning Bayesian
	networks from data. One of the hard problems in this area is how
	to effectively learn the structure of a belief network from incomplete
	data---that is, in the presence of missing values or hidden variables.
	In a recent paper, I introduced an algorithm called Structural EM
	that combines the standard Expectation Maximization (EM) algorithm,
	which optimizes parameters, with structure search for model selection.
	That algorithm learns networks based on penalized likelihood scores,
	which include the BIC/MDL score and various approximations to the
	Bayesian score. In this paper, I extend Structural EM to deal directly
	with Bayesian model selection. I prove the convergence of the resulting
	algorithm and show how to apply it for learning a large class of
	probabilistic models, including Bayesian networks and some variants
	thereof.},
  crossref = {Cooper:uai98},
  linkpdf = {http://www.cs.huji.ac.il/~nir/Papers/Fr2.pdf}
}

@INPROCEEDINGS{Garfinkel:reductionism91,
  author = {Alan Garfinkel},
  title = {Reductionism},
  pages = {443--459},
  chapter = {24},
  crossref = {Boyd:philosophy91}
}

@INPROCEEDINGS{Ghahramani:factorial94,
  author = {Zoubin Ghahramani},
  title = {Factorial Learning and the {EM} Algorithm},
  pages = {617--624},
  crossref = {Tesauro:nips94},
  linkdjvu = {http://nips.djvuzone.org/djvu/nips07/0617.djvu},
  linkpsgz = {http://www.gatsby.ucl.ac.uk/~zoubin/papers/fact.ps.gz}
}

@INPROCEEDINGS{Ghahramani:bfa00,
  author = {Zoubin Ghahramani and Matthew J. Beal},
  title = {Variational Inference for {B}ayesian Mixtures of Factor Analysers},
  pages = {831--864},
  abstract = {We present an algorithm that infers the model structure of a mixture
	of factor analysers using an efficient and deterministic variational
	approximation to full Bayesian integration over model parameters.
	This procedure can automatically determine the optimal number of
	components and the local dimensionality of each component (i.e. the
	number of factors in each factor analyser). Alternatively it can
	be used to infer posterior distributions over number of components
	and dimensionalities. Since all parameters are integrated out the
	method is not prone to overfitting. Using a stochastic procedure
	for adding components it is possible to perform the variational optimisation
	incrementally and to avoid local maxima. Results show that the method
	works very well in practice and connectly infers the number and dimensionality
	of nontrivial synthetic examples. By importance sampling from the
	variational approximation we show how to obtain unbiased estimates
	of the true evidence, the exact predictive density, and the KL divergence
	between the variational posterior and the true posterior, not only
	in this model but for variational approximations in general.},
  crossref = {Solla:nips99},
  file = {06-2000.pdf:http\://www.gatsby.ucl.ac.uk/publications/papers/06-2000.pdf:PDF},
  group = {mixtures, dimensional reduction},
  linkps = {http://www.gatsby.ucl.ac.uk/publications/papers/06-1999.ps}
}

@INCOLLECTION{Ghahramani:graphical00,
  author = {Zoubin Ghahramani and Matthew J. Beal},
  title = {Graphical Models and Variational Methods},
  crossref = {Opper:advanced01},
  linkpsgz = {http://www.gatsby.ucl.ac.uk/~zoubin/papers/advmf.ps.gz}
}

@INPROCEEDINGS{Ghahramani:propagation01,
  author = {Zoubin Ghahramani and Matthew J. Beal},
  title = {Propagation Algorithms for Variational {B}ayesian Learning},
  crossref = {Leen:nips00},
  linkpsgz = {http://www.gatsby.ucl.ac.uk/~zoubin/papers/nips00beal.ps.gz}
}

@INPROCEEDINGS{Ghahramani:incompl94,
  author = {Zoubin Ghahramani and Michael I. Jordan},
  title = {Supervised learning from incomplete data via an {EM} appproach},
  year = {1994},
  pages = {120--127},
  crossref = {Cowan:nips93},
  linkpsz = {http://www.cs.berkeley.edu/~jordan/papers/nips93.ps.Z}
}

@INPROCEEDINGS{Girard:uncertain01,
  author = {Agathe Girard and Carl Edward Rasmussen and Joaquin {Qui\~nonero
	Candela} and Roderick Murray-Smith},
  title = {Gaussian Process Priors with Uncertain Inputs---Application to Multiple-Step
	Ahead Time Series Forecasting},
  pages = {529--536},
  crossref = {Becker:nips02}
}

@INPROCEEDINGS{Bishop:gps_nips97,
  author = {Paul W. Goldberg and Christopher K. I. Williams and Christopher M.
	Bishop},
  title = {Regression with Input-Dependent Noise: A {G}aussian Process Treatment},
  pages = {493--499},
  crossref = {Jordan:nips97}
}

@INPROCEEDINGS{Bishop:gpsnips97,
  author = {Paul W. Goldberg and Christopher K. I. Williams and Christopher M.
	Bishop},
  title = {Regression with Input-Dependent Noise: A {G}aussian Process Treatment},
  pages = {493--499},
  crossref = {Jordan:nips97}
}

@article{Gonen:multiple,
  author = {G\"{o}nen, Mehmet and Alpaydin, Ethem},
  title = {Multiple Kernel Learning Algorithms},
  journal = JMLR,
  volume = {12},
  month = {Jul},
  year = {2011},
  pages = {2211--2268},
  numpages = {58},
  acmid = {2021071},
  publisher = {JMLR.org}
} 

@techreport{Seeger:multiple04,
  author=   {Matthias Seeger and Michael I. Jordan},
  title=  {Sparse {G}aussian {P}rocess Classification with Multiple Classes},
  institution= {Department of Statistics, University of California at Berkeley},
  number = {661},
  year =  {2004},
}

@INPROCEEDINGS{Scholkopf:generalized01,
    author = {Bernhard Sch\"olkopf and Ralf Herbrich and Alex J. Smola},
    title = {A Generalized Representer Theorem},
    booktitle = {In Proceedings of the Annual Conference on Computational Learning Theory},
    year = {2001},
    pages = {416--426}
}



@Incollection{Shi:learning05,
  author = {Jian Qing Shi and Roderick Murray-Smith and D. Michael Titterington and Barak Pearlmutter},
  title = {Learning with large data sets using filtered {G}aussian Process priors},
  booktitle = {Proceedings of the Hamilton Summer School on Switching and Learning in Feedback systems},
  editor = {Roderick Murray-Smith and R. Shorten},
  publisher = {LNCS 3355, Springer-Verlag},
  year = {2005},
  pages = {128--139}
}

@Article{Skolidis:multiclass11,
  author =   {Grigorios Skolidis and Guido Sanguinetti},
  title =    {Bayesian Multitask Classification With {G}aussian Process Priors},
  journal =   {IEEE Transactions on Neural Networks},
  year =     {2011},
  volume =    {22},
  number =    {12},
  pages =    {2011--2021},
}

@INPROCEEDINGS{Graepel:gpdiff03,
  author = {Thore Graepel},
  title = {Solving Noisy Linear Operator Equations by {G}aussian Processes:
	Application to Ordinary and Partial Differential Equations},
  pages = {234--241},
  abstract = {We formulate the problem of solving stochastic linear operator equations
	in a Bayesian Gaussian process (GP) framework. The solution is obtained
	in the spirit of a collocation method based on noisy evaluations
	of the target function at randomly drawn or deliberately chosen points.
	Prior knowledge about the solution is encoded in terms of the covariance
	kernel of the GP. As in GP regression, analytical expressions for
	the mean and variance of the estimated target function are obtained
	from which the solution to the operator equation follows by a manipulation
	of the kernel. Linear initial and boundary value constraints can
	be enforced by embedding the non-parametric model in a form that
	automatically satisfies the boundary conditions. The method is illustrated
	on a noisy linear first-order ordinary differential equation with
	initial condition and on a noisy second-order partial differential
	equation with Dirichlet boundary conditions.},
  crossref = {Fawcett:icml03},
  file = {graepel03.pdf:http\://www.research.microsoft.com/~thoreg/papers/graepel03.pdf:PDF},
  group = {gp, ode}
}

@INPROCEEDINGS{Graepel:kernel01,
  author = {Thore Graepel and Ralf Herbrich},
  title = {The Kernel {G}ibbs Sampler},
  crossref = {Leen:nips00}
}

@INCOLLECTION{Gull:develop88,
  author = {Steven F. Gull},
  title = {Developments in maximum entropy data analysis},
  booktitle = {Developments in maximum entropy data analysis},
  pages = {53--71},
  crossref = {Skilling:entropy88}
}

@INCOLLECTION{Gull:induct88,
  author = {Steven F. Gull},
  title = {{B}ayesian inductive inference and maximum entropy},
  pages = {53--74},
  crossref = {Erickson:max-ent88}
}

@INCOLLECTION{Gull:line88,
  author = {Steven F. Gull},
  title = {{B}ayesian data analysis --- straight-line fitting},
  pages = {511--518},
  crossref = {Skilling:entropy88}
}

@INCOLLECTION{Guyon:informative96,
  author = {Isabelle Guyon and Nada Matic and Vladimir Vapnik},
  title = {Discovering Informative Patterns and Data Cleaning},
  pages = {181--203},
  crossref = {Fayyad:kddm96}
}

@INPROCEEDINGS{Ham:kernelDimred04,
  author = {Jihun Ham and Daniel D. Lee and Sebastian Mika and Bernhard Sch\"olkopf},
  title = {A Kernel View of Dimensionality Reduction of Manifolds},
  abstract = {We interpret several well-known algorithms for dimensionality reduction
	of manifolds as kernel methods. Isomap, graph Laplacian eigenmap,
	and locally linear embedding (LLE) all utilize local neighborhood
	information to construct a global embedding of the manifold. We show
	how all three algorithms can be described as kernel PCA on specially
	constructed Gram matrices, and illustrate the similarities and differences
	between the algorithms with representative examples.},
  crossref = {Greiner:icml04},
  linkpdf = {http://kingman.cs.ualberta.ca/_banff04/icml/pages/papers/296.pdf}
}

@INPROCEEDINGS{Hampshire:bayes90,
  author = {J. B. Hampshire and Barak Pearlmutter},
  title = {Equivalence proofs for multi-layer perceptron classifiers and the
	{B}ayesian discriminant function},
  pages = {159--172},
  crossref = {Touretzky:connectionist90}
}

@INPROCEEDINGS{Hanson:bias89,
  author = {S. J. Hanson and L. Y. Pratt},
  title = {Comparing biases for minimal network construction with back-propagation},
  year = {1989},
  pages = {177--185},
  crossref = {Touretzky:nips88}
}

@INPROCEEDINGS{Heckerman:probibilistic86,
  author = {David Heckerman},
  title = {Probabilistic Interpretation for {MYCIN}'s Certainty Factors},
  pages = {167--196},
  crossref = {Kanal:uncertainty86}
}

@INCOLLECTION{Heckerman:tutorial98,
  author = {David Heckerman},
  title = {A Tutorial on Learning With {B}ayesian Networks},
  pages = {301--354},
  crossref = {Jordan:learning98},
  trnumber = {MSR-TR-95-06}
}

@INPROCEEDINGS{Heckerman:inferring98,
  author = {David Heckerman and Eric Horvitz},
  title = {Inferring Informational Goals from Free-Text Queries},
  year = {1998},
  crossref = {Cooper:uai98}
}

@INPROCEEDINGS{Higdon:nonstationary98,
  author = {David M. Higdon and Jenise Swall and John Kern},
  title = {Non-stationary spatial modeling},
  pages = {761--768},
  crossref = {Bernardo:bayesian98}
}

@INPROCEEDINGS{Hinton:digit_mix95,
  author = {Geoffrey E. Hinton and M. D. Revow and Peter Dayan},
  title = {Recognizing handwritten digits using mixtures of linear models},
  year = {1995},
  crossref = {Tesauro:nips94},
  linkpsgz = {http://www.cs.toronto.edu/~hinton/absps/pancake.ps.gz}
}

@INPROCEEDINGS{Hinton:sne02,
  author = {Geoffrey E. Hinton and Sam T. Roweis},
  title = {Stochastic Neighbor Embedding},
  pages = {857--864},
  crossref = {Becker:nips02},
  linkpsgz = {http://www.cs.toronto.edu/~roweis/papers/sne_final.ps.gz}
}

@INCOLLECTION{Hinton:HCE98,
  author = {Geoffrey E. Hinton and Brian Sallans and Zoubin Ghahramani},
  title = {A Hierarchical Community of Experts},
  pages = {479--494},
  crossref = {Jordan:learning98},
  linkpsgz = {http://www.gatsby.ucl.ac.uk/~zoubin/papers/erice.ps.gz}
}

@INCOLLECTION{Hinton:elastic92,
  author = {Geoffrey E. Hinton and Christopher K. I. Williams and M. D. Revow},
  title = {Adaptive elastic models for hand-printed character recognition},
  pages = {512--519},
  crossref = {Moody:nips91}
}
@techreport{Hinton:practical10,
    author = {Geoffrey E. Hinton},
    journal = {UTML TR 2010-003},
    keywords = {rbm},
    title = {A Practical Guide to Training Restricted {B}oltzmann Machines},
    year = {2010}
}



@INPROCEEDINGS{Honkela:unsupervised04,
  author = {Antti Honkela and Harri Valpola},
  title = {Unsupervised variational {B}ayesian learning of nonlinear models},
  pages = {593--600},
  abstract = {In this paper we present a framework for using multi-layer perceptron
	(MLP) networks in nonlinear generative models trained by variational
	Bayesian learning. The nonlinearity is handled by linearizing it
	using a Gauss-Hermite quadrature at the hidden neurons. This yields
	an accurate approximation for cases of large posterior variance.
	The method can be used to derive nonlinear counterparts for linear
	algorithms such as factor analysis, independent component/factor
	analysis and state-space models. This is demonstrated with a nonlinear
	factor analysis experiment in which even 20 sources can be estimated
	from a real world speech data set.},
  crossref = {Saul:nips04},
  file = {NIPS2004_0322.pdf:http\://books.nips.cc/papers/files/nips17/NIPS2004_0322.pdf:PDF},
  linksoftware = {http://www.cis.hut.fi/projects/bayes/software/}
}

@INPROCEEDINGS{Horvitz:lumiere98,
  author = {Eric Horvitz and Jack Breese and David Heckerman and D. Hovel and
	K. Rommelse},
  title = {The Lumiere Project: {B}ayesian User Modeling for Inferring the Goals
	and Needs of Software Users},
  year = {1998},
  crossref = {Cooper:uai98}
}

@INPROCEEDINGS{Jaakkola:genmodels98,
  author = {Tommi S. Jaakkola and David Haussler},
  title = {Exploiting Generative Models in Discriminative Classifiers},
  crossref = {Kearns:nips98},
  institution = {Department of Computer Science, University of California, Santa Cruz and Isaac Newton Institute for Mathematical Sciences, University of Cambridge, Cambridge}
}

@INPROCEEDINGS{Jaakkola:intractable96,
  author = {Tommi S. Jaakkola and Michael I. Jordan},
  title = {Computing Upper and Lower Bounds on Likelihoods in Intractable Networks},
  crossref = {Horvitz:uai96},
  linkpsz = {http://www.cs.berkeley.edu/~jordan/papers/jaak-ul-bounds.ps.Z}
}

@INCOLLECTION{Jaakkola:mixtures97,
  author = {Tommi S. Jaakkola and Michael I. Jordan},
  title = {Improving the Mean Field Approximation via the use of Mixture Distributions.},
  booktitle = {Learning in Graphical Models},
  pages = {163--174},
  crossref = {Jordan:learning98},
  linkpsz = {http://www.cs.berkeley.edu/~jordan/papers/mixture-mean-field.ps.Z}
}

@INPROCEEDINGS{Jaakkola:recursive97,
  author = {Tommi S. Jaakkola and Michael I. Jordan},
  title = {Recursive Algorithms for Approximating Probabilities in Graphical Models},
  crossref = {Mozer:nips96},
  linkpsz = {http://www.cs.berkeley.edu/~jordan/papers/recur.ps.Z}
}

@INPROCEEDINGS{Jaakkola:fast96,
  author = {Tommi S. Jaakkola and Lawrence K. Saul and Michael I. Jordan},
  title = {Fast Learning by Bounding Likelihoods in Sigmoid Type Belief Networks},
  pages = {528--534},
  crossref = {Touretzky:nips95},
  linkpsgz = {http://www.cs.berkeley.edu/~jordan/papers/fastlearn.ps.gz}
}

@Article{Presser:caredata15,
  author = 	 {Lizzie Presser and Maia Hruskova and Helen Rowbottom and Jesse Kancir},
  title = 	 {Care.data and access to UK health records: patient privacy and public trust},
  journal = 	 {Technology Science},
  year = 	 {2015},
  OPTkey = 	 {},
  volume =	 {2015081103},
  OPTnumber = 	 {},
  OPTpages = 	 {},
  OPTmonth = 	 {August},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  link = {http://techscience.org/a/2015081103},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Jacob:clustered08,
  author = {Laurent Jacob and Francis Bach and Jean-Philippe Vert},
  title = {Clustered Multi-Task Learning: A Convex Formulation},
  pages = {745--752},
  crossref = {Koller:nips08}
}

@INPROCEEDINGS{Joachims:making98,
  author = {Thorsten Joachims},
  title = {Making large-Scale {SVM} Learning Practical},
  pages = {169--184},
  crossref = {Scholkopf:advances98},
  linkpsgz = {http://www.joachims.org/publications/joachims_99a.ps.gz}
}

@INPROCEEDINGS{Joachims:transductive99,
  author = {Thorsten Joachims},
  title = {Transductive Inference for Text Classification using Support Vector
	Machines},
  year = {1999},
  crossref = {Bratko:icml99},
  linkpsgz = {http://www.joachims.org/publications/joachims_99c.ps.gz}
}

@INCOLLECTION{Jordan:variational98,
  author = {Michael I. Jordan and Zoubin Ghahramani and Tommi S. Jaakkola and
	Lawrence K. Saul},
  title = {An Introduction to Variational Methods for Graphical Models},
  year = {1998},
  pages = {105--162},
  crossref = {Jordan:learning98},
  linkpsgz = {http://www.cs.berkeley.edu/~jordan/papers/variational-intro.ps.gz}
}

@INPROCEEDINGS{Kazawa:multitopic05,
  author = {Hideto Kazawa and Tomonori Izumitani and Hirotoshi Taira and
	Eisaku Maeda},
  title = {Maximal Margin Labeling for Multi-Topic Text Categorization},
  pages = {649-656},
  crossref = {Saul:nips04}
}

@INPROCEEDINGS{Keeler:numerals91,
  author = {J. D. Keeler and D. E. Rumelhart and W-K Leow},
  title = {Integrated Segmentation and Recognition of Hand-Printed Numerals},
  pages = {557--563},
  crossref = {Lippmann:nips90}
}

@INPROCEEDINGS{Kolen:fractal91,
  author = {J. F. Kolen and J. B. Pollack},
  title = {Back Propagation is Sensitive to Initial Conditions},
  year = {1991},
  pages = {860--867},
  crossref = {Lippmann:nips90}
}

@INPROCEEDINGS{Kramer:eff89,
  author = {A. H. Kramer and A. Sangiovanni-Vincentelli},
  title = {Efficient Parallel Learning Algorithms for Neural Networks},
  year = {1989},
  pages = {40--48},
  crossref = {Touretzky:nips88}
}

@INPROCEEDINGS{Lang:dim90,
  author = {K. J. Lang and G. E. Hinton},
  title = {Dimensionality reduction and prior knowledge in {E}-set recognition},
  year = {1990},
  pages = {178--185},
  crossref = {Touretzky:nips89}
}

@INPROCEEDINGS{LeCun:obd90,
  author = {Yann {Le~Cun} and J. S. Denker and Sara. A. Solla},
  title = {Optimal Brain Damage},
  year = {1990},
  crossref = {Touretzky:nips89}
}

@INPROCEEDINGS{LeCun:learn93,
  author = {Yann {Le~Cun} and Patrice Y. Simard and Barak Pearlmutter},
  title = {Automatic learning rate maximization by on-line estimation of the
	{H}essian's eigenvectors},
  year = {1993},
  pages = {156--163},
  crossref = {Hanson:nips92}
}

@INCOLLECTION{Lindley:approximate80,
  author = {Dennis V. Lindley},
  title = {Approximate {B}ayesian Methods},
  pages = {223--237},
  crossref = {Bernardo:bayesian80}
}

@article{Srivastava:dropout14,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@INPROCEEDINGS{Denil:predicting13, 
    author = {Misha Denil and Babak Shakibi and Laurent Dinh and Marc'aurelio Ranzato and Nando D. Freitas}, 
    linkpdf = {http://media.nips.cc/nipsbooks/nipspapers/paper_files/nips26/1053.pdf},
    crossref = {Burges:nips13},
    Pages = {2148--2156} 
   }
@INPROCEEDINGS{Liu:robust94,
  author = {Y. Liu},
  title = {Robust parameter estimation and model selection for neural network
	regression},
  year = {1994},
  pages = {192--199},
  crossref = {Cowan:nips93}
}

@INPROCEEDINGS{Lodhi:text01,
  author = {Huma Lodhi and John Shawe-Taylor and Nello Cristianini and Chris Watkins},
  title = {Text Classification using Kernels},
  pages = {563--569},
  crossref = {Leen:nips00}
}

@INPROCEEDINGS{Lowe:neuroscale96,
  author = {David Lowe and Michael E. Tipping},
  title = {Neuroscale: Novel topographic feature extraction with radial basis function networks},
  pages = {543--549},
  crossref = {Mozer:nips96},
  linkpsgz = {ftp://ftp.research.microsoft.com/users/mtipping/nips96.ps.gz}
}

@INCOLLECTION{MacKay:gpintroduction98,
  author = {David J. C. {MacKay}},
  title = {Introduction to {G}aussian Processes},
  pages = {133--166},
  abstract = {Feedforward neural networks such as multilayer perceptrons are popular
	tools for nonlinear regression and classification problems. From
	a Bayesian perspective, a choice of a neural network model can be
	viewed as defining a prior probability distribution over non-linear
	functions, and the neural network's learning process can be interpreted
	in terms of the posterior probability distribution over the unknown
	function. (Some learning algorithms search for the function with
	maximum posterior probability and other Monte Carlo methods draw
	samples from this posterior probability). In the limit of large but
	otherwise standard networks, \cite{Neal:book96} has shown that the
	prior distribution over non-linear functions implied by the Bayesian
	neural network falls in a class of probability distributions known
	as Gaussian processes. The hyperparameters of the neural network
	model determine the characteristic lengthscales of the Gaussian process.
	Neal's observation motivates the idea of discarding parameterized
	networks and working directly with Gaussian processes. Computations
	in which the parameters of the network are optimized are then replaced
	by simple matrix operations using the covariance matrix of the Gaussian
	process. In this chapter I will review work on this idea by \cite{Williams:Gaussian96},
	\cite{Neal:montecarlogp97}, \cite{Barber:Gaussian97} and \cite{Gibbs:variational00},
	and will assess whether, for supervised regression and classification
	tasks, the feedforward network has been superceded.},
  crossref = {Bishop:neural98},
  group = {gp},
  linkpsgz = {http://www.cs.toronto.edu/~mackay/gpB.ps.gz}
}

@INCOLLECTION{MacKay:intro98,
  author = {David J. C. {MacKay}},
  title = {Introduction to {M}onte {C}arlo Methods},
  pages = {175--204},
  crossref = {Jordan:learning98}
}

@INPROCEEDINGS{Maron:framework98,
  author = {Oded Maron and M. Lozano-Prez},
  title = {A Framework for Multiple-Instance Learning},
  pages = {570--576},
  crossref = {Jordan:nips97}
}

@INPROCEEDINGS{Meeds:alternative05,
  author = {Edward Meeds and Simon Osindero},
  title = {An Alternative Infinite Mixture of Gaussian Process Experts},
  abstract = {We present an infinite mixture model in which each component comprises
	a multivariate Gaussian distribution over an input space, and a Gaussian
	Process model over an output space. Our model is neatly able to deal
	with non-stationary covariance functions, discontinuities, multimodality
	and overlapping output signals. The work is similar to that by Rasmussen
	and Ghahramani \cite{Rasmussen:infinite01}; however, we use a full
	generative model over input and output space rather than just a conditional
	model. This allows us to deal with incomplete data, to perform inference
	over inverse functional mappings as well as for regression, and also
	leads to a more powerful and consistent Bayesian specification of
	the effective `gating network' for the different experts},
  crossref = {Weiss:nips05},
  file = {NIPS2005_0798.pdf:http\://books.nips.cc/papers/files/nips18/NIPS2005_0798.pdf:PDF},
  group = {gp,mixtures}
}

@INPROCEEDINGS{Mika:fisher99,
  author = {Sebastian Mika and Gunnar R\"atsch and Jason Weston and Bernhard
	Sch\"olkopf and Klaus-Robert M\"uller},
  title = {Fisher Discriminant Analysis with Kernels},
  pages = {41--48},
  crossref = {Hu:nnsp99},
  linkps = {http://ida.first.fhg.de/publications/MikRaeWesSchMue99.ps}
}

@INPROCEEDINGS{Minka:automatic01,
  author = {Thomas P. Minka},
  title = {Automatic Choice of Dimensionality for {PCA}},
  pages = {598--604},
  crossref = {Leen:nips00},
  linkpsgz = {http://www.cs.cmu.edu/Web/Groups/NIPS/00papers-pub-on-web/Minka.ps.gz}
}

@INPROCEEDINGS{Minka:ep01,
  author = {Thomas P. Minka},
  title = {Expectation Propagation for approximate {B}ayesian inference},
  crossref = {Breese:uai01},
  file = {minka-ep-uai.pdf:http\://www.research.microsoft.com/~minka/papers/ep/minka-ep-uai.pdf:PDF}
}

@INPROCEEDINGS{Moody:gpe92,
  author = {J. E. Moody},
  title = {The effective number of parameters: an analysis of generalization
	and regularization in nonlinear learning systems},
  year = {1992},
  pages = {847--854},
  crossref = {Moody:nips91}
}

@INPROCEEDINGS{Movellan:contrastive90,
  author = {J R Movellan},
  title = {Contrastive {H}ebbian Learning in the Continuous {H}opfield Model},
  crossref = {Touretzky:connectionist90}
}

@INPROCEEDINGS{Mozer:skeleton89,
  author = {Michael C. Mozer and P. Smolensky},
  title = {Skeletonization: a technique for trimming the fat from a network
	via relevance assessment},
  year = {1989},
  pages = {107--115},
  crossref = {Touretzky:nips88}
}

@INCOLLECTION{Neal:em93,
  author = {Radford M. Neal and Geoffrey E. Hinton},
  title = {A View of the {EM} Algorithm that Justifies Incremental, Sparse,
	and Other Variants},
  pages = {355--368},
  crossref = {Jordan:learning98},
  linkps = {http://www.cs.toronto.edu/~hinton/absps/emk.ps}
}

@INPROCEEDINGS{Ng:spectral02,
  author = {Andrew Y. Ng and Michael I. Jordan and Yair Weiss},
  title = {On Spectral Clustering: Analysis and an algorithm},
  crossref = {Dietterich:nips01},
  file = {nips01-spectral.pdf:http\://www.robotics.stanford.edu/~ang/papers/nips01-spectral.pdf:PDF},
  linkps = {http://www.robotics.stanford.edu/~ang/papers/nips01-spectral.ps}
}

@INPROCEEDINGS{Nix:error95,
  author = {A. D. Nix and A. S. Weigend},
  title = {Learning local error bars for nonlinear regression},
  year = {1995},
  pages = {489--496},
  crossref = {Tesauro:nips94}
}

@INPROCEEDINGS{Norton:learning93,
  author = {Steven W. Norton and Haym Hirsh},
  title = {Learning {DNF} Via Probabilistic Evidence Combination},
  pages = {220--227},
  crossref = {Utgoff:icml93}
}

@INPROCEEDINGS{Ohagan:numerical92,
  author = {Anthony O'Hagan},
  title = {Some {B}ayesian Numerical Analysis},
  pages = {345--363},
  crossref = {Bernardo:bayesian92}
}

@INCOLLECTION{Pacioreck:nonstationaryCov04,
  author = {Christopher J. Paciorek and Mark J. Schervish},
  title = {Nonstationary Covariance Functions for {G}aussian Process Regression},
  crossref = {Thrun:nips03}
}

@INPROCEEDINGS{Pelleg:xmeans00,
  author = {Dan Pelleg and Andrew Moore},
  title = {X-means: Extending K-means with Efficient Estimation of the Number of Clusters},
  crossref = {Langley:icml00},
  linkpsgz = {http://www.autonlab.org/papers/xmeans.ps.gz}
}

@INPROCEEDINGS{Pentland:photobook94,
  author = {Alex Pentland and Rosalind Picard and Stan Sclaroff},
  title = {Photobook: Tools for Content-Based Manipulation of Image Databases},
  pages = {34--47},
  crossref = {Niblack:storage94}
}

@INCOLLECTION{Platt:smo98,
  author = {John C. Platt},
  title = {Fast Training of Support Vector Machines Using Sequential Minimal Optimization},
  pages = {185--208},
  crossref = {Scholkopf:advances98},
  linkpsgz = {http://research.microsoft.com/users/jplatt/smo-book.ps.gz}
}

@INBOOK{Raftery:hypothesis96,
  chapter = {10},
  pages = {164--187},
  title = {Hypothesis Testing and Model Selection},
  author = {Adrian E. Raftery},
  crossref = {Gilks:book96}
}

@INPROCEEDINGS{Rasmussen:nips96,
  author = {Carl Edward Rasmussen},
  title = {A practical {M}onte {C}arlo implementation of {B}ayesian learning},
  year = {1996},
  pages = {598--604},
  crossref = {Touretzky:nips95}
}

@INPROCEEDINGS{Rasmussen:infinite01,
  author = {Carl Edward Rasmussen and Zoubin Ghahramani},
  title = {Infinite Mixtures of {G}aussian Process Experts},
  pages = {881--888},
  abstract = {We present an extension to the Mixture of Experts (ME) model, where
	the individual experts are Gaussian Process (GP) regression models.
	Using an input-dependent adaptation of the Dirichlet Process, we
	implement a gating network for an infinite number of Experts. Inference
	in this model may be done efficiently using a Markov Chain relying
	on Gibbs sampling. The model allows the effective covariance function
	to vary with the inputs, and may handle large datasets –-- thus potentially
	overcoming two of the biggest hurdles with GP models. Simulations
	show the viability of this approach.},
  crossref = {Dietterich:nips01},
  file = {AA06.pdf:http\://books.nips.cc/papers/files/nips14/AA06.pdf:PDF},
  group = {gp,mixtures}
}

@INPROCEEDINGS{Rennie:fast05,
  author = {Jason D. M. Rennie and Nathan Srebro},
  title = {Fast maximum margin factorization for collaborative prediction},
  pages = {713--719},
  crossref = {deRaedt:icml05},
  file = {RennieSrebroICML05.pdf:http\://www.cs.ucl.ac.uk/staff/Y.Ying/reading/RennieSrebroICML05.pdf:PDF}
}

@INCOLLECTION{Ripley:flexible94,
  author = {Brian D. Ripley},
  title = {Flexible Non-linear Approaches to Classification},
  pages = {105--126},
  crossref = {Cherkassky:statistics94}
}

@INPROCEEDINGS{Roth:nonlinear99,
  author = {Volker Roth and Volker Steinhage},
  title = {Nonlinear Discriminant Analysis Using Kernel Functions},
  pages = {568--574},
  crossref = {Solla:nips99}
}

@INPROCEEDINGS{Roweis:SPCA97,
  author = {Sam T. Roweis},
  title = {{EM} Algorithms for {PCA} and {SPCA}},
  pages = {626--632},
  crossref = {Jordan:nips97},
  file = {empca.pdf:http\://www.cs.toronto.edu/~roweis/papers/empca.pdf:PDF}
}

@INPROCEEDINGS{Roweis:global01,
  author = {Sam T. Roweis and Lawrence K. Saul and Geoffrey E. Hinton},
  title = {Global Coordination of Local Linear Models},
  pages = {889--896},
  abstract = {High dimensional data that lies on or near a low dimensional manifold
	can be described by a collection of local linear models. Such a description,
	however, does not provide a global parameterization of the manifold
	--- arguably an important goal of unsupervised learning. In this
	paper, we show how to learn a collection of local linear models that
	solves this more difficult problem. Our local linear models are represented
	by a mixture of factor analyzers, and the "global coordination" of
	these models is achieved by adding a regularizing term to the standard
	maximum likelihood objective function. The regularizer breaks a degeneracy
	in the mixture model's parameter space, favoring models whose internal
	coordinate systems are aligned in a consistent way. As a result,
	the internal coordinates change smoothly and continuously as one
	traverses a connected path on the manifold --- even when the path
	crosses the domains of many different local models. The regularizer
	takes the form of a Kullback-Leibler divergence and illustrates an
	unexpected application of variational methods: not to perform approximate
	inference in intractable probabilistic models, but to learn more
	useful internal representations in tractable ones.},
  crossref = {Dietterich:nips01},
  group = {dimensional reduction, mixtures},
  linkpsgz = {http://www.cs.toronto.edu/~roweis/papers/gc_final.ps.gz}
}

@INCOLLECTION{Rumelhart:pdp86,
  author = {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  title = {Learning internal representations by error propagation},
  pages = {318--362},
  note = {Reprinted in \cite{Anderson:collect88}},
  crossref = {Rumelhart:book86}
}

@INPROCEEDINGS{Salakhutdinov:bayespmf08,
  author = {Ruslan Salakhutdinov and Andriy Mnih},
  title = {Bayesian Probabilistic Matrix Factorization using {MCMC}},
  pages = {880--887},
  crossref = {Roweis:icml08},
  file = {bpmf.pdf:http\://www.cs.toronto.edu/~rsalakhu/papers/bpmf.pdf:PDF}
}
@INPROCEEDINGS{Salakhutdinov:quantitative08,
  author = {Ruslan Salakhutdinov and Iain Murray},
  title = {On the Quantitative Analysis of Deep Belief Networks},
  pages = {872--879},
  crossref = {Roweis:icml08}
}

@INPROCEEDINGS{Salakhutdinov:pmf08,
  author = {Ruslan Salakhutdinov and Andriy Mnih},
  title = {Probabilistic Matrix Factorization},
  pages = {1257--1264},
  abstract = {Many existing approaches to collaborative filtering can neither handle
	very large datasets nor easily deal with users who have very few
	ratings. In this paper we present the Probabilistic Matrix Factorization
	(PMF) model which scales linearly with the number of observations
	and, more importantly, performs well on the large, sparse, and very
	imbalanced Netflix dataset. We further extend the PMF model to include
	an adaptive prior on the model parameters and show how the model
	capacity can be controlled automatically. Finally, we introduce a
	constrained version of the PMF model that is based on the assumption
	that users who have rated similar sets of movies are likely to have
	similar preferences. The resulting model is able to generalize considerably
	better for users with very few ratings. When the predictions of multiple
	PMF models are linearly combined with the predictions of Restricted
	Boltzmann Machines models, we achieve an error rate of 0.8861, that
	is nearly 7\% better than the score of Netflixâs own system.},
  crossref = {Platt:nips07},
  optpdf = {http://books.nips.cc/papers/files/nips20/NIPS2007_1007.pdf}
}

@INPROCEEDINGS{Saul:substructure96,
  author = {Lawrence K. Saul and Michael I. Jordan},
  title = {Exploiting tractable substructures in intractable networks},
  year = {1996},
  pages = {486--492},
  crossref = {Touretzky:nips95},
  linkpsz = {http://www.cs.berkeley.edu/~jordan/papers/exploit.ps.Z}
}

@INPROCEEDINGS{Scholkopf:incorporating96,
  author = {Bernhard Sch\"olkopf and Christopher J. C. Burges and Vladimir N.
	Vapnik},
  title = {Incorporating invariances in support vector learning machines},
  pages = {47--52},
  crossref = {vonderMalsburg:icann96},
  linkpsgz = {http://citeseer.ist.psu.edu/rd/26763024%2C61849%2C1%2C0.25%2CDownload/http://citeseer.ist.psu.edu/cache/papers/cs/236/http:zSzzSzsvm.first.gmd.dezSzpaperszSzvirtual.ps.gz/sch96incorporating.ps.gz}
}

@INPROCEEDINGS{Schwaighofer:transductive02,
  author = {Anton Schwaighofer and Volker Tresp},
  title = {Transductive and Inductive Methods for Approximate {G}aussian Process
	Regression},
  pages = {953--960},
  abstract = {Gaussian process regression allows a simple analytical treatment of
	exact Bayesian inference and has been found to provide good performance,
	yet scales badly with the number of training data. In this paper
	we compare several approaches towards scaling Gaussian process regression
	to large data sets: the subset of representers method, the reduced
	rank approximation, online Gaussian processes and the Bayesian committee
	machine. Furthermore we provide theoretical insight into some of
	our experimental results. We found that the subset of representers
	methods can give good and particularly fast predictions for data
	sets with high and medium noise levels. On complex low noise data
	sets the Bayesian committee machine achieves significantly better
	accuracy, yet at a higher computational cost.},
  crossref = {Becker:nips02},
  file = {nips02_approxgp.pdf:http\://www.tresp.org/papers/nips02_approxgp.pdf:PDF},
  group = {bcm,spgp}
}

@INPROCEEDINGS{Seeger:bayesian99,
  author = {Matthias Seeger},
  title = {Bayesian Model Selection for Support Vector Machines, {G}aussian
	Processes and Other Kernel Classifiers},
  pages = {603--609},
  crossref = {Solla:nips99},
  file = {nips-paper.pdf:http\://www.cs.berkeley.edu/~mseeger/papers/nips-paper.pdf:PDF},
  linkpsgz = {http://www.cs.berkeley.edu/~mseeger/papers/nips-paper.ps.gz}
}

@INPROCEEDINGS{Seeger:covariance02,
  author = {Matthias Seeger},
  title = {Covariance Kernels from {B}ayesian Generative Models},
  pages = {905-912},
  crossref = {Dietterich:nips01},
  linkpsgz = {http://www.cs.berkeley.edu/~mseeger/papers/nips2001.ps.gz}
}

@INPROCEEDINGS{Shawe-Taylor:eigenspectrum02,
  author = {John Shawe-Taylor and Chris Williams and Nello Cristianini and Jaz
	S. Kandola},
  title = {On the Eigenspectrum of the Gram Matrix and Its Relationship to the
	Operator Eigenspectrum},
  pages = {23--40},
  crossref = {Cesa-Bianchi:ALT02},
  file = {eigenspectrum.pdf:http\://www.support-vector.net/papers/eigenspectrum.pdf:PDF}
}

@INPROCEEDINGS{Shon:learning05,
  author = {Aaron P. Shon and Keith Grochow and Aaron Hertzmann and Rajesh P.
	N. Rao},
  title = {Learning Shared Latent Structure for Image Synthesis and Robotic
	Imitation},
  abstract = {We propose an algorithm that uses Gaussian process regression to learn
	common hidden structure shared between corresponding sets of heterogenous
	observations. The observation spaces are linked via a single, reduced-dimensionality
	latent variable space. We present results from two datasets demonstrating
	the algorithms' ability to synthesize novel data from learned correspondences.
	We first show that the method can be used to learn the nonlinear
	mapping between corresponding views of objects, filling in missing
	data as needed to synthesize novel views. We then show that the method
	can be used to acquire a mapping between human degrees of freedom
	and robotic degrees of freedom for a humanoid robot, allowing robotic
	imitation of human poses from motion capture data.},
  crossref = {Weiss:nips05},
  file = {nips05.pdf:http\://www.cs.washington.edu/homes/aaron/pub/nips05.pdf:PDF},
  group = {gplvm}
}

@INCOLLECTION{Sibisi:maxent91,
  author = {S. Sibisi},
  title = {{B}ayesian interpolation},
  pages = {349--355},
  crossref = {Grandy:maxent91}
}

@INPROCEEDINGS{Simard:distance93,
  author = {P. Simard and Y. {Le~Cun} and J. Denker},
  title = {Efficient pattern recognition using a new transformation distance},
  booktitle = nips,
  year = {1993},
  pages = {50--58},
  crossref = {Hanson:nips92},
  linkdjvu = {http://nips.djvuzone.org/djvu/nips05/0050.djvu}
}

@INPROCEEDINGS{Simard:tangent92,
  author = {P. Simard and B. Victorri and Y. {Le~Cun} and J. Denker},
  title = {Tangent prop -- a formalism for specifying selected invariances in
	an adaptive network},
  year = {1992},
  pages = {895--903},
  crossref = {Moody:nips91}
}

@INPROCEEDINGS{Singer:hmm92,
  author = {E. Singer and R. P. Lippmann},
  title = {Improved hidden {M}arkov model speech recognition using radial basis
	function networks},
  year = {1992},
  pages = {159--166},
  crossref = {Moody:nips91}
}

@INCOLLECTION{Skilling:maxent91,
  author = {John Skilling},
  title = {On parameter estimation and quantified {MaxEnt}},
  pages = {267--273},
  crossref = {Grandy:maxent91}
}

@INPROCEEDINGS{Smola:sparsegp00,
  author = {Alexander J. Smola and Peter L. Bartlett},
  title = {Sparse greedy {G}aussian Process Regression},
  pages = {619--625},
  abstract = {We present a simple sparse greedy technique to approximate the maximum
	a posteriori estimate of Gaussian Processes with much improved scaling
	behaviour in the sample size $m$. In particular, computational requirements
	are $O(n^2m)$, storage is $O(nm)$, the cost for prediction is $O(n)$
	and the cost to compute confidence bounds is $O(nm)$, where $n<<m$.
	We show how to compute a stopping criterion, give bounds on the approximation
	error, and show applications to large scale problems.},
  crossref = {Leen:nips00},
  group = {spgp},
  linkpsgz = {http://www.nips.cc/Web/Groups/NIPS/NIPS2000/00papers-pub-on-web/SmolaBartlett.ps.gz}
}

@INPROCEEDINGS{Smola:sparse00,
  author = {Alex J. Smola and Bernhard Sch\"olkopf},
  title = {Sparse Greedy Matrix Approximation for Machine Learning},
  pages = {911--918},
  crossref = {Langley:icml00}
}

@Article{Calupka:framework13,
  author = 	 {Krzysztof Calupka and Christopher K. I. Williams and Iain Murray},
  title = 	 {A Framework for Evaluating Approximation Methods for Gaussian
Process Regression},
  journal = 	 jmlr,
  year = 	 2013,
  OPTkey = 	 {},
  volume =	 {14},
  OPTnumber = 	 {},
  pages =	 {333--350},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Snelson:pseudo05,
  author = {Edward Snelson and Zoubin Ghahramani},
  title = {Sparse {G}aussian Processes using Pseudo-inputs},
  abstract = {We present a new Gaussian process (GP) regression model whose covariance
	is parameterized by the locations of $M$ pseudo-input points, which
	we learn by gradient based optimization. We take $M<<N$, where $N$
	is the number of real data points, and hence obtain a sparse regression
	method which has $O(M^2N)$ training cost and $O(M^2)$ prediction
	cost per test case. We also find hyperparameters of the covariance
	function in the same joint optimization. The method can be viewed
	as a Bayesian regression model with a particular input dependent
	noise. The method turns out to be closely related to several other
	sparse GP approaches, and we discuss the relation in detail. We finally
	demonstrate its performance on some large data sets, and make a direct
	comparision to other sparse GP methods. We show that our method can
	match full GP performance with small $M$, i.e. very sparse solutions,
	and it significantly outperforms other approaches in this regime.},
  crossref = {Weiss:nips05},
  file = {SPGP_draft.pdf:http\://www.gatsby.ucl.ac.uk/~snelson/SPGP_draft.pdf:PDF},
  group = {spgp}
}

@INPROCEEDINGS{Snelson:local07,
  author = {Edward Snelson and Zoubin Ghahramani},
  title = {Local and Global Sparse {G}aussian Process Approximations},
  year = {2007},
  abstract = {Gaussian process (GP) models are flexible probabilistic nonparametric
	models for regression, classification and other tasks. Unfortunately
	they suffer from computational intractability for large data sets.
	Over the past decade there have been many different approximations
	developed to reduce this cost. Most of these can be termed global
	approximations, in that they try to summarize all the training data
	via a small set of support points. A different approach is that of
	local regression, where many local experts account for their own
	part of space. In this paper we start by investigating the regimes
	in which these different approaches work well or fail. We then proceed
	to develop a new sparse GP approximation which is a combination of
	both the global and local approaches. Theoretically we show that
	it is derived as a natural extension of the framework developed by
	Qui\~nonero Candela and Rasmussen [2005] for sparse GP approximations.
	We demonstrate the benefits of the combined approximation on some
	1D examples for illustration, and on some large real-world data sets.},
  crossref = {Meila:aistats07},
  file = {localGP.pdf:http\://www.gatsby.ucl.ac.uk/~snelson/localGP.pdf:PDF},
  group = {gp, spgp}
}

@Article{Glaus:bitseq12,
  author = 	 {Peter Glaus and Antti Honkela and Magnus Rattray},
  title = 	 {Identifying differentially expressed transcripts from RNA-seq data with biological variation},
  journal = 	 {Bioinformatics},
  year = 	 {2012},
  OPTkey = 	 {},
  volume =	 {28},
  number =	 {13},
  pages =	 {1721--1728},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1093/bioinformatics/bts260},
  linkpdf =	 {http://bioinformatics.oxfordjournals.org/content/28/13/1721.full.pdf+html},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  abstract =	 {\textbf{Motivation}: High-throughput sequencing enables expression analysis at the level of individual transcripts. The analysis of transcriptome expression levels and differential expression (DE) estimation requires a probabilistic approach to properly account for ambiguity caused by shared exons and finite read sampling as well as the intrinsic biological variance of transcript expression.\\\\

\textbf{Results:} We present Bayesian inference of transcripts from sequencing data (BitSeq), a Bayesian approach for estimation of transcript expression level from RNA-seq experiments. Inferred relative expression is represented by Markov chain Monte Carlo samples from the posterior probability distribution of a generative model of the read data. We propose a novel method for DE analysis across replicates which propagates uncertainty from the sample-level model while modelling biological variance using an expression-level-dependent prior. We demonstrate the advantages of our method using simulated data as well as an RNA-seq dataset with technical and biological replication for both studied conditions.\\\\

\textbf{Availability:} The implementation of the transcriptome expression estimation and differential expression analysis, BitSeq, has been written in C++ and Python. The software is available online from http://code.google.com/p/bitseq/, version 0.4 was used for generating results presented in this article.\\\\\

\textbf{Contact:} glaus@cs.man.ac.uk, antti.honkela@hiit.fi or m.rattray@sheffield.ac.uk},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Solak:derivative03,
  author = {E. Solak and Roderick Murray-Smith and W. E. Leithead and D. J. Leith
	and C. E. Rasmussen},
  title = {Derivative observations in {G}aussian Process models of Dynamic Systems},
  crossref = {Becker:nips02},
  linkps = {http://www.dcs.gla.ac.uk/~rod/publications/SolMurLeiLeiRas03.ps}
}

@INPROCEEDINGS{Sollich:probabilisticNIPS99,
  author = {Peter Sollich},
  title = {Probabilistic methods for Support Vector Machines},
  pages = {349--355},
  crossref = {Solla:nips99},
  linkpsgz = {http://www.mth.kcl.ac.uk/~psollich/papers/SVM_NIPSIX.ps.gz}
}

@INPROCEEDINGS{Stutz:autoclass94,
  author = {John Stutz and Peter Cheeseman},
  title = {{AutoClass} -- a {B}ayesian Approach to Classification},
  crossref = {Skilling:entropy94}
}

@INPROCEEDINGS{Szummer:clustering01,
  author = {Martin Szummer and Tommi S. Jaakkola},
  title = {Clustering and Efficient use of Unlabeled Examples},
  crossref = {Leen:nips00},
  linkpsgz = {http://www.ai.mit.edu/people/tommi/papers/SzuJaa-nips01.ps.gz}
}

@INPROCEEDINGS{Szummer:information02,
  author = {Martin Szummer and Tommi S. Jaakkola},
  title = {Information regularization with partially labeled data},
  crossref = {Dietterich:nips01},
  file = {SzuJaa-nips02.pdf:http\://www.ai.mit.edu/people/tommi/papers/SzuJaa-nips02.pdf:PDF}
}

@INPROCEEDINGS{Szummer:kernel00,
  author = {Martin Szummer and Tommi S. Jaakkola},
  title = {Kernel expansions with unlabeled examples},
  crossref = {Solla:nips99},
  linkpsgz = {http://www.ai.mit.edu/people/tommi/papers/SzuJaa-nips00.ps.gz}
}

@INPROCEEDINGS{Szummer:partially02,
  author = {Martin Szummer and Tommi S. Jaakkola},
  title = {Partially labeled classification with Markov random walks},
  pages = {945--952},
  crossref = {Dietterich:nips01},
  linkpsgz = {http://www.ai.mit.edu/people/szummer/papers/SzummerJaakkola-nips01.ps.gz}
}

@INPROCEEDINGS{Taylor:motion06,
  author = {Graham W. Taylor and Geoffrey E. Hinton and Sam Roweis},
  title = {Modeling Human Motion Using Binary Latent Variables},
  abstract = {We propose a non-linear generative model for human motion data that
	uses an undirected model with binary latent variables and real-valued
	"visible" variables that represent joint angles. The latent and visible
	variables at each time step receive directed connections from the
	visible variables at the last few time-steps. Such an architecture
	makes on-line inference efficient and allows us to use a simple approximate
	learning procedure. After training, the model finds a single set
	of parameters that simultaneously capture several different kinds
	of motion. We demonstrate the power of our approach by synthesizing
	various motion sequences and by performing on-line filling in of
	data lost during motion capture.},
  crossref = {Schoelkopf:nips06},
  file = {gwtaylor_nips.pdf:http\://www.cs.toronto.edu/~gwtaylor/publications/nips2006mhmublv/gwtaylor_nips.pdf:PDF},
  group = {mocap, Boltzmann machine},
  linksoftware = {http://www.cs.toronto.edu/~gwtaylor/publications/nips2006mhmublv/code.html}
}

@INPROCEEDINGS{Teh:collapsedHDP07,
  author = {Yee Whye Teh and Kenichi Kurihara and Max Welling},
  title = {Collapsed Variational Inference for {HDP}},
  abstract = {A wide variety of Dirichlet-multinomial `topic' models have found
	interesting applications in recent years. While Gibbs sampling remains
	an important method of inference in such models, variational techniques
	have certain advantages such as easy assessment of convergence, easy
	optimization without the need to maintain detailed balance, a bound
	on the marginal likelihood, and side-stepping of issues with topic-identifiability.
	The most accurate variational technique thus far, namely collapsed
	variational LDA (CV-LDA) \cite{Teh:collapsedLDA06}, did not deal
	with model selection nor did it include inference for hyperparameters.
	We address both issues by generalizing their technique, obtaining
	the first variational algorithm to deal with the HDP and to deal
	with hyperparameters of Dirichlet variables. Experiments show a very
	significant improvement in accuracy relative to CV-LDA.},
  crossref = {Platt:nips07},
  group = {dp, variational, topic models}
}

@INPROCEEDINGS{Teh:alignment02,
  author = {Yee Whye Teh and Sam Roweis},
  title = {Automatic Alignment of Local Representations},
  pages = {841--848},
  abstract = {We present an automatic alignment procedure which maps the disparate
	internal representations learned by several local dimensionality
	reduction experts into a single, coherent global coordinate system
	for the original data space. Our algorithm can be applied to any
	set of experts, each of which produces a low-dimensional local representation
	of a high-dimensional input. Unlike recent efforts to coordinate
	such models by modifying their objective functions \cite{Roweis:global01},
	\cite{Verbeek:coordinating02} our algorithm is invoked after training
	and applies an efficient eigensolver to post-process the trained
	models. The post-processing has no local optima and the size of the
	system it must solve scales with the number of local models rather
	than the number of original data points, making it more efficient
	than model-free algorithms such as Isomap \cite{Tenenbaum:isomap00}
	or LLE \cite{Roweis:lle00}.},
  crossref = {Becker:nips02},
  file = {AA46.pdf:http\://books.nips.cc/papers/files/nips15/AA46.pdf:PDF},
  group = {mixtures, dimensional reduction},
  linkpsgz = {http://books.nips.cc/papers/files/nips15/AA46.ps.gz}
}

@INPROCEEDINGS{Teh:semiparametric05,
  author = {Yee Whye Teh and Matthias Seeger and Michael I. Jordan},
  title = {Semiparametric Latent Factor Models},
  pages = {333--340},
  abstract = {We propose a semiparametric model for regression problems involving
	multiple response variables. The model makes use of a set of Gaussian
	processes that are linearly mixed to capture dependencies that may
	exist among the response variables. We propose an efficient approximate
	inference scheme for this semiparametric model whose complexity is
	linear in the number of training data points. We present experimental
	results in the domain of multi-joint robot arm dynamics. },
  crossref = {Cowell:aistats05},
  file = {265.pdf:http\://www.gatsby.ucl.ac.uk/aistats/fullpapers/265.pdf:PDF},
  group = {gp}
}

@INPROCEEDINGS{Thrun:learning96,
  author = {Sebastian Thrun},
  title = {Is Learning The $n$-th Thing Any Easier Than Learning The First?},
  pages = {640--646},
  crossref = {Touretzky:nips95}
}

@INPROCEEDINGS{Tipping:binary98,
  author = {Michael E. Tipping},
  title = {Probabilistic visualisation of high-dimensional binary data},
  pages = {592--598},
  crossref = {Kearns:nips98},
  group = {dimensional reduction},
  linkpsgz = {ftp://ftp.research.microsoft.com/users/mtipping/nips98.ps.gz}
}

@INPROCEEDINGS{Tipping:relevance00,
  author = {Michael E. Tipping},
  title = {The Relevance Vector Machine},
  pages = {652--658},
  crossref = {Solla:nips99}
}

@INPROCEEDINGS{Tipping:sparse00,
  author = {Michael E. Tipping},
  title = {Sparse Kernel Principal Component Analysis},
  pages = {633--639},
  crossref = {Leen:nips00},
  linkpsgz = {ftp://ftp.research.microsoft.com/users/mtipping/skpca_nips.ps.gz}
}

@INCOLLECTION{Titsias:infinite08,
  author = {Michalis K. Titsias},
  title = {The Infinite Gamma-Poisson Feature Model},
  pages = {1513--1520},
  crossref = {Platt:nips07}
}

@INPROCEEDINGS{Titsias:variational09,
  author = {Michalis K. Titsias},
  title = {Variational Learning of Inducing Variables in Sparse {G}aussian Processes},
  pages = {567--574},
  crossref = {Welling:aistats09}
}

@INPROCEEDINGS{Tresp:mixtures00,
  author = {Voker Tresp},
  title = {Mixtures of {G}aussian Processes},
  abstract = {We introduce the mixture of Gaussian processes (MGP) model which is
	useful for applications in which the optimal bandwidth of a map is
	input dependent. The MGP is derived from the mixture of experts model
	and can also be used for modeling general conditional probability
	densities. We discuss how Gaussian processes in particular in form
	of Gaussian process classification, the support vector machine and
	the MGP model can be used for quantifying the dependencies in graphical
	models.},
  crossref = {Leen:nips00},
  file = {moe_gpr2.pdf:http\://www.tresp.org/papers/moe_gpr2.pdf:PDF},
  group = {gp, mixtures},
  linkpsgz = {http://www.tresp.org/papers/moe_gpr2.ps.gz},
  optpages = {654--660}
}

@INPROCEEDINGS{Urtasun:dgplvm07,
  author = {Raquel Urtasun and Trevor Darrell},
  title = {Discriminative {G}aussian Process Latent Variable Model for Classification},
  year = {2007},
  abstract = {Supervised learning is difficult with high dimensional input spaces
	and very small training sets, but accurate classification may be
	possible if the data lie on a low-dimensional manifold. Gaussian
	Process Latent Variable Models can discover low dimensional manifolds
	given only a small number of examples, but learn a latent space without
	regard for class labels. Existing methods for discriminative manifold
	learning (e.g., LDA, GDA) do constrain the class distribution in
	the latent space, but are generally deterministic and may not generalize
	well with limited training data. We introduce a method for Gaussian
	Process Classification using latent variable models trained with
	discriminative priors over the latent space, which can learn a discriminative
	latent space from a small training set.},
  crossref = {Ghahramani:icml07},
  file = {517.pdf:http\://www.machinelearning.org/proceedings/icml2007/papers/517.pdf:PDF},
  group = {gp,gplvm, dimensional reduction}
}

@INPROCEEDINGS{Verbeek:coordinating02,
  author = {Jakob J. Verbeek and Nikos A. Vlassis and Ben J. A. Kr\"{o}se},
  title = {Coordinating Principal Component Analyzers},
  pages = {914--919},
  abstract = {Mixtures of Principal Component Analyzers can be used to model high
	dimensional data that lie on or near a low dimensional manifold.
	By linearly mapping the PCA subspaces to one global low dimensional
	space, we obtain a `global' low dimensional coordinate system for
	the data. As shown by Roweis et al., ensuring consistent global low-dimensional
	coordinates for the data can be expressed as a penal- ized likelihood
	optimization problem. We show that a restricted form of the Mixtures
	of Probabilistic PCA model allows for a more efficient algorithm.
	Experimental results are provided to illustrate the viability method.},
  crossref = {Dorronsoro:icann02},
  file = {Verbeek02icann.pdf:ftp\://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/Verbeek02icann.pdf:PDF},
  group = {mixtures, dimensionality reduction}
}

@INPROCEEDINGS{Vigario:artifacts97,
  author = {Ricardo N. Vig\'ario and Veikko Jousm\"aki and Matti H\"am\"al\"ainen
	and Riitta Hari and Erkki Oja},
  title = {Independent Component Analysis for Identification of Artifacts in
	Magnetoencephalographic Recordings},
  pages = {229--235},
  crossref = {Jordan:nips97},
  label2 = {Data},
  link2 = {http://www.cis.hut.fi/projects/ica/eegmeg/MEG_data.html},
  linkps = {http://www.cis.hut.fi/~rvigario/publications/nips97/nips97.ps}
}

@INPROCEEDINGS{Vinokourov:inferring02,
  author = {Alexei Vinokourov and Nello Cristianini and John Shawe-Taylor},
  title = {Inferring a Semantic Representation of Text via Cross-Language Correlation
	Analysis},
  pages = {1473--1480},
  abstract = {The problem of learning a semantic representation of a text document
	from data is addressed, in the situation where a corpus of unlabeled
	paired documents is available, each pair being formed by a short
	English document and its French translation. This representation
	can then be used for any retrieval, categorization or clustering
	task, both in a standard and in a cross-lingual setting. By using
	kernel functions, in this case simple bag-of-words inner products,
	each part of the corpus is mapped to a high-dimensional space. The
	correlations between the two spaces are then learnt by using kernel
	Canonical Correlation Analysis. A set of directions is found in the
	first and in the second space that are maximally correlated. Since
	we assume the two representations are completely independent apart
	from the semantic content, any correlation between them should reflect
	some semantic similarity. Certain patterns of English words that
	relate to a specific meaning should correlate with certain patterns
	of French words corresponding to the same meaning, across the corpus.
	Using the semantic representation obtained in this way we first demonstrate
	that the correlations detected between the two versions of the corpus
	are significantly higher than random, and hence that a representation
	based on such features does capture statistical patterns that should
	reflect semantic information. Then we use such representation both
	in cross-language and in single-language retrieval tasks, observing
	performance that is consistently and significantly superior to LSI
	on the same data.},
  crossref = {Becker:nips02},
  file = {alexei_nips02.pdf:http\://www.support-vector.net/papers/alexei_nips02.pdf:PDF},
  group = {language, cca}
}

@INPROCEEDINGS{Wang:stopping95,
  author = {C. Wang and S. S. Venkatesh and J. S. Judd},
  title = {Optimal stopping and effective machine complexity in learning},
  pages = {303--310},
  crossref = {Cowan:nips93}
}

@INPROCEEDINGS{Wang:gpdm05,
  author = {Jack M. Wang and David J. Fleet and Aaron Hertzmann},
  title = {Gaussian Process Dynamical Models},
  abstract = {This paper introduces Gaussian Process Dynamical Models (GPDM) for
	nonlinear time series analysis. A GPDM comprises a low-dimensional
	latent space with associated dynamics, and a map from the latent
	space to an observation space. We marginalize out the model parameters
	in closed form, which amounts to using Gaussian Process (GP) priors
	for both the dynamics and the observation mappings. This results
	in a nonparameteric model for dynamical systems that accounts for
	uncertainty in the model. We demonstrate the approach on human motion
	capture data in which each pose is 62-dimensional. Despite the use
	of small data sets, the GPDM leans an effective representation of
	the nonlinear dynamics in these spaces.},
  crossref = {Weiss:nips05},
  file = {NIPS2005.pdf:http\://www.cs.toronto.edu/~fleet/research/Papers/NIPS2005.pdf:PDF},
  group = {gplvm},
  label2 = {Web-page},
  link2 = {http://www.dgp.toronto.edu/~jmwang/gpdm/}
}

@INPROCEEDINGS{Waterhouse:bayesian96,
  author = {Steve Waterhouse and David J. C. MacKay and Tony Robinson},
  title = {{B}ayesian Methods for Mixtures of Experts},
  pages = {351--357},
  crossref = {Touretzky:nips95}
}

@INPROCEEDINGS{Weinberger:learning04,
  author = {Kilian Q. Weinberger and Fei Sha and Lawrence K. Saul},
  title = {Learning a kernel matrix for nonlinear dimensionality reduction},
  pages = {839--846},
  abstract = {We investigate how to learn a kernel matrix for high dimensional data
	that lies on or near a low dimensional manifold. Noting that the
	kernel matrix implicitly maps the data into a nonlinear feature space,
	we show how to discover a mapping that ``unfolds" the underlying
	manifold from which the data was sampled. The kernel matrix is constructed
	by maximizing the variance in feature space subject to local constraints
	that preserve the angles and distances between nearest neighbors.
	The main optimization involves an instance of semidefinite programming
	- a fundamentally different computation than previous algorithms
	for manifold learning, such as Isomap and locally linear embedding.
	The optimized kernels perform better than polynomial and Gaussian
	kernels for problems in manifold learning, but worse for problems
	in large margin classification. We explain these results in terms
	of the geometric properties of different kernels and comment on various
	interpretations of other manifold learning algorithms as kernel methods.},
  crossref = {Greiner:icml04},
  file = {kernel_icml04.pdf:http\://www.seas.upenn.edu/~kilianw/publications/PDFs/kernel_icml04.pdf:PDF}
}

@INPROCEEDINGS{Williams:connection01,
  author = {Christopher K. I. Williams},
  title = {On a Connection between Kernel {PCA} and Metric Multidimensional
	Scaling},
  pages = {675--681},
  crossref = {Leen:nips00},
  linkpsgz = {http://www.dai.ed.ac.uk/homes/ckiw/postscript/mds5.ps.gz}
}

@INCOLLECTION{Williams:Gaussian95,
  author = {Christopher K. I. Williams},
  title = {Regression with {G}aussian Processes},
  note = {Paper presented at the \emph{Mathematics of Neural Networks and Applications
	conference}, Oxford, UK, July 1995},
  crossref = {Ellacott:mathematics95},
  trnumber = {NCRG/95/023}
}

@INPROCEEDINGS{Williams:infinite96,
  author = {Christopher K. I. Williams},
  title = {Computing with Infinite Networks},
  abstract = {For neural networks with a wide class of weight priors, it can be
	shown that in the limit of an infinite number of hidden units the
	prior over functions tends to a Gaussian process. In this paper analytic
	forms are derived for the covariance function of the Gaussian processes
	corresponding to networks with sigmoidal and Gaussian hidden units.
	This allows predictions to be made efficiently using networks with
	an infinite number of hidden units, and shows that, somewhat paradoxically,
	it may be easier to carry out Bayesian prediction with infinite networks
	rather than finite ones.},
  crossref = {Mozer:nips96},
  group = {gp},
  linkpsz = {http://www.ncrg.aston.ac.uk/Papers/postscript/NCRG_96_026.ps.zip}
}

@INCOLLECTION{Williams:prediction98,
  author = {Christopher K. I. Williams},
  title = {Prediction with {G}aussian Processes: From Linear Regression to Linear
	Prediction and Beyond},
  abstract = {The main aim of this paper is to provide a tutorial on regression
	with Gaussian processes. We start from Bayesian linear regression,
	and show how by a change of viewpoint one can see this method as
	a Gaussian process predictor based on priors over functions, rather
	than on priors over parameters. This leads into a more general discussion
	of Gaussian processes in section 4. Section 5 deals with further
	issues, including hierarchical modelling and the setting of the parameters
	that control the Gaussian process, the covariance functions fro neural
	network models and the use of Gaussian processes in classification
	problems.},
  crossref = {Jordan:learning98},
  group = {gp},
  linkpsgz = {http://www.dai.ed.ac.uk/homes/ckiw/postscript/NCRG_97_012.ps.gz}
}

@INPROCEEDINGS{Williams:pog02,
  author = {Christopher K. I. Williams and Felix V. Agakov and Stephen N. Felderof},
  title = {Products of {G}aussians},
  pages = {1017--1024},
  abstract = {Recently Hinton \cite{Hinton:product99} has introduced the Products
	of Experts (PoE) model in which several individual probabilistic
	models for data are combined to provide an overall model of the data.
	Below we consideer PoE models in which each expert is a Gaussian.
	Although the product of Gaussians is also a Gaussian, if each Gaussian
	has a simple structure the product can have a richer structure. We
	examine (1) Products of Gaussian pancakes which give rise to probabilistic
	Minor Components Analysis, (2) products of 1-factor PPCA models and
	(3) a products of experts construction for an AR(1) process.},
  crossref = {Dietterich:nips01},
  file = {AA15.pdf:http\://books.nips.cc/papers/files/nips14/AA15.pdf:PDF},
  group = {products of gaussians},
  linkpsgz = {http://www.dai.ed.ac.uk/homes/ckiw/postscript/pog1a.ps.gz}
}

@INPROCEEDINGS{Williams:Gaussian96,
  author = {Christopher K. I. Williams and Carl E. Rasmussen},
  title = {{G}aussian Processes for Regression},
  pages = {514--520},
  crossref = {Touretzky:nips95},
  trnumber = {NCRG/96/013}
}

@INPROCEEDINGS{Williams:nystrom00,
  author = {Christopher K. I. Williams and Matthias Seeger},
  title = {Using the {N}ystr\"om Method to Speed Up Kernel Machines},
  pages = {682--688},
  abstract = {A major problem for kernel-based predictors (such as Support Vector
	Machines and Gaussian processes) is that the amount of computation
	required to find the solution scales as $O(n^3)$, where $n$ is the
	number of training examples. We show that an approximation to the
	eigendecompositoin of the Gram matrix can be computed by the Nystr\"om
	method (which is used for the numerical solution of eigenproblems).
	This is achieved by carrying out an eigendecomposition on a smaller
	system of size $m<n$, and then expanding the results back up to $n$
	dimensions. The computational complexity of a predictor using this
	approximation is $O(m^2n)$. We report experiments on the USPS and
	abalone data sets and show that we can set $m<<n$ without any significant
	decrease in the accuracy of the solution.},
  crossref = {Leen:nips00},
  group = {spgp},
  linkpsgz = {http://www.nips.cc/Web/Groups/NIPS/NIPS2000/00papers-pub-on-web/WilliamsSeeger.ps.gz}
}

@INPROCEEDINGS{Wipf:perspectives03,
  author = {David P. Wipf and Jason A. Palmer and Bhaskar D. Rao},
  title = {Perspectives on Sparse {B}ayesian Learning},
  pages = {249--256},
  abstract = {Recently, relevance vector machines (RVM) have been fashioned from
	a sparse Bayesian learning (SBL) framework to perform supervised
	learning using a weight prior that encourages sparsity of representation.
	The methodology incorporates an additional set of hyper parameters
	governing the prior, one for each weight, and then adopts a specific
	approximation to the full martinalization over all weights and hyperparameters.
	Despite its empirical success however, no rigorous motivation for
	this particular approximation is currently available. To address
	this issue, we demonstrate that SBL can be recast as the application
	of a rigorous variational approximation to the full model by expressing
	the prior in a dual form. This formulation obviates the necessity
	of assuming any hyperpriors and leads to natural, intuitive explanations
	of why sparsity is achieved in practice.},
  crossref = {Thrun:nips03},
  file = {NIPS2003_AA32.pdf:http\://books.nips.cc/papers/files/nips16/NIPS2003_AA32.pdf:PDF},
  group = {sbl}
}

@INPROCEEDINGS{Wolpert:ev93,
  author = {D. H. Wolpert},
  title = {On the use of Evidence in Neural Networks},
  pages = {539--546},
  crossref = {Hanson:nips92}
}

@INPROCEEDINGS{Xing:distance02,
  author = {Eric P. Xing and Andrew Y. Ng and Michael I. Jordan and Stuart Russell},
  title = {Distance metric learning, with application to clustering with side-information},
  crossref = {Becker:nips02},
  linkpsgz = {http://www.cs.berkeley.edu/~jordan/papers/metric.ps.gz}
}

@INPROCEEDINGS{Yaeger:effective96,
  author = {Larry Yaeger and Richard Lyon and Brandyn Webb},
  title = {Effective Training of a Neural Network Character Classifier for Word
	Recognition},
  pages = {807--813},
  abstract = {We have combined an artificial neural network (ANN) character classifier
	with context-driven search over character segmentation, word segmentation,
	and word recognition hypotheses to provide robust recognition of
	hand-printed English text in new models of Apple Computer's Newton
	MessagePad. We present some innovations in the training and use of
	ANNs as character classifiers for word recognition, including normalized
	output error, frequency balancing, error emphasis, negative training,
	and stroke warping. A recurring theme of reducing \emph{a priori}
	biases emerges and is discussed.},
  crossref = {Mozer:nips96},
  file = {Yaegeretal.NIPS96.pdf:http\://www.beanblossom.in.us/larryy/Yaegeretal.NIPS96.pdf:PDF},
  group = {hand writing},
  linkdjvu = {http://books.nips.cc/papers/files/nips09/0807.djvu}
}

@ARTICLE{Lichtenberg:yeastcell05,
  author = {Ulrik {de Lichtenberg} and Rasmus Wernersson and Thomas Skot Jensen
	and Henrik Bjorn Nielsen and Anders Fausboll and Peer Schmidt and
	Flemming Bryde Hansen and Steen Knudsen and Soren Brunak},
  title = {New Weakly Expressed Cell Cycle-Regulated Genes in Yeast},
  journal = {Yeast},
  year = {2005},
  volume = {22},
  pages = {1191--1201},
  number = {15},
  group = {yeast, cell cycle, gene networks}
}

@BOOKLET{Ockham:razor96,
  title = {\emph{Expositio aurea super totam artem veterem}},
  author = {William {of Ockham}},
  howpublished = {Written c. 1320, first printed in Bologna 1496.},
  year = {1496},
  note = {Commentaries on Aristotle's \emph{Elenchus} and Porphyry's \emph{Isagoge}}
}

@PHDTHESIS{Alvarez:thesis11,
  author = {Mauricio A. \'Alvarez},
  title = {Convolved {G}aussian Process Priors for Multivariate Regression with
	Applications to Dynamical Systems},
  school = {School of Computer Science, University of Manchester},
  year = {2011},
  address = {Manchester, UK}
}

@ARTICLE{Abu_mostafa:VC89,
  author = {Y. S. Abu-Mostafa},
  title = {The {V}apnik-{C}hervonenkis Dimension: Information Versus Complexity
	in Learning},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {312--317},
  number = {3}
}

@ARTICLE{Ackley:boltzmann85,
  author = {D. Ackley and Geoffrey E. Hinton and Terrence J. Sejnowski},
  title = {A Learning Algorithm for {B}oltzmann Machines},
  journal = {Cognitive Science},
  year = {1985},
  volume = {9},
  pages = {147--169}
}

@ARTICLE{Agarwal:pose06,
  author = {Ankur Agarwal and Bill Triggs},
  title = {Recovering 3{D} Human Pose from Monocular Images},
  journal = PAMI,
  year = {2006},
  volume = {28},
  number = {1},
  abstract = {We describe a learning-based method for recovering 3D human body pose
	from single images and monocular image sequences. Our approach requires
	neither an explicit body model nor prior labeling of body parts in
	the image. Instead, it recovers pose by direct nonlinear regression
	against shape descriptor vectors extracted automatically from image
	silhouettes. For robustness against local silhouette segmentation
	errors, silhouette shape is encoded by histogram-of-shape-contexts
	descriptors. We evaluate several different regression methods: ridge
	regression, Relevance Vector Machine (RVM) regression, and Support
	Vector Machine (SVM) regression over both linear and kernel bases.
	The RVMs provide much sparser regressors without compromising performance,
	and kernel bases give a small but worthwhile improvement in performance.
	The loss of depth and limb labeling information often makes the recovery
	of 3D pose from single silhouettes ambiguous. To handle this, the
	method is embedded in a novel regressive tracking framework, using
	dynamics from the previous state estimate together with a learned
	regression value to disambiguate the pose. We show that the resulting
	system tracks long sequences stably. For realism and good generalization
	over a wide range of viewpoints, we train the regressors on images
	resynthesized from real human motion capture data. The method is
	demonstrated for several representations of full body pose, both
	quantitatively on independent but similar test data and qualitatively
	on real image sequences. Mean angular errors of 4-6 degrees are obtained
	for a variety of walking motions.},
  doi = {10.1109/TPAMI.2006.21},
  file = {Agarwal-pami05.pdf:http\://lear.inrialpes.fr/pubs/2006/AT06a/Agarwal-pami05.pdf:PDF},
  group = {human motion}
}

@TECHREPORT{Eea:state05,
  author = {European Environment Agency},
  title = {The European Environment: State and Outlook 2005},
  institution = {The European Environment Agency},
  year = {2005},
  abstract = {This is the third state and outlook report on the European environment
	produced by the European Environment Agency (EEA) since 1994. Looking
	back, the last report, published in 1999 concluded that, despite
	25 years of Community environmental policy, environmental quality
	in the European Union (EU) was mixed and that the unsustainable development
	of some key economic sectors was the major barrier to further improvements.
	That remains the EEA's key conclusion, despite significant progress
	on some issues demonstrating that environmental policy works. Were
	we to fast-forward to the year 2010, it would be my strong hope that
	in its next state and outlook report, the EEA would be able to report
	significant environmental improvements, not least as a result of
	reversing unsustainable trends in sectors such as energy, agriculture
	and transport.},
  file = {SOER2005_all.pdf:http\://reports.eea.europa.eu/state_of_environment_report_2005_1/en/SOER2005_all.pdf:PDF},
  group = {asthma},
  isbn = {92-9167-776-0}
}

@ARTICLE{Aizerman:potential64,
  author = {M. A. Aizerman and E. M. Braverman and L. I. Rozonoer},
  title = {The Probability Problem of Pattern Recognition Learning and the Method
	of Potential Functions},
  journal = {Automation and Remote Control},
  year = {1964},
  volume = {25},
  pages = {1175--1190}
}

@INPROCEEDINGS{Akaike:armenia73,
  author = {H. Akaike},
  title = {Information Theory and an Extension of the Maximum Likelihood Principle},
  booktitle = {2nd International Symposium on Information Theory},
  year = {1973},
  editor = {B. N. Petrov and F. Cs{\'{a}}ki},
  pages = {267--281},
  address = {{T}sahkadsov, {A}rmenia, {USSR}}
}

@ARTICLE{Akaike:predict70,
  author = {H. Akaike},
  title = {Statistical Predictor Identification},
  journal = {Annals of the Institute for Mathematical Statistics},
  year = {1970},
  volume = {22},
  pages = {203--217}
}

@ARTICLE{Akaike:fpe69,
  author = {H. Akaike},
  title = {Fitting Autoregressive Models for Prediction},
  journal = {Annals of the Institute of Statistical Mathematics},
  year = {1969},
  volume = {21},
  pages = {243--247}
}

@ARTICLE{Akam:Dros87,
  author = {Michael Akam},
  title = {The molecular basis for metameric pattern in the {\it Drosophila}
	embryo},
  journal = {Development},
  year = {1987},
  volume = {101},
  pages = {1--22},
  number = {1},
  abstract = {The metameric organization of the Drosophila embryo is generated in
	the first 5 h after fertilization. An initially rather simple pattern
	provides the foundation for subsequent development and diversification
	of the segmented part of the body. Many of the genes that control
	the formation of this pattern have been identified and at least twenty
	have been cloned. By combining the techniques of genetics, molecular
	biology and experimental embryology, it is becoming possible to unravel
	the role played by each of these genes. The repeating segment pattern
	is defined by the persistent expression of engrailed and of other
	genes of the 'segment polarity' class. The establishment of this
	pattern is directed by a transient molecular prepattern that is generated
	in the blastoderm by the activity of the 'pair-rule' genes. Maternal
	determinants at the poles of the egg coordinate this prepattern and
	define the anteroposterior sequence of pattern elements. The primary
	effect of these determinants is not known, but genes required for
	their production have been identified and the product of one of these,
	bicoid is known to be localized at the anterior of the egg. One early
	consequence of their activity is to define domains along the A-P
	axis within which a series of 'cardinal' genes are transcribed. The
	activity of the cardinal genes is required both to coordinate the
	process of segmentation and to define the early domains of homeotic
	gene expression. Further interactions between the homeotic genes
	and other classes of segmentation genes refine the initial establishment
	of segment identities.},
  file = {1.pdf:http\://dev.biologists.org/cgi/reprint/101/1/1.pdf:PDF},
  group = {gene networks, Drosophila},
  optpmid = {2896587}
}

@article{Moignard:characterization13,
	Annote = {10.1038/ncb2709},
	Author = {Moignard, Victoria and Macaulay, Iain C. and Swiers, Gemma and Buettner, Florian and Sch{\"u}tte, Judith and Calero-Nieto, Fernando J. and Kinston, Sarah and Joshi, Anagha and Hannah, Rebecca and Theis, Fabian J. and Jacobsen, Sten Eirik and de Bruijn, Marella F. and G{\"o}ttgens, Berthold},
	Date = {2013/04//print},
	Date-Added = {2015-05-08 08:46:41 +0000},
	Date-Modified = {2015-05-08 08:46:41 +0000},
	Isbn = {1465-7392},
	Journal = {Nat Cell Biol},
	L3 = {http://www.nature.com/ncb/journal/v15/n4/abs/ncb2709.html#supplementary-information},
	M3 = {10.1038/ncb2709},
	Month = {04},
	Number = {4},
	Pages = {363--372},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Title = {Characterization of transcriptional networks in blood stem and progenitor cells using high-throughput single-cell gene expression analysis},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/ncb2709},
	Volume = {15},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/ncb2709}}

@article{Buettner:analysis15,
	Annote = {Recent technical developments have enabled the transcriptomes of hundreds of cells to be assayed in an unbiased manner, opening up the possibility that new subpopulations of cells can be found. However, the effects of potential confounding factors, such as the cell cycle, on the heterogeneity of gene expression and therefore on the ability to robustly identify subpopulations remain unclear. We present and validate a computational approach that uses latent variable models to account for such hidden factors. We show that our single-cell latent variable model (scLVM) allows the identification of otherwise undetectable subpopulations of cells that correspond to different stages during the differentiation of naive T cells into T helper 2 cells. Our approach can be used not only to identify cellular subpopulations but also to tease apart different sources of gene expression heterogeneity in single-cell transcriptomes.},
	Author = {Buettner, Florian and Natarajan, Kedar N and Casale, F Paolo and Proserpio, Valentina and Scialdone, Antonio and Theis, Fabian J and Teichmann, Sarah A and Marioni, John C and Stegle, Oliver},
	Date = {2015/02//print},
	Date-Added = {2015-05-08 08:43:56 +0000},
	Date-Modified = {2015-05-08 08:43:56 +0000},
	Isbn = {1087-0156},
	Journal = {Nat Biotech},
	L3 = {10.1038/nbt.3102; http://www.nature.com/nbt/journal/v33/n2/abs/nbt.3102.html#supplementary-information},
	M3 = {Computational Biology},
	Month = {02},
	Number = {2},
	Pages = {155--160},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Title = {Computational analysis of cell-to-cell heterogeneity in single-cell RNA-sequencing data reveals hidden subpopulations of cells},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nbt.3102},
	Volume = {33},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nbt.3102}}

@Article{Buettner:resolving12,
  author = 	 {Florian Buettner and Fabian J. Theis},
  title = 	 {A novel approach for resolving differences in single-cell gene expression patterns from zygote to blastocyst},
  journal = 	 {Bioinformatics},
  year = 	 {2012},
  OPTkey = 	 {},
  volume =	 {28},
  number =	 {18},
  pages =	 {i626--i632},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1093/bioinformatics/bts385},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Buettner:probabilistic14,
  author = 	 {Florian Buettner and Victoria Moignard and Berthold G\"ottgens and Fabian J. Theis},
  title = 	 {Probabilistic PCA of censored data: accounting for uncertainties in the visualization of high-throughput single-cell qPCR data},
  journal = 	 {Bioinformatics},
  year = 	 {2014},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTpages = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1093/bioinformatics/btu134},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Guo:fate10,
  author = 	 {Guoji Guo and Mikael Huss and Guo Qing Tong and Chaoyang Wang and Li Li Sun and Neil D. Clarke and Paul Robsonemail},
  title = 	 {Resolution of Cell Fate Decisions Revealed by Single-Cell Gene Expression Analysis from Zygote to Blastocyst},
  journal = 	 {Developmental Cell},
  year = 	 {2010},
  OPTkey = 	 {},
  volume =	 {18},
  number =	 {4},
  pages =	 {675--685},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1016/j.devcel.2010.02.012},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  abstract =	 {Three distinct cell types are present within the 64-cell stage mouse blastocyst. We have investigated cellular development up to this stage using single-cell expression analysis of more than 500 cells. The 48 genes analyzed were selected in part based on a whole-embryo analysis of more than 800 transcription factors. We show that in the morula, blastomeres coexpress transcription factors specific to different lineages, but by the 64-cell stage three cell types can be clearly distinguished according to their quantitative expression profiles. We identify Id2 and Sox2 as the earliest markers of outer and inner cells, respectively. This is followed by an inverse correlation in expression for the receptor-ligand pair Fgfr2/Fgf4 in the early inner cell mass. Position and signaling events appear to precede the maturation of the transcriptional program. These results illustrate the power of single-cell expression analysis to provide insight into developmental mechanisms. The technique should be widely applicable to other biological systems.},
  OPTgroup = 	 {}
}

@ARTICLE{Albertini:Sontag93,
  author = {F. Albertini and Eduardo D. Sontag},
  title = {For Neural Networks, Function Determines Form},
  journal = NN,
  year = {1993},
  volume = {6},
  pages = {975--990},
  number = {7}
}

@ARTICLE{Allen:discrimination04,
  author = {Jess Allen and Hazel M. Davey and David Broadhurst and Jem J. Rowland
	and Stephen G. Oliver and Douglas B. Kell},
  title = {Discrimination of the Modes of Action of Antifungal Substances by
	use of Metabolic Footprinting},
  journal = {Appl Environ Microbiol.},
  year = {2004},
  volume = {70},
  pages = {6157--6165},
  number = {10},
  abstract = {Diploid cells of Saccharomyces cerevisiae were grown under controlled
	conditions with a Bioscreen instrument, which permitted the essentially
	continuous registration of their growth via optical density measurements.
	Some cultures were exposed to concentrations of a number of antifungal
	substances with different targets or modes of action (sterol biosynthesis,
	respiratory chain, amino acid synthesis, and the uncoupler). Culture
	supernatants were taken and analyzed for their "metabolic footprints"
	by using direct-injection mass spectrometry. Discriminant function
	analysis and hierarchical cluster analysis allowed these antifungal
	compounds to be distinguished and classified according to their modes
	of action. Genetic programming, a rule-evolving machine learning
	strategy, allowed respiratory inhibitors to be discriminated from
	others by using just two masses. Metabolic footprinting thus represents
	a rapid, convenient, and information-rich method for classifying
	the modes of action of antifungal substances.},
  doi = {10.1128/AEM.70.10.6157-6165.2004},
  file = {6157.pdf:http\://aem.asm.org/cgi/reprint/70/10/6157.pdf:PDF},
  group = {metabolic footprint},
  pmid = {15466562}
}

@ARTICLE{Allen:highthroughput03,
  author = {Jess K. Allen and Hazel M. Davey and David Broadhurst and Jim K.
	Heald and Jem J. Rowland and Stephen G. Oliver and Douglas B. Kell},
  title = {High-throughput characterisation of yeast mutants for functional
	genomics using metabolic footprinting},
  journal = {Nature Biotechnology},
  year = {2003},
  volume = {21},
  pages = {692--696},
  number = {6},
  abstract = {Many technologies have been developed to help explain the function
	of genes discovered by systematic genome sequencing. At present,
	transcriptome and proteome studies dominate large-scale functional
	analysis strategies. Yet the metabolome, because it is 'downstream',
	should show greater effects of genetic or physiological changes and
	thus should be much closer to the phenotype of the organism. We earlier
	presented a functional analysis strategy that used metabolic fingerprinting
	to reveal the phenotype of silent mutations of yeast genes1. However,
	this is difficult to scale up for high-throughput screening. Here
	we present an alternative that has the required throughput (2 min
	per sample). This 'metabolic footprinting' approach recognizes the
	significance of 'overflow metabolism' in appropriate media. Measuring
	intracellular metabolites is time-consuming and subject to technical
	difficulties caused by the rapid turnover of intracellular metabolites
	and the need to quench metabolism and separate metabolites from the
	extracellular space. We therefore focused instead on direct, noninvasive,
	mass spectrometric monitoring of extracellular metabolites in spent
	culture medium. Metabolic footprinting can distinguish between different
	physiological states of wild-type yeast and between yeast single-gene
	deletion mutants even from related areas of metabolism. By using
	appropriate clustering and machine learning techniques, the latter
	based on genetic programming2, 3, 4, 5, 6, 7, 8, we show that metabolic
	footprinting is an effective method to classify 'unknown' mutants
	by genetic defect.},
  doi = {10.1038/nbt823},
  file = {nbt823.pdf:http\://www.nature.com/nbt/journal/v21/n6/pdf/nbt823.pdf:PDF},
  group = {metabolic footprint}
}

@ARTICLE{Alspach:bayes72,
  author = {D. L. Alspach and H. W. Sorenson},
  title = {Nonlinear {B}ayesian Estimation Using {G}aussian Sum Approximations},
  journal = {IEEE Transactions on Automatic Control},
  year = {1972},
  volume = {17},
  pages = {439--447},
  number = {4}
}

@ARTICLE{Alter:svd00,
  author = {Orly Alter and Patrick O. Brown and David Botstein},
  title = {Singular Value Decomposition for Genome-Wide Expression Data Processing
	and Modeling},
  journal = pnasusa,
  year = {2000},
  volume = {97},
  pages = {10101--10106},
  number = {18},
  label1 = {abstract},
  link1 = {http://www.pnas.org/cgi/content/abstract/97/18/10101}
}

@ARTICLE{Alter:integrative04,
  author = {Orly Alter and Gene H. Golub},
  title = {Integrative Analysis of Genome-Scale Data Using Pseudoinverse Projection
	Predicts Novel Correlation Between DNA Replication and RNA Transcription},
  journal = {Proceedings of the National Academy of Sciences USA},
  year = {2004},
  volume = {101},
  pages = {16577--16582},
  number = {47}
}

@TECHREPORT{Amari:em95,
  author = {Shun-Ichi Amari},
  title = {Information Geometry of the {EM} and {em} Algorithms for Neural Networks},
  institution = {Department of Mathematical Engineering and Information Physics},
  year = {1995},
  address = {University of Tokyo, Japan}
}

@ARTICLE{Amit:stat_mech87,
  author = {D. Amit and H. Gutfreund and H. Sompolinsky},
  title = {Statistical Mechanics of Neural Networks Near Saturation},
  journal = PRa,
  year = {1987},
  volume = {173},
  pages = {30--67}
}

@INCOLLECTION{Anderson:logistic82,
  author = {J. A. Anderson},
  title = {Logistic Discrimination},
  booktitle = {Classification, Pattern Recognition and Reduction of Dimensionality},
  publisher = nholland,
  year = {1982},
  editor = {P. R. Krishnaiah and L. N. Kanal},
  volume = {2},
  series = {Handbook of Statistics},
  pages = {169--191},
  address = {Amsterdam}
}

@ARTICLE{Anderson:63,
  author = {T. W. Anderson},
  title = {Asymptotic Theory for Principal Component Analysis},
  journal = {Annals of Mathematical Statistics},
  year = {1963},
  volume = {34},
  pages = {122--148}
}

@INPROCEEDINGS{Andriluka:people08,
  author = {Mykhaylo Andriluka and Stefan Roth and Bernt Schiele},
  title = {People-Tracking-by-Detection and People-Detection-by-Tracking},
  booktitle = pCVPR,
  year = {2008},
  pages = {758--765},
  month = {23--28 Jun.},
  publisher = ieeecomp,
  abstract = {Both detection and tracking people are challenging problems, especially
	in complex real world scenes that commonly involve multiple people,
	complicated occlusions, and cluttered or even moving backgrounds.
	People detectors have been shown to be able to locate pedestrians
	even in complex street scenes, but false positives have remained
	frequent. The identification of particular individuals has remained
	challenging as well. Tracking methods are able to find a particular
	individual in image sequences, but are severely challenged by real-world
	scenarios such as crowded street scenes. In this paper, we combine
	the advantages of both detection and tracking in a single framework.
	The approximate articulation of each person is detected in every
	frame based on local features that model the appearance of individual
	body parts. Prior knowledge on possible articulations and temporal
	coherency within a walking cycle are modeled using a hierarchical
	Gaussian process latent variable model (hGPLVM). We show how the
	combination of these results improves hypotheses for position and
	articulation of each person in several subsequent frames. We present
	experimental results that demonstrate how this allows to detect and
	track multiple people in cluttered scenes with reoccurring occlusions.},
  group = {tracking}
}

@ARTICLE{Anlauf:adatron89,
  author = {J. K. Anlauf and M. Biehl},
  title = {The AdaTron: an Adaptive Perceptron Algorithm},
  journal = EPL,
  year = {1989},
  volume = {10},
  pages = {687--692},
  number = {7}
}

@ARTICLE{Appel:colourI77,
  author = {K. Appel and W. Haken},
  title = {Every Planar Map is Four Colorable. {Part I}. {D}ischarging},
  journal = {Illinois Journal of Mathematics},
  year = {1977},
  volume = {21},
  pages = {429--490}
}

@ARTICLE{Appel:colourII77,
  author = {K. Appel and W. Haken and J. Koch},
  title = {Every Planar Map is Four Colorable. {Part II}. {R}educibility},
  journal = {Illinois Journal of Mathematics},
  year = {1977},
  volume = {21},
  pages = {491--567}
}

@ARTICLE{Archibald:rare26,
  author = {Raymond C. Archibald},
  title = {A Rare Pamphlet of {M}oivre and some of his Discoveries},
  journal = {Isis},
  year = {1926},
  volume = {8},
  pages = {671--676}
}

@ARTICLE{Argyriou:convex08,
  author = {Andreas Argyriou and Theodoros Evgeniou and Massimiliano Pontil},
  title = {Convex multi-task feature learning},
  journal = {Machine Learning},
  year = {2008},
  volume = {73},
  pages = {243-272},
  number = {3}
}

@INPROCEEDINGS{Argyriou:algorithm08,
  author = {Andreas Argyriou and Andreas Maurer and Massimiliano Pontil},
  title = {An Algorithm for Transfer Learning in a Heterogeneous Environment},
  booktitle = {ECML/PKDD (1)},
  year = {2008},
  pages = {71-85}
}

@INPROCEEDINGS{Arikan:synthesizing02,
  author = {O. Arikan and D. A. Forsyth},
  title = {Synthesizing Constrained Motions from Examples},
  booktitle = {ACM Transactions on Graphics (SIGGRAPH 2002)},
  year = {2002},
  file = {s2002.pdf :http\://www.cs.berkeley.edu/~okan/papers/s2002/s2002.pdf :PDF},
  label1 = {Web page},
  link1 = {http://www.cs.berkeley.edu/~okan/papers/s2002/motionSynthesis.html},
  optpages = {483--490}
}

@ARTICLE{Arkin:stoch98,
  author = {A. Arkin and J. Ross and H. H. McAdams},
  title = {Stochastic kinetic analysis of developmental pathway bifurcation
	in phage lambda-infected {\it Escherichia coli} cells},
  journal = {Genetics},
  year = {1998},
  volume = {149},
  pages = {1633--1648},
  group = {gene networks}
}

@ARTICLE{Arnold:57,
  author = {V. I. Arnold},
  title = {On Functions of Three Variables},
  journal = DOKLADY,
  year = {1957},
  volume = {114},
  pages = {679--681},
  number = {4}
}

@ARTICLE{Aronszajn:theory50,
  author = {Nachman Aronszajn},
  title = {Theory of Reproducing Kernels},
  journal = {Trans. Amer. Math. Soc.},
  year = {1950},
  volume = {68},
  pages = {337--404},
  mrclass = {46.0X},
  mrnumber = {14,479c},
  mrreviewer = {T. H. Hildebrandt}
}

@ARTICLE{Ashcroft:p53phosphorylation99,
  author = {M. Ashcroft and M. H. G. Kubbutat and K. H. Vousden },
  title = {Regulation of p53 Function and Stability by Phosphorylation},
  journal = {Mol. Cel. Biol.},
  year = {1999},
  volume = {19},
  number = {3},
  optgroup = {p53, phosphorylation},
  optpages = {1751--1758}
}

@ARTICLE{Atteia1994,
  author = {Olivier Atteia and Jean-Pascal Dubois and Richard Webster},
  title = {Geostatistical analysis of soil contamination in the {S}wiss {J}ura.},
  journal = {Environ Pollut},
  year = {1994},
  volume = {86},
  pages = {315--327},
  number = {3},
  __markedentry = {[neil:6]},
  abstract = {The topsoil of a 14.5 km(2) region of the Swiss Jura has been surveyed
	to identify the distributions of trace metals in it. The soil was
	sampled at 366 sites selected by combining a square grid and nesting.
	Concentrations of seven potentially toxic metals, namely Cd, Co,
	Cr, Cu, Ni, Pb and Zn, were measured. Land use and geology (stratigraphy)
	were also recorded. Variograms were bounded in the range from 110
	m to 1500 m with contributions to the variance at all distances exceeding
	6 m. The variograms of Cd, Cr, Cu and Pb are dominated by short range
	correlation, those of Co and Ni by correlation of long range, and
	Zn is intermediate. The concentrations were estimated at the nodes
	of a fine grid by ordinary block kriging and then contoured to produce
	maps. The maps of Co and Ni have a coarse patchy pattern similar
	to that of the geology, suggesting that these metals derive from
	the bedrock. This is supported by analysing the variance by geology.
	Copper and Pb have finer patterns of distribution, and are more likely
	to have been added with fertilizer or manure or domestic waste. Cadmium
	could originate from human activities, such as smelters or fertilizer
	spreading, or from specific geological deposits, such as moraine.},
  institution = {Swiss Federal Institute of Technology, IATE-Pédologie, EPF Lausanne,
	1015 Lausanne, Switzerland.},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {0269749194901724},
  pmid = {15091623},
  timestamp = {2012.06.28}
}

@ARTICLE{Attias:ifa98,
  author = {Hagai Attias},
  title = {Independent Factor Analysis},
  journal = NC,
  year = {1998},
  volume = {11},
  pages = {803--851}
}

@ARTICLE{Augusto:temporal05,
  author = {Juan Carlos Augusto},
  title = {Temporal Reasoning for Decision Support in Medicine},
  journal = {Artificial Intelligence in Medicine},
  year = {2005},
  volume = {33},
  pages = {1--24},
  abstract = {\emph{Objective}: Handling time-related concepts is essential in medicine.
	During diagnosis it can make a substantial difference to know the
	temporal order in which some symptoms occurred or for how long they
	lasted. During prognosis the potential evolutions of a disease are
	conceived as a description of events unfolding in time. In therapy
	planning the different steps of treatment must be applied in a precise
	order, with a given frequency and for a certain span of time in order
	to be effective. This article offers a survey on the use of temporal
	reasoning for decision supportrelated tasks in medicine.\\\\ \emph{Material
	and methods}: Key publications of the area, mainly circumscribed
	to the latest two decades, are reviewed and classified according
	to three important stages of patient treatment requiring decision
	support: diagnosis, prognosis and therapy planning/management. Other
	complementary publications, like those on time-centered information
	storage and retrieval, are also considered as they provide valuable
	support to the above mentioned three stages. Results: Key areas are
	highlighted and used to organize the latest contributions. The survey
	of previous research is followed by an analysis of what can still
	be improved and what is needed to make the next generation of decision
	support systems for medicine more effective.\\\\ \emph{Conclusions}:
	It can be observed that although the area has been considerably developed,
	there are still areas where more research is needed to make time-based
	systems of widespread use in decision support-related areas of medicine.
	Several suggestions for further exploration are proposed as a result
	of the survey.},
  group = {alms},
  label1 = {Journal Link},
  label2 = {Science Direct},
  link1 = {http://www.journals.elsevierhealth.com/periodicals/artmed/article/PIIS093336570400106X/abstract},
  link2 = {http://www.sciencedirect.com/science?_ob=GatewayURL&_origin=inwardhub&_urlversion=4&_method=citationSearch&_piikey=S093336570400106X&_referrer=portal.acm.org&_version=1&md5=a8dab918923c6d7b7877bf56838e1300}
}

@INPROCEEDINGS{Awasthi:image07,
  author = {Prajal Awasthi and Aakanksaha Gagrani and Balaraman Ravindran},
  title = {Image Modelling using Tree Structured Conditional Random Fields},
  booktitle = {Proceedings of the 20th International Joint Conference on Artificial
	Intelligence (IJCAI 2007)},
  year = {2007},
  editor = {Manuela M. Veloso},
  pages = {2060--2065},
  abstract = {In this paper we present a discriminative framework based on conditional
	random fields for stochastic modeling of images in a hierarchical
	fashion. The main advantage of the proposed framework is its ability
	to incorporate a rich set of interactions among the image sites.
	We achieve this by inducing a hierarchy of hidden variables over
	the given label field. The proposed tree like structure of our model
	eliminates the need for a huge parameter space and at the same time
	permits the use of exact and efficient inference procedures based
	on belief propagation. We demonstrate the generality of our approach
	by applying it to two important computer vision tasks, namely image
	labeling and object detection. The model parameters are trained using
	the contrastive divergence algorithm. We report the performance on
	real world images and compare it with the existing approaches.},
  file = {IJCAI07-332.pdf:http\://www.ijcai.org/papers07/Papers/IJCAI07-332.pdf:PDF},
  group = {tree}
}

@TECHREPORT{Bach:pcca05,
  author = {Francis R. Bach and Michael I. Jordan},
  title = {A probabilistic interpretation of canonical correlation analysis},
  institution = {Department of Statistics, University of California, Berkeley},
  year = {2005},
  number = {688},
  abstract = {We give a probabilistic interpretation of canonical correlation (CCA)
	analysis as a latent variable model for two Gaussian random vectors.
	Our interpretation is similar to the probabilistic interpretation
	of principal component analysis (Tipping and Bishop, 1999, Roweis,
	1998). In addition, we can interpret Fisher linear discriminant analysis
	(LDA) as CCA between appropriately defined vectors.},
  file = {probacca.pdf:http\://cmm.ensmp.fr/~bach/probacca.pdf:PDF},
  group = {CCA, LDA, dimensional reduction}
}

@ARTICLE{Bach:kica02,
  author = {Francis R. Bach and Michael I. Jordan},
  title = {Kernel Independent Component Analysis},
  journal = jmlr,
  year = {2002},
  volume = {3},
  pages = {1--48},
  abstract = {We present a class of algorithms for independent component analysis
	(ICA) which use contrast functions based on canonical correlations
	in a reproducing kernel Hilbert space. On the one hand, we show that
	our contrast functions are related to mutual information and have
	desirable mathematical properties as measures of statistical dependence.
	On the other hand, building on recent developments in kernel methods,
	we show that these criteria and their derivatives can be computed
	e±ciently. Minimizing these criteria leads to flexible and robust
	algorithms for ICA. We illustrate with simulations involving a wide
	variety of source distributions, showing that our algorithms outperform
	many of the presently known algorithms.},
  file = {bach02a.pdf:http\://www.jmlr.org/papers/volume3/bach02a/bach02a.pdf:PDF},
  group = {cca},
  linkps = {http://www.jmlr.org/papers/volume3/bach02a/bach02a.ps},
  linkpsgz = {http://www.jmlr.org/papers/volume3/bach02a/bach02a.ps.gz},
  linksoftware = {http://www.cs.berkeley.edu/~fbach/kernel-ica/}
}

@INPROCEEDINGS{Bahl:mmi86,
  author = {L. R. Bahl and P.F. Brown and P. V. de Souza and R. L. Mercer},
  title = {Maximum Mutual Information Estimation of Hidden {M}arkov Model Parameters
	for Speech Recognition},
  booktitle = {Proceedings of the IEEE Conference on Acoustics, Speech and Signal
	Processing},
  year = {1986},
  pages = {49--52},
  publisher = {IEEE}
}

@ARTICLE{Bahl:speechrec83,
  author = {L. R Bahl and F. Jelinek and R. L. Mercer},
  title = {A Maximum Likelihood Approach to Continuous Speech Recognition},
  journal = PAMI,
  year = {1983},
  volume = {5},
  pages = {179--190},
  number = {2}
}

@ARTICLE{Bakker:taskClustering03,
  author = {Bart Bakker and Tom Heskes},
  title = {Task Clustering and Gating for {B}ayesian Multitask Learning},
  journal = jmlr,
  year = {2003},
  volume = {4},
  pages = {83-99}
}

@INPROCEEDINGS{Balan:adaptive06,
  author = {Alexandru O. Balan and Michael J. Black},
  title = {An Adaptive Appearance Model Approach for Model-based Articulated
	Object Tracking},
  booktitle = pCVPR,
  year = {2006},
  pages = {758--765},
  address = {New York, NY, U.S.A.},
  month = {17--22 Jun.},
  publisher = ieeecomp,
  abstract = {The detection and tracking of three-dimensional human body models
	has progressed rapidly but successful approaches typically rely on
	accurate foreground silhouettes obtained using background segmentation.
	There are many practical applications where such information is imprecise.
	Here we develop a new image likelihood function based on the visual
	appearance of the subject being tracked. We propose a robust, adaptive,
	appearance model based on the Wandering-Stable-Lost framework extended
	to the case of articulated body parts. The method models appearance
	using a mixture model that includes an adaptive template, frame-to-frame
	matching and an outlier process. We employ an annealed particle filtering
	algorithm for inference and take advantage of the 3D body model to
	predict selfocclusion and improve pose estimation accuracy. Quantitative
	tracking results are presented for a walking sequence with a 180
	degree turn, captured with four synchronized and calibrated cameras
	and containing significant appearance changes and self-occlusion
	in each view.},
  group = {tracking}
}

@ARTICLE{Baldassarre:multioutput11,
  author = {Luca Baldassarre and Lorenzo Rosasco and Annalisa Barla and Alessandro
	Verri},
  title = {Multi-Output Learning via Spectral Filtering},
  doi = {10.1007/s10994-012-5282-y},
  journal = {Machine Learning},
  year = {2012},
  pages = {259--301},
  volume = {87},
  number = {3},
  abstract = {In this paper we study a class of regularized kernel methods for multi-output learning which are based on filtering the spectrum of the kernel matrix. The considered methods include Tikhonov regularization as a special case, as well as interesting alternatives such as vector-valued extensions of L2 boosting and other iterative schemes. Computational properties are discussed for various examples of kernels for vector-valued functions and the benefits of iterative techniques are illustrated. Generalizing previous results for the scalar case, we show a finite sample bound for the excess risk of the obtained estimator, which allows to prove consistency both for regression and multi-category classification. Finally, we present some promising results of the proposed algorithms on artificial and real data.}
}

@BOOK{Baldi:book01,
  title = {Bioinformatics: The Machine Learning Approach},
  publisher = mit,
  year = {2001},
  author = {Pierre Baldi and S. Brunak},
  address = {Cambridge, MT}
}

@ARTICLE{Baldi:minima89,
  author = {Pierre Baldi and K. Hornik},
  title = {Neural networks and Principal Component Analysis: Learning from Examples
	Without Local Minima},
  journal = NN,
  year = {1989},
  volume = {2},
  pages = {53--58},
  number = {1}
}

@ARTICLE{Banerjee:sparse07,
  author = {Onureena Banerjee and Laurent El Ghaoui and Alexandre d'Aspremont},
  title = {Model Selection Through Sparse Maximum Likelihood Estimation for
	Multivariate {G}aussian or Binary Data},
  journal = jmlr,
  year = {2007}
}

@TECHREPORT{Barber:ensemble97,
  author = {David Barber and Christopher M. Bishop},
  title = {On computing the {KL} Divergence for {B}ayesian Neural Networks},
  institution = {Neural Computing Research Group},
  year = {1997},
  address = {Aston University, Birmingham, U.K.}
}

@ARTICLE{Barenco:ranked06,
  author = {Martino Barenco and Daniela Tomescu and Daniel Brewer and Robin Callard
	and Jaroslav Stark and Michael Hubank},
  title = {Ranked prediction of p53 targets using hidden variable dynamic modeling},
  journal = {Genome Biology},
  year = {2006},
  volume = {7},
  pages = {R25},
  number = {3},
  abstract = {Full exploitation of microarray data requires hidden information that
	cannot be extracted using current analysis methodologies. We present
	a new approach, hidden variable dynamic modeling (HVDM), which derives
	the hidden profile of a transcription factor from time series microarray
	data, and generates a ranked list of predicted targets. We applied
	HVDM to the p53 network, validating predictions experimentally using
	small interfering RNA. HVDM can be applied in many systems biology
	contexts to predict regulation of gene activity quantitatively.},
  file = {gb-2006-7-3-r25.pdf:http\://genomebiology.com/content/pdf/gb-2006-7-3-r25.pdf:PDF},
  group = {gene networks, network motifs, single input motifs},
  linkhtml = {http://genomebiology.com/2006/7/3/R25}
}

@ARTICLE{Barnard:optimization92,
  author = {E. Barnard},
  title = {Optimization for Training Neural Nets},
  journal = IEEE,
  year = {1992},
  volume = {3},
  pages = {232--240},
  number = {2}
}

@ARTICLE{Barnard:invariance91,
  author = {E. Barnard and D. Casasent},
  title = {Invariance and Neural Nets},
  journal = IEEE,
  year = {1991},
  volume = {2},
  pages = {498--508},
  number = {5}
}

@INCOLLECTION{Barron:pse84,
  author = {A. R. Barron},
  title = {Predicted Squared Error: A Criterion for Automatic Model Selection},
  booktitle = {Self-Organizing Methods in Modelling},
  publisher = {Marcel Dekker},
  year = {1984},
  editor = {S. J. Farlow},
  volume = {54},
  series = {Statistics: Textbooks and Monographs},
  pages = {87--103},
  address = {New York}
}

@ARTICLE{Barron:univ93,
  author = {A. R. Barron},
  title = {Universal Approximation Bounds for Superposition of a Sigmoidal Function},
  journal = {IEEE Transactions on Information Theory},
  year = {1993},
  volume = {39},
  pages = {930--945},
  number = {3}
}

@Article{Box:science76,
  author = 	 {George E. P. Box},
  title = 	 {Science and Statistics},
  journal = 	 jasa,
  year = 	 {1976},
  OPTkey = 	 {},
  volume =	 {71},
  number =	 {365},
  OPTpages = 	 {791--799},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Barron:unifying88,
  author = {A. R. Barron and R. L. Barron},
  title = {Statistical Learning Networks: A Unifying View},
  booktitle = {Computing Science and Statistics: 20th Symposium on the Interface},
  year = {1988},
  editor = {E. J. Wegman and D. T. Gantz and J. J. Miller},
  pages = {192--203},
  address = {Fairfax, Virginia},
  publisher = {American Statistical Association}
}

@ARTICLE{Barry:blackbox96,
  author = {Ronald Paul Barry and Jay M. {Ver Hoef}},
  title = {Blackbox kriging: spatial prediction without specifying variogram
	models},
  journal = {Journal of Agricultural, Biological and Environmental Statistics},
  year = {1996},
  volume = {1},
  pages = {297-322},
  number = {3}
}

@ARTICLE{Barton2008,
  author = {Anne Barton and Wendy Thomson and Xiayi Ke and Steve Eyre and Anne
	Hinks and John Bowes and Darren Plant and Laura J Gibbons and Wellcome
	Trust Case Control Consortium and Y. E. A. R. Consortium and B. I.
	R. A. C. Consortium and Anthony G Wilson and Deborah E Bax and Ann
	W Morgan and Paul Emery and Sophia Steer and Lynne Hocking and David
	M Reid and Paul Wordsworth and Pille Harrison and Jane Worthington},
  title = {Rheumatoid arthritis susceptibility loci at chromosomes 10p15, 12q13
	and 22q13.},
  journal = {Nat Genet},
  year = {2008},
  volume = {40},
  pages = {1156--1159},
  number = {10},
  month = {Oct},
  abstract = {The WTCCC study identified 49 SNPs putatively associated with rheumatoid
	arthritis at P = 1 x 10(-4) - 1 x 10(-5) (tier 3). Here we show that
	three of these SNPs, mapping to chromosome 10p15 (rs4750316), 12q13
	(rs1678542) and 22q13 (rs3218253), are also associated (trend P =
	4 x 10(-5), P = 4 x 10(-4) and P = 4 x 10(-4), respectively) in a
	validation study of 4,106 individuals with rheumatoid arthritis and
	an expanded reference group of 11,238 subjects, confirming them as
	true susceptibility loci in individuals of European ancestry.},
  doi = {10.1038/ng.218},
  institution = {Arthritis Research Campaign, Epidemiology Unit, The University of
	Manchester, Manchester, UK. anne.barton@manchester.ac.uk},
  keywords = {Arthritis, Rheumatoid, genetics/pathology; Case-Control Studies; Chromosome
	Mapping; Chromosomes, Human, Pair 10, genetics; Chromosomes, Human,
	Pair 12, genetics; Chromosomes, Human, Pair 22, genetics; Genetic
	Linkage; Genetic Predisposition to Disease, genetics; Humans; Polymorphism,
	Single Nucleotide, genetics},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ng.218},
  pmid = {18794857},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1038/ng.218}
}

@ARTICLE{Bates:p53signalling96,
  author = {S. Bates and K. H. Vousden},
  title = {p53 in signalling checkpoint arrest or apoptosis},
  journal = {Curr. Opin. Genet. Dev.},
  year = {1996},
  volume = {6},
  pages = {1--7},
  optgroup = {p53}
}

@ARTICLE{Battiti:learning89,
  author = {R. Battiti},
  title = {Accelerated Backpropagation Learning: Two Optimization Methods},
  journal = {Complex Systems},
  year = {1989},
  volume = {3},
  pages = {331--342}
}

@ARTICLE{Battogtokh:ensemble02,
  author = {D. Battogtokh and D. K. Asch and M. E. Case and J. Arnold},
  title = {An Ensemble Method for Identifying Regulatory Circuits with Special
	Reference to the qa gene cluster of \emph{Neurospora crassa}},
  journal = pnasusa,
  year = {2002},
  pages = {16904--16909},
  number = {99},
  group = {gene networks}
}

@ARTICLE{Baudat:discriminant00,
  author = {Gaston Baudat and Fatiha Anouar},
  title = {Generalized Discriminant Analysis Using a Kernel Approach},
  journal = NC,
  year = {2000},
  volume = {12},
  pages = {2385--2404}
}

@ARTICLE{Baum:capabilities88,
  author = {Eric B. Baum},
  title = {On the Capabilities of Multilayer Perceptrons},
  journal = {Journal of Complexity},
  year = {1988},
  volume = {4},
  pages = {193--215}
}

@ARTICLE{Baum:VCdim89,
  author = {Eric B. Baum and David Haussler},
  title = {What Size Net Gives Valid Generalization?},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {151--160},
  number = {1}
}

@INPROCEEDINGS{Baum:distributions88,
  author = {Eric B. Baum and F. Wilczek},
  title = {Supervised learning of probability distributions by neural networks},
  booktitle = {Neural Information Processing Systems},
  year = {1988},
  editor = {D. Z. Anderson},
  pages = {52--61},
  address = {New York},
  publisher = {American Institute of Physics}
}

@INPROCEEDINGS{Baxter:internal95,
  author = {J. Baxter},
  title = {Learning Internal Representations},
  booktitle = {Proc. {COLT}},
  year = {1995},
  volume = {8},
  pages = {311-320},
  publisher = {Morgan Kaufmann Publishers}
}

@INPROCEEDINGS{Baxter:doodle06,
  author = {William V. Baxter and Ken-Ichi Anjyo},
  title = {Latent Doodle Space},
  booktitle = {EUROGRAPHICS},
  year = {2006},
  volume = {25},
  number = {3},
  pages = {477--485},
  address = {Vienna, Austria},
  month = {September 4-8},
  abstract = {We propose the concept of a latent doodle space, a low-dimensional
	space derived from a set of input doodles, or simple line drawings.
	The latent space provides a foundation for generating new drawings
	that are similar, but not identical to, the input examples. The two
	key components of this technique are 1) a heuristic algorithm for
	finding stroke correspondences between the drawings, and 2) the use
	of latent variable methods to automatically extract a low-dimensional
	latent doodle space from the inputs. We present two practical applications
	that demonstrate the utility of this idea: first, a randomized stamp
	tool that creates a different image on every usage; and second, "personalized
	probabilistic fonts," a handwriting synthesis technique that mimics
	the idiosyncrasies of one's own handwriting.},
  doi = {10.1111/j.1467-8659.2006.00967.x},
  file = {baxter_doodle_eg2006_preprint.pdf:http\://www.cavie-x.net/doodle/contents/baxter_doodle_eg2006_preprint.pdf:PDF},
  group = {gplvm}
}

@ARTICLE{Bayarri:calibration09,
  author = {M. J. Bayarri and James O. Berger and Marc C. Kennedy and Athanasios
	Kottas and Rui Paulo and Jerry Sacks and John A. Cafeo and Chin-Hsu
	Lin and Jian Tu},
  title = {Predicting Vehicle Crashworthiness: Validation of Computer Models
	for Functional and Hierarchical Data},
  journal = {Journal of the American Statistical Association},
  year = {2009},
  volume = {104},
  pages = {929-943},
  number = {487}
}

@ARTICLE{Bayes:doctrine63,
  author = {Thomas Bayes},
  title = {An Essay Towards Solving a Problem in the Doctrine of Chances},
  journal = {Philosophical Transactions of the Royal Society},
  year = {1763},
  volume = {53},
  pages = {370--418},
  doi = {10.1098/rstl.1763.0053},
  pdf = {http://rstl.royalsocietypublishing.org/content/53/370.full.pdf}
}

@INPROCEEDINGS{Becker:second_order88,
  author = {S. Becker and Yann {Le~Cun}},
  title = {Improving the convergence of back-propagation learning with second
	order methods},
  booktitle = {Proceedings of the 1988 Connectionist Models Summer School},
  year = {1989},
  editor = {David S. Touretzky and Geoffrey E. Hinton and Terrence J. Sejnowski},
  pages = {29--37},
  address = {San Mateo, CA},
  publisher = {Morgan Kaufmann}
}

@ARTICLE{Belkin:laplacian03,
  author = {Mikhail Belkin and Partha Niyogi},
  title = {Laplacian eigenmaps for dimensionality reduction and data representation},
  journal = NC,
  year = {2003},
  volume = {15},
  pages = {1373--1396},
  number = {6},
  doi = {10.1162/089976603321780317},
  linkps = {http://people.cs.uchicago.edu/~misha/paper1.ps}
}

@ARTICLE{Bell:edge97,
  author = {A J. Bell and Terrence J. Sejnowski},
  title = {The `Independent Components' of Natural Scenes are Edge Filters},
  journal = {Vision Research},
  year = {1997},
  volume = {37},
  pages = {3327--3338}
}

@ARTICLE{Bell:ica95,
  author = {A. J. Bell and Terrence J. Sejnowski},
  title = {An information maximization approach to blind separation and blind
	deconvolution},
  journal = NC,
  year = {1995},
  volume = {7},
  pages = {1129--1159},
  number = {6}
}

@ARTICLE{Bello:ieee92,
  author = {M. G. Bello},
  title = {Enhanced training algorithms, and integrated training/architecture
	selection for multilayer perceptron networks},
  journal = IEEE,
  year = {1992},
  volume = {3},
  pages = {864--875},
  number = {6}
}

@ARTICLE{Bengio:eigenfunctions04,
  author = {Yoshua Bengio and Olivier Delalleau and Jean-Francois Palement and
	Nicolas {Le Roux} and Marie Ouimet and Pascal Vincent},
  title = {Learning Eigenfunctions Links Spectral Embedding and Kernel {PCA}},
  journal = NC,
  year = {2004},
  volume = {16},
  pages = {2197--2219},
  number = {10},
  owner = {neil},
  timestamp = {2012.01.03}
}

@ARTICLE{Bengio:LeRec95,
  author = {Yoshua Bengio and Yann LeCunn and Craig Nohl and Chris Burges},
  title = {{LeRec}: A {NN/HMM} Hybrid for On-Line Handwriting Recognition},
  journal = NC,
  year = {1995},
  volume = {7},
  number = {5},
  abstract = {We introduce a new approach for on-line recognition of handwritten
	words written in unconstrained mixed style. The preprocessor performs
	a word-level normalization by fitting a model of the word structure
	using the EM algorithm. Words are then coded into low resolution
	"annotated images" where each pixel contains information about trajectory
	direction and curvature. The recognizer is a convolution network
	which can be spatially replicated. From the network output, a hidden
	Markov model produces word scores. The entire system is globally
	trained to minimize word-level errors.},
  file = {bengio-95.pdf:http\://yann.lecun.com/exdb/publis/pdf/bengio-95.pdf:PDF},
  group = {hand writing},
  linkdjvu = {http://yann.lecun.com/exdb/publis/djvu/bengio-95.djvu},
  optpages = {1289--1303}
}

@ARTICLE{Bergman:drosophila05,
  author = {Casey M. Bergman and J. W. Carlson and S. E. Celniker},
  title = {\emph{Drosophila} {DNase} I footprint database: a systematic genome
	annotation of transcription factor binding sites in the fruitfly,
	\emph{{D}rosophila melanogaster}},
  journal = bioinf,
  year = {2005},
  volume = {21},
  pages = {1747--1749},
  number = {8},
  abstract = {{\bf Summary}: Despite increasing numbers of computational tools developed
	to predict cis-regulatory sequences, the availability of high-quality
	datasets of transcription factor binding sites limits advances in
	the bioinformatics of gene regulation. Here we present such a dataset
	based on a systematic literature curation and genome annotation of
	DNase I footprints for the fruitfly, \emph{Drosophila melanogaster}.
	Using the experimental results of 201 primary references, we annotated
	1367 binding sites from 87 transcription factors and 101 target genes
	in the \emph{D.melanogaster} genome sequence. These data will provide
	a rich resource for future bioinformatics analyses of transcriptional
	regulation in Drosophila such as constructing motif models, training
	cis-regulatory module detectors, benchmarking alignment tools and
	continued text mining of the extensive literature on transcriptional
	regulation in this important model organism.\\\\ {\bf Availability}:
	\url{http://www.flyreg.org/}\\\\ {\bf Contact}: cbergman@gen.cam.ac.uk},
  file = {1747:http\://bioinformatics.oxfordjournals.org/cgi/reprint/21/8/1747:PDF},
  pmid = {15572468}
}


Title1–20	
Cited by
Year

@InProceedings{Elgammal:inferring04,
  author = 	 {A. Elgammal and C. S. Lee},
  title = 	 {Inferring 3D body pose from silhouettes using activity manifold learning},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 pCVPR,
  OPTpages = 	 {},
  year =	 2004,
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@InProceedings{Vasilescu:multilinear02,
  title = 	 {Multilinear Analysis of Image Ensembles: TensorFaces},
  year = 	 {2002},
  OPTkey = 	 {},
  booktitle = {European Conference on Computer Vision},
  author = 	 {M. A. O. Vasilescu and D. Terzopoulos},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {Copenhagen, Denmark},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  pages = {447--460},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@ARTICLE{Besag:pseudolikelihood75,
  author = {Julian Besag},
  title = {Statistical Analysis of Non-Lattice Data},
  journal = {The Statistician},
  year = {1975},
  volume = {24},
  pages = {179--195},
  number = {3},
  owner = {neil},
  timestamp = {2012.01.03}
}

@ARTICLE{Bhadeshia:impact95,
  author = {H. K. D. H. Bhadeshia and David J. C. {MacKay} and L. E. Svensson},
  title = {Impact Toughness of {C-MN} Steel Arc Welds - {B}ayesian Neural Network
	Analysis},
  journal = {Materials Science and Technology},
  year = {1995},
  volume = {11},
  pages = {1046--1051},
  number = {10}
}

@INPROCEEDINGS{Bilmes:vocal06,
  author = {Jeff Bilmes and Jonathan Malkin and Xiao Li and Susumu Harada and
	Kelley Kilanski and Katrin Kirchhoff and Richard Wright and Amarnag
	Subramanya and James Landay and Patricia Dowden and Howard Chizeck},
  title = {The Vocal Joystick},
  booktitle = {Proceedings of the IEEE Conference on Acoustics, Speech and Signal
	Processing},
  year = {2006},
  month = {May},
  publisher = {IEEE},
  note = {To appear.},
  file = {ICASSP-2006-VJ.pdf:http\://ssli.ee.washington.edu/vj/files/ICASSP-2006-VJ.pdf:PDF}
}

@ARTICLE{Bintu:applications05,
  author = {Lacramioara Bintu and Nicolas E. Buchler and Hernan G. Garcia and
	Ulrich Gerland and Terence Hwa and Jan\'{e} Kondev and Rob Phillips},
  title = {Transcriptional Regulation by the Numbers: Applications},
  journal = {Current Opinion in Genetics \& Development},
  year = {2005},
  volume = {15},
  pages = {125--135},
  abstract = {With the increasing amount of experimental data on gene expression
	and regulation, there is a growing need for quantitative models to
	describe the data and relate them to the different contexts. The
	thermodynamic models reviewed in the preceding paper provide a useful
	framework for the quantitative analysis of bacterial transcription
	regulation. We review a number of well-characterized bacterial promoters
	that are regulated by one or two species of transcription factors,
	and apply the thermodynamic framework to these promoters. We show
	that the framework allows one to quantify vastly different forms
	of gene expression using a few parameters. As such, it provides a
	compact description useful for higher-level studies, e.g., of genetic
	networks, without the need to invoke the biochemical details of every
	component. Moreover, it can be used to generate hypotheses on the
	likely mechanisms of transcriptional control.},
  group = {gene networks},
  pmid = {15797195}
}

@ARTICLE{Bintu:models05,
  author = {Lacramioara Bintu and Nicolas E Buchler and Hernan G Garcia and Ulrich
	Gerland and Terence Hwa and Jan\'{e} Kondev and Rob Phillips},
  title = {Transcriptional Regulation by the Numbers: Models},
  journal = {Current Opinion in Genetics \& Development},
  year = {2005},
  volume = {15},
  pages = {119--124},
  abstract = {The study of gene regulation and expression is often discussed in
	quantitative terms. In particular, the expression of genes is regularly
	characterized with respect to how much, how fast, when and where.
	Whether discussing the level of gene expression in a bacterium or
	its precise location within a developing embryo, the natural language
	for these experiments is that of numbers. Such quantitative data
	demands quantitative models. We review a class of models ("thermodynamic
	models") which exploit statistical mechanics to compute the probability
	that RNA polymerase is at the appropriate promoter. This provides
	a mathematically precise elaboration of the idea that activators
	are agents of recruitment which increase the probability that RNA
	polymerase will be found at the promoter of interest. We discuss
	a framework which describes the interactions of repressors, activators,
	helper molecules and RNA polymerase using the concept of effective
	concentrations, expressed in terms of a function we call the "regulation
	factor". This analysis culminates in an expression for the probability
	of RNA polymerase binding at the promoter of interest as a function
	of the number of regulatory proteins in the cell. In a companion
	paper \cite{Bintu:applications05}, these ideas are applied to several
	case studies which illustrate the use of the general formalism.},
  group = {gene networks},
  pmid = {15797194}
}

@ARTICLE{Bird:signals03,
  author = {Susannah M. Bird and Julie E. Gray},
  title = {Signals from the cuticle affect epidermal cell differentiation},
  journal = {New Phytologist},
  year = {2003},
  volume = {157},
  pages = {9--23}
}

@ARTICLE{Bischof:mdl99,
  author = {Horst Bischof and Ales Leonardis and Alexander Selb},
  title = {{MDL} Principle for Robust Vector Quantization},
  journal = {Pattern Analysis and Applications},
  year = {1999},
  volume = {2},
  pages = {59--72},
  linkps = {http://barbados.fhs-hagenberg.ac.at/fsp/tasks/task21/resul/publis/robust-methods/BLS99.ps}
}

@INCOLLECTION{Bishop:bayes95,
  author = {Christopher M. Bishop},
  title = {{B}ayesian methods for neural networks},
  booktitle = {Oxford Lectures on Neural Networks},
  publisher = {Oxford University Press},
  year = {1995},
  editor = {E. Rolls and D. Sherrington and L. Tarassenko}
}

@INPROCEEDINGS{Bishop:icann99,
  author = {Christopher M. Bishop},
  title = {Variational Principal Components},
  booktitle = {Proceedings Ninth International Conference on Artificial Neural Networks,
	ICANN'99},
  year = {1999},
  volume = {1},
  pages = {509--514},
  optpublisher = {IEE}
}

@ARTICLE{Bishop:bayesian97,
  author = {Christopher M. Bishop},
  title = {{B}ayesian neural networks},
  journal = {Journal of the {B}razilian Computer Society},
  year = {1997},
  volume = {1},
  pages = {61--68},
  number = {4},
  note = {Special issue on neural networks}
}

@ARTICLE{Bishop:noise95,
  author = {Christopher M. Bishop},
  title = {Training with noise is equivalent to {T}ikhonov regularization},
  journal = NC,
  year = {1995},
  volume = {7},
  pages = {108--116},
  number = {1}
}

@TECHREPORT{Bishop:mdns94,
  author = {Christopher M. Bishop},
  title = {Mixture density networks},
  institution = {Neural Computing Research Group},
  year = {1994},
  number = {NCRG/94/001},
  address = {Aston University, Birmingham, UK}
}

@ARTICLE{Bishop:novelty94,
  author = {Christopher M. Bishop},
  title = {Novelty Detection and Neural Network Validation},
  journal = {IEE Proceedings: Vision, Image and Signal Processing},
  year = {1994},
  volume = {141},
  pages = {217--222},
  number = {4},
  note = {Special issue on applications of neural networks}
}

@ARTICLE{Bishop:review94,
  author = {Christopher M. Bishop},
  title = {Neural networks and their applications},
  journal = {Review of Scientific Instruments},
  year = {1994},
  volume = {65},
  pages = {1803--1832},
  number = {6}
}

@ARTICLE{Bishop:ieee93,
  author = {Christopher M. Bishop},
  title = {Curvature-driven smoothing: a learning algorithm for feedforward
	networks},
  journal = IEEE,
  year = {1993},
  volume = {4},
  pages = {882--884},
  number = {5}
}

@ARTICLE{Bishop:hessian92,
  author = {Christopher M. Bishop},
  title = {Exact Calculation of the {H}essian Matrix for the Multilayer Perceptron},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {494--501},
  number = {4}
}

@ARTICLE{Bishop:rbfs91,
  author = {Christopher M. Bishop},
  title = {Improving the Generalization Properties of Radial Basis Function
	Neural Networks},
  journal = NC,
  year = {1991},
  volume = {3},
  pages = {579--588},
  number = {4}
}

@ARTICLE{Bishop:retrain91,
  author = {Christopher M. Bishop},
  title = {A Fast Procedure for Retraining the Multilayer Perceptron},
  journal = IJNS,
  year = {1991},
  volume = {2},
  pages = {229--236},
  number = {3}
}

@ARTICLE{Bishop:tokamak95,
  author = {Christopher M. Bishop and P. S. Haynes and M. E. U. Smith and T.
	N. Todd and D. L. Trotman},
  title = {Real-time control of a tokamak plasma using neural networks},
  journal = NC,
  year = {1995},
  volume = {7},
  pages = {206--217}
}

@INPROCEEDINGS{Bishop:iee_gtmtt97,
  author = {Christopher M. Bishop and Geoffrey E. Hinton and Iain G. D. Strachan},
  title = {{GTM} Through Time},
  booktitle = {Proceedings of the IEE Fifth International Conference on Artificial
	Neural Networks, Cambridge, U.K.},
  year = {1997},
  pages = {111--116},
  abstract = {The standard GTM (generative topographic mapping) algorithm assumes
	that the data on which it is trained consists of independent, identically
	distributed (i.i.d.) vectors. For time series, however, the i.i.d.
	assumption is a poor approximation. In this paper we show how the
	GTM algorithm can be extended to model time series by incorporating
	it as the emission density in a hidden Markov model. Since GTM has
	discrete hidden states we are able to find a tractable EM algorithm,
	based on the forward-backward algorithm, to train the model. We illustrate
	the performance of GTM through time using flight recorder data from
	a helicopter.},
  file = {Bishop-GTMTT-IEE-97.pdf:http\://research.microsoft.com/~cmbishop/downloads/Bishop-GTMTT-IEE-97.pdf:PDF},
  group = {gtm},
  isbn = {0-852-96690-3}
}

@ARTICLE{Bishop:oil93,
  author = {Christopher M. Bishop and Gwilym D. James},
  title = {Analysis of multiphase flows using dual-energy gamma densitometry
	and neural networks},
  journal = {Nuclear Instruments and Methods in Physics Research},
  year = {1993},
  volume = {A327},
  pages = {580--593},
  abstract = {Dual-energy gamma densitometry offers a powerful technique for the
	non-intrusive analysis of multiphase flows. By employing multiple
	beam lines, information on the phase configuration can be obtained.
	Once the configuration is known, it then becomes possible in principle
	to determine the phase fractions. In practice, however, the extraction
	of the phase fractions from the densitometer data is complicated
	by the wide variety of phase configurations which can arise, and
	by the considerable difficulties of modelling multiphase flows. In
	this paper we show that neural network techniques provide a powerful
	approach to the analysis of data from dual-energy gamma densitometers,
	allowing both the phase configuration and the phase fractions to
	be determined with high accuracy, whilst avoiding the uncertainties
	associated with modelling. The technique is well suited to the determination
	of oil, water and gas fractions in multiphase oil pipelines. Results
	from linear and non-linear network models are compared, and a new
	technique for validating the network output is described.},
  doi = {10.1016/0168-9002(93)90728-Z}
}

@ARTICLE{Bishop:errorbar_pub95,
  author = {Christopher M. Bishop and Cazhaow Qazaz and Christopher K. I. Williams
	and H. Zhu},
  title = {{B}ayesian error bars and regression},
  year = {1995},
  note = {To be submitted to IEEE Transactions on Neural Networks}
}

@INPROCEEDINGS{Bishop:beta_icann97,
  author = {Christopher M. Bishop and Cazhaow S. Qazaz},
  title = {{B}ayesian Inference of Noise Levels in Regression},
  booktitle = {Proceedings 1996 International Conference on Artificial Neural Networks,
	ICANN'96, Bochum, Germany},
  year = {1997},
  pages = {59--64},
  publisher = springer
}

@ARTICLE{Bishop:curve92,
  author = {Christopher M. Bishop and C. M. Roach},
  title = {Fast curve fitting using neural networks},
  journal = {Review of Scientific Instruments},
  year = {1992},
  volume = {63},
  pages = {4450--4456},
  number = {10}
}

@ARTICLE{Bishop:cxrs93,
  author = {Christopher M. Bishop and C. M. Roach and M. G. von Hellermann},
  title = {Automatic analysis of {JET} charge exchange recombination spectra
	using neural networks},
  journal = {Plasma Physics and Controlled Fusion},
  year = {1993},
  volume = {35},
  pages = {765--773}
}

@ARTICLE{Bishop:profiles93,
  author = {Christopher M. Bishop and Iain G. D. Strachan and J. O'Rourke and
	G. P. Maddison and P. S. Thomas},
  title = {Reconstruction of tokamak density profiles using feed-forward networks},
  journal = {Neural Computing and Applications},
  year = {1993},
  volume = {1},
  pages = {4--16},
  number = {1}
}

@ARTICLE{Bishop:developments98,
  author = {Christopher M. Bishop and Marcus Svens\'{e}n and Christopher K. I.
	Williams},
  title = {Developments of the Generative Topographic Mapping},
  journal = {Neurocomputing},
  year = {1998},
  volume = {21},
  pages = {203--204}
}

@ARTICLE{Bishop:gtmncomp98,
  author = {Christopher M. Bishop and Marcus Svens\'{e}n and Christopher K. I.
	Williams},
  title = {{GTM}: the {G}enerative {T}opographic {M}apping},
  journal = NC,
  year = {1998},
  volume = {10},
  pages = {215--234},
  number = {1},
  abstract = {Latent variable models represent the probability density of data in
	a space of several dimensions in terms of a smaller number of latent,
	or hidden, variables. A familiar example is factor analysis, which
	is based on a linear transformation between the latent space and
	the data space. In this article, we introduce a form of nonlinear
	latent variable model called the generative topographic mapping,
	for which the parameters of the model can be determined using the
	expectation-maximization algorithm. GTM provides a principled alternative
	to the widely used self-organizing map (SOM) of Kohonen (1982) and
	overcomes most of the significant limitations of the SOM. We demonstrate
	the performance of the GTM algorithm on a toy problem and on simulated
	data from flow diagnostics for a multiphase oil pipeline.},
  doi = {10.1162/089976698300017953},
  file = {bishop-gtm-ncomp-98.pdf:http\://research.microsoft.com/~cmbishop/downloads/bishop-gtm-ncomp-98.pdf:PDF},
  group = {GTM}
}

@INPROCEEDINGS{Bishop:gtmnips96,
  author = {Christopher M. Bishop and Marcus Svens\'{e}n and Christopher K. I.
	Williams},
  title = {{GTM}: a principled alternative to the {S}elf-{O}rganizing {M}ap},
  booktitle = nips,
  year = {1997},
  volume = {9},
  pages = {354--360},
  publisher = mit,
  linkpszip = {http://www.ncrg.aston.ac.uk/Papers/postscript/NCRG_96_030.ps.zip}
}

@INPROCEEDINGS{Bishop:ieemag97,
  author = {Christopher M. Bishop and Marcus Svens\'{e}n and Christopher K. I.
	Williams},
  title = {Magnification factors for the {GTM} algorithm},
  booktitle = {Proceedings of the IEE Fifth International Conference on Artificial
	Neural Networks, Cambridge, U.K.},
  year = {1997},
  pages = {64--69},
  abstract = {The generative topographic mapping (GTM) algorithm of C. M. Bishop
	et al. (1996) has been introduced as a principled alternative to
	the self-organizing map (SOM). As well as avoiding a number of deficiencies
	in the SOM, the GTM algorithm has the key property that the smoothness
	properties of the model are decoupled from the reference vectors,
	and are described by a continuous mapping from a lower-dimensional
	latent space into the data space. Magnification factors, which are
	approximated by the difference between code-book vectors in SOMs,
	can therefore be evaluated for the GTM model as continuous functions
	of the latent variables using the techniques of differential geometry.
	They play an important role in data visualization by highlighting
	the boundaries between data clusters, and are illustrated here for
	both a toy data set, and a problem involving the identification of
	crab species from morphological data.},
  doi = {10.1049/cp:19970703},
  group = {GTM},
  isbn = {0-852-96690-3},
  linkpsgz = {http://www.dai.ed.ac.uk/homes/ckiw/postscript/NCRG_97_008.ps.gz}
}

@INPROCEEDINGS{Bishop:wsommag97,
  author = {Christopher M. Bishop and Marcus Svens\'{e}n and Christopher K. I.
	Williams},
  title = {Magnification factors for the {SOM} and {GTM} algorithms},
  booktitle = {Proceedings 1997 Workshop on Self-Organizing Maps, Helsinki University
	of Technology, Finland.},
  year = {1997},
  pages = {333--338}
}

@INCOLLECTION{Bishop:latent97,
  author = {Christopher M. Bishop and Michael E. Tipping},
  title = {Latent variable models and data visualization},
  booktitle = {Statistics and Neural Networks},
  publisher = {Oxford University Press},
  year = {1997},
  editor = {M. Titterington and J. Kay}
}

@ARTICLE{Bishop:hierarchy98,
  author = {Christopher M. Bishop and Michael E. Tipping},
  title = {A Hierarchical Latent Variable Model for Data Visualisation},
  journal = PAMI,
  year = {1998},
  volume = {20},
  pages = {281--293},
  number = {3},
  abstract = {Visualization has proven to be a powerful and widely-applicable tool
	for the analysis and interpretation of multivariate data. Most visualization
	algorithms aim to find a projection from the data space down to a
	two-dimensional visualization space. However, for complex data sets
	living in a high-dimensional space, it is unlikely that a single
	two-dimensional projection can reveal all of the interesting structure.
	We therefore introduce a hierarchical visualization algorithm which
	allows the complete data set to be visualized at the top level, with
	clusters and subclusters of data points visualized at deeper levels.
	The algorithm is based on a hierarchical mixture of latent variable
	models, whose parameters are estimated using the expectation-maximization
	algorithm. We demonstrate the principle of the approach on a toy
	data set, and we then apply the algorithm to the visualization of
	a synthetic data set in 12 dimensions obtained from a simulation
	of multiphase flows in oil pipelines, and to data in 36 dimensions
	derived from satellite images. A Matlab software implementation of
	the algorithm is publicly available from the World Wide Web.},
  doi = {10.1109/34.667885},
  file = {Bishop-hierarchical98.pdf:ftp\://ftp.research.microsoft.com/users/mtipping/Bishop-hierarchical98.pdf:PDF},
  group = {pca, hierarchical models, ppca},
  linksoftware = {http://www.ncrg.aston.ac.uk/PhiVis/Welcome.html}
}

@INPROCEEDINGS{Bishop:non-linear00,
  author = {Christopher M. Bishop and John Winn},
  title = {Non-linear {B}ayesian Image Modelling},
  booktitle = {Proceedings Sixth European Conference on Computer Vision},
  year = {2000},
  volume = {1},
  pages = {3--17},
  address = {Dublin},
  publisher = springer,
  abstract = {In recent years several techniques have been proposed for modelling
	the low-dimensional manifolds, or `subspaces', of natural images.
	Examples include principal component analysis (as used for instance
	in `eigen-faces'), independent component analysis, and auto-encoder
	neural networks. Such methods suffer from a number of restrictions
	such as the limitation to linear manifolds or the absence of a probabilistic
	representation. In this paper we exploit recent developments in the
	fields of variational inference and latent variable models to develop
	a novel and tractable probabilistic approach to modelling manifolds
	which can handle complex non-linearities. Our framework comprises
	a mixture of sub-space components in which both the number of components
	and the effective dimensionality of the sub-spaces are determined
	automatically as part of the Bayesian inference procedure. We illustrate
	our approach using two classical problems: modelling the manifold
	of face images and modelling the manifolds of hand-written digits.},
  file = {Bishop-ECCV00.pdf:http\://research.microsoft.com/~cmbishop/downloads/Bishop-ECCV00.pdf:PDF},
  group = {mixtures, dimensional reduction},
  linkps = {http://research.microsoft.com/~cmbishop/downloads/Bishop-ECCV00.ps}
}

@ARTICLE{Blais:TFNets05,
  author = {Alexandre Blais and Brian D. Dynlacht},
  title = {Constructing transcriptional regulatory networks},
  journal = {Genes and Development},
  year = {2005},
  volume = {19},
  pages = {1499--1511},
  group = {gene networks}
}

@MISC{Blake:UCI98,
  author = {C. L. Blake and C. J. Merz},
  title = {{UCI} Repository of machine learning databases},
  year = {1998},
  institution = {University of California, Irvine, Dept. of Information and Computer
	Sciences},
  url = {http://www.ics.uci.edu/$\sim$mlearn/MLRepository.html}
}

@INPROCEEDINGS{Bledsoe:ntup59,
  author = {W. W. Bledsoe and I. Browning},
  title = {Pattern Recognition and Reading by Machine},
  booktitle = {Proceedings Eastern Joint Computer Conference},
  year = {1959},
  pages = {225--232}
}

@ARTICLE{Blei:lda03,
  author = {David M. Blei and Andrew Y. Ng and Michael I. Jordan},
  title = {Latent {D}irichlet Allocation},
  journal = jmlr,
  year = {2003},
  volume = {3},
  pages = {993--1022},
  abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic
	model for collections of discrete data such as text corpora. LDA
	is a three-level hierarchical Bayesian model, in which each item
	of a collection is modeled as a finite mixture over an underlying
	set of topics. Each topic is, in turn, modeled as an infinite mixture
	over an underlying set of topic probabilities. In the context of
	text modeling, the topic probabilities provide an explicit representation
	of a document. We present efficient approximate inference techniques
	based on variational methods and an EM algorithm for empirical Bayes
	parameter estimation. We report results in document modeling, text
	classification, and collaborative filtering, comparing to a mixture
	of unigrams model and the probabilistic LSI model.},
  file = {BleiNgJordan2003.pdf:http\://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf:PDF},
  group = {lda},
  linksoftware = {http://www.cs.princeton.edu/~blei/lda-c/}
}

@ARTICLE{Block:review62,
  author = {H. D. Block},
  title = {The perceptron: a model for brain functioning},
  journal = {Reviews of Modern Physics},
  year = {1962},
  volume = {34},
  pages = {123--135},
  number = {1},
  note = {Reprinted in \cite{Anderson:collect88}}
}

@ARTICLE{Blum:approx91,
  author = {E. K. Blum and L. K. Li},
  title = {Approximation theory and feedforward networks},
  journal = NN,
  year = {1991},
  volume = {4},
  pages = {511--515},
  number = {4}
}

@ARTICLE{Blum:65,
  author = {J. R. Blum},
  title = {Multidimensional stochastic approximation methods},
  journal = {Annals of Mathematical Statistics},
  year = {1954},
  volume = {25},
  pages = {737--744}
}

@ARTICLE{Blumer:learnability89,
  author = {A. Blumer and A. Ehrenfeucht and David Haussler and M. K. Warmuth},
  title = {Learnability and the {V}apnik-{C}hervonenkis dimension},
  journal = {Journal of the Association for Computing Machinery},
  year = {1989},
  volume = {36},
  pages = {929--965},
  number = {4}
}

@ARTICLE{Boer:leu3p05,
  author = {Viktor M. Boer and Jean-Marc Daran and Marinka J.H. Almering and
	Johannes H. de Winde and Jack T. Pronk},
  title = {Contribution of the \emph{Saccharomyces Cerevisiae} Transcriptional
	Regulator Leu3p to Physiiology and Gene Expression in Nitrogen- and
	Carbon-limited Chemostat Cultures},
  journal = {FEMS Yeast Research},
  year = {2005},
  volume = {5},
  pages = {885--897},
  group = {yeast}
}

@ARTICLE{Bosman2009,
  author = {Erika A Bosman and Elizabeth Quint and Helmut Fuchs and Martin Hrabé
	de Angelis and Karen P Steel},
  title = {Catweasel mice: a novel role for {S}ix1 in sensory patch development
	and a model for branchio-oto-renal syndrome},
  journal = {Dev Biol},
  year = {2009},
  volume = {328},
  pages = {285--296},
  number = {2},
  month = {Apr},
  abstract = {Large-scale mouse mutagenesis initiatives have provided new mouse
	mutants that are useful models of human deafness and vestibular dysfunction.
	Catweasel is a novel N-ethyl-N-nitrosourea (ENU)-induced mutation.
	Heterozygous catweasel mutant mice exhibit mild headtossing associated
	with a posterior crista defect. We mapped the catweasel mutation
	to a critical region of 13 Mb on chromosome 12 containing the Six1,
	-4 and -6 genes. We identified a basepair substitution in exon 1
	of the Six1 gene that changes a conserved glutamic acid (E) at position
	121 to a glycine (G) in the Six1 homeodomain. Cwe/Cwe animals lack
	Preyer and righting reflexes, display severe headshaking and have
	severely truncated cochlea and semicircular canals. Cwe/Cwe animals
	had very few hair cells in the utricle, but their ampullae and cochlea
	were devoid of any hair cells. Bmp4, Jag1 and Sox2 expression were
	largely absent at early stages of sensory development and NeuroD
	expression was reduced in the developing vestibulo-acoustic ganglion.
	Lastly we show that Six1 genetically interacts with Jag1. We propose
	that the catweasel phenotype is due to a hypomorphic mutation in
	Six1 and that catweasel mice are a suitable model for branchio-oto-renal
	syndrome. In addition Six1 has a pivotal role in early sensory patch
	development and may act in the same genetic pathway as Jag1.},
  doi = {10.1016/j.ydbio.2009.01.030},
  institution = {The Wellcome Trust Sanger Institute, The Wellcome Trust Genome Campus,
	Hinxton CB10 1SA, UK.},
  keywords = {Amino Acid Sequence; Animals; Behavior, Animal, physiology; Bone Morphogenetic
	Protein 4, metabolism; Branchio-Oto-Renal Syndrome, embryology/genetics/pathology;
	Calcium-Binding Proteins, metabolism; Disease Models, Animal; Ear,
	Inner, abnormalities/embryology/growth /&/ development; Embryo, Mammalian,
	abnormalities/physiology; Ethylnitrosourea; Hair Cells, Auditory,
	pathology; Homeodomain Proteins, genetics/physiology; Intercellular
	Signaling Peptides and Proteins, metabolism; Kidney, abnormalities/embryology/growth
	/&/ development; Membrane Proteins, metabolism; Mice; Mice, Mutant
	Strains; Molecular Sequence Data; Mutagens; Point Mutation; SOXB1
	Transcription Factors, metabolism},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pii = {S0012-1606(09)00081-5},
  pmid = {19389353},
  timestamp = {2010.04.09}
}

@ARTICLE{Boulesteix:predicting05,
  author = {Anne-Laure Boulesteix and Korbinian Strimmer},
  title = {Predicting Transcription Factor Activities from Combined Analysis
	of Microarray and {ChIP} Data: a Partial Least Squares Approach},
  journal = {Theor. Biol. Med. Model.},
  year = {2005},
  volume = {2},
  pages = {1471--16582},
  number = {23},
  group = {gene networks}
}

@ARTICLE{Bouman:multiscale94,
  author = {C. A. Bouman and M. Shapiro},
  title = {A Mutliscale Random Field Model for {B}ayesian Image Segmentation},
  journal = {IEEE Transactions on Image Processing},
  year = {1994},
  volume = {3},
  pages = {162--177},
  number = {2}
}

@ARTICLE{Bourlard:assoc88,
  author = {H. Bourlard and Y. Kamp},
  title = {Auto-association by multilayer perceptrons and singular value decomposition},
  journal = {Biological Cybernetics},
  year = {1988},
  volume = {59},
  pages = {291--294}
}

@ARTICLE{Bourlard:links90,
  author = {H. Bourlard and C. J. Wellekens},
  title = {Links between {M}arkov models and multilayer perceptrons},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1990},
  volume = {12},
  pages = {1167--1178},
  number = {12}
}

@INPROCEEDINGS{Boyen+Koller:NIPS-1998,
  author = {Xavier Boyen and Daphne Koller},
  title = {Approximate Learning of Dynamic Models},
  booktitle = {Proceedings of the 11th Annual Conference on Neural Information Processing
	Systems (NIPS-98)},
  year = {1998},
  pages = {396--402},
  address = {Denver, Colorado},
  month = {December}
}

@INPROCEEDINGS{Boyen+Koller:UAI-1998,
  author = {Xavier Boyen and Daphne Koller},
  title = {Tractable Inference for Complex Stochastic Processes},
  booktitle = {Proceedings of the 14th Annual Conference on Uncertainty in Artificial
	Intelligence (UAI-98)},
  year = {1998},
  pages = {33--42},
  address = {Madison, Wisconsin},
  month = {July}
}

@PHDTHESIS{Boyle:thesis07,
  author = {Phillip Boyle},
  title = {Gaussian Processes for Regression and Optimisation},
  school = {Victoria University of Wellington},
  year = {2007},
  address = {Wellington, New Zealand}
}

@TECHREPORT{Boyle:techreport05,
  author = {Phillip Boyle and Marcus Frean},
  title = {Multiple Output {G}aussian Process Regression},
  institution = {School of Mathematical and Computing Sciences, Victoria University,
	New Zealand},
  year = {2005},
  type = {Technical Report},
  number = {CS-TR-05/2}
}

@ARTICLE{Brazma:miame01,
  author = {Alvis Brazma and P Hingamp and J Quackenbush and G Sherlock and P
	Spellman and C Stoeckert and J Aach and W Ansorge and C A Ball and
	H C Causton and T Gaasterland and P Glenisson and F C P Holstege
	and I F Kim and V Markowitz and J C Matese and H Parkinson and A
	Robinson and U Sarkans and S Schulze-Kremer and J Stewart and R Taylor
	and J Vilo and M Vingron},
  title = {Minimum information about a microarray experiment ({MIAME}) --- toward
	standards for microarray data},
  journal = {Nature Genetics},
  year = {2001},
  volume = {29},
  pages = {365--371}
}

@ARTICLE{Brazma:gene00,
  author = {Alvis Brazma and L. Vilo},
  title = {Gene Expression Data Analysis},
  journal = {FEBS Letters},
  year = {2000},
  volume = {480},
  pages = {17--24}
}

@ARTICLE{Brem2002,
  author = {Rachel B Brem and Gaël Yvert and Rebecca Clinton and Leonid Kruglyak},
  title = {Genetic dissection of transcriptional regulation in budding yeast.},
  journal = {Science},
  year = {2002},
  volume = {296},
  pages = {752--755},
  number = {5568},
  month = {Apr},
  abstract = {To begin to understand the genetic architecture of natural variation
	in gene expression, we carried out genetic linkage analysis of genomewide
	expression patterns in a cross between a laboratory strain and a
	wild strain of Saccharomyces cerevisiae. Over 1500 genes were differentially
	expressed between the parent strains. Expression levels of 570 genes
	were linked to one or more different loci, with most expression levels
	showing complex inheritance patterns. The loci detected by linkage
	fell largely into two categories: cis-acting modulators of single
	genes and trans-acting modulators of many genes. We found eight such
	trans-acting loci, each affecting the expression of a group of 7
	to 94 genes of related function.},
  doi = {10.1126/science.1069516},
  institution = {Fred Hutchinson Cancer Research Center (FHCRC), 1100 Fairview Avenue
	North, D4-100, Seattle, WA 98109, USA and Howard Hughes Medical Institute.},
  keywords = {Chromosome Mapping; Crosses, Genetic; DNA-Binding Proteins; Fungal
	Proteins, genetics/metabolism; Gene Expression Profiling; Gene Expression
	Regulation, Fungal; Genes, Fungal; Genetic Linkage; Genetic Markers;
	Genome, Fungal; Genotype; Oligonucleotide Array Sequence Analysis;
	Polymorphism, Genetic; RNA, Fungal, genetics/metabolism; RNA, Messenger,
	genetics/metabolism; Regulatory Sequences, Nucleic Acid; Saccharomyces
	cerevisiae Proteins, genetics/metabolism; Saccharomyces cerevisiae,
	genetics/growth /&/ development/physiology; Trans-Activators, genetics/metabolism;
	Transcription Factors, genetics/metabolism; Transcription, Genetic},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {1069516},
  pmid = {11923494},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1126/science.1069516}
}

@INCOLLECTION{Bridle:softmax90,
  author = {J. S. Bridle},
  title = {Probabilistic interpretation of feedforward classification network
	outputs, with relationships to statistical pattern recognition},
  booktitle = {Neurocomputing: Algorithms, Architectures and Applications},
  publisher = springer,
  year = {1990},
  editor = {F. {Fogelman Souli\'{e}} and J. H\'{e}rault},
  pages = {227--236},
  address = {New York}
}

@ARTICLE{Brin:anatomy98,
  author = {Segey Brin and Lawrence Page},
  title = {The anatomy of a large-scale hypertextual web search engine},
  journal = {Computer Networks and ISDN Systems},
  year = {1998},
  volume = {30},
  pages = {107--117},
  number = {1--7},
  file = {google.pdf:http\://www-db.stanford.edu/pub/papers/google.pdf:PDF}
}

@MISC{Brookes:matrix05,
  author = {Michael Brookes},
  title = {The Matrix Reference Manual},
  howpublished = {Available on-line.},
  year = {2005},
  note = {\url{http://www.ee.ic.ac.uk/hp/staff/dmb/matrix/intro.html}},
  label1 = {Site},
  link1 = {http://www.ee.ic.ac.uk/hp/staff/dmb/matrix/}
}

@ARTICLE{Broomhead:rbfs88,
  author = {D. S. Broomhead and David Lowe},
  title = {Multivariable functional interpolation and adaptive networks},
  journal = {Complex Systems},
  year = {1988},
  volume = {2},
  pages = {321--355}
}

@ARTICLE{Brown:cytokineDestabilize96,
  author = {Cheryl Y. Brown and Cathy A. Lagnado and Gregory J. Goodall},
  title = {A cytokine {mRNA}-destabilizing element that is structurally and
	functionally distinct from {A+U}-rich elements },
  journal = pnasusa,
  year = {1996},
  volume = {93},
  pages = {13721--13725},
  number = {24},
  abstract = {The control of mRNA stability is crucial to the regulation of cytokine
	expression. We describe here a novel, potent destabilizing element
	found in the 3' untranslated region of granulocyte colony-stimulating
	factor mRNA. This element, which appears to require at least one
	stem-loop structure, we term the stem-loop destabilizing element
	(SLDE). Functionally equivalent elements appear to also exist in
	the interleukin 2 and interleukin 6 mRNAs. The SLDE is functionally
	distinct from the A+U-rich elements, which are also present in these
	and other cytokine mRNAs, because it destabilizes a chimeric mRNA
	in a tumor cell line in which A+U-rich elements do not function.
	In addition, the effect of the SLDE is insensitive to calcium ionophore
	and is therefore regulated independently of A+U destabilizing elements.
	The existence of two distinct mRNA-destabilizing elements provides
	an additional mechanism for the differential regulation of cytokine
	expression.},
  file = {picrender.fcgi?artid=19403&blobtype=pdf:http\://www.pubmedcentral.nih.gov/picrender.fcgi?artid=19403&blobtype=pdf:PDF},
  group = {cytokine},
  pmid = {8943001}
}

@ARTICLE{Brown:speech94,
  author = {Guy J. Brown and Martin P. Cooke},
  title = {Computational Auditory Scene Analysis},
  journal = CSL,
  year = {1994},
  volume = {8},
  pages = {297--333},
  file = {csl.pdf:http\://www.dcs.shef.ac.uk/~guy/pdf/csl.pdf:PDF}
}

@ARTICLE{Brown:yeastsvm2000,
  author = {M. Brown and W. N. Grundy and D. Lin and Nello Cristianini and C.
	Sugnet and Manuel {Ares Jr} and David Haussler},
  title = {The optimised internal representation of multilayer classifier networks
	performs nonlinear discriminant analysis},
  journal = pnasusa,
  year = {2000},
  volume = {97},
  pages = {17--14}
}

@ARTICLE{Bruniquel2003,
  author = {Denis Bruniquel and Ronald H Schwartz},
  title = {Selective, stable demethylation of the interleukin-2 gene enhances
	transcription by an active process.},
  journal = {Nat Immunol},
  year = {2003},
  volume = {4},
  pages = {235--240},
  number = {3},
  month = {Mar},
  abstract = {A role for DNA demethylation in transcriptional regulation of genes
	expressed in differentiated somatic cells remains controversial.
	Here, we define a small region in the promoter-enhancer of the interleukin-2
	(Il2) gene that demethylates in T lymphocytes following activation,
	and remains demethylated thereafter. This epigenetic change was necessary
	and sufficient to enhance transcription in reporter plasmids. The
	demethylation process started as early as 20 minutes after stimulation
	and was not prevented by a G1 to S phase cell cycle inhibitor that
	blocks DNA replication. These results imply that this demethylation
	process proceeds by an active enzymatic mechanism.},
  doi = {10.1038/ni887},
  institution = {Laboratory of Cellular and Molecular Immunology, National Institute
	of Allergy and Infectious Diseases, National Institutes of Health,
	Bethesda, MD 20892-0420, USA.},
  keywords = {Animals; CD4-Positive T-Lymphocytes, physiology; DNA Methylation,
	drug effects; Interleukin-2, genetics; Mice; Mice, Transgenic; Promoter
	Regions, Genetic; Receptors, Antigen, T-Cell, genetics; Sirolimus,
	pharmacology; Transcription, Genetic, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ni887},
  pmid = {12548284},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/ni887}
}

@TECHREPORT{Buckheit:wavelab95,
  author = {Jonathan B. Buckheit and David L. Donoho},
  title = {{WaveLab} and Reproducible Research},
  institution = {Stanford University},
  year = {1995},
  file = {wavelab.pdf:http\://www-stat.stanford.edu/~donoho/Reports/1995/wavelab.pdf:PDF}
}

@ARTICLE{Buhmann:vq93,
  author = {Joachim Buhmann and K. K\"{u}hnel},
  title = {Vector Quantization with Complexity Costs},
  journal = {IEEE Transactions on Information Theory},
  year = {1993},
  volume = {39},
  pages = {1133--1145},
  number = {4},
  linkpsgz = {http://www-dbv.cs.uni-bonn.de/postscript/buhmann.ccvq.ps.gz}
}

@ARTICLE{Buja:96,
  author = {Andreas Buja and Dianne Cook and Deborah F Swayne},
  title = {Interactive High-Dimensional Data Visualization},
  journal = {Journal of Computational and Graphical Statistics},
  year = {1996},
  volume = {5},
  pages = {78--99},
  number = {1}
}

@ARTICLE{Buntine:guide96,
  author = {Wray L. Buntine},
  title = {A Guide to the Literature on Learning Probabilistic Networks from
	Data},
  journal = TKDE,
  year = {1996},
  volume = {8},
  pages = {195--210},
  number = {2}
}

@ARTICLE{Buntine:hessian93,
  author = {Wray L. Buntine and Anders S. Weigend},
  title = {Computing second derivatives in feed-forward networks: a review},
  journal = IEEE,
  year = {1993},
  volume = {5},
  pages = {480--488},
  number = {3}
}

@ARTICLE{Buntine:bayes91,
  author = {Wray L. Buntine and Anders S. Weigend},
  title = {{B}ayesian back-propagation},
  journal = {Complex Systems},
  year = {1991},
  volume = {5},
  pages = {603--643}
}

@ARTICLE{Burch2005,
  author = {John B E Burch},
  title = {Regulation of {GATA} gene expression during vertebrate development},
  journal = {Semin Cell Dev Biol},
  year = {2005},
  volume = {16},
  pages = {71--81},
  number = {1},
  month = {Feb},
  abstract = {GATA factors regulate critical events in hematopoietic lineages (GATA-1/2/3),
	the heart and gut (GATA-4/5/6) and various other tissues. Transgenic
	approaches have revealed that GATA genes are regulated in a modular
	fashion by sets of enhancers that govern distinct temporal and/or
	spatial facets of the overall expression patterns. Efforts are underway
	to resolve how these GATA gene enhancers are themselves regulated
	in order to elucidate the genetic and molecular hierarchies that
	govern GATA expression in particular developmental contexts. These
	enhancers also afford a raft of tools that can be used to selectively
	perturb and probe various developmental events in transgenic animals.},
  doi = {10.1016/j.semcdb.2004.10.002},
  institution = {Cell and Developmental Biology Program, Fox Chase Cancer Center,
	333 Cottman Avenue, Philadelphia, PA 19111, USA. john.burch@fccc.edu},
  keywords = {Animals; DNA-Binding Proteins, genetics/metabolism; Enhancer Elements,
	Genetic; Erythroid-Specific DNA-Binding Factors; Fishes, growth /&/
	development; GATA2 Transcription Factor; GATA3 Transcription Factor;
	GATA4 Transcription Factor; GATA5 Transcription Factor; GATA6 Transcription
	Factor; Gene Expression Regulation, Developmental; Heart, growth
	/&/ development; Intestines, growth /&/ development; Trans-Activators,
	genetics; Transcription Factors, genetics/metabolism; Vertebrates,
	growth /&/ development/metabolism},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pii = {S1084-9521(04)00098-9},
  pmid = {15659342},
  timestamp = {2010.04.08}
}

@TECHREPORT{Burges:simplifiedsv,
  author = {C. J. C. Burges},
  title = {Simplified Support Vector Decision Rules},
  institution = {Bell Laboratories, Lucent Technologies},
  optyear = {after 1995}
}

@ARTICLE{Burges:tut98,
  author = {C. J. C. Burges},
  title = {A Tutorial on Support Vector Machines for Pattern Recognition},
  journal = {Data Mining and Knowledge Discovery},
  year = {1998},
  volume = {2},
  pages = {121--167},
  number = {2}
}

@ARTICLE{Burns:razor15,
  author = {C Delisle Burns},
  title = {Occam's Razor},
  journal = {Mind},
  year = {1915},
  volume = {24},
  pages = {392}
}

@ARTICLE{Burrascano:delta91,
  author = {P. Burrascano},
  title = {A norm selection criterion for the generalized delta rule},
  journal = IEEE,
  year = {1991},
  volume = {2},
  pages = {125--130},
  number = {1}
}

@BOOK{Butkovskiy:characteristics1993,
  title = {Characteristics of Distributed-Parameter Systems},
  publisher = {Kluwer Academic Publishers},
  year = {1993},
  author = {A. G. Butkovskiy and L. M. Pustyl'nikov}
}

@ARTICLE{Byrd:lbfgsb95,
  author = {Richard H. Byrd and Peihuang Lu and Jorge Nocedal},
  title = {A Limited Memory Algorithm for Bound Constrained Optimization},
  journal = {SIAM Journal on Scientific and Statistical Computing},
  year = {1995},
  volume = {16},
  pages = {1190--1208},
  number = {5},
  abstract = {An algorithm for solving large nonlinear optimization problems with
	simple bounds is described. It is based on the gradient projection
	method and uses a limted memory BFGS matrix to approximate the hessian
	of the objective function. It is shown to take advantage of the form
	of the limited memory approximation to implement the algorithm efficiently.
	The results of numerical tests on a a set of large problems are reported.},
  group = {optimisation},
  linkpsgz = {http://www.ece.northwestern.edu/~nocedal/PSfiles/limited.ps.gz},
  linksoftware = {http://www.ece.northwestern.edu/~nocedal/lbfgsb.html}
}

@ARTICLE{Calder:dynamic08,
  author = {Catherine A. Calder},
  title = {A dynamic process convolution approach to modeling ambient particulate
	matter concentrations},
  journal = {Environmetrics},
  year = {2008},
  volume = {19},
  pages = {39-48}
}

@ARTICLE{Calder:kalmanConvolution07,
  author = {Catherine A. Calder},
  title = {Dynamic factor process convolution models for multivariate space-time
	data with application to air quality assessment},
  journal = {Environmental and Ecological Statistics},
  year = {2007},
  volume = {14},
  pages = {229-247},
  number = {3}
}

@PHDTHESIS{Calder:thesis03,
  author = {Catherine A. Calder},
  title = {Exploring latent structure in spatial temporal processes using process
	convolutions},
  school = {Institute of Statistics and Decision Sciences, Duke University},
  year = {2003},
  address = {Durham, NC, USA}
}

@INPROCEEDINGS{Calder:convolution07,
  author = {Catherine A. Calder and Noel A. C. Cressie},
  title = {{S}ome Topics in Convolution-Based Spatial Modeling},
  booktitle = {Proceedings of the 56th Session of the International Statistics Institute},
  year = {2007},
  month = {August}
}

@ARTICLE{Calderhead:estimating08,
  author = {Ben Calderhead and Mark Girolami},
  title = {Estimating Bayes Factors for Nonlinear ODE Models by Thermodynamic
	Integration via Population MCMC},
  journal = {Statistics and Computing},
  year = {2008},
  group = {Bayes ranking, systems biology}
}

@ARTICLE{Calvetti:implicitly94,
  author = {Daniela Calvetti and L. Reichel and D. C. Sorensen},
  title = {An implicitly restarted {L}anczos method for large symmetric eigenvalue
	problems},
  journal = {Electronic Transactions on Numerical Analysis},
  year = {1994},
  volume = {2},
  pages = {1--21},
  file = {pp1-21.pdf:ftp\://ftp.maths.tcd.ie/pub/EMIS/journals/ETNA/vol.2.1994/pp1-21.dir/pp1-21.pdf:PDF},
  linkps = {ftp://ftp.maths.tcd.ie/pub/EMIS/journals/ETNA/vol.2.1994/pp1-21.dir/pp1-21.ps}
}

@ARTICLE{Campbell:crabs74,
  author = {N. A. Campbell and R. J. Mahon},
  title = {A multi-variate study of variation in two species of rock crab of
	genus {\emph{Leptograpsus}}},
  journal = {Australian Journal of Zoology},
  year = {1974},
  volume = {22},
  pages = {417--425}
}

@ARTICLE{Canny:edge86,
  author = {John Canny},
  title = {A Computational Approach to Edge Detection},
  journal = PAMI,
  year = {1986},
  volume = {8},
  pages = {679--698},
  number = {6}
}

@ARTICLE{Caponnetto:universal08,
  author = {Andrea Caponnetto and Charles A. Micchelli and Massimiliano Pontil
	and Yiming Ying},
  title = {Universal Kernels for Multi-Task Learning},
  journal = jmlr,
  year = {2008},
  volume = {9},
  pages = {1615--1646},
  issn = {1533-7928}
}

@ARTICLE{Cardoso:blind98,
  author = {Jean-Francois Cardoso},
  title = {Blind Signal Separation: Statistical Principles},
  journal = {Proceedings of the IEEE},
  year = {1998},
  volume = {9},
  pages = {2009--2025},
  number = {10}
}

@ARTICLE{Cardoso:infomax97,
  author = {Jean-Francois Cardoso},
  title = {Infomax and Maximum Likelihood for Blind Source Separation},
  journal = {IEEE Letters on Signal Processing},
  year = {1997},
  volume = {4},
  pages = {112--114},
  number = {4}
}

@ARTICLE{Carmeli:vector06,
  author = {Claudio Carmeli and Ernesto De Vito and Alessandro Toigo},
  title = {Vector valued reproducing kernel {H}ilbert spaces of integrable functions
	and {M}ercer theorem},
  journal = {Anal. Appl. (Singap.)},
  year = {2006},
  volume = {4},
  pages = {377--408},
  number = {4},
  fjournal = {Analysis and Applications}
}

@ARTICLE{Carrivick:identification06,
  author = {L. Carrivick and Simon Rogers and J. Clark and Colin Campbell and
	Mark Girolami and C. Cooper},
  title = {Identification of Prognostic Signatures in Breast Cancer Microarray
	Data using {B}ayesian Techniques},
  journal = {The Journal of the Royal Society Interface},
  year = {2006},
  volume = {3},
  pages = {367--381},
  number = {8},
  abstract = {We apply a new Bayesian data analysis technique (latent process decomposition)
	to four recent microarray datasets for breast cancer. Compared to
	hierarchical cluster analysis, for example, this technique has advantages
	such as objective assessment of the optimal number of sample or gene
	clusters in the data, penalization of overcomplex models fitting
	to noise in the data and a common latent space of explanatory variables
	for samples and genes. Our analysis provides a clearer insight into
	these datasets, enabling assignment of patients to one of four principal
	processes, each with a distinct clinical outcome. One process is
	indolent and associated with under-expression across a number of
	genes associated with tumour growth. One process is associated with
	over expression of GRB7 and ERBB2. The most aggressive process is
	associated with abnormal expression of transcription factor genes,
	including members of the FOX family of transcription factor genes.},
  doi = {10.1098/rsif.2005.0093},
  file = {L38M4771988U6521.pdf:http\://www.journals.royalsoc.ac.uk/index/L38M4771988U6521.pdf:PDF},
  group = {breast cancer, microarray},
  optpmid = {16849266}
}

@INPROCEEDINGS{Carroll:radon89,
  author = {S. M. Carroll and B. W. Dickinson},
  title = {Construction of Neural Nets Using the Radon Transform},
  booktitle = {Proceedings of the International Joint Conference on Neural Networks},
  year = {1989},
  volume = {1},
  pages = {607--611},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@ARTICLE{Caruana:multitask97,
  author = {Rich Caruana},
  title = {Multitask Learning},
  journal = {Machine Learning},
  year = {1997},
  volume = {28},
  pages = {41-75},
  number = {1}
}

@ARTICLE{Cayley:colour79,
  author = {A. Cayley},
  title = {On the colourings of maps},
  journal = {Proceedings of the Royal Geographical Society},
  year = {1879},
  volume = {1},
  pages = {259--261}
}

@ARTICLE{Cerf:packet74,
  author = {Vinton G Cerf and Robert E Kahn},
  title = {A Protocol for Packet Network Intercommunication},
  journal = {IEEE Transactions on Communications},
  year = {1974},
  volume = {COM-22},
  pages = {637--648},
  number = {5},
  group = {npa}
}

@INCOLLECTION{Challenor:towards06,
  author = {Peter G. Challenor and Robin K. S. Hankin and Robert Marsh},
  title = {Towards the probability of rapid climate change},
  booktitle = {Avoiding Dangerous Climate Change},
  publisher = cup,
  year = {2006},
  editor = {Hans Joachim Schellnhuber and Wolfgang Cramer and Nebojsa Nakicenovic
	and Tom Wigley and Gary Yohe},
  pages = {55--63},
  abstract = {The climate of North West Europe is mild compared to Alaska because
	the overturning circulation in the Atlantic carries heat northwards.
	If this circulation were to collapse, as it appears to have done
	inthe past, the climate of Europe, and the whole Northern Hemisphere,
	could change rapidly. This event is normally classified as a `low
	probability/high impact' event, but there have been few attempts
	to quantify the probability. We present a statistical method that
	can be used, with a climate model, to estimate the probability of
	such a rapid climate change. To illustrate the method we use an intermediate
	complexity climate model, C-GOLDSTEIN combined with the SRES illustrative
	emission scenarios. The resulting probabilities are much higher than
	would be expected for a low probability event, around 30-40\% depending
	upon the scenario. The most probable reason for this is the simplicity
	of the climate model, but the possibility exists that we may be at
	greater risk than we believed.},
  isbn = {0-521-86-4712}
}

@ARTICLE{Chaloner:experimental95,
  author = {Kathryn Chaloner and Isabella Verdinelli},
  title = {Bayesian Experimental Design: A Review},
  journal = {Statistical Science},
  year = {1995},
  volume = {10},
  pages = {273--304},
  number = {3},
  abstract = {This paper reviews the literature on Bayesian experimental design,
	both for linear and non-linear models. A unified view of the topic
	is presented by putting experimental design in a decision theoretic
	framework. This framework justifies many optimality criteria, and
	opens new possibilities. Various design criteria become part of a
	single, coherent approach.},
  file = {Chaloner%20Verdinelli.pdf:http\://www.stat.uiowa.edu/~gwoodwor/AdvancedDesign/Chaloner%20Verdinelli.pdf:PDF},
  group = {decision theory, experimental design}
}

@INPROCEEDINGS{Chauvin:hidden89,
  author = {Y. Chauvin},
  title = {A back-propagation algorithm with optimal use of hidden units},
  booktitle = nips,
  year = {1989},
  editor = {D. S. Touretzky},
  volume = {1},
  pages = {519--526},
  address = {San Mateo, CA},
  publisher = {Morgan Kaufmann}
}

@ARTICLE{Chen:geometry93,
  author = {A. M. Chen and H. Lu and R. Hecht-Nielsen},
  title = {On the geometry of feedforward neural network error surfaces},
  journal = NC,
  year = {1993},
  volume = {5},
  pages = {910--927},
  number = {6}
}

@ARTICLE{Chen:aurich95,
  author = {Chyi-Ying A. Chen and Ann-Bin Shyu},
  title = {{AU}-rich elements: characterization and importance in {mRNA} degradation},
  journal = trendsbio,
  year = {1995},
  volume = {20},
  pages = {465--470},
  number = {11},
  abstract = {Adenylate/uridylate-rich elements (AREs) are found in the 3' untranslated
	region (UTR) of many messenger RNAs (mRNAs) that code for proto-oncogenes,
	nuclear transcription factors and cytokines. They represent the most
	common determinant of RNA stability in mammalian cells. Moreover,
	ARE-directed mRNA degradation is influenced by many exogenous factors,
	including phorbol esters, calcium ionophores, cytokines and transcription
	inhibitors. These observations suggest that AREs play a critical
	role in the regulation of gene expression during cell growth and
	differentiation, and in the immune response.},
  doi = {10.1016/S0968-0004(00)89102-1},
  group = {cytokine}
}

@ARTICLE{Chen:ols89,
  author = {S. Chen and S. A. Billings and W. Luo},
  title = {Orthogonal least squares methods and their application to non-linear
	system identification},
  journal = {International Journal of Control},
  year = {1989},
  volume = {50},
  pages = {1873--1896},
  number = {5}
}

@ARTICLE{Chen:ols91,
  author = {S. Chen and C. F. N. Cowan and P. M. Grant},
  title = {Orthogonal least squares learning algorithm for radial basis function
	networks},
  journal = IEEE,
  year = {1991},
  volume = {2},
  pages = {302--309},
  number = {2}
}

@ARTICLE{Chen:ols92,
  author = {S. Chen and P. M. Grant and C. F. N. Cowan},
  title = {Orthogonal least-squares algorithm for training multioutput radial
	basis function networks},
  journal = {IEE Proceedings, F},
  year = {1992},
  volume = {139},
  pages = {378--384},
  number = {6}
}

@INPROCEEDINGS{Chen:inferring10,
  author = {Yu Chen and Tae-Kyun Kim and Roberto Cipolla},
  title = {Inferring 3D Shapes and Deformations from Single Views},
  booktitle = eccv,
  year = {2010}
}

@ARTICLE{Titterington:review94,
  author = {B. Cheng and David M. Titterington},
  title = {Neural networks: a review from a statistical perspective},
  journal = {Statistical Science},
  year = {1994},
  volume = {9},
  pages = {2--54},
  number = {1}
}

@ARTICLE{Cheng:phosphorylation98,
  author = {Xiaodong Cheng and Yuliang Ma and Michael Moore and Brian A. Hemmings
	and Susan S. Taylor},
  title = {Phosphorylation and activation of cAMP-dependent protein kinase by
	phosphoinositide-dependent protein kinase},
  journal = pnasusa,
  year = {1998},
  volume = {95},
  number = {17},
  abstract = {Although phosphorylation of Thr-197 in the activation loop of the
	catalytic subunit of cAMP-dependent protein kinase (PKA) is an essential
	step for its proper biological function, the kinase responsible for
	this reaction in vivo has remained elusive. Using nonphosphorylated
	recombinant catalytic subunit as a substrate, we have shown that
	the phosphoinositide-dependent protein kinase, PDK1, expressed in
	293 cells, phosphorylates and activates the catalytic subunit of
	PKA. The phosphorylation of PKA by PDK1 is rapid and is insensitive
	to PKI, the highly specific heat-stable protein kinase inhibitor.
	A mutant form of the catalytic subunit where Thr-197 was replaced
	with Asp was not a substrate for PDK1. In addition, phosphorylation
	of the catalytic subunit can be monitored immunochemically by using
	antibodies that recognize Thr-197 phosphorylated enzyme but not unphosphorylated
	enzyme or the Thr197Asp mutant. PDK1, or one of its homologs, is
	thus a likely candidate for the in vivo PKA kinase that phosphorylates
	Thr-197. This finding opens a new dimension in our thinking about
	this ubiquitous protein kinase and how it is regulated in the cell.},
  group = {phosphorylation},
  optpages = {9849–-9854}
}

@ARTICLE{Cheung2009,
  author = {Vivian G Cheung and Richard S Spielman},
  title = {Genetics of human gene expression: mapping DNA variants that influence
	gene expression.},
  journal = {Nat Rev Genet},
  year = {2009},
  volume = {10},
  pages = {595--604},
  number = {9},
  month = {Sep},
  abstract = {There is extensive natural variation in human gene expression. As
	quantitative phenotypes, expression levels of genes are heritable.
	Genetic linkage and association mapping have identified cis- and
	trans-acting DNA variants that influence expression levels of human
	genes. New insights into human gene regulation are emerging from
	genetic analyses of gene expression in cells at rest and following
	exposure to stimuli. The integration of these genetic mapping results
	with data from co-expression networks is leading to a better understanding
	of how expression levels of individual genes are regulated and how
	genes interact with each other. These findings are important for
	basic understanding of gene regulation and of diseases that result
	from disruption of normal gene regulation.},
  doi = {10.1038/nrg2630},
  institution = {Howard Hughes Medical Institute, University of Pennsylvania, Philadelphia,
	Pennsylvania 19104, USA. vcheung@mail.med.upenn.edu},
  keywords = {Chromosome Mapping, methods; Epistasis, Genetic, genetics; Gene Expression
	Regulation, genetics; Genetic Linkage; Genetic Variation, physiology;
	Humans; Models, Biological},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {nrg2630},
  pmid = {19636342},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/nrg2630}
}

@TECHREPORT{Chickering:NPhard94,
  author = {D. M. Chickering and D. Geiger and David Heckerman},
  title = {Learning {B}ayesian networks is {NP-hard}},
  institution = {Microsoft Research},
  year = {1994},
  number = {MSR-TR-94-17},
  note = {Available from \url{http://research.microsoft.com/\~{ }heckerman/}},
  optmonth = {#Nov#}
}

@ARTICLE{Chidananda:CNN79,
  author = {K. {Chidananda Gowda} and G. Krishna},
  title = {The condensed nearest neighbor rule using the concept of mutual nearest
	neighbourhood},
  journal = {TIT},
  year = {1979},
  volume = {25},
  pages = {488--490}
}

@MASTERSTHESIS{Chin:mthesis98,
  author = {K. K. Chin},
  title = {Support Vector Machines applied to Speech Pattern Classification},
  school = {Department of Engineering, University of Cambridge},
  year = {1998},
  month = Aug
}

@TECHREPORT{Cho:frequency00,
  author = {Junghoo Cho and Hector Garcia-Molina},
  title = {Estimating Frequency of Change},
  institution = {Stanford University},
  year = {2000},
  note = {Available from \url{http://www-db.stanford.edu/\~{ }cho/publications.html}}
}

@INPROCEEDINGS{Cho:synchronizing00,
  author = {Junghoo Cho and Hector Garcia-Molina},
  title = {Synchronizing a database to Improve Freshness},
  booktitle = {Proceedings 2000 ACM International Conference on Management of Data
	(SIGMOD)},
  year = {2000}
}

@ARTICLE{Choe:preferred05,
  author = {S. E. Choe and M. Boutros and A. M. Michelson and G. M. Church and
	M. S. Halfon},
  title = {Preferred Analysis Methods for {Affymetrix} {GeneChips} revealed
	by a Wholly Defined Control Dataset},
  journal = {Genome Biology},
  year = {2005},
  volume = {6},
  number = {R16}
}

@ARTICLE{Chou2010,
  author = {Jonathan Chou and Sylvain Provot and Zena Werb},
  title = {{GATA3} in development and cancer differentiation: cells {GATA} have
	it!},
  journal = {J Cell Physiol},
  year = {2010},
  volume = {222},
  pages = {42--49},
  number = {1},
  month = {Jan},
  abstract = {There is increasing evidence that the numerous mechanisms that regulate
	cell differentiation during normal development are also involved
	in tumorigenesis. In breast cancer, differentiation markers expressed
	by the primary tumor are routinely profiled to guide clinical decisions.
	Indeed, numerous studies have shown that the differentiation profile
	correlates with the metastatic potential of tumors. The transcription
	factor GATA3 has emerged recently as a strong predictor of clinical
	outcome in human luminal breast cancer. In the mammary gland, GATA3
	is required for luminal epithelial cell differentiation and commitment,
	and its expression is progressively lost during luminal breast cancer
	progression as cancer cells acquire a stem cell-like phenotype. Importantly,
	expression of GATA3 in GATA3-negative, undifferentiated breast carcinoma
	cells is sufficient to induce tumor differentiation and inhibits
	tumor dissemination in a mouse model. These findings demonstrate
	the exquisite ability of a differentiation factor to affect malignant
	properties, and raise the possibility that GATA3 or its downstream
	genes could be used in treating luminal breast cancer. This review
	highlights our recent understanding of GATA3 in both normal mammary
	development and tumor differentiation.},
  doi = {10.1002/jcp.21943},
  institution = {Department of Anatomy, University of California, San Francisco, California
	94143-0452, USA.},
  keywords = {Animals; Breast Neoplasms, pathology; Cell Differentiation; Embryonic
	Development; Female; GATA3 Transcription Factor, metabolism; Humans;
	Neoplasm Metastasis, pathology; Organ Specificity},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pmid = {19798694},
  timestamp = {2010.04.08}
}

@INPROCEEDINGS{Choudrey:flexible01,
  author = {Rizwan A. Choudrey and Stephen J. Roberts},
  title = {Flexible {B}ayesian Independent Component Analysis for Blind Source
	Separation},
  booktitle = {Proceedings of the 3rd International Conference on Independent Component
	Analysis and Blind Signal Separation, ICA 2001, San Diego, California},
  year = {2001}
}

@ARTICLE{Christensen2009,
  author = {Brock C Christensen and E. Andres Houseman and Carmen J Marsit and
	Shichun Zheng and Margaret R Wrensch and Joseph L Wiemels and Heather
	H Nelson and Margaret R Karagas and James F Padbury and Raphael Bueno
	and David J Sugarbaker and Ru-Fang Yeh and John K Wiencke and Karl
	T Kelsey},
  title = {Aging and environmental exposures alter tissue-specific DNA methylation
	dependent upon CpG island context.},
  journal = {PLoS Genet},
  year = {2009},
  volume = {5},
  pages = {e1000602},
  number = {8},
  month = {Aug},
  abstract = {Epigenetic control of gene transcription is critical for normal human
	development and cellular differentiation. While alterations of epigenetic
	marks such as DNA methylation have been linked to cancers and many
	other human diseases, interindividual epigenetic variations in normal
	tissues due to aging, environmental factors, or innate susceptibility
	are poorly characterized. The plasticity, tissue-specific nature,
	and variability of gene expression are related to epigenomic states
	that vary across individuals. Thus, population-based investigations
	are needed to further our understanding of the fundamental dynamics
	of normal individual epigenomes. We analyzed 217 non-pathologic human
	tissues from 10 anatomic sites at 1,413 autosomal CpG loci associated
	with 773 genes to investigate tissue-specific differences in DNA
	methylation and to discern how aging and exposures contribute to
	normal variation in methylation. Methylation profile classes derived
	from unsupervised modeling were significantly associated with age
	(P<0.0001) and were significant predictors of tissue origin (P<0.0001).
	In solid tissues (n = 119) we found striking, highly significant
	CpG island-dependent correlations between age and methylation; loci
	in CpG islands gained methylation with age, loci not in CpG islands
	lost methylation with age (P<0.001), and this pattern was consistent
	across tissues and in an analysis of blood-derived DNA. Our data
	clearly demonstrate age- and exposure-related differences in tissue-specific
	methylation and significant age-associated methylation patterns which
	are CpG island context-dependent. This work provides novel insight
	into the role of aging and the environment in susceptibility to diseases
	such as cancer and critically informs the field of epigenomics by
	providing evidence of epigenetic dysregulation by age-related methylation
	alterations. Collectively we reveal key issues to consider both in
	the construction of reference and disease-related epigenomes and
	in the interpretation of potentially pathologically important alterations.},
  doi = {10.1371/journal.pgen.1000602},
  institution = {Department of Pathology and Laboratory Medicine, Brown University,
	Providence, RI, USA.},
  keywords = {Adult; Age Factors; Aged; Aged, 80 and over; Aging, genetics; CpG
	Islands; DNA Methylation; Environmental Exposure; Epigenesis, Genetic;
	Female; Humans; Infant, Newborn; Male; Middle Aged; Organ Specificity},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {19680444},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1371/journal.pgen.1000602}
}

@Article{Jylanki:robust11,
  author = 	 {Pasi Jyl\"anki and Jarno Vanhatalo and Aki Vehtari},
  title = 	 {Robust {G}aussian Process Regression with a {S}tudent-$t$ Likelihood},
  journal = 	 jmlr,
  year = 	 {2011},
  OPTkey = 	 {},
  volume =	 {12},
  OPTnumber = 	 {},
  pages =	 {3227--3257},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Chu:ordinal04,
  author = 	 {Wei Chu and Zoubin Ghahramani},
  title = 	 {Gaussian Processes for Ordinal Regression},
  journal = 	 jmlr,
  year = 	 {2005},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  pages =	 {1019--1041},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  linkpdf =	 {http://www.gatsby.ucl.ac.uk/~chuwei/paper/gpor.pdf},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}


@ARTICLE{Chudin:assessment01,
  author = {Eugene Chudin and R Walker and A Kosaka and S Wu and D Rabert and
	T Chang and D Kreder},
  title = {Assessment of the relationship between signal intensities and transcript
	concentration for Affymetrix GeneChip arrays},
  journal = {Genome Biology},
  year = {2001},
  volume = {3},
  number = {1},
  abstract = {\bf{Background}\\ \\ Affymetrix microarrays have become increasingly
	popular in gene-expression studies; however, limitations of the technology
	have not been well established for commercially available arrays.
	The hybridization signal has been shown to be proportional to actual
	transcript concentration for specialized arrays containing hundreds
	of distinct probe pairs per gene. Additionally, the technology has
	been described as capable of distinguishing concentration levels
	within a factor of 2, and of detecting transcript frequencies as
	low as 1 in 2,000,000. Using commercially available arrays, we assessed
	these representations directly through a series of 'spike-in' hybridizations
	involving four prokaryotic transcripts in the absence and presence
	of fixed eukaryotic background. The contribution of probe-target
	interactions to the mismatch signal was quantified under various
	analyte concentrations.\\ \\ \bf{Results}\\ \\ A linear relationship
	between transcript abundance and signal was consistently observed
	between 1 pM and 10 pM transcripts. The signal ceased to be linear
	above the 10 pM level and commenced saturating around the 100 pM
	level. The 0.1 pM transcripts were virtually undetectable in the
	presence of eukaryotic background. Our measurements show that preponderance
	of the signal for mismatch probes derives from interactions with
	the target transcripts.\\ \\ \bf{Conclusions}\\ \\ Landmark studies
	outlining an observed linear relationship between signal and transcript
	concentration were carried out under highly specialized conditions
	and may not extend to commercially available arrays under routine
	operating conditions. Additionally, alternative metrics that are
	not based on the difference in the signal of members of a probe pair
	may further improve the quantitative utility of the Affymetrix GeneChip®
	array.},
  label1 = {PubMed},
  link1 = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?rendertype=abstract&artid=150452},
  optnote = {research0005}
}

@ARTICLE{Churchill2002,
  author = {Gary A Churchill},
  title = {Fundamentals of experimental design for cDNA microarrays.},
  journal = {Nat Genet},
  year = {2002},
  volume = {32 Suppl},
  pages = {490--495},
  month = {Dec},
  abstract = {Microarray technology is now widely available and is being applied
	to address increasingly complex scientific questions. Consequently,
	there is a greater demand for statistical assessment of the conclusions
	drawn from microarray experiments. This review discusses fundamental
	issues of how to design an experiment to ensure that the resulting
	data are amenable to statistical analysis. The discussion focuses
	on two-color spotted cDNA microarrays, but many of the same issues
	apply to single-color gene-expression assays as well.},
  doi = {10.1038/ng1031},
  institution = {The Jackson Laboratory, 600 Main Street, Bar Harbor, ME 04609, USA.
	garyc@jax.org},
  keywords = {Animals; DNA, Complementary, analysis; Gene Expression; Gene Expression
	Profiling, methods; Mice; Models, Biological; Oligonucleotide Array
	Sequence Analysis, methods; Reference Standards; Reproducibility
	of Results; Research Design; Statistics as Topic},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ng1031},
  pmid = {12454643},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/ng1031}
}

@ARTICLE{Cirz:inhibition05,
  author = {Ryan T. Cirz and Jodie K. Chin and David R. Andes and Valérie de
	Crécy-Lagard and William A. Craig and Floyd E. Romesberg},
  title = {Inhibition of Mutation and Combating the Evolution of Antibiotic
	Resistance},
  journal = {PLoS Biology},
  year = {2005},
  volume = {3},
  number = {6},
  optgroup = {SOS response}
}

@ARTICLE{Cohn:active96,
  author = {David A. Cohn and Zoubin Ghahramani and Michael I. Jordan},
  title = {Active Learning with Statistical Models},
  journal = jair,
  year = {1996},
  volume = {4},
  pages = {129--145},
  linkps = {http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/cohn96a.ps}
}

@ARTICLE{Coifman:diffusion06,
  author = {Ronald R. Coifman and Stephane Lafon},
  title = {Diffusion Maps},
  journal = {Applied Computational and harmonic Analysis},
  year = {2006},
  volume = {21},
  pages = {5--30}
}

@ARTICLE{Comon:ica94,
  author = {Pierre Comon},
  title = {Independent component analysis: a new concept?},
  journal = {Signal Processing},
  year = {1994},
  volume = {36},
  pages = {287--314}
}

@ARTICLE{HapMap:second08,
  author = {The International HapMap Consortium},
  title = {A second generation human haplotype map of over 3.1 million SNPs},
  journal = {Nature},
  year = {2008},
  abstract = {We describe the Phase II HapMap, which characterizes over 3.1 million
	human single nucleotide polymorphisms (SNPs) genotyped in 270 individuals
	from four geographically diverse populations and includes 25–35\%
	of common SNP variation in the populations surveyed. The map is estimated
	to capture untyped common variation with an average maximum r 2 of
	between 0.9 and 0.96 depending on population. We demonstrate that
	the current generation of commercial genome-wide genotyping products
	captures common Phase II SNPs with an average maximum r 2 of up to
	0.8 in African and up to 0.95 in non-African populations, and that
	potential gains in power in association studies can be obtained through
	imputation. These data also reveal novel aspects of the structure
	of linkage disequilibrium. We show that 10–30\% of pairs of individuals
	within a population share at least one region of extended genetic
	identity arising from recent ancestry and that up to 1\% of all common
	variants are untaggable, primarily because they lie within recombination
	hotspots. We show that recombination rates vary systematically around
	genes and between genes of different function. Finally, we demonstrate
	increased differentiation at non-synonymous, compared to synonymous,
	SNPs, resulting from systematic differences in the strength or efficacy
	of natural selection between populations.},
  doi = {10.1038/nature06258},
  group = {SNP},
  optpages = {851--861},
  optvolume = {449},
  pmid = {17943122}
}

@ARTICLE{Constantinopoulos:bayesian06,
  author = {C. Constantinopoulos and Michalis K. Titsias and A. Likas},
  title = {Bayesian Feature and Model Selection for {G}aussian Mixture Models},
  journal = PAMI,
  year = {2006},
  volume = {28},
  pages = {1013--1018},
  number = {6}
}

@ARTICLE{Conti:multi09,
  author = {Stefano Conti and Anthony O'Hagan},
  title = {Bayesian emulation of complex multi-output and dynamic computer models},
  journal = {Journal of Statistical Planning and Inference},
  year = {2009},
  volume = {140},
  pages = {640--651},
  number = {3},
  abstract = {Computer models are widely used in scientific research to study and
	predict the behaviour of complex systems. The run times of computer-intensive
	simulators are often such that it is impractical to make the thousands
	of model runs that are conventionally required for sensitivity analysis,
	uncertainty analysis or calibration. In response to this problem,
	highly efficient techniques have recently been developed based on
	a statistical meta-model (the emulator) that is built to approximate
	the computer model. The approach, however, is less straightforward
	for dynamic simulators, designed to represent time-evolving systems.
	Generalisations of the established methodology to allow for dynamic
	emulation are here proposed and contrasted. Advantages and difficulties
	are discussed and illustrated with an application to the Sheffield
	Dynamic Global Vegetation Model, developed within the UK Centre for
	Terrestrial Carbon Dynamics.},
  doi = {doi:10.1016/j.jspi.2009.08.006},
  keywords = {Bayesian inference, Computer experiments, Dynamic models, Hierarchical
	models}
}

@ARTICLE{Cooke:glimpsing03,
  author = {Martin P. Cooke},
  title = {Glimpsing Speech},
  journal = {Journal of Phonetics},
  year = {2003},
  volume = {31},
  pages = {579--584},
  number = {3--4}
}

@INCOLLECTION{Cool:modelling97,
  author = {T. Cool and H. K. D. H. Bhadeshia and David J. C. {MacKay}},
  title = {Modelling the Mechanical Properties in the {HAZ} of Power Plant Steels
	i: {B}ayesian Neural Network Analysis of Proof Strength},
  booktitle = {Mathematical Modelling of Weld Phenomena 3},
  publisher = {Institute of Materials},
  year = {1997},
  editor = {H. Cerjak},
  series = {Materials Modelling Series},
  pages = {403--441},
  address = {London}
}

@ARTICLE{Cooper:belief90,
  author = {Gregory F. Cooper},
  title = {The Computational Complexity of Using Probabilistic Inference Using
	{B}ayesian Belief Networks},
  journal = {Artificial Intelligence},
  year = {1990},
  volume = {42},
  pages = {393--405}
}

@ARTICLE{Cope:benchmark03,
  author = {L. M. Cope and Rafael A. Irizarry and H. Jaffee and Z. Wu and Terrence
	P. Speed},
  title = {A benchmark for {A}ffymetrix {GeneChip} Expression Measures},
  journal = bioinf,
  year = {2004},
  volume = {20},
  pages = {323--331},
  number = {3},
  file = {323.pdf?ijkey=83iw8rxPSScW6&keytype=ref:http\://bioinformatics.oxfordjournals.org/cgi/reprint/20/3/323.pdf?ijkey=83iw8rxPSScW6&keytype=ref:PDF}
}

@MISC{Corel:gallery98,
  author = {{Corel Corporation Ltd}},
  title = {{Corel GALLERY Magic 1,000,000}},
  howpublished = {Available from \url{http://www.corel.com}.},
  year = {1998},
  note = {Superceded by {Corel GALLERY 1,300,000}.}
}

@ARTICLE{Cortes:svnet95,
  author = {C. Cortes and Vladimir N. Vapnik},
  title = {Support Vector Networks},
  journal = ML,
  year = {1995},
  volume = {20},
  pages = {273--297},
  label1 = {SpringerLink},
  link1 = {http://www.springerlink.com/(3tpyqe45rso3ndnb3ug4onzz)/app/home/contribution.asp?referrer=parent&backto=issue,3,3;journal,21,124;linkingpublicationresults,1:400309,1}
}

@ARTICLE{Cotter:90,
  author = {N. E. Cotter},
  title = {The {S}tone-{W}eierstrass Theorem and its Application to Neural Networks},
  journal = IEEE,
  year = {1990},
  volume = {1},
  pages = {290--295},
  number = {4}
}

@ARTICLE{Cottrell:retinotopy86,
  author = {M. Cottrell and J. C. Fort},
  title = {A stochastic model of retinotopy: a self organizing process},
  journal = {Biological Cybernetics},
  year = {1986},
  volume = {53},
  pages = {405--411}
}

@ARTICLE{Coulthard2011,
  author = {Lydia R Coulthard and John C Taylor and Steve Eyre and Biologics
	in Rheumatoid Arthritis Genetics and Genomics and James I Robinson
	and Anthony G Wilson and John D Isaacs and Kimme Hyrich and Paul
	Emery and Anne Barton and Jennifer H Barrett and Ann W Morgan and
	Michael F McDermott},
  title = {Genetic variants within the MAP kinase signalling network and anti-TNF
	treatment response in rheumatoid arthritis patients.},
  journal = {Ann Rheum Dis},
  year = {2011},
  volume = {70},
  pages = {98--103},
  number = {1},
  month = {Jan},
  abstract = {Rheumatoid arthritis (RA) does not always respond to available treatments,
	including tumour necrosis factor (TNF) antagonists. A study was undertaken
	to investigate whether genetic variation within genes, encoding proteins
	in the p38 signalling network, contributes to the variable response
	to TNF antagonists.1102 UK Caucasian patients with RA receiving anti-TNF
	therapy (infliximab, adalimumab and etanercept) were genotyped for
	38 pairwise-tagging single nucleotide polymorphisms (SNPs) spanning
	12 candidate genes from the p38 network. Regression analyses were
	performed to test association between genotype and treatment response
	at 6 months using both absolute change in DAS28 (Disease Activity
	Score across 28 joints) and European League Against Rheumatism (EULAR)
	improvement criteria. Stratified analyses were performed to investigate
	association with individual therapies.Seven SNPs, in five genes,
	were associated with improvement in DAS28 at 6 months at a nominal
	0.1 significance level, jointly explaining 3\% of variance in outcome
	in a model adjusting for other predictors. These encoded proteins
	both upstream (MKK6) and downstream (MAPKAPK2, MSK1, MSK2) of p38,
	and MAPK14, the p38-α isoform of p38 MAPK. One SNP (rs2716191 in
	MAP2K6) was associated with EULAR response at the 0.1 level. SNPs
	generally showed greater correlation with response to infliximab
	and adalimumab, but not to etanercept.More SNPs than would be expected
	by chance, mapping to the p38 signalling network, showed association
	with the anti-TNF response as a whole, and particularly with the
	response to infliximab and adalimumab. Validation of these findings
	in independent cohorts is warranted.},
  doi = {10.1136/ard.2010.133249},
  institution = {NIHR-Leeds Musculoskeletal Biomedical Research Unit (NIHR-LMBRU),
	University of Leeds, Leeds, UK.},
  keywords = {Aged; Antibodies, Monoclonal, therapeutic use; Antirheumatic Agents,
	therapeutic use; Arthritis, Rheumatoid, drug therapy/genetics; Cohort
	Studies; Female; Genotype; Humans; Immunoglobulin G, therapeutic
	use; MAP Kinase Signaling System, genetics; Male; Middle Aged; Polymorphism,
	Single Nucleotide; Receptors, Tumor Necrosis Factor, therapeutic
	use; Severity of Illness Index; Treatment Outcome; Tumor Necrosis
	Factor-alpha, antagonists /&/ inhibitors; p38 Mitogen-Activated Protein
	Kinases, genetics},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ard.2010.133249},
  pmid = {20805296},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1136/ard.2010.133249}
}

@ARTICLE{Courcelle:comparative01,
  author = {Justin Courcelle and Arkady Khodursky and Brian Peter and Patrick
	O. Brown and and Philip C. Hanawalt},
  title = {Comparative Gene Expression Profiles Following {UV} Exposure in Wild-Type
	and {SOS}-Deficient \emph{Escherichia coli}},
  journal = {Genetics},
  year = {2001},
  volume = {158},
  pages = {41--64},
  abstract = {The SOS response in UV-irradiated Escherichia coli includes the upregulation
	of several dozen genes that are negatively regulated by the LexA
	repressor. Using DNA microarrays containing amplified DNA fragments
	from 95.5\% of all open reading frames identified on the E. coli
	chromosome, we have examined the changes in gene expression following
	UV exposure in both wild-type cells and lexA1 mutants, which are
	unable to induce genes under LexA control. We report here the time
	courses of expression of the genes surrounding the 26 documented
	lexA-regulated regions on the E. coli chromosome. We observed 17
	additional sites that responded in a lexA-dependent manner and a
	large number of genes that were upregulated in a lexA-independent
	manner although upregulation in this manner was generally not more
	than twofold. In addition, several transcripts were either downregulated
	or degraded following UV irradiation. These newly identified UV-responsive
	genes are discussed with respect to their possible roles in cellular
	recovery following exposure to UV irradiation.},
  group = {E. coli, SOS response},
  pmid = {1461638}
}

@ARTICLE{Cover:geom65,
  author = {T. M. Cover},
  title = {Geometrical and statistical properties of systems of linear inequalities
	with applications in pattern recognition},
  journal = {IEEE Transactions on Electronic Computers},
  year = {1965},
  volume = {14},
  pages = {326--334}
}



@Article{Edwards:privacy04,
  author = 	 {Lilian Edwards},
  title = 	 {The Problem with Privacy},
  journal = 	 {International Review of Law Computers & Technology},
  year = 	 {2004},
  volume =	 {18},
  number =	 {3},
  pages =	 {263--294}
}

@ARTICLE{deFinetti:prevision37,
  author = {Bruno de Finetti},
  title = {La Pr\'evision: Ses Lois Logiques, Ses Sources Subjectives},
  journal = {Annales de l'Institut Henri Poincar\'e},
  volume = {7},
  pages = {1--68},
  year = {1937}
}
@ARTICLE{Cox:probability46,
  author = {R. T. Cox},
  title = {Probability, Frequency and Reasonable Expectation},
  journal = {American Journal of Physics},
  year = {1946},
  volume = {14},
  pages = {1--13},
  number = {1}
}

@MISC{Csato:gprt05,
  author = {Lehel Csat\'o},
  title = {Sparsity in {G}aussian Processes: Questions},
  howpublished = {Talk at the Sheffield Gaussian Process Round Table.},
  month = {June},
  year = {2005},
  note = {Slides available from \url{http://www.dcs.shef.ac.uk/ml/gprt/slides/lehelcsato.pdf}}
}

@PHDTHESIS{Csato:thesis02,
  author = {Lehel Csat\'o},
  title = {Gaussian Processes --- Iterative Sparse Approximations},
  school = {Aston University},
  year = {2002},
  linkpsgz = {http://www.ncrg.aston.ac.uk/~csatol/publications/thesis.ps.gz}
}

@ARTICLE{Csato:sparse02,
  author = {Lehel Csat\'o and Manfred Opper},
  title = {Sparse On-Line {G}aussian Processes},
  journal = NC,
  year = {2002},
  volume = {14},
  pages = {641--668},
  number = {3},
  abstract = {We develop an approach for sparse representations of Gaussian Process
	(GP) models (which are Bayesian types of kernel machines) in order
	to overcome their limitations for large data sets. The method is
	based on a combination of a Bayesian online algorithm together with
	a sequential construction of a relevant subsample of the data which
	fully specifies the prediction of the GP model. By using an appealing
	parametrisation and projection techniques that use the RKHS norm,
	recursions for the effective parameters and a sparse Gaussian approximation
	of the posterior process are obtained. This allows for both a propagation
	of predictions as well as of Bayesian error measures. The significance
	and robustness of our approach is demonstrated on a variety of experiments.},
  file = {CsatoOpper_SparseOnlineGP.pdf:http\://www.ncrg.aston.ac.uk/~csatol/publications/CsatoOpper_SparseOnlineGP.pdf:PDF},
  group = {spgp}
}

@ARTICLE{Csikasz-Nagy:cellcycle06,
  author = {A. Csikasz-Nagy and D. Battogtokh and K. C. Chen and B. Novak and
	J. J. Tyson},
  title = {Analysis of a generic model of eukaryotic cell-cycle regulation},
  journal = {Biophysical Journal},
  year = {2006},
  volume = {90},
  pages = {4361--4379},
  group = {gene networks}
}

@ARTICLE{Cucker:mathematical02,
  author = {Felipe Cucker and Stephen Smale},
  title = {On the Mathematical Foundations of Learning},
  journal = {Bull. Amer. Math. Soc. (N.S.)},
  year = {2002},
  volume = {39},
  pages = {1--49},
  number = {1},
  fjournal = {American Mathematical Society. Bulletin. New Series}
}

@ARTICLE{Custovic:maas02,
  author = {A. Custovic and B. M. Simpson and C. S. Murray and L. Lowe and A.
	Woodcock},
  title = {The National Asthma Campaign Manchester Asthma and Allergy Study},
  journal = {Pediatr Allergy Immunol},
  year = {2002},
  volume = {13},
  number = {Suppl. 15},
  optpages = {32--37}
}

@ARTICLE{Cybenko:approx89,
  author = {G. Cybenko},
  title = {Approximation by superpositions of a sigmoidal function},
  journal = {Mathematics of Control, Signals and Systems},
  year = {1989},
  volume = {2},
  pages = {304--314}
}

@ARTICLE{Dhaeseleer:genetic00,
  author = {Patrik D'haeseleer and Shoudan Liang and Roland Somogyi},
  title = {Genetic Network Inference: From Co-expression Clustering to Reverse
	Engineering},
  journal = bioinf,
  year = {2000},
  volume = {16},
  pages = {707--726},
  number = {8},
  abstract = {{\bf motivation:} Advances in molecular biological, analytical and
	computational technologies are enabling us to systematically investigate
	the complex molecular processes underlying biological systems. In
	particular, using high-throughput gene expression assays, we are
	able to measure the output of the gene regulatory network. We aim
	here to review datamining and modeling approaches for conceptualizing
	and unraveling the functional relationships implicit in these datasets.
	Clustering of co-expression profiles allows us to infer shared regulatory
	inputs and functional pathways. We discuss various aspects of clustering,
	ranging from distance measures to clustering algorithms and multiple-cluster
	memberships. More advanced analysis aims to infer causal connections
	between genes directly, i.e. who is regulating whom and how. We discuss
	several approaches to the problem of reverse engineering of genetic
	networks, from discrete Boolean networks, to continuous linear and
	non-linear models. We conclude that the combination of predictive
	modeling with systematic experimental verification will be required
	to gain a deeper insight into living organisms, therapeutic targeting
	and bioengineering.\\\\ {\bf Contact:} patrik@cs.unm.edu; sliang@mail.arc.nasa.gov;
	rsomogyi@incyte.com},
  file = {707.pdf:http\://bioinformatics.oxfordjournals.org/cgi/reprint/16/8/707.pdf:PDF},
  group = {gene networks}
}

@ARTICLE{Dagum:belief93,
  author = {Paul Dagum and Michael Luby},
  title = {Approximating probabilistic inference in {B}ayesian belief networks
	is {NP}-hard},
  journal = {Artificial Intelligence},
  year = {1993},
  volume = {60},
  pages = {141--153}
}

@ARTICLE{Davidson:regulatory02,
  author = {Eric H. Davidson and Jonathan P. Rast and Paola Oliveri and Andrew
	Ransick and Cristina Calestani and Chiou-Hwa Yuh and Takuya Minokawa
	and Gabriele Amore and Veronica Hinmand and C\'esar Arenas-Mena and
	Ochan Otim and C. Titus Brown and Carolina B. Livi and Pei Yun Lee
	and Roger Revilla and Alistair G. Rust and Zheng jun Pan and Maria
	J. Schilstra and Peter J. Clarke and Maria I. Arnone and Lee Rowen
	and R. Andrew Cameron and David R. {McClay} and Leroy Hood and Hamid
	Bolouri},
  title = {A Genomic Regulatory Network for Development},
  journal = {Science},
  year = {2002},
  volume = {295},
  pages = {1669--1678},
  abstract = {Development of the body plan is controlled by large networks of regulatory
	genes. A gene regulatory network that controls the specification
	of endoderm and mesoderm in the sea urchin embryo is summarized here.
	The network was derived from large-scale perturbation analyses, in
	combination with computational methodologies, genomic data, cis-regulatory
	analysis, and molecular embryology. The network contains over 40
	genes at present, and each node can be directly verified at the DNA
	sequence level by cis-regulatory analysis. Its architecture reveals
	specific and general aspects of development, such as how given cells
	generate their ordained fates in the embryo and why the process moves
	inexorably forward in developmental time.},
  file = {..%5C1669.pdf:http\://www.bio.davidson.edu/Courses/Molbio/MolStudents/spring2002/Hartman/only/..%5C1669.pdf:PDF},
  group = {gene networks},
  pmid = {11872831}
}

@ARTICLE{Dawid:prequential84,
  author = {A. Philip Dawid},
  title = {Present Position and Potential Developments: Some Personal Views:
	Statistical Theory: The Prequential Approach},
  journal = JRSSa,
  year = {1984},
  volume = {147},
  pages = {278--292}
}

@ARTICLE{Dawid:callibrated82,
  author = {A. Philip Dawid},
  title = {The Well-Callibrated {B}ayesian},
  journal = jasa,
  year = {1982},
  volume = {77},
  pages = {605--613}
}

@ARTICLE{Day:mixture69,
  author = {N. E. Day},
  title = {Estimating the components of a mixture of normal distributions},
  journal = {Biometrika},
  year = {1969},
  volume = {56},
  pages = {463--474},
  number = {3}
}

@ARTICLE{Hinton:helm96,
  author = {Peter Dayan and Geoffrey E. Hinton},
  title = {Varieties of {H}elmholtz Machines},
  journal = {Neural Networks},
  year = {1996},
  pages = {1385--1403}
}

@ARTICLE{Hinton:helm94,
  author = {Peter Dayan and Geoffrey E. Hinton and Radford M. Neal and Richard
	S. Zemel},
  title = {The {H}elmholtz machine},
  journal = NC,
  year = {1995},
  volume = {7},
  pages = {889--904},
  number = {5},
  linkpsgz = {http://www.cs.toronto.edu/~hinton/absps/helmholtz.ps.gz}
}

@ARTICLE{DellaGatta:direct08,
  author = {Giusy {Della Gatta} and Mukesh Bansal and Alberto Ambesi-Impiombato
	and Dario Antonini and Caterina Missero and Diego di Bernardo},
  title = {Direct Targets of the TRP63 transcription Factor Revealed by a Combination
	of Gene Expression Profiling and Reverse Engineering},
  journal = {Genome Research},
  year = {2008},
  volume = {18},
  pages = {939--948},
  number = {6},
  month = {Jun},
  abstract = {Genome-wide identification of bona-fide targets of transcription factors
	in mammalian cells is still a challenge. We present a novel integrated
	computational and experimental approach to identify direct targets
	of a transcription factor. This consists of measuring time-course
	(dynamic) gene expression profiles upon perturbation of the transcription
	factor under study, and in applying a novel "reverse-engineering"
	algorithm (TSNI) to rank genes according to their probability of
	being direct targets. Using primary keratinocytes as a model system,
	we identified novel transcriptional target genes of TRP63, a crucial
	regulator of skin development. TSNI-predicted TRP63 target genes
	were validated by Trp63 knockdown and by ChIP-chip to identify TRP63-bound
	regions in vivo. Our study revealed that short sampling times, in
	the order of minutes, are needed to capture the dynamics of gene
	expression in mammalian cells. We show that TRP63 transiently regulates
	a subset of its direct targets, thus highlighting the importance
	of considering temporal dynamics when identifying transcriptional
	targets. Using this approach, we uncovered a previously unsuspected
	transient regulation of the AP-1 complex by TRP63 through direct
	regulation of a subset of AP-1 components. The integrated experimental
	and computational approach described here is readily applicable to
	other transcription factors in mammalian systems and is complementary
	to genome-wide identification of transcription-factor binding sites.},
  doi = {10.1101/gr.073601.107},
  institution = {Telethon Institute of Genetics and Medicine, 80131 Naples, Italy.},
  keywords = {Algorithms; Animals; Binding Sites; Cells, Cultured; Chromatin Immunoprecipitation;
	Computational Biology; Gene Expression Profiling; Gene Regulatory
	Networks; Humans; Keratinocytes; Mice; Oligonucleotide Array Sequence
	Analysis; Phosphoproteins; Trans-Activators; Transcription Factor
	AP-1},
  owner = {neil},
  pii = {gr.073601.107},
  pmid = {18441228},
  timestamp = {2009.10.27},
  url = {http://dx.doi.org/10.1101/gr.073601.107}
}

@Article{Girolami:manifold11,
  author = 	 {Mark Girolami and Ben Calderhead},
  title = 	 {Riemann manifold Langevin and Hamiltonian Monte Carlo methods},
  journal = 	 JRSSb,
  year = 	 2011,
  volume =	 73,
  number =	 2,
  pages =	 {1--37}
}

@ARTICLE{Dempster:EM77,
  author = {Arthur P. Dempster and Nan M. Laird and Donald B. Rubin},
  title = {Maximum likelihood from incomplete data via the {EM} algorithm},
  journal = JRSSb,
  year = {1977},
  volume = {39},
  pages = {1--38},
  number = {1}
}

@ARTICLE{DeRisi:genetcont97,
  author = {DeRisi J., V.R. Iyer, P.O. Brown},
  title = {Exploring the metabolic and genetic control of gene expression on
	a genomic scale},
  journal = {Science},
  year = {1997},
  volume = {278},
  pages = {680--686}
}

@INPROCEEDINGS{DeSieno:concience88,
  author = {D. DeSieno},
  title = {Adding a concience to competitive learning},
  booktitle = {Proceedings IEEE International Conference on Neural Networks},
  year = {1988},
  pages = {117--124},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@ARTICLE{Diaconis:ppr84,
  author = {P. Diaconis and M. Shahshahani},
  title = {On nonlinear functions of linear combinations},
  journal = {SIAM Journal of Scienctific and Statistical Computing},
  year = {1984},
  volume = {5},
  pages = {175--191},
  number = {1}
}

@ARTICLE{Dixon2007,
  author = {Anna L Dixon and Liming Liang and Miriam F Moffatt and Wei Chen and
	Simon Heath and Kenny C C Wong and Jenny Taylor and Edward Burnett
	and Ivo Gut and Martin Farrall and G. Mark Lathrop and Gonçalo R
	Abecasis and William O C Cookson},
  title = {A genome-wide association study of global gene expression.},
  journal = {Nat Genet},
  year = {2007},
  volume = {39},
  pages = {1202--1207},
  number = {10},
  month = {Oct},
  abstract = {We have created a global map of the effects of polymorphism on gene
	expression in 400 children from families recruited through a proband
	with asthma. We genotyped 408,273 SNPs and identified expression
	quantitative trait loci from measurements of 54,675 transcripts representing
	20,599 genes in Epstein-Barr virus-transformed lymphoblastoid cell
	lines. We found that 15,084 transcripts (28\%) representing 6,660
	genes had narrow-sense heritabilities (H2) > 0.3. We executed genome-wide
	association scans for these traits and found peak lod scores between
	3.68 and 59.1. The most highly heritable traits were markedly enriched
	in Gene Ontology descriptors for response to unfolded protein (chaperonins
	and heat shock proteins), regulation of progression through the cell
	cycle, RNA processing, DNA repair, immune responses and apoptosis.
	SNPs that regulate expression of these genes are candidates in the
	study of degenerative diseases, malignancy, infection and inflammation.
	We have created a downloadable database to facilitate use of our
	findings in the mapping of complex disease loci.},
  doi = {10.1038/ng2109},
  institution = {National Heart and Lung Institute, Imperial College London, London
	SW3 6LY, UK.},
  keywords = {Chaperonins, genetics; Child; Family; Gene Expression; Genome, Human;
	Genotype; Heat-Shock Proteins, genetics; Humans; Polymorphism, Single
	Nucleotide; Quantitative Trait, Heritable},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ng2109},
  pmid = {17873877},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/ng2109}
}

@BOOKLET{Dollery:systems07,
  title = {Systems Biology: a vision for engineering and medicine},
  author = {Colin Dollery and Richard Kitney and Richard Challis and David Delpy
	and David Edwards and Adriano Henney and Tom Kirkwood and Denis Noble
	and Malcolm Rowland and Lionel Tarassenko and David Williams},
  howpublished = {Available from \url{http://www.raeng.org.uk/policy/engagement/systemsbiology.htm}.},
  month = {February},
  year = {2007},
  group = {systems biology}
}

@ARTICLE{Drucker:doublebp92,
  author = {H. Drucker and Y. {Le~Cun}},
  title = {Improving generalization performance using double back-propagation},
  journal = IEEE,
  year = {1992},
  volume = {3},
  pages = {991--997},
  number = {6}
}

@ARTICLE{Duane:hybrid87,
  author = {S. Duane and A. D. Kennedy and B. J. Pendleton and D. Roweth},
  title = {Hybrid {M}onte {C}arlo},
  journal = {Physics Letters B},
  year = {1987},
  volume = {195},
  pages = {216--222},
  number = {2}
}

@ARTICLE{Duarte:global07,
  author = {Natalie C. Duarte and Scott A. Becker and Neema Jamshidi and Ines
	Thiele and Monica L. Mo and Thuy D. Vo and Rohith Srivas and Bernhard
	\OE. Palsson},
  title = {Global Reconstruction of the Human Metabolic Network Based on Genomic
	and Bibliomic data},
  journal = pnasusa,
  year = {2007},
  volume = {104},
  pages = {1777--1782},
  number = {6},
  abstract = {Metabolism is a vital cellular process, and its malfunction is a major
	contributor to human disease. Metabolic networks are complex and
	highly interconnected, and thus systems-level computational approaches
	are required to elucidate and understand metabolic genotype-phenotype
	relationships. We have manually reconstructed the global human metabolic
	network based on Build 35 of the genome annotation and a comprehensive
	evaluation of >50 years of legacy data (i.e., bibliomic data). Herein
	we describe the reconstruction process and demonstrate how the resulting
	genome-scale (or global) network can be used (i) for the discovery
	of missing information, (ii) for the formulation of an in silico
	model, and (iii) as a structured context for analyzing high-throughput
	biological data sets. Our comprehensive evaluation of the literature
	revealed many gaps in the current understanding of human metabolism
	that require future experimental investigation. Mathematical analysis
	of network structure elucidated the implications of intracellular
	compartmentalization and the potential use of correlated reaction
	sets for alternative drug target identification. Integrated analysis
	of high-throughput data sets within the context of the reconstruction
	enabled a global assessment of functional metabolic states. These
	results highlight some of the applications enabled by the reconstructed
	human metabolic network. The establishment of this network represents
	an important step toward genome-scale human systems biology.},
  doi = {10.1073/pnas.0610772104},
  file = {1777.pdf:http\://www.pnas.org/cgi/reprint/104/6/1777.pdf:PDF},
  group = {metabolic network},
  pmid = {17267599}
}

@ARTICLE{Dudoit:open03,
  author = {Sandrine Dudoit and Robert C Gentleman and John Quackenbush},
  title = {Open source software for the analysis of microarray data.},
  journal = {Biotechniques},
  year = {2003},
  volume = {Suppl},
  pages = {45--51},
  month = {Mar},
  abstract = {DNA microarray assays represent the first widely used application
	that attempts to build upon the information provided by genome projects
	in the study of biological questions. One of the greatest challenges
	with working with microarrays is collecting, managing, and analyzing
	data. Although several commercial and noncommercial solutions exist,
	there is a growing body of freely available, open source software
	that allows users to analyze data using a host of existing techniques
	and to develop their own and integrate them within the system. Here
	we review three of the most widely used and comprehensive systems,
	the statistical analysis tools written in R through the Bioconductor
	project (http://www.bioconductor.org), the Java-based TM4 software
	system available from The Institute for Genomic Research (http://www.tigr.org/software),
	and BASE, the Web-based system developed at Lund University (http://base.thep.lu.se).},
  institution = {University of California, Berkeley, CA, USA.},
  keywords = {Database Management Systems; Gene Expression Profiling, methods; Information
	Dissemination, methods; Information Storage and Retrieval, methods;
	Oligonucleotide Array Sequence Analysis, methods; Sequence Analysis,
	DNA, methods; Software},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {12664684},
  timestamp = {2010.10.05}
}

@MISC{Duhaime:legal98,
  author = {Lloyd Duhaime},
  title = {Legal Dictionary},
  howpublished = {Available from \url{http://www.fifthdistrictcourt.com/dictionary/legal.htm}.},
  year = {1998},
  organization = {The World Wide Legal Information Association}
}

@ARTICLE{Dunn:metabolome05,
  author = {Warwick B Dunn and Nigel J. C. Bailey and Helen E. Johnson},
  title = {Measuring the metabolome: current analytical technologies},
  journal = {Analyst},
  year = {2005},
  volume = {130},
  pages = {606--625},
  number = {5},
  abstract = {The post-genomics era has brought with it ever increasing demands
	to observe and characterise variation within biological systems.
	This variation has been studied at the genomic (gene function), proteomic
	(protein regulation) and the metabolomic (small molecular weight
	metabolite) levels. Whilst genomics and proteomics are generally
	studied using microarrays (genomics) and 2D-gels or mass spectrometry
	(proteomics), the technique of choice is less obvious in the area
	of metabolomics. Much work has been published employing mass spectrometry,
	NMR spectroscopy and vibrational spectroscopic techniques, amongst
	others, for the study of variations within the metabolome in many
	animal, plant and microbial systems. This review discusses the advantages
	and disadvantages of each technique, putting the current status of
	the field of metabolomics in context, and providing examples of applications
	for each technique employed.},
  doi = {10.1039/b418288j},
  group = {metabolome},
  pmid = {15852128}
}

@ARTICLE{Durbin:elastic89,
  author = {R. Durbin and R. Szeliski and A. Yuille},
  title = {An analysis of the elastic net approach to the travelling salesman
	problem},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {348--358},
  number = {3}
}

@ARTICLE{Durbin:tsp87,
  author = {Durbin, R. and Willshaw, D.},
  title = {An analogue approach to the travelling salesman problem},
  journal = {Nature},
  year = {1987},
  volume = {326},
  pages = {689--691}
}

@MISC{Dutcher:motview,
  author = {Steven Dutcher and Andrew Gardner},
  title = {MotView},
  note = {A motion capture viewer.},
  label1 = {Webpage},
  link1 = {http://www.ict.usc.edu/graphics/animWeb/humanoid/programs.html}
}

@ARTICLE{Egger2004,
  author = {Gerda Egger and Gangning Liang and Ana Aparicio and Peter A Jones},
  title = {Epigenetics in human disease and prospects for epigenetic therapy.},
  journal = {Nature},
  year = {2004},
  volume = {429},
  pages = {457--463},
  number = {6990},
  month = {May},
  abstract = {Epigenetic mechanisms, which involve DNA and histone modifications,
	result in the heritable silencing of genes without a change in their
	coding sequence. The study of human disease has focused on genetic
	mechanisms, but disruption of the balance of epigenetic networks
	can cause several major pathologies, including cancer, syndromes
	involving chromosomal instabilities, and mental retardation. The
	development of new diagnostic tools might reveal other diseases that
	are caused by epigenetic alterations. Great potential lies in the
	development of 'epigenetic therapies'--several inhibitors of enzymes
	controlling epigenetic modifications, specifically DNA methyltransferases
	and histone deacetylases, have shown promising anti-tumorigenic effects
	for some malignancies.},
  doi = {10.1038/nature02625},
  institution = {Department of Biochemistry and Molecular Biology, USC/Norris Comprehensive
	Cancer Center, Keck School of Medicine of the University of Southern
	California, 1441 Eastlake Avenue, Room 8302L, Los Angeles, California
	90089-9181, USA.},
  keywords = {DNA Methylation; Disease; Epigenesis, Genetic, genetics; Gene Silencing;
	Gene Therapy, trends; Genetics, Medical, trends; Humans},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {nature02625},
  pmid = {15164071},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/nature02625}
}

@ARTICLE{Eisen:DNAArrays,
  author = {Michael B. Eisen and Patrick O. Brown},
  title = {{DNA} Arrays for Analysis of Gene Expression},
  journal = {Methods in Enzymology},
  year = {1999},
  volume = {303},
  optpages = {179--205}
}

@ARTICLE{Eisen:exppatterns98,
  author = {Michael B. Eisen and Paul T. Spellman and Patrick O. Brown and David
	Botstein},
  title = {Cluster analysis and display of genome-wide expression patterns},
  journal = pnasusa,
  year = {1998},
  volume = {95},
  pages = {14863--14868}
}

@ARTICLE{Elowitz:synthetic00,
  author = {Michael B. Elowitz and Stanislas Leibler},
  title = {Synthetic Oscillatory Network of Transcriptional Regulators},
  journal = {Nature},
  year = {2000},
  volume = {403},
  pages = {335--338},
  number = {6767},
  abstract = {Networks of interacting biomolecules carry out many essential functions
	in living cells, but the `design principles' underlying the functioning
	of such intracellular networks remain poorly understood, despite
	intensive efforts including quantitative analysis of relatively simple
	systems. Here we present a complementary approach to this problem:
	the design and construction of a synthetic network to implement a
	particular function. We used three transcriptional repressor systems
	that are not part of any natural biological clock to build an oscillating
	network, termed the repressilator, in Escherichia coli. The network
	periodically induces the synthesis of green fluorescent protein as
	a readout of its state in individual cells. The resulting oscillations,
	with typical periods of hours, are slower than the cell-division
	cycle, so the state of the oscillator has to be transmitted from
	generation to generation. This artificial clock displays noisy behaviour,
	possibly because of stochastic fluctuations of its components. Such
	'rational network design may lead both to the engineering of new
	cellular behaviours and to an improved understanding of naturally
	occurring networks.},
  doi = {10.1038/35002125},
  group = {repressilator},
  pmid = {10659856}
}

@ARTICLE{Emilsson2008,
  author = {Valur Emilsson and Gudmar Thorleifsson and Bin Zhang and Amy S Leonardson
	and Florian Zink and Jun Zhu and Sonia Carlson and Agnar Helgason
	and G. Bragi Walters and Steinunn Gunnarsdottir and Magali Mouy and
	Valgerdur Steinthorsdottir and Gudrun H Eiriksdottir and Gyda Bjornsdottir
	and Inga Reynisdottir and Daniel Gudbjartsson and Anna Helgadottir
	and Aslaug Jonasdottir and Adalbjorg Jonasdottir and Unnur Styrkarsdottir
	and Solveig Gretarsdottir and Kristinn P Magnusson and Hreinn Stefansson
	and Ragnheidur Fossdal and Kristleifur Kristjansson and Hjortur G
	Gislason and Tryggvi Stefansson and Bjorn G Leifsson and Unnur Thorsteinsdottir
	and John R Lamb and Jeffrey R Gulcher and Marc L Reitman and Augustine
	Kong and Eric E Schadt and Kari Stefansson},
  title = {Genetics of gene expression and its effect on disease.},
  journal = {Nature},
  year = {2008},
  volume = {452},
  pages = {423--428},
  number = {7186},
  month = {Mar},
  abstract = {Common human diseases result from the interplay of many genes and
	environmental factors. Therefore, a more integrative biology approach
	is needed to unravel the complexity and causes of such diseases.
	To elucidate the complexity of common human diseases such as obesity,
	we have analysed the expression of 23,720 transcripts in large population-based
	blood and adipose tissue cohorts comprehensively assessed for various
	phenotypes, including traits related to clinical obesity. In contrast
	to the blood expression profiles, we observed a marked correlation
	between gene expression in adipose tissue and obesity-related traits.
	Genome-wide linkage and association mapping revealed a highly significant
	genetic component to gene expression traits, including a strong genetic
	effect of proximal (cis) signals, with 50\% of the cis signals overlapping
	between the two tissues profiled. Here we demonstrate an extensive
	transcriptional network constructed from the human adipose data that
	exhibits significant overlap with similar network modules constructed
	from mouse adipose data. A core network module in humans and mice
	was identified that is enriched for genes involved in the inflammatory
	and immune response and has been found to be causally associated
	to obesity-related traits.},
  doi = {10.1038/nature06758},
  institution = {deCODE genetics, 101 Reykjavik, Iceland.},
  keywords = {Adipose Tissue, metabolism; Adolescent; Adult; Aged; Aged, 80 and
	over; Animals; Blood, metabolism; Body Mass Index; Cohort Studies;
	European Continental Ancestry Group, genetics; Female; Gene Expression
	Profiling; Gene Expression Regulation, genetics; Genome, Human; Humans;
	Iceland; Lod Score; Male; Mice; Middle Aged; Obesity, genetics; Polymorphism,
	Single Nucleotide, genetics; Quantitative Trait Loci, genetics; Sample
	Size; Waist-Hip Ratio},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {nature06758},
  pmid = {18344981},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/nature06758}
}

@ARTICLE{Erlang:solution17,
  author = {Agner Krarup Erlang},
  title = {Solution of some Problems in the Theory of Probabilities of Significance
	in Automatic Telephone Exchanges},
  journal = {Elektrotkeknikeren},
  year = {1917},
  volume = {13},
  group = {npa}
}

@ARTICLE{Erlang:theory09,
  author = {Agner Krarup Erlang},
  title = {The Theory of Probabilities and Telephone Conversations},
  journal = {Nyt Tidsskrift for Matematik B},
  year = {1909},
  volume = {20},
  group = {npa}
}

@ARTICLE{Erwin:energy92,
  author = {E. Erwin and K. Obermayer and K. Schulten},
  title = {Self-organizing maps: ordering, convergence properties and energy
	functions},
  journal = {Biological Cybernetics},
  year = {1992},
  volume = {67},
  pages = {47--55}
}

@ARTICLE{Esch2000,
  author = {H. Van Esch and P. Groenen and M. A. Nesbit and S. Schuffenhauer
	and P. Lichtner and G. Vanderlinden and B. Harding and R. Beetz and
	R. W. Bilous and I. Holdaway and N. J. Shaw and J. P. Fryns and W.
	Van de Ven and R. V. Thakker and K. Devriendt},
  title = {{GATA3} haplo-insufficiency causes human {HDR} syndrome},
  journal = {Nature},
  year = {2000},
  volume = {406},
  pages = {419--422},
  number = {6794},
  month = {Jul},
  abstract = {Terminal deletions of chromosome 10p result in a DiGeorge-like phenotype
	that includes hypoparathyroidism, heart defects, immune deficiency,
	deafness and renal malformations. Studies in patients with 10p deletions
	have defined two non-overlapping regions that contribute to this
	complex phenotype. These are the DiGeorge critical region II (refs
	1, 2), which is located on 10p13-14, and the region for the hypoparathyroidism,
	sensorineural deafness, renal anomaly (HDR) syndrome (Mendelian Inheritance
	in Man number 146255), which is located more telomeric (10p14-10pter).
	We have performed deletion-mapping studies in two HDR patients, and
	here we define a critical 200-kilobase region which contains the
	GATA3 gene. This gene belongs to a family of zinc-finger transcription
	factors that are involved in vertebrate embryonic development. Investigation
	for GATA3 mutations in three other HDR probands identified one nonsense
	mutation and two intragenic deletions that predicted a loss of function,
	as confirmed by absence of DNA binding by the mutant GATA3 protein.
	These results show that GATA3 is essential in the embryonic development
	of the parathyroids, auditory system and kidneys, and indicate that
	other GATA family members may be involved in the aetiology of human
	malformations.},
  doi = {10.1038/35019088},
  institution = {Laboratory for Molecular Oncology, Centre for Human Genetics, University
	of Leuven and Flanders Interuniversity Institute for Biotechnology,
	Belgium.},
  keywords = {Amino Acid Sequence; Animals; COS Cells; Chromosomes, Human, Pair
	10; Cloning, Molecular; DNA Mutational Analysis; DNA-Binding Proteins,
	deficiency/genetics; Deafness, genetics; Female; GATA3 Transcription
	Factor; Gene Deletion; Humans; Hypoparathyroidism, genetics; Kidney,
	abnormalities; Male; Mice; Molecular Sequence Data; Pedigree; Physical
	Chromosome Mapping; Syndrome; Trans-Activators, deficiency/genetics;
	Zinc Fingers},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pmid = {10935639},
  timestamp = {2010.04.08}
}

@ARTICLE{Euler:solutio36,
  author = {Leonhard Euler},
  title = {Solutio Problematis Ad Geometriam Situs Pertinentis},
  journal = {Commentarii Academiae Scientiarum Imperialis Petropolitanae},
  year = {1736},
  volume = {8},
  pages = {128--140},
  file = {E053.pdf:http\://math.dartmouth.edu/~euler/docs/originals/E053.pdf:PDF}
}

@ARTICLE{Everson:flexible99,
  author = {Richard M. Everson and Stephen J. Roberts},
  title = {{ICA}: A flexible non-linearity and decorrelating manifold approach},
  journal = NC,
  year = {1999},
  volume = {11},
  pages = {1957--1983},
  number = {8}
}

@ARTICLE{Evgeniou:multitask05,
  author = {Theodoros Evgeniou and Charles A. Micchelli and Massimiliano Pontil},
  title = {Learning Multiple Tasks with Kernel Methods},
  journal = {Journal of Machine Learning Research},
  year = {2005},
  volume = {6},
  pages = {615-637}
}

@ARTICLE{Eyre2010,
  author = {Stephen Eyre and Anne Hinks and John Bowes and Edward Flynn and Paul
	Martin and Anthony G Wilson and Ann W Morgan and Paul Emery and Sophia
	Steer and Lynne J Hocking and David M Reid and Pille Harrison and
	Paul Wordsworth and Yorkshire Early Arthritis Consortium and Biologics
	in RA Control Consortium and Wendy Thomson and Jane Worthington and
	Anne Barton},
  title = {Overlapping genetic susceptibility variants between three autoimmune
	disorders: rheumatoid arthritis, type 1 diabetes and coeliac disease.},
  journal = {Arthritis Res Ther},
  year = {2010},
  volume = {12},
  pages = {R175},
  number = {5},
  abstract = {Genome wide association studies, replicated by numerous well powered
	validation studies, have revealed a large number of loci likely to
	play a role in susceptibility to many multifactorial diseases. It
	is now well established that some of these loci are shared between
	diseases with similar aetiology. For example, a number of autoimmune
	diseases have been associated with variants in the PTPN22, TNFAIP3
	and CTLA4 genes. Here we have attempted to define overlapping genetic
	variants between rheumatoid arthritis (RA), type 1 diabetes (T1D)
	and coeliac disease (CeD).We selected eight SNPs previously identified
	as being associated with CeD and six T1D-associated SNPs for validation
	in a sample of 3,962 RA patients and 3,531 controls. Genotyping was
	performed using the Sequenom MassArray platform and comparison of
	genotype and allele frequencies between cases and controls was undertaken.
	A trend test P-value < 0.004 was regarded as significant.We found
	statistically significant evidence for association of the TAGAP locus
	with RA (P = 5.0 × 10-4). A marker at one other locus, C1QTNF6, previously
	associated with T1D, showed nominal association with RA in the current
	study but did not remain statistically significant at the corrected
	threshold.In exploring the overlap between T1D, CeD and RA, there
	is strong evidence that variation within the TAGAP gene is associated
	with all three autoimmune diseases. Interestingly a number of loci
	appear to be specific to one of the three diseases currently studied
	suggesting that they may play a role in determining the particular
	autoimmune phenotype at presentation.},
  doi = {10.1186/ar3139},
  institution = {Arthritis Research UK, Epidemiology Unit, Stopford Building, Oxford
	Road, The University of Manchester, Manchester M13 9PT, UK. steve.eyre@manchester.ac.uk},
  keywords = {Adult; Arthritis, Rheumatoid, genetics; Celiac Disease, genetics;
	Diabetes Mellitus, Type 1, genetics; Female; GTPase-Activating Proteins,
	genetics; Genetic Predisposition to Disease, genetics; Genotype;
	Humans; Male; Middle Aged; Oligonucleotide Array Sequence Analysis;
	Polymorphism, Single Nucleotide},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ar3139},
  pmid = {20854658},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1186/ar3139}
}

@ARTICLE{Fagiolo1993,
  author = {U. Fagiolo and A. Cossarizza and E. Scala and E. Fanales-Belasio
	and C. Ortolani and E. Cozzi and D. Monti and C. Franceschi and R.
	Paganelli},
  title = {Increased cytokine production in mononuclear cells of healthy elderly
	people.},
  journal = {Eur J Immunol},
  year = {1993},
  volume = {23},
  pages = {2375--2378},
  number = {9},
  month = {Sep},
  abstract = {The production of cytokines during aging, except interleukin (IL)-2,
	has been neglected in humans. We measured the in vitro production
	of IL-6, tumor necrosis factor (TNF)-alpha, interferon (IFN)-gamma
	and IL-1 beta by peripheral mononuclear cells from selected healthy
	young (mean age 26.8 years) and aged (mean age 80.2 years) subjects.
	Significant increases of IL-6, TNF-alpha and IL-1 beta levels were
	found in mitogen-stimulated cultures from aged donors, occurring
	at 24 to 72 h after stimulation. No significant differences were
	observed for IFN-gamma production. Proliferative capability of cells
	stimulated with PHA was not impaired in aged subjects. Since the
	amounts of all cytokines studied were similar in unstimulated cultures
	from young and aged subjects, and also serum levels of TNF-alpha
	did not differ, these data indicate that the cellular machinery for
	the production of these cytokines is well preserved in aging, and
	also that cells from old people are able to up-regulate their production
	in response to appropriate stimuli. The increases in cytokine synthesis
	were not dependent on changes in the number of monocytes, nor were
	they related to the significant rise of CD45RO+, and the concomitant
	decrease of CD45RA+, occurring in both CD4+ and CD8+ lymphocytes
	from aged subjects. The increased production of pro-inflammatory
	cytokines by stimulated mononuclear cells of healthy aged subjects
	may be relevant to several aspects of age-associated pathological
	events, including atherosclerosis, osteoporosis, fibrosis and dementia.},
  doi = {10.1002/eji.1830230950},
  institution = {Institute of Internal Medicine, University of Padua, Italy.},
  keywords = {Adult; Aged; Aged, 80 and over; Aging, metabolism; Antigens, CD45,
	analysis; Cells, Cultured; Cytokines, biosynthesis; Female; Humans;
	Interleukin-1, biosynthesis; Interleukin-6, biosynthesis; Leukocytes,
	Mononuclear, metabolism; Male; Tumor Necrosis Factor-alpha, biosynthesis},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {8370415},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1002/eji.1830230950}
}

@ARTICLE{Fagnoni2000,
  author = {F. F. Fagnoni and R. Vescovini and G. Passeri and G. Bologna and
	M. Pedrazzoni and G. Lavagetto and A. Casti and C. Franceschi and
	M. Passeri and P. Sansoni},
  title = {Shortage of circulating naive CD8(+) T cells provides new insights
	on immunodeficiency in aging.},
  journal = {Blood},
  year = {2000},
  volume = {95},
  pages = {2860--2868},
  number = {9},
  month = {May},
  abstract = {Clinical observations indicate that elderly people are prone to severe,
	often lethal infectious diseases induced by novel pathogens. Since
	the ability to mount primary immune responses relies on the availability
	of naive T cells, the circulating naive T-cell reservoir was evaluated
	throughout the human life span. Naive T cells were identified as
	CD95(-) T lymphocytes for their phenotypic and functional features.
	Indeed, the lack of CD95 marker is sufficient to identify a population
	of naive T cells, as defined by coincidence with previously characterized
	CD45RA(+) CD62L(+) T cells. Naive CD95(-) T cells, as expected, require
	a costimulatory signal, such as CD28, to optimally proliferate after
	anti-CD3 stimulation. Cytofluorimetric analysis of circulating T
	lymphocytes from 120 healthy subjects ranging in age from 18 to 105
	years revealed that naive T cells decreased sharply with age. The
	younger subjects had a naive T-lymphocyte count of 825 +/- 48 cells/microL,
	and the centenarians had a naive T-lymphocyte count of 177 +/- 28
	cells/microL. Surprisingly, the naive T-cell count was lower in CD8(+)
	than in CD4(+) subsets at any age, and the oldest individuals were
	almost completely depleted of circulating naive CD8(+) T cells (13
	+/- 4 cells/microL). Concomitantly, a progressive expansion of CD28(-)
	T cells occurs with age, which can be interpreted as a compensatory
	mechanism. These data provide new insights into age-related T-cell-mediated
	immunodeficiency and reveal some analogies of T-cell dynamics between
	advanced aging and human immunodeficiency virus (HIV) infection.
	In conclusion, the exhaustion of the naive CD8(+) T-cell reservoir,
	which has never been reported before, suggests that this T-cell pool
	is a major target of the aging process and may define a parameter
	possibly related to the life span of humans. (Blood. 2000;95:2860-2868)},
  institution = {Department of Internal Medicine and Biomedical Sciences and the Institute
	of Biological Chemistry, University of Parma, Parma, Italy.},
  keywords = {Adolescent; Adult; Aged; Aged, 80 and over; Aging, immunology; Antigens,
	CD, blood; Antigens, CD45, analysis; CD4 Lymphocyte Count; CD8-Positive
	T-Lymphocytes, immunology; Humans; Immunologic Deficiency Syndromes,
	blood/epidemiology/immunology; L-Selectin, analysis; Lymphocyte Activation;
	Lymphocyte Count; Middle Aged; Regression Analysis; T-Lymphocytes,
	immunology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {10779432},
  timestamp = {2011.09.14}
}

@ARTICLE{Famili:systemic03,
  author = {I. Famili and Bernhard \OE Palsson},
  title = {Systemic Metabolic Reactions are Obtained by Singular Value Decomposition
	of Genome-Scale Stoichiometric Matrices},
  journal = jtheoretbio,
  year = {2003},
  volume = {224},
  pages = {87--96},
  number = {1},
  abstract = {Genome-scale metabolic networks can be reconstructed. The systemic
	biochemical properties of these networks can now be studied. Here,
	genome-scale reconstructed metabolic networks were analysed using
	singular value decomposition (SVD). All the individual biochemical
	conversions contained in a reconstructed metabolic network are described
	by a stoichiometric matrix (S). SVD of S led to the definition of
	the underlying modes that characterize the overall biochemical conversions
	that take place in a network and rank-ordered their importance. The
	modes were shown to correspond to systemic biochemical reactions
	and they could be used to identify the groups and clusters of individual
	biochemical reactions that drive them. Comparative analysis of the
	Escherichia coli, Haemophilus influenzae, and Helicobacter pylori
	genome-scale metabolic networks showed that the four dominant modes
	in all three networks correspond to: (1) the conversion of ATP to
	ADP, (2) redox metabolism of NADP, (3) proton-motive force, and (4)
	inorganic phosphate metabolism. The sets of individual metabolic
	reactions deriving these systemic conversions, however, differed
	among the three organisms. Thus, we can now define systemic metabolic
	reactions, or eigen-reactions, for the study of systems biology of
	metabolism and have a basis for comparing the overall properties
	of genome-specific metabolic networks.},
  doi = {10.1016/S0022-5193(03)00146-2},
  file = {sdarticle.pdf:http\://www.sciencedirect.com/science?_ob=MImg&_imagekey=B6WMD-490RDGR-1-1T&_cdi=6932&_user=494590&_orig=search&_coverDate=09%2F07%2F2003&_sk=997759998&view=c&wchp=dGLbVzW-zSkWA&md5=87cf0ac0fae1032b528cb6ce175f6e5d&ie=/sdarticle.pdf:PDF},
  group = {metabolic network},
  pmid = {12900206}
}

@ARTICLE{Fang:modelbased03,
  author = {Y. Fang and A. Brass and D. Hoyle and A. Hayes and A. Bashein and
	S. Oliver and D. Waddell and Magnus Rattray},
  title = {A model-based analysis of microarray experimental error and normalisation},
  journal = {Nucleic Acids Research (methods)},
  year = {2003},
  volume = {31},
  pages = {e96},
  number = {16}
}

@InProceedings{Feurer:automl15,
  author = 	 {Matthias Feurer and Aaron Klein and Katharina Eggensperger and Jost Tobias Springenberg and Manuel Blum and Frank Hutter},
  title = 	 {Efficient and Robust Automated Machine Learning},
  booktitle = nips,
  crossref =	 {Cortes:nips15}
}

@INPROCEEDINGS{Felzenszwalb:efficient00,
  author = {Pedro F. Felzenszwalb and Daniel P. Huttenlocher},
  title = {Efficient Matching of Pictorial Structures},
  booktitle = pCVPR,
  year = {2000},
  volume = {2},
  pages = {66--73},
  address = {Hilton Head Island, South Carolina, U.S.A.},
  month = {13--15 Jun.},
  publisher = ieeecomp,
  abstract = {A pictorial structure is a collection of parts arranged in a deformable
	configuration. Each part is represented using a simple appearance
	model and the deformable configuration is represented by spring-like
	connections between pairs of parts. While pictorial structures were
	introduced a number of years ago, they have not been broadly applied
	to matching and recognition problems. This has been due in part to
	the computational difficulty of matching pictorial structures to
	images. In this paper we present an efficient algorithm for finding
	the best global match of a pictorial stucture to an image. With this
	improved algorithm, pictorial structures provide a practical and
	powerful framework for quantitative descriptions of objects and scenes,
	and are suitable for many generic image recognition problems. We
	illustrate the approach using simple models of a person and a car.},
  doi = {10.1109/CVPR.2000.854739},
  group = {tree},
  linkps = {http://people.cs.uchicago.edu/~pff/papers/blobrec2.ps.gz}
}

@ARTICLE{Feng:combining02,
  author = {Xiaojuan Feng and Christopher K. I. Williams and Stephen N. Felderhof},
  title = {Combining Belief Networks and Neural Networks for Scene Segmentation},
  journal = PAMI,
  year = {2002},
  volume = {24},
  pages = {467--483},
  number = {4},
  abstract = {We are concerned with the problem of image segmentation, in which
	each pixel is assigned to one of a predefined finite number of labels.
	In Bayesian image analysis, this requires fusing together local predictions
	for the class labels with a prior model of label images. Following
	the work of, we consider the use of tree-structured belief networks
	(TSBNs) as prior models. The parameters in the TSBN are trained using
	a maximum-likelihood objective function with the EM algorithm and
	the resulting model is evaluated by calculating how efficiently it
	codes label images. A number of authors have used Gaussian mixture
	models to connect the label field to the image data. In this paper,
	we compare this approach to the scaled-likelihood method of where
	local predictions of pixel classification from neural networks are
	fused with the TSBN prior. Our results show a higher performance
	is obtained with the neural networks. We evaluate the classification
	results obtained and emphasize not only the maximum a posteriori
	segmentation, but also the uncertainty, as evidenced e.g., by the
	pixelwise posterior marginal entropies. We also investigate the use
	of conditional maximum-likelihood training for the TSBN and find
	that this gives rise to improved classification performance over
	the ML-trained TSBN.},
  doi = {10.1109/34.993555},
  group = {tree, image segmentation},
  linkpsgz = {http://www.dai.ed.ac.uk/homes/ckiw/postscript/final7.ps.gz},
  linksoftware = {http://www.dai.ed.ac.uk/homes/ckiw/code/cbn.html}
}

@MISC{Feynman:bottom59,
  author = {Richard P. Feynman},
  title = {There's Plenty of Room at the Bottom: An Invitation to Enter a New
	Field of Physics},
  howpublished = {Talk at Annual meeting of the American Physical Society},
  year = {1959},
  note = {Available from \url{http://www.zyvex.com/nanotech/feynman.html}},
  group = {nanotechnology}
}

@ARTICLE{Fickett:eukaryotic97,
  author = {J.W. Fickett and A.G. Hatzigeorgiou},
  title = {Eukaryotic promoter recognition},
  journal = {Genome Research},
  year = {1997},
  volume = {7},
  pages = {861--878}
}

@ARTICLE{Fine:efficient01,
  author = {S. Fine and K. Scheinberg},
  title = {Efficient {SVM} training using low-rank kernel representations},
  journal = jmlr,
  year = {2001},
  volume = {2},
  optpages = {243--264}
}

@Article{Fisher:theoretical22,
  author = {Ronald A. Fisher},
  year = 1922,
  title = {On the Mathematical Foundations of Theoretical Statistics}, 
  journal = {Philosophical Transactions of the Royal Society, A},
  pages = {309--368},
  volume = 222
}


@Article{Hinton:acoustic12,
  author = 	 {Geoffrey Hinton and Li Deng and Dong Yu and George E. Dahl and Abdel-rahman Mohamed and Navdeep Jaitly and Andrew Senior and Vincent Vanhoucke and Patrick Nguyen and Tara N. Sainath and Brian Kingsbury},
  title = 	 {Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  journal = 	 {IEEE Signal Processing Magazine},
  year = 	 {2012},
  volume =	 {29},
  number =	 {6},
  pages =	 {82--97},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1109/MSP.2012.2205597},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@InProceedings{Learned:labeled16,
  author = 	 {Erik Learned-Miller and Gary B. Huang and Aruni {RoyChowdhury} and Haoxiang Li and Gang Hua},
  title = 	 {Labeled Faces in the Wild: A Survey},
  OPTkey = 	 {},
  booktitle =	 {Advances in Face Detection and Facial Image Analysis},
  pages =	 {189--248},
  year =	 {2016},
  editor =	 {Michal Kawulok and M. Emre Celebi and Bogdan Smolka},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  publisher =	 {Springer},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1007/978-3-319-25958-1_8},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Srivastava:dropout14,
  author = 	 {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title = 	 {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = 	 jmlr,
  year = 	 2014,
  OPTkey = 	 {},
  volume =	 {15},
  OPTnumber = 	 {},
  pages =	 {1929--1958},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  linkpdf =	 {http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@InProceedings{Taigman:deepface14,
  title = {{DeepFace}: Closing the Gap to Human-Level Performance in Face Verification},
  author = {Yaniv Taigman and Ming Yang and Marc'Aurelio Ranzato and Lior Wolf},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 pCVPR,
  OPTpages = 	 {},
  year =	 2014,
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1109/CVPR.2014.220},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

  
@ARTICLE{Fisher:discrim36,
  author = {Ronald A. Fisher},
  title = {The Use of Multiple Measurements in Taxonomic Problems},
  journal = {Annals of Eugenics},
  year = {1936},
  volume = {7},
  pages = {179--188},
  note = {Reprinted in \emph{Contributions to Mathematical Statistics}, John
	Wiley: New York (1950)}
}

@ARTICLE{Floyd:sample,
  author = {S. Floyd and M. Warmuth},
  title = {Sample Compression, Learnability, and the {V}apnik {C}hernovenkis
	Dimension},
  journal = {Machine Learning},
  year = {1995},
  volume = {27},
  pages = {1--36}
}

@ARTICLE{Fomekong-Nanfack:efficient07,
  author = {Yves Fomekong-Nanfack and Jaap A. Kaandorp and Joke Blom},
  title = {Efficient parameter estimation for spatio-temporal models of pattern
	formation: case study of Drosophila melanogaster},
  journal = bioinf,
  year = {2007},
  volume = {23},
  pages = {3356--3363},
  number = {24},
  abstract = {\bf{Motivation:} Diffusable and non-diffusable gene products play
	a major role in body plan formation. A quantitative understanding
	of the spatio-temporal patterns formed in body plan formation, by
	using simulation models is an important addition to experimental
	observation. The inverse modelling approach consists of describing
	the body plan formation by a rule-based model, and fitting the model
	parameters to real observed data. In body plan formation, the data
	are usually obtained from fluorescent immunohistochemistry or in
	situ hybridizations. Inferring model parameters by comparing such
	data to those from simulation is a major computational bottleneck.
	An important aspect in this process is the choice of method used
	for parameter estimation. When no information on parameters is available,
	parameter estimation is mostly done by means of heuristic algorithms.\\\\
	\bf{Results:} We show that parameter estimation for pattern formation
	models can be efficiently performed using an evolution strategy (ES).
	As a case study we use a quantitative spatio-temporal model of the
	regulatory network for early development in Drosophila melanogaster.
	In order to estimate the parameters, the simulated results are compared
	to a time series of gene products involved in the network obtained
	with immunohistochemistry. We demonstrate that a (µ,{lambda})-ES
	can be used to find good quality solutions in the parameter estimation.
	We also show that an ES with multiple populations is 5–140 times
	as fast as parallel simulated annealing for this case study, and
	that combining ES with a local search results in an efficient parameter
	estimation method.\\\\ Supplementary information and availability:
	Bioinformatics online; software: \url{http://www.science.uva.nl/research/scs/3D-RegNet/fly_ea}\\\
	\bf{Contact:} jaapk@science.uva.nl},
  doi = {doi:10.1093/bioinformatics/btm433},
  file = {3356.pdf:http\://bioinformatics.oxfordjournals.org/cgi/reprint/23/24/3356.pdf:PDF},
  group = {Drosophila, blastoderm},
  linksoftware = {http://www.science.uva.nl/research/scs/3D-RegNet/fly_ea},
  pmid = {17893088}
}

@ARTICLE{Forger:circadian03,
  author = {D. B. Forger and C. S. Peskin},
  title = {A detailed predictive model of the mammalian circadian clock},
  journal = {Proceedings of the National Academy of Sciences USA},
  year = {2003},
  volume = {100},
  pages = {14806--14811},
  group = {gene networks}
}

@ARTICLE{Fortin2006,
  author = {Carl F Fortin and Anis Larbi and Olivier Lesur and Nadine Douziech
	and Tamas Fulop},
  title = {Impairment of SHP-1 down-regulation in the lipid rafts of human neutrophils
	under GM-CSF stimulation contributes to their age-related, altered
	functions.},
  journal = {J Leukoc Biol},
  year = {2006},
  volume = {79},
  pages = {1061--1072},
  number = {5},
  month = {May},
  abstract = {It has been shown that the functions and the rescue from apoptosis
	by proinflammatory mediators of polymorphonuclear leukocytes (PMN)
	tend to diminish with aging. Here, we investigated the role of protein
	tyrosine phosphatases (PTP), especially Src homology domain-containing
	protein tyrosine phosphatase-1 (SHP-1), in the age-related, altered
	PMN functions under granulocyte macrophage-colony stimulating factor
	(GM-CSF) stimulation. The inhibition of PTP suggested a differential
	effect of GM-CSF on phosphatase activity in modulating PMN functions
	with aging. The down-regulation of phosphatase activity of immunopurified
	SHP-1 from lipid rafts of PMN of young donors was found significantly
	altered at 1 min of stimulation with aging. In young donors, SHP-1
	is displaced from lipid rafts at 1 min of stimulation, whereas in
	the elderly, SHP-1 is constantly present. We assessed in PMN lipid
	rafts the phosphorylation of tyrosine and serine residues of SHP-1,
	which regulates its activity. We observed an alteration in the phosphorylation
	of tyrosine and serine residues of SHP-1 in PMN of elderly subjects,
	suggesting that GM-CSF was unable to inhibit SHP-1 activity by serine
	phosphorylation. GM-CSF activates Lyn rapidly, and we found alterations
	in its activation and translocation to the lipid rafts with aging.
	We also demonstrate that SHP-1 in the PMN of elderly is constantly
	recruited to Lyn, which cannot be relieved by GM-CSF. In contrast,
	in the young, the resting recruitment could be relieved by GM-CSF.
	Our results suggest an alteration of the SHP-1 modulation by GM-CSF
	in lipid rafts of PMN with aging. These alterations could contribute
	to the decreased GM-CSF effects on PMN.},
  doi = {10.1189/jlb.0805481},
  institution = {Laboratory for Immunology, Research Center on Aging, Clinical Research
	Center, and Department of Medicine, Faculty of Medicine, University
	of Sherbrooke, Sherbrooke, Québec, Canada.},
  keywords = {Adult; Age Factors; Aged; Aging, immunology; Apoptosis, drug effects/immunology;
	Chemotaxis, Leukocyte, drug effects/immunology; Down-Regulation,
	drug effects/immunology; Enzyme Inhibitors, pharmacology; Granulocyte-Macrophage
	Colony-Stimulating Factor, immunology/pharmacology; Humans; Immunity,
	Cellular, drug effects/immunology; Intracellular Signaling Peptides
	and Proteins, antagonists /&/ inhibitors/chemistry/metabolism; Membrane
	Microdomains, drug effects/metabolism; Neutrophils, drug effects/immunology/metabolism;
	Phosphorylation, drug effects; Protein Phosphatase 1; Protein Transport,
	drug effects/immunology; Protein Tyrosine Phosphatase, Non-Receptor
	Type 6; Protein Tyrosine Phosphatases, antagonists /&/ inhibitors/chemistry/metabolism;
	Reactive Oxygen Species, metabolism; Serine, metabolism; Tyrosine,
	metabolism; src-Family Kinases, drug effects/immunology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {jlb.0805481},
  pmid = {16501054},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1189/jlb.0805481}
}

@ARTICLE{Fraga2005,
  author = {Mario F Fraga and Esteban Ballestar and Maria F Paz and Santiago
	Ropero and Fernando Setien and Maria L Ballestar and Damia Heine-Suñer
	and Juan C Cigudosa and Miguel Urioste and Javier Benitez and Manuel
	Boix-Chornet and Abel Sanchez-Aguilera and Charlotte Ling and Emma
	Carlsson and Pernille Poulsen and Allan Vaag and Zarko Stephan and
	Tim D Spector and Yue-Zhong Wu and Christoph Plass and Manel Esteller},
  title = {Epigenetic differences arise during the lifetime of monozygotic twins.},
  journal = {Proc Natl Acad Sci U S A},
  year = {2005},
  volume = {102},
  pages = {10604--10609},
  number = {30},
  month = {Jul},
  abstract = {Monozygous twins share a common genotype. However, most monozygotic
	twin pairs are not identical; several types of phenotypic discordance
	may be observed, such as differences in susceptibilities to disease
	and a wide range of anthropomorphic features. There are several possible
	explanations for these observations, but one is the existence of
	epigenetic differences. To address this issue, we examined the global
	and locus-specific differences in DNA methylation and histone acetylation
	of a large cohort of monozygotic twins. We found that, although twins
	are epigenetically indistinguishable during the early years of life,
	older monozygous twins exhibited remarkable differences in their
	overall content and genomic distribution of 5-methylcytosine DNA
	and histone acetylation, affecting their gene-expression portrait.
	These findings indicate how an appreciation of epigenetics is missing
	from our understanding of how different phenotypes can be originated
	from the same genotype.},
  doi = {10.1073/pnas.0500398102},
  institution = {Epigenetics Laboratory, Spanish National Cancer Centre (CNIO), Melchor
	Fernandez Almagro 3, 28029 Madrid, Spain.},
  keywords = {5-Methylcytosine, metabolism; Acetylation; Adult; Analysis of Variance;
	DNA Methylation; Electrophoresis, Capillary; Epigenesis, Genetic,
	genetics; Female; Gene Expression Regulation, Developmental; Histones,
	metabolism; Humans; Male; Nucleic Acid Amplification Techniques;
	Oligonucleotide Array Sequence Analysis; Phenotype; Questionnaires;
	Restriction Mapping; Reverse Transcriptase Polymerase Chain Reaction;
	Sequence Analysis, DNA; Spain; Twins, Monozygotic, genetics/metabolism/physiology;
	X Chromosome Inactivation, genetics},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {0500398102},
  pmid = {16009939},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1073/pnas.0500398102}
}

@ARTICLE{Franceschi2007,
  author = {Claudio Franceschi and Miriam Capri and Daniela Monti and Sergio
	Giunta and Fabiola Olivieri and Federica Sevini and Maria Panagiota
	Panourgia and Laura Invidia and Laura Celani and Maria Scurti and
	Elisa Cevenini and Gastone C Castellani and Stefano Salvioli},
  title = {Inflammaging and anti-inflammaging: a systemic perspective on aging
	and longevity emerged from studies in humans.},
  journal = {Mech Ageing Dev},
  year = {2007},
  volume = {128},
  pages = {92--105},
  number = {1},
  month = {Jan},
  abstract = {A large part of the aging phenotype, including immunosenescence, is
	explained by an imbalance between inflammatory and anti-inflammatory
	networks, which results in the low grade chronic pro-inflammatory
	status we proposed to call inflammaging. Within this perspective,
	healthy aging and longevity are likely the result not only of a lower
	propensity to mount inflammatory responses but also of efficient
	anti-inflammatory networks, which in normal aging fail to fully neutralize
	the inflammatory processes consequent to the lifelong antigenic burden
	and exposure to damaging agents. Such a global imbalance can be a
	major driving force for frailty and common age-related pathologies,
	and should be addressed and studied within an evolutionary-based
	systems biology perspective. Evidence in favor of this conceptualization
	largely derives from studies in humans. We thus propose that inflammaging
	can be flanked by anti-inflammaging as major determinants not only
	of immunosenescence but eventually of global aging and longevity.},
  doi = {10.1016/j.mad.2006.11.016},
  institution = {Department of Experimental Pathology, University of Bologna, via
	S. Giacomo 12, 40126 Bologna, Italy. claudio.franceschi@unibo.it},
  keywords = {Aging, physiology; Humans; Inflammation Mediators, physiology; Inflammation,
	physiopathology; Longevity, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {S0047-6374(06)00249-1},
  pmid = {17116321},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1016/j.mad.2006.11.016}
}

@ARTICLE{Frean:upstart90,
  author = {M. Frean},
  title = {The upstart algorithm: a method for constructing and training feedforward
	neural networks},
  journal = NC,
  year = {1990},
  volume = {2},
  pages = {198--209},
  number = {2}
}

@ARTICLE{Fredriksson:breastfeeding07,
  author = {Pia Fredriksson and Niina Jaakkola and Jouni JK Jaakkola},
  title = {Breastfeeding and childhood asthma: a six-year population-based cohort
	study},
  journal = {BMC Pediatrics},
  year = {2007},
  volume = {7},
  number = {39},
  abstract = {{\bf Background}\\\\ The question of the protective effect of breastfeeding
	on development of asthma has raised substantial interest, but the
	scientific evidence of the optimal duration of breastfeeding is controversial.\\\\
	{\bf Methods}\\\\ The authors elaborated the optimal duration of
	breastfeeding with respect to the risk of asthma primarily, and secondarily
	to the risk of persistent wheezing, cough and phlegm in school age
	in a population-based cohort study with the baseline in 1991 and
	follow-up in 1997. The study population comprised 1984 children aged
	7 to 14 years at the end of the follow-up (follow-up rate 77). Information
	on breastfeeding was based on the baseline survey and information
	on the health outcomes at the follow-up. {\bf Results}\\\\ There
	was a U-shaped relation between breastfeeding and the outcomes with
	the lowest risk with breastfeeding from four to nine months for asthma
	and seven to nine months for persistent wheezing, cough and phlegm.
	{\bf Conclusion}\\\\ Our results suggest a U shape relation between
	duration of breastfeeding and risk of asthma with an optimal duration
	of 4 to 6 months. A true concave relation would explain the inconsistent
	results from the previous studies.},
  doi = {10.1186/1471-2431-7-39},
  file = {picrender.fcgi?artid=2228279&blobtype=pdf:http\://www.pubmedcentral.nih.gov/picrender.fcgi?artid=2228279&blobtype=pdf:PDF},
  group = {asthma},
  pmid = {2228279}
}

@ARTICLE{Freund:selective97,
  author = {Yoav Freund and H. S. Seung and E. Shamir and Naftali Tishby},
  title = {Selective Sampling Using the Query by Committee Algorithm},
  journal = ML,
  year = {1997},
  volume = {20},
  pages = {133--168}
}

@ARTICLE{Fricker:probabilistic11,
  author = {Thomas E. Fricker and Jeremy E. Oakley and Neil D. Sims and Keith
	Worden},
  title = {Probabilistic uncertainty analysis of an FRF of a structure using
	a {G}aussian process emulator},
  journal = {Mechanical Systems and Signal Processing},
  year = {2011},
  volume = {25},
  pages = {2962-2975},
  number = {8}
}

@ARTICLE{Friedman:sparse08,
  author = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
  title = {Sparse Inverse Covariance Estimation with the Graphical Lasso},
  journal = {Biostatistics},
  year = {2008},
  volume = {9},
  pages = {432--441},
  number = {3},
  month = {Jul},
  abstract = {We consider the problem of estimating sparse graphs by a lasso penalty
	applied to the inverse covariance matrix. Using a coordinate descent
	procedure for the lasso, we develop a simple algorithm---the graphical
	lasso---that is remarkably fast: It solves a 1000-node problem (approximately
	500,000 parameters) in at most a minute and is 30-4000 times faster
	than competing methods. It also provides a conceptual link between
	the exact problem and the approximation suggested by Meinshausen
	and Bühlmann (2006). We illustrate the method on some cell-signaling
	data from proteomics.},
  doi = {10.1093/biostatistics/kxm045},
  institution = {Department of Statistics, Stanford University, CA 94305, USA.},
  keywords = {Algorithms; Animals; Biometry; Data Interpretation, Statistical; Humans;
	Models, Statistical; Neural Networks (Computer); Proteomics; Reference
	Values; Regression Analysis; Sample Size; Signal Transduction; Time
	Factors},
  owner = {neil},
  pii = {kxm045},
  pmid = {18079126},
  timestamp = {2009.08.02}
}

@ARTICLE{Friedman:mars91,
  author = {J. H. Friedman},
  title = {Multivariate adaptive regression splines (with discussion)},
  journal = {Annals of Statistics},
  year = {1991},
  volume = {19},
  pages = {1--141},
  number = {1}
}

@ARTICLE{Friedman:ppr81,
  author = {J. H. Friedman and W. Stuetzle},
  title = {Projection pursuit regression},
  journal = {Journal of the American Statistical Association},
  year = {1981},
  volume = {76},
  pages = {817--823},
  number = {376}
}

@ARTICLE{Friedman:PP74,
  author = {J. H. Friedman and J. W. Tukey},
  title = {A projection pursuit algorithm for exploratory data analysis},
  journal = {IEEE Transactions on Computers},
  year = {1974},
  volume = {{C-23}},
  pages = {881--889}
}

@ARTICLE{Friedman:bayesian00,
  author = {Nir Friedman and Michal Linial and Iftach Nachman and Dana Pe'er},
  title = {Using {B}ayesian Networks to Analyze Expression Data},
  journal = {Journal of Computational Biology},
  year = {2000},
  volume = {7},
  pages = {601--620},
  abstract = {DNA hybridization arrays simultaneously measure the expression level
	for thousands of genes. These measurements provide a "snapshot" of
	transcription levels within the cell. A major challenge in computational
	biology is to uncover, from such measurements, gene/protein interactions
	and key biological features of cellular systems. In this paper, we
	propose a new framework for discovering interactions between genes
	based on multiple expression measurements. This framework builds
	on the use of \emph{Bayesian networks} for representing statistical
	dependencies. A Bayesian network is a graph-based model of joint
	multivariate probability distributions that captures properties of
	conditional independence between variables. Such models are attractive
	for their ability to describe complex stochastic processes and because
	they provide a clear methodology for learning from (noisy) observations.
	We start by showing how Bayesian networks can describe interactions
	between genes. We then describe a method for recovering gene interactions
	from microarray data using tools for learning Bayesian networks.
	Finally, we demonstrate this method on the \emph{S. cerevisiae} cell-cycle
	measurements of \cite{Spellman:yeastcellcy98}.},
  group = {gene networks},
  label1 = {Liebert Online},
  link1 = {http://www.liebertonline.com/doi/abs/10.1089/106652700750050961;jsessionid=itUefFmofhc-Vps8OL?cookieSet=1&journalCode=cmb}
}

@ARTICLE{Friel:marginal08,
  author = {Nial Friel and Anthony N. Pettit},
  title = {Marginal Likelihood Estimation via Power Posteriors},
  journal = JRSSb,
  year = {2008},
  volume = {70},
  pages = {589--607}
}

@ARTICLE{Fritzsch2007,
  author = {Bernd Fritzsch and Kirk W Beisel and Sarah Pauley and Garrett Soukup},
  title = {Molecular evolution of the vertebrate mechanosensory cell and ear},
  journal = {Int J Dev Biol},
  year = {2007},
  volume = {51},
  pages = {663--678},
  number = {6-7},
  abstract = {The molecular basis of mechanosensation, mechanosensory cell development
	and mechanosensory organ development is reviewed with an emphasis
	on its evolution. In contrast to eye evolution and development, which
	apparently modified a genetic program through intercalation of genes
	between the master control genes on the top (Pax6, Eya1, Six1) of
	the hierarchy and the structural genes (rhodopsin) at the bottom,
	the as yet molecularly unknown mechanosensory channel precludes such
	a firm conclusion for mechanosensors. However, recent years have
	seen the identification of several structural genes which are involved
	in mechanosensory tethering and several transcription factors controlling
	mechanosensory cell and organ development; these warrant the interpretation
	of available data in very much the same fashion as for eye evolution:
	molecular homology combined with potential morphological parallelism.
	This assertion of molecular homology is strongly supported by recent
	findings of a highly conserved set of microRNAs that appear to be
	associated with mechanosensory cell development across phyla. The
	conservation of transcription factors and their regulators fits very
	well to the known or presumed mechanosensory specializations which
	can be mostly grouped as variations of a common cellular theme. Given
	the widespread distribution of the molecular ability to form mechanosensory
	cells, it comes as no surprise that structurally different mechanosensory
	organs evolved in different phyla, presenting a variation of a common
	theme specified by a conserved set of transcription factors in their
	cellular development. Within vertebrates and arthropods, some mechanosensory
	organs evolved into auditory organs, greatly increasing sensitivity
	to sound through modifications of accessory structures to direct
	sound to the specific sensory epithelia. However, while great attention
	has been paid to the evolution of these accessory structures in vertebrate
	fossils, comparatively less attention has been spent on the evolution
	of the inner ear and the central auditory system. Recent advances
	in our molecular understanding of ear and brain development provide
	novel avenues to this neglected aspect of auditory neurosensory evolution.},
  doi = {10.1387/ijdb.072367bf},
  institution = {Creighton University, Dept of Biomedical Sciences, Omaha, NE 68178,
	USA. Fritzsch@Creighton.edu},
  keywords = {Animals; Ear, physiology; Evolution, Molecular; Gene Expression Regulation,
	Developmental; Hair Cells, Auditory, physiology; Mechanoreceptors,
	physiology; Models, Biological; Morphogenesis, genetics; Phylogeny;
	Species Specificity; Vertebrates},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pii = {072367bf},
  pmid = {17891725},
  timestamp = {2010.04.09}
}

@ARTICLE{Fuentes:nonstationary02,
  author = {Montserrat Fuentes},
  title = {Interpolation of nonstationary air pollution processes: a spatial
	spectral approach},
  journal = statmod,
  year = {2002},
  volume = {2},
  pages = {281-298}
}

@ARTICLE{Fuentes:spectral02,
  author = {Montserrat Fuentes},
  title = {Spectral methods for nonstationary spatial processes},
  journal = {Biometrika},
  year = {2002},
  volume = {89},
  pages = {197-210},
  number = {1}
}

@ARTICLE{Fujii:bayesian96,
  author = {H. Fujii and David J. C. {MacKay} and H. K. D. H. Bhadeshia},
  title = {{B}ayesian neural network analysis of fatigue crack growth rate in
	nickel base superalloys},
  journal = {ISIJ International},
  year = {1996},
  volume = {36},
  pages = {1373--1382},
  number = {11}
}

@INCOLLECTION{Fukunaga:intrinsic82,
  author = {K. Fukunaga},
  title = {Intrinsic dimensionality extraction},
  booktitle = {Classification, Pattern Recognition and Reduction of Dimensionality},
  publisher = nholland,
  year = {1982},
  editor = {P. R. Krishnaiah and L. N. Kanal},
  volume = {2},
  series = {Handbook of Statistics},
  pages = {347--360},
  address = {Amsterdam}
}

@ARTICLE{Fukunaga:parzen89,
  author = {K. Fukunaga and R. R. Hayes},
  title = {The reduced {P}arzen classifier},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1989},
  volume = {11},
  pages = {423--425},
  number = {4}
}

@ARTICLE{Fukunaga:knn75,
  author = {K. Fukunaga and P. M. Narendra},
  title = {A branch and bound algorithm for computing $k$-nearest neighbors},
  journal = {IEEE Transactions on Computers},
  year = {1975},
  volume = {24},
  pages = {750--753}
}

@ARTICLE{Fukushima:neo88,
  author = {K. Fukushima},
  title = {Neocognitron: a hierarchical neural network capable of visual pattern
	recognition},
  journal = NN,
  year = {1988},
  volume = {1},
  pages = {119--130},
  number = {2}
}

@ARTICLE{Fukushima:neo83,
  author = {K. Fukushima and S. Miyake and T. Ito},
  title = {Neocognitron: a neural network model for a mechanism of visual pattern
	recognition},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  year = {1983},
  volume = {13},
  pages = {826--834}
}

@ARTICLE{Fulton2009,
  author = {Debra L Fulton and Saravanan Sundararajan and Gwenael Badis and Timothy
	R Hughes and Wyeth W Wasserman and Jared C Roach and Rob Sladek},
  title = {{TFCat}: the curated catalog of mouse and human transcription factors},
  journal = {Genome Biol},
  year = {2009},
  volume = {10},
  pages = {R29},
  number = {3},
  abstract = {Unravelling regulatory programs governed by transcription factors
	(TFs) is fundamental to understanding biological systems. TFCat is
	a catalog of mouse and human TFs based on a reliable core collection
	of annotations obtained by expert review of the scientific literature.
	The collection, including proven and homology-based candidate TFs,
	is annotated within a function-based taxonomy and DNA-binding proteins
	are organized within a classification system. All data and user-feedback
	mechanisms are available at the TFCat portal (http://www.tfcat.ca).},
  doi = {10.1186/gb-2009-10-3-r29},
  institution = {Department of Medical Genetics, Centre for Molecular Medicine and
	Therapeutics, Child and Family Research Institute, University of
	British Columbia, Vancouver, Canada. debra@cmmt.ubc.ca},
  keywords = {Animals; DNA, metabolism; Databases, Protein; Humans; Mice; Protein
	Binding; Sequence Homology, Amino Acid; Transcription Factors, genetics/metabolism},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pii = {gb-2009-10-3-r29},
  pmid = {19284633},
  timestamp = {2010.04.08}
}

@ARTICLE{Funahashi:approx89,
  author = {K. Funahashi},
  title = {On the approximate realization of continuous mappings by neural networks},
  journal = NN,
  year = {1989},
  volume = {2},
  pages = {183--192},
  number = {3}
}

@PHDTHESIS{Fuselier:refined06,
  author = {Edward J. {Fuselier Jr}},
  title = {Refined error estimates for matrix-valued radial basis functions},
  school = {Texas A\&M University},
  year = {2006},
  file = {Fuselier:refined06.pdf:Statistical Learning/Vector-valued/Fuselier:refined06.pdf:PDF}
}

@ARTICLE{Getz:twoway2000,
  author = {G. Getz, E. Levin and E. Domany},
  title = {Coppled Two-Way clustering analysis of gene microarray data},
  journal = {physica A.},
  year = {2000},
  volume = {279},
  pages = {457--464}
}

@ARTICLE{Lavorgna:genetarget98,
  author = {G.E. Lavorgna, E. Boncinelli, A Wagner and T. Werner},
  title = {Detection of potential targets in genes in silicon},
  journal = {Trends in Genetics},
  year = {1998},
  volume = {14},
  pages = {375--376}
}

@ARTICLE{Gaffney:delay06,
  author = {Eamonn Gaffney and Nicholas A. M. Monk},
  title = {Gene expression time delays and Turing pattern formation systems},
  journal = {Bulletin of Mathematical Biology},
  year = {2006},
  volume = {68},
  pages = {99--130},
  group = {gene networks, delays}
}

@ARTICLE{Galland:boltzmann93,
  author = {Conrad C. Galland},
  title = {The limitations of deterministic {B}oltzmann machines},
  journal = NW,
  year = {1993},
  volume = {4},
  pages = {355--379},
  number = {3}
}

@ARTICLE{Gallant:deriv92,
  author = {A. R. Gallant and H. White},
  title = {On learning the derivatives of an unknown mapping with multilayer
	feedforward networks},
  journal = NN,
  year = {1992},
  volume = {5},
  pages = {129--138},
  number = {1}
}

@INPROCEEDINGS{Gallant:mistake88,
  author = {A. R. Gallant and H. White},
  title = {There exists a neural network that does not make avoidable mistakes},
  booktitle = {IEEE International Conference on Neural Networks},
  year = {1988},
  volume = {1},
  pages = {657--664},
  address = {San Diego, CA},
  month = Jul,
  publisher = {IEEE}
}

@INPROCEEDINGS{Gallant:disc86,
  author = {S. I. Gallant},
  title = {Optimal Linear Discriminants},
  booktitle = {Proceedings of the Eighth IEEE International Conference on Pattern
	Recognition},
  year = {1986},
  volume = {1},
  pages = {849--852},
  address = {Washington, DC},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{Gallant:learn86,
  author = {S. I. Gallant},
  title = {Three constructive algorithms for network learning},
  booktitle = {Proceedings of the Eighth Annual Conference of the Cognitive Science
	Society},
  year = {1986},
  pages = {652--660},
  address = {Hillsdale, NJ},
  publisher = {Lawrence Erlbaum}
}

@ARTICLE{Gallinari:disc91,
  author = {P. Gallinari and S. Thiria and F. Badran and F. Fogelman Soulie},
  title = {On the relations between discriminant analysis and multilayer perceptrons
	},
  journal = NN,
  year = {1991},
  volume = {4},
  pages = {349--360},
  number = {3}
}

@INPROCEEDINGS{Gallinari:mlp88,
  author = {P. Gallinari and S. Thiria and F. Fogelman Soulie},
  title = {Multi-layer Perceptrons and Data Analysis},
  booktitle = {IEEE International Conference on Neural Networks},
  year = {1988},
  volume = {1},
  pages = {391--399},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@INCOLLECTION{Gammerman:graphical95,
  author = {A. Gammerman and Z. Luo and C. G. G. Aitken and M. J. Brewer},
  title = {Exact and Approximate Algorithms and their Implementations in Mixed
	Graphical Models},
  booktitle = {Probabilistic Reasoning and {B}ayesian Belief Networks},
  publisher = {Alfred Waller},
  year = {1995},
  editor = {A. Gammerman},
  pages = {33--53}
}

@ARTICLE{Gao:defining04,
  author = {Feng Gao and Barrett C. Foat and Harmen J. Bussemaker},
  title = {Defining Transcriptional Networks Through Integrative Modeling of
	{mRNA} Expression and Transcription Factor Binding Data},
  journal = bmcbioinf,
  year = {2004},
  volume = {5},
  pages = {1471--2105},
  number = {31},
  abstract = {{\bf Background}\\\\ Functional genomics studies are yielding information
	about regulatory processes in the cell at an unprecedented scale.
	In the yeast S. cerevisiae, DNA microarrays have not only been used
	to measure the mRNA abundance for all genes under a variety of conditions
	but also to determine the occupancy of all promoter regions by a
	large number of transcription factors. The challenge is to extract
	useful information about the global regulatory network from these
	data.\\\\ {\bf Results}\\\\ We present MA-Networker, an algorithm
	that combines microarray data for mRNA expression and transcription
	factor occupancy to define the regulatory network of the cell. Multivariate
	regression analysis is used to infer the activity of each transcription
	factor, and the correlation across different conditions between this
	activity and the mRNA expression of a gene is interpreted as regulatory
	coupling strength. Applying our method to S. cerevisiae, we find
	that, on average, 58\% of the genes whose promoter region is bound
	by a transcription factor are true regulatory targets. These results
	are validated by an analysis of enrichment for functional annotation,
	response for transcription factor deletion, and over-representation
	of cis-regulatory motifs. We are able to assign directionality to
	transcription factors that control divergently transcribed genes
	sharing the same promoter region. Finally, we identify an intrinsic
	limitation of transcription factor deletion experiments related to
	the combinatorial nature of transcriptional control, to which our
	approach provides an alternative.\\\\ {\bf Conclusion}\\\\ Our reliable
	classification of ChIP positives into functional and non-functional
	TF targets based on their expression pattern across a wide range
	of conditions provides a starting point for identifying the unknown
	sequence features in non-coding DNA that directly or indirectly determine
	the context dependence of transcription factor action. Complete analysis
	results are available for browsing or download at \url{http://bussemaker.bio.columbia.edu/papers/MA-Networker/}.},
  group = {gene networks},
  label1 = {Biomedcentral},
  link1 = {http://www.biomedcentral.com/1471-2105/5/31/}
}

@ARTICLE{Gardner:space88,
  author = {E. Gardner},
  title = {The space of interactions of neural networks models},
  journal = {Journal of Physics, A},
  year = {1988},
  volume = {21},
  pages = {257--270}
}

@ARTICLE{Gardner:inferring03,
  author = {Timothy S. Gardner and Diego di Bernardo and David Lorenz and James
	J. Collins},
  title = {Inferring Genetic Networks and Identifying Compond Mode of Action
	via Expression Profiling},
  journal = {Science},
  year = {2003},
  volume = {301}
}

@ARTICLE{Gates:nn72,
  author = {G. W. Gates},
  title = {The reduced nearest neighbor rule},
  journal = {IEEE Transactions on Information Theory},
  year = {1972},
  volume = {18},
  pages = {431--433}
}


@ARTICLE{Gavard:bayesian96,
  author = {L. Gavard and H. K. D. H. Bhadeshia and David J. C. {MacKay} and
	S. Suzuki},
  title = {{B}ayesian Neural Network Model for {A}ustentite Formation in Steels},
  journal = {Materials Science and Technology},
  year = {1996},
  volume = {12},
  pages = {453--463}
}

@INPROCEEDINGS{Geiger:rank09,
  author = {Andreas Geiger and Raquel Urtasun and Trevor Darrell},
  title = {Rank Priors for Continuous Non-Linear Dimensionality Reduction},
  booktitle = pCVPR,
  year = {2009},
  address = {Miami, FL}
}

@ARTICLE{Gelfand:nonstationary04,
  author = {Alan E. Gelfand and Alexandra M. Schmidt and Sudipto Banerjee and
	C. F. Sirmans},
  title = {Nonstationary Multivariate Process Modeling through Spatially Varying
	Coregionalization},
  journal = {TEST},
  year = {2004},
  volume = {13},
  pages = {263-312},
  number = {2}
}

@ARTICLE{Gelman:simulating98,
  author = {Andrew Gelman and Xiao-Li Meng},
  title = {Simulating Normalizing Constants: From Importance Sampling to Bridge
	Sampling to Path Sampling},
  journal = {Statistical Science},
  year = {1998},
  volume = {13},
  pages = {163--185},
  number = {2}
}

@ARTICLE{Geman:bias92,
  author = {Stuart Geman and Elie Bienenstock and Rene Doursat},
  title = {Neural networks and the bias/variance dilema},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {1--58},
  number = {1}
}

@ARTICLE{Geman:stochastic84,
  author = {Stuart Geman and Donald Geman},
  title = {Stochastic Relaxation, {G}ibbs Distributions, and {B}ayesian Restoration
	of Images},
  journal = PAMI,
  year = {1984},
  volume = {6},
  pages = {721--741},
  number = {6}
}

@ARTICLE{Gentleman:bioconductor2004,
  author = {Robert C Gentleman and Vincent J Carey and Douglas M Bates and Ben
	Bolstad and Marcel Dettling and Sandrine Dudoit and Byron Ellis and
	Laurent Gautier and Yongchao Ge and Jeff Gentry and Kurt Hornik and
	Torsten Hothorn and Wolfgang Huber and Stefano Iacus and Rafael Irizarry
	and Friedrich Leisch and Cheng Li and Martin Maechler and Anthony
	J Rossini and Gunther Sawitzki and Colin Smith and Gordon Smyth and
	Luke Tierney and Jean Y H Yang and Jianhua Zhang},
  title = {Bioconductor: Open Software Development for Computational Biology
	and Bioinformatics.},
  journal = {Genome Biol},
  year = {2004},
  volume = {5},
  pages = {R80},
  number = {10},
  abstract = {The Bioconductor project is an initiative for the collaborative creation
	of extensible software for computational biology and bioinformatics.
	The goals of the project include: fostering collaborative development
	and widespread use of innovative software, reducing barriers to entry
	into interdisciplinary scientific research, and promoting the achievement
	of remote reproducibility of research results. We describe details
	of our aims and methods, identify current challenges, compare Bioconductor
	to other open bioinformatics projects, and provide working examples.},
  doi = {10.1186/gb-2004-5-10-r80},
  institution = {Department of Biostatistical Science, Dana-Farber Cancer Institute,
	44 Binney St, Boston, MA 02115, USA. rgentlem@jimmy.harvard.edu},
  keywords = {Computational Biology, instrumentation/methods; Internet; Reproducibility
	of Results; Software},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {gb-2004-5-10-r80},
  pmid = {15461798},
  timestamp = {2010.10.05},
  url = {http://dx.doi.org/10.1186/gb-2004-5-10-r80}
}

@ARTICLE{Genton:kernelsStatistics:2001,
  author = {Marc G. Genton},
  title = {Classes of Kernels for Machine Learning: A Statistics Perspective},
  journal = jmlr,
  year = {2001},
  volume = {2},
  pages = {299-312}
}

@ARTICLE{Geva:p53,
  author = {Naama Geva-Zatorsky and Nitzan Rosenfeld and Shalev Itzkovitz and
	Ron Milo and Alex Sigal and Erez Dekel and Talia Yarnitzky and Yuvalal
	Liron and Paz Polak and Galit Lahav and Uri Alon},
  title = {Oscillations and Variability in the p53 System},
  journal = {Molecular Systems Biology},
  year = {2006}
}

@TECHREPORT{Ghahramani:emmixtures97,
  author = {Zoubin Ghahramani and Geoffrey E. Hinton},
  title = {The {EM} algorithm for mixtures of factor analyzers},
  institution = {The University of Toronto},
  year = {1997},
  number = {CRG-TR-96-1},
  abstract = {Factor analysis, a statistical method for modeling the covariance
	structure of high dimensional data using a small number of latent
	variables, can be extended by allowing dierent local factor models
	in different regions of the input space. This results in a model
	which concurrently performs clustering and dimensionality reduction,
	and can be thought of as a reduced dimension mixture of Gaussians.
	We present an exact Expectation Maximization algorithm for fitting
	the parameters of this mixture of factor analyzers.},
  file = {tr-96-1.pdf:http\://www.cs.toronto.edu/~hinton/absps/tr-96-1.pdf:PDF},
  group = {mixtures, dimensionality reduction},
  linkpsgz = {http://ftp.cs.toronto.edu/pub/zoubin/tr-96-1.ps.gz}
}

@ARTICLE{Ghahramani:factorial97,
  author = {Zoubin Ghahramani and Michael I. Jordan},
  title = {Factorial Hidden Markov models},
  journal = {Machine Learning},
  year = {1997},
  volume = {29},
  pages = {245--273},
  linkpsgz = {ftp://ftp.cs.toronto.edu/pub/zoubin/fhmmML.ps.gz}
}

@TECHREPORT{Ghahramani:missing94,
  author = {Zoubin Ghahramani and Michael I. Jordan},
  title = {Learning from incomplete data},
  institution = {Massachusetts Institute of Technology},
  year = {1994},
  number = {CBCL 108},
  linkps = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1509.ps}
}

@ARTICLE{Ghosh:honn92,
  author = {J. Ghosh and Y. Shin},
  title = {Efficient higher-order neural networks for classification and function
	approximation},
  journal = IJNS,
  year = {1992},
  volume = {3},
  pages = {323--350},
  number = {4}
}

@ARTICLE{Gibbs:variational00,
  author = {Mark N. Gibbs and David J. C. {MacKay}},
  title = {Variational {G}aussian Process Classifiers},
  journal = IEEE,
  year = {2000},
  volume = {11},
  pages = {1458--1464},
  number = {6},
  abstract = {Gaussian processes are a promising non-linear interpolation tool \cite{Williams:gauss95},\cite{Williams:Gaussian96},
	but it is not straightforward to solve classification problems with
	them. In this paper the variational methods of \cite{Jaakkola:regression96}
	are applied to Gaussian processes to produce an efficient Bayesian
	binary classifier.},
  group = {gp},
  linkpsgz = {http://www.inference.phy.cam.ac.uk/mackay/vgc.ps.gz}
}

@UNPUBLISHED{Gibbs:variational98,
  author = {Mark N. Gibbs and David J. C. {MacKay}},
  title = {Variational {G}aussian process classifiers},
  note = {Available from \url{ http://www.inference.phy.cam.ac.uk/mackay/}},
  year = {1998},
  file = {vgc.pdf:http\://www.inference.phy.cam.ac.uk/mackay/vgc.pdf:PDF},
  institution = {Cavendish Laboratory, Cambridge, U.K.},
  linkpsgz = {http://www.inference.phy.cam.ac.uk/mackay/vgc.ps.gz}
}

@UNPUBLISHED{Gibbs:efficient_gp97,
  author = {Mark N. Gibbs and David J. C. {MacKay}},
  title = {Efficient implementation of {G}aussian processes},
  note = {Unpublished manuscript, available from \url{ http://www.inference.phy.cam.ac.uk/mackay/}},
  year = {1997},
  institution = {Cavendish Laboratory, Cambridge, U.K.},
  linkpsgz = {http://www.inference.phy.cam.ac.uk/mackay/gpros.ps.gz}
}

@ARTICLE{Gibson2008a,
  author = {Greg Gibson},
  title = {The environmental contribution to gene expression profiles.},
  journal = {Nat Rev Genet},
  year = {2008},
  volume = {9},
  pages = {575--581},
  number = {8},
  month = {Aug},
  abstract = {Microarray analysis provides a bridge between the molecular genetic
	analysis of model organisms in laboratory settings and studies of
	physiology, development, and adaptation in the wild. By sampling
	species across a range of environments, it is possible to gain a
	broad picture of the genomic response to environmental perturbation.
	Incorporating estimates of genetic relationships into study designs
	will facilitate genomic analysis of environmental plasticity by aiding
	the identification of major regulatory loci in natural populations.},
  doi = {10.1038/nrg2383},
  institution = {School of Integrative Biology, The University of Queensland, Goddard
	Building, St Lucia Campus, Brisbane, Queensland 4072, Australia.
	g.gibson1@uq.edu.au},
  keywords = {Adaptation, Biological, genetics; Animals; Base Sequence; Chromosome
	Mapping; Cluster Analysis; Environment; Gene Expression Profiling;
	Genetic Variation, physiology; Genomics; Humans; Models, Biological;
	Oligonucleotide Array Sequence Analysis; Pedigree; Transcription,
	Genetic, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {nrg2383},
  pmid = {18574472},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/nrg2383}
}

@ARTICLE{Gibson:desc90,
  author = {G. J. Gibson and C. F. N. Cowan},
  title = {On the Decision Regions of Multilayer Perceptrons},
  journal = {Proceedings of the IEEE},
  year = {1990},
  volume = {78},
  pages = {1590--1594},
  number = {10}
}

@ARTICLE{Gibson:efficient00,
  author = {Michael A. Gibson and Jehoshua Bruck},
  title = {Efficient Exact Stochastic Simulation of Chemical Systems with Many
	Species and Many Channels},
  journal = JPhysChemA,
  year = {2000},
  volume = {104},
  pages = {1876--1889},
  abstract = {There are two fundamental ways to view coupled systems of chemical
	equations: as continuous, represented by differential equations whose
	variables are concentrations, or as discrete, represented by stochastic
	processes whose variables are numbers of molecules. Although the
	former is by far more common, systems with very small numbers of
	molecules are important in some applications (e.g., in small biological
	cells or in surface processes). In both views, most complicated systems
	with multiple reaction channels and multiple chemical species cannot
	be solved analytically. There are \emph{exact} numerical simulation
	methods to simulate trajectories of discrete, stochastic systems,
	(methods that are rigorously equivalent to the Master Equation approach)
	but these do not scale well to systems with many reaction pathways.
	This paper presents the Next Reaction Method, an exact algorithm
	to simulate coupled chemical reactions that is also \emph{efficient}:
	it (a) uses only a single random number per simulation event, and
	(b) takes time proportional to the \emph{logarithm} of the number
	of reactions, not to the number of reactions itself. The Next Reaction
	Method on this application is compared with one standard method and
	an optimized version of that standard method.},
  group = {stochastic simulation}
}

@article{Maxwell:governors1867,
 ISSN = {03701662},
 URL = {http://www.jstor.org/stable/112510},
 author = {James Clerk Maxwell},
 journal = {Proceedings of the Royal Society of London},
 pages = {270--283},
 publisher = {The Royal Society},
 title = {On Governors},
 volume = {16},
 year = {1867}
}

@ARTICLE{Giles:honn87,
  author = {C. L. Giles and T. Maxwell},
  title = {Learning, invariance, and generalization in high-order neural networks},
  journal = {Applied Optics},
  year = {1987},
  volume = {26},
  pages = {4972--4978},
  number = {23}
}

@ARTICLE{Gilks:adaptive92,
  author = {W. R. Gilks and P. Wild},
  title = {Adaptive Rejection Sampling for {G}ibbs sampling},
  journal = {Applied Statistics},
  year = {1992},
  volume = {41},
  pages = {337--348}
}

@ARTICLE{Gillespie:exact77,
  author = {Daniel T. Gillespie},
  title = {Exact Stochastic Simulation of Coupled Chemical Reactions},
  journal = JPhysChem,
  year = {1977},
  volume = {81},
  pages = {2340--2361},
  number = {25},
  abstract = {There are two formalisms for mathematically describing the time behavior
	of a spatially homogeneous chemical system: The \emph{deterministic
	approach} regards the time evolution as a continuous, wholly predictable
	process which is governed by a set of coupled, ordinary differential
	equations (the ``reaction-rate equations''); the \emph{stochastic
	approach} regards the time evolution as a kind of random-walk process
	which is governed by a single differential-difference equation (the
	``master equation''). Fairly simple kinetic theory arguments show
	that the stochastic formulation of chemical kinetics has a firmer
	physical basis than the deterministic formulation, but unfortunately
	the stochastic master equation is often mathematically intractable.
	There is, however, a way to make exact numerical calculations within
	the framework of the stochastic formulation without having to deal
	with the master equation directly. It is a relatively simple digital
	computer algorithm which uses a rigorously derived Monte Carlo procedure
	to \emph{numerically simulate} the time evolution of the given chemical
	system. Like the master equation, this ``stochastic simulation algorithm''
	correctly accounts for the inherent fluctuations and correlations
	that are necessarily ignored in the deterministic formulation. In
	addition, unlike most procedures for numerically solving the deterministic
	reaction-rate equations, this algorithm never approximates infinitesimal
	time increments $\mathrm{d}t$ by finite time steps $\Delta t$. The
	feasibility and utility of the simulation algorithm are demonstrated
	by applying it to several well-known model chemical systems, including
	the Lotka model, the Brusselator, and the Oregonator.},
  group = {stochastic simulation}
}

@PHDTHESIS{Girard:approximate04,
  author = {Agathe Girard},
  title = {Approximate Methods for Propagation of Uncertainty with Gaussian
	Process Models},
  school = {University of Glasgow},
  year = {2004}
}

@ARTICLE{Girolami:mercer02,
  author = {Mark Girolami},
  title = {Mercer Kernel Based Clustering in Feature Space},
  journal = IEEE,
  year = {2002},
  volume = {13},
  pages = {780--784},
  number = {4},
  label1 = {Zipped PS},
  link1 = {http://cis.paisley.ac.uk/giro-ci0/pubs_2001/tnnl0049_df.zip}
}

@ARTICLE{Girolami:variational01,
  author = {Mark Girolami},
  title = {A Variational Method for Learning Sparse and Overcomplete Representations},
  journal = NC,
  year = {2001},
  volume = {13},
  pages = {2517--2532},
  number = {11},
  label1 = {Zipped PS},
  link1 = {http://cis.paisley.ac.uk/giro-ci0/pubs_2001/nc01_mag_a_ps.zip}
}

@ARTICLE{Girolami:biologically04,
  author = {Mark Girolami and R. Breitling},
  title = {Biologically Valid Linear Factor Models of Gene Expression},
  journal = bioinf,
  year = {2004},
  volume = {20},
  pages = {3021--3033},
  number = {17},
  label1 = {Supplementary Material},
  link1 = {http://www.dcs.gla.ac.uk/people/personal/girolami/lfm}
}

@ARTICLE{Girolami:multinomial06,
  author = {Mark Girolami and Simon Rogers},
  title = {Variational {B}ayesian Multinomial Probit Regression with {G}aussian
	Process Priors},
  journal = NC,
  year = {2006},
  note = {To appear. See also Techreport TR-2005-205 from Department of Computer
	Science, University of Glasgow},
  abstract = {It is well known in the statistics literature that augmenting binary
	and polychotomous response models with Gaussian latent variables
	enables exact Bayesian analysis via Gibbs sampling from the parameter
	posterior. By adopting such a data augmentation strategy, dispensing
	with priors over regression coefficients in favour of Gaussian Process
	(GP) priors over functions, and employing variational approximations
	to the full posterior we obtain efficient computational methods for
	Gaussian Process classification in the multi-class setting. The model
	augmentation with additional latent variables ensures full a posteriori
	class coupling whilst retaining the simple a priori independent GP
	covariance structure from which sparse approximations, such as multi-class
	Informative Vector Machines (IVM), emerge in a very natural and straightforward
	manner. This is the first time that a fully Variational Bayesian
	treatment for multi-class GP classification has been developed without
	having to resort to additional explicit approximations to the non-Gaussian
	likelihood term. Empirical comparisons with exact analysis via MCMC
	and Laplace approximations illustrate the utility of the variational
	approximation as a computationally economic alternative to full MCMC
	and it is shown to be more accurate than the Laplace approximation.},
  file = {NC_MGSR_2005_nov_9.pdf:http\://eprints.pascal-network.org/archive/00001172/01/NC_MGSR_2005_nov_9.pdf:PDF},
  group = {gp}
}

@ARTICLE{Girosi:best90,
  author = {Federico Girosi and Tomaso Poggio},
  title = {Networks and the Best Approximation Property},
  journal = {Biological Cybernetics},
  year = {1990},
  volume = {63},
  pages = {169--176}
}

@ARTICLE{Girosi:kolmog89,
  author = {F. Girosi and T. Poggio},
  title = {Representation properties of networks: {K}olmogorov's theorem is
	irrelevant},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {465--469},
  number = {4}
}

@INPROCEEDINGS{Gish:prob90,
  author = {H. Gish},
  title = {A Probabilistic Approach to the Understanding and Training of Neural
	Network Classifiers},
  booktitle = {Proceedings of the IEEE Conference on Acoustics, Speech and Signal
	Processing},
  year = {1990},
  pages = {1361--1364},
  publisher = {IEEE}
}

@ARTICLE{Gneiting:analogies01,
  author = {Tilmann Gneiting and Zolt\'{a}n Sasv\'{a}ri and Martin Schlather},
  title = {Analogies and Correspondences between Variograms and Covariance functions},
  journal = {Advances in Applied Probability},
  year = {2001},
  volume = {33},
  pages = {617-630},
  number = {3}
}

@ARTICLE{Golightly:biochemical06,
  author = {Andrew Golightly and Darren J. Wilkinson},
  title = {Bayesian Sequential Inference for Stochastic Kinetic Biochemical
	Network Models},
  journal = {Journal of Computational Biology},
  year = {2006},
  volume = {13},
  pages = {838--851},
  number = {3},
  abstract = {As postgenomic biology becomes more predictive, the ability to infer
	rate parameters of genetic and biochemical networks will become increasingly
	important. In this paper, we explore the Bayesian estimation of stochastic
	kinetic rate constants governing dynamic models of intracellular
	processes. The underlying model is replaced by a diffusion approximation
	where a noise term represents intrinsic stochastic behavior and the
	model is identified using discrete-time (and often incomplete) data
	that is subject to measurement error. Sequential MCMC methods are
	then used to sample the model parameters on-line in several data-poor
	contexts. The methodology is illustrated by applying it to the estimation
	of parameters in a simple prokaryotic auto-regulatory gene network.},
  group = {sde, nonlinear diffusion, gene networks},
  linkjournal = {http://www.liebertonline.com/doi/pdf/10.1089/cmb.2006.13.838},
  linkps = {http://www.mas.ncl.ac.uk/~n9026132/lacpaper.ps}
}

@ARTICLE{Golightly:kinetic05,
  author = {Andrew Golightly and Darren J. Wilkinson},
  title = {Bayesian Inference for Stochastic Kinetic Models Using a Diffusion
	Approximation},
  journal = {Biometrics},
  year = {2005},
  volume = {61},
  pages = {781--788},
  abstract = {Summary. This article is concerned with the Bayesian estimation of
	stochastic rate constants in the context of dynamic models of intracellular
	processes. The underlying discrete stochastic kinetic model is replaced
	by a diffusion approximation (or stochastic differential equation
	approach) where a white noise term models stochastic behavior and
	the model is identified using equispaced time course data. The estimation
	framework involves the introduction of m- 1 latent data points between
	every pair of observations. MCMC methods are then used to sample
	the posterior distribution of the latent process and the model parameters.
	The methodology is applied to the estimation of parameters in a prokaryotic
	autoregulatory gene network.},
  file = {paper2.pdf:http\://www.mas.ncl.ac.uk/~n9026132/paper2.pdf:PDF},
  group = {sde, nonlinear diffusion, gene networks}
}

@ARTICLE{Golightly:multivariate05,
  author = {Andrew Golightly and Darren J. Wilkinson},
  title = {Bayesian Sequential Inference for Nonlinear Multivariate Diffusions},
  journal = {Statistics and Computing},
  year = {2005},
  abstract = {In this paper, we adapt recently developed simulation-based sequential
	algorithms to the problem concerning the Bayesian analysis of discretely
	observed diffusion processes. The estimation framework involves the
	introduction of $m-1$ latent data points between every pair of observations.
	Sequential MCMC methods are then used to sample the posterior distribution
	of the latent data and the model parameters on-line. The method is
	applied to the estimation of parameters in a simple stochastic volatility
	model (SV) of the U.S. short-term interest rate. We also provide
	a simulation study to validate our method, using synthetic data generated
	by the SV model with parameters calibrated to match weekly observations
	of the U.S. short-term interest rate.},
  group = {sde, nonlinear diffusion},
  pdfnote = {http://www.mas.ncl.ac.uk/~n9026132/svpaper5.pdf}
}

@ARTICLE{Golub:pseudo65,
  author = {G. Golub and W. Kahan},
  title = {Calculating the singular values and pseudo-inverse of a matrix},
  journal = {SIAM Numerical Analysis, B},
  year = {1965},
  volume = {2},
  pages = {205--224},
  number = {2}
}

@ARTICLE{Golub:molecular99,
  author = {T. R. Golub and D. K. Slonim and P. Tamayo and C. Huard and M. Gaasenbeek
	and J. P. Mesirov and H Coller and M. L. Loh and J. R. Downing and
	M. A. Caligiuri and C. D. Bloomfield and E. S. Lander},
  title = {Molecular classification of cancer: class discovery and class prediction
	by gene expression monitoring},
  journal = {Science},
  year = {1999},
  volume = {286},
  pages = {531--7},
  number = {5439},
  label1 = {Science Issue},
  link1 = {http://www.sciencemag.org/cgi/pmidlookup?view=full&pmid=10521349}
}

@ARTICLE{Goodsell:p53tumor99,
  author = {David S. Goodsell},
  title = {The Molecular Perspective: p53 Tumor Suppressor},
  journal = {The Oncologist, Vol. 4, No. 2, 138-139, April 1999},
  year = {1999},
  volume = {4},
  pages = {138--139},
  number = {2},
  abstract = {The p53 tumor suppressor has been termed ``the Guardian of the Cell.''
	It is not essential for life—mice that are deficient in this protein
	are born seemingly normal—but it is essential in its role of protecting
	an organism from rogue cells. p53 guards two gates: a gate to life
	and a gate to death. Sensing damage to DNA, p53 can initiate two
	processes to isolate the damaged cell and prevent its uncontrolled
	growth. It can halt cell division, freezing the cell at the G1 checkpoint
	of the cellular cycle. The cell is unable to reproduce, and its damaged
	genome is safely isolated. p53 can also initiate a more permanent
	solution: programmed cell death, or apoptosis. p53 tumor suppressor
	acts as transcriptional activator, controlling the expression of
	a variety of genes important in cell cycle regulation and apoptosis.
	p53, composed of four identical subunits, binds to a specific site
	on the DNA, and interacts with transcription interaction factors,
	leading to the initiation of transcription by RNA polymerase II.
	p53 itself is present at extremely low levels in most cells, and
	has a life span of mere minutes. These low levels allow the action
	of p53 to be genetically controlled. Levels may be raised quickly
	by synthesis of more p53, and high levels are quickly reduced when
	synthesis abates. The induction of p53 has a hair-trigger: even a
	single double-stranded break of the DNA has been predicted to be
	enough. As one might expect, disruption of a process with such an
	important function will have dire consequences. Approximately half
	of all cases of human cancer may be attributed to a defective p53
	protein. Most of these are caused by missense mutations in the p53
	gene, changing one amino acid in the protein to another. This may
	alter the binding of the protein to DNA or to the transcription factors,
	corrupting the signal from p53 to the cellular machinery, or it may
	unnaturally increase the stability of the protein, corrupting the
	delicate balance of synthesis and degradation that controls the level
	of p53 in the cell. Either way, p53 is unable to open the gates to
	cell cycle arrest or apoptosis, and cancerous cells are allowed to
	proliferate without control.}
}

@ARTICLE{Gorry:experience68,
  author = {G. Anthony Gorry and G. Octo Barnett},
  title = {Experience with a Model of Sequential Diagnosis},
  journal = {Computers and Biomedical Research},
  year = {1968},
  volume = {1},
  pages = {490--507}
}

@ARTICLE{Goulard:lmc92,
  author = {Michel Goulard and Marc Voltz},
  title = {Linear Coregionalization Model: Tools for estimation and choice of
	cross-variogram matrix},
  journal = {Mathematical Geology},
  year = {1992},
  volume = {24},
  pages = {269-286},
  number = {3}
}

@INCOLLECTION{Grunwald:mdlGrammar94,
  author = {Peter Gr\"unwald},
  title = {A Minimum Description Length approach to Grammar Inference},
  booktitle = {Symbolic, Connectionist and Statistical Approaches to Learning for
	Natural Language Processing},
  publisher = springer,
  year = {1994},
  editor = {S. Wermter and E. Riloff and G. Scheler},
  volume = {1040},
  series = lnai,
  pages = {203--216},
  address = {Berlin, Germany},
  group = {MDL, language},
  linkps = {http://www.cwi.nl/~pdg/ftp/mdlagi.ps}
}

@PHDTHESIS{Graepel:thesis98,
  author = {Thore Graepel},
  title = {Statistical Physics of Clustering Algorithms},
  school = {Technische Universit\"at Berlin},
  year = {1998},
  linkpsgz = {http://stat.cs.tu-berlin.de/~guru/papers/diplom.ps.gz}
}

@ARTICLE{Gray:hic00,
  author = {Julie E. Gray and Geoff H. Holroyd and Frederique M. {van der Lee}
	and Ahmad R. Bahrami and Peter C. Sijmons and F. Ian Woodward and
	Wolfgang Schuch and Alistair M. Hetherington},
  title = {The \emph{HIC} signalling pathway links $\mathrm{CO}_2$ perception
	to stomatal development},
  journal = {Nature},
  year = {2000},
  volume = {408},
  pages = {713--716}
}

@ARTICLE{Greetham2007,
  author = {Darren Greetham and Charles D Ellis and Devesh Mewar and Ursula Fearon
	and Sinead Nic an Ultaigh and Douglas J Veale and François Guesdon
	and Anthony G Wilson},
  title = {Functional characterization of NF-kappaB inhibitor-like protein 1
	(NFkappaBIL1), a candidate susceptibility gene for rheumatoid arthritis.},
  journal = {Hum Mol Genet},
  year = {2007},
  volume = {16},
  pages = {3027--3036},
  number = {24},
  month = {Dec},
  abstract = {Several studies have implicated the NF-kappaB inhibitor-like protein
	1 (NFkBIL1) gene located in the class III region of the major histocompatibility
	complex (MHC) as a possible susceptibility locus for rheumatoid arthritis
	(RA). Based on limited homology, it has been suggested to be a member
	of the inhibitor of NF-kappaB (IkappaB) family of proteins, but a
	role in mRNA processing has also been proposed. We have investigated
	the expression of NFkBIL1 in RA synovial tissue and characterized
	its function. Real-time PCR showed the two NFkBIL1 mRNA splice variants
	are expressed in a tissue-specific manner. Dual immunofluorescent
	staining of human RA synovium with polyclonal anti-NFkBIL1 antibodies
	and anti-CD68, anti-CD3 or anti-factor VIII showed that NFkBIL1 was
	expressed in the rheumatoid synovial lining and sub-lining layers
	and co-localized in CD68+ and CD3+, but not Factor VIII+ cells. Confocal
	microscopy of cultured synovial fibroblasts revealed expression in
	speckled nuclear and homogenous cytoplasmic distributions, suggesting
	shuttling between the cytoplasmic and nuclear compartments. Functional
	tests showed that NFkBIL1 isoforms were incapable of associating
	with NF-kappaB and did not inhibit it, thus disproving the hypothesis
	that NFkBIL1 functions as an IkappaB. Affinity purification of endogenous
	NFkBIL1 proteins and co-immunoprecipitation experiments showed that
	NFkBIL1 can associate with mRNA and with three protein partners,
	identified by mass spectrometry as leukophysin, translation elongation
	factor 1 alpha and CTP synthase I. These data support a potential
	role for NFkBL1 in the pathogenesis of RA and indicates that it may
	be involved in mRNA processing or the regulation of translation.},
  doi = {10.1093/hmg/ddm261},
  keywords = {Arthritis, Rheumatoid, genetics/pathology; Biopsy; Carbon-Nitrogen
	Ligases, metabolism; Cells, Cultured; DEAD-box RNA Helicases, metabolism;
	Female; Genetic Predisposition to Disease; Hela Cells; Histocompatibility
	Antigens Class II, genetics/metabolism/physiology; Humans; Male;
	Neoplasm Proteins, metabolism; Peptide Elongation Factor 1, metabolism;
	Protein Biosynthesis, genetics; Protein Isoforms, metabolism; RNA
	Processing, Post-Transcriptional; RNA, Messenger, metabolism; Synovial
	Membrane, metabolism/pathology; Tissue Distribution},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ddm261},
  pmid = {17855452},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1093/hmg/ddm261}
}

@ARTICLE{Grimm:mouse98,
  author = {C Grimm and B Chatterjee and J Favor and T Immervoll and J Loster
	and N Klopp and R Sandulache and J Graw},
  title = {Aphakia (ak), A Mouse Mutation Affecting Early Eye Development: Fine
	Mapping, Consideration of Candidate Genes and Altered {P}ax6 and
	{S}ix3 Gene Expression Pattern},
  journal = {Developmental Genetics},
  year = {1998},
  volume = {23},
  pages = {299--316},
  number = {4}
}

@ARTICLE{Groban:phosphorylation06,
  author = {Eli S Groban and Arjun Narayanan and Matthew P Jacobson},
  title = {Conformational Changes in Protein Loops and Helices Induced by Post-Translational
	Phosphorylation},
  journal = {PLoS Comput. Biol.},
  year = {2006},
  volume = {2},
  number = {4},
  abstract = {Post-translational phosphorylation is a ubiquitous mechanism for modulating
	protein activity and protein-protein interactions. In this work,
	we examine how phosphorylation can modulate the conformation of a
	protein by changing the energy landscape. We present a molecular
	mechanics method in which we phosphorylate proteins in silico and
	then predict how the conformation of the protein will change in response
	to phosphorylation. We apply this method to a test set comprised
	of proteins with both phosphorylated and non-phosphorylated crystal
	structures, and demonstrate that it is possible to predict localized
	phosphorylation-induced conformational changes, or the absence of
	conformational changes, with near-atomic accuracy in most cases.
	Examples of proteins used for testing our methods include kinases
	and prokaryotic response regulators. Through a detailed case study
	of cyclin-dependent kinase 2, we also illustrate how the computational
	methods can be used to provide new understanding of how phosphorylation
	drives conformational change, why substituting Glu or Asp for a phosphorylated
	amino acid does not always mimic the effects of phosphorylation,
	and how a phosphatase can “capture” a phosphorylated amino acid.
	This work illustrates how computational methods can be used to elucidate
	principles and mechanisms of post-translational phosphorylation,
	which can ultimately help to bridge the gap between the number of
	known sites of phosphorylation and the number of structures of phosphorylated
	proteins.},
  doi = {10.1371/journal.pcbi.0020032},
  file = {picrender.fcgi?artid=1440919&blobtype=pdf:http\://www.pubmedcentral.nih.gov/picrender.fcgi?artid=1440919&blobtype=pdf:PDF},
  group = {protein structure, phosphorylation},
  optpages = {e32},
  optpmid = {1440919}
}

@INPROCEEDINGS{Grochow:styleik04,
  author = {Keith Grochow and Steven L. Martin and Aaron Hertzmann and Zoran
	Popovic},
  title = {Style-Based Inverse Kinematics},
  booktitle = {ACM Transactions on Graphics (SIGGRAPH 2004)},
  year = {2004},
  pages = {522--531},
  abstract = {This paper presents an inverse kinematics system based on a learned
	model of human poses. Given a set of constraints, our system can
	produce the most likely pose satisfying those constraints, in real
	time. Training the model on different input data leads to different
	styles of IK. The model is represented as a probability distribution
	over the space of all possible poses. This means that our IK system
	can generate any pose, but prefers poses that are most similar to
	the space of poses in the training data. We represent the probability
	with a novel model called a Scaled Gaussian Process Latent Variable
	Model. The parameters of the model are all learned automatically;
	no manual tuning is required for the learning component of the system.
	We additionally describe a novel procedure for interpolating between
	styles.\\\\ Our style-based IK can replace conventional IK, wherever
	it is used in computer animation and computer vision. We demonstrate
	our system in the context of a number of applications: interactive
	character posing, trajectory keyframing, real-time motion capture
	with missing markers, and posing from a 2D image.},
  doi = {10.1145/1186562.1015755},
  file = {styleik.pdf:http\://grail.cs.washington.edu/projects/styleik/styleik.pdf:PDF},
  group = {gplvm},
  label1 = {Web page},
  link1 = {http://grail.cs.washington.edu/projects/styleik/}
}

@ARTICLE{Gudivada:content95,
  author = {Venkat N. Gudivada and Vijay V. Raghavan},
  title = {Content-Based Image Retrieval Systems},
  journal = {IEEE Computer},
  year = {1995},
  volume = {28},
  pages = {18--22},
  number = {9}
}

@TECHREPORT{Gunn:SVMforregr98,
  author = {S. Gunn},
  title = {Support Vector Machines for Classification and Regression},
  institution = {Image Speech and Intelligent Systems Group, University of Southampton},
  year = {1998},
  month = May,
  note = {Available from \url{http://www.isis.ecs.soton.ac.uk/research/svm/}}
}

@ARTICLE{Gursky:pattern04,
  author = {Vitaly V. Gursky and Johannes Jaeger and Konstantin N. Kozlov and
	John Reinitz and Alexander Samsonov},
  title = {Pattern formation and nuclear divisions are uncoupled in {D}rosophila
	segmentation: comparison of spatially discrete and continuous models},
  journal = {Physica D},
  year = {2004},
  volume = {197},
  pages = {286-302}
}

@ARTICLE{Gutenkunst:universally07,
  author = {Ryan N. Gutenkunst and Joshua J. Waterfall and Fergal P. Casey and
	Kevin S. Brown and Christopher R. Myers and James P. Sethna},
  title = {Universally Sloppy Parameter Sensitivities in Systems Biology},
  year = {2007},
  note = {Submitted},
  abstract = {Quantitative computational models can play important roles in modern
	biology as compact, predictive descriptions of complex systems. Such
	models typically involve many free parameters, and assigning their
	values is often a substantial obstacle to model development and use.
	Directly measuring in vivo biochemical parameters is difficult, and
	several researchers have found that collectively fitting parameters
	to other experimental data yields large parameter uncertainties.
	Nevertheless, Brown et al. showed in a growth-factor-signaling model
	that collective fitting could yield well-constrained predictions
	even when it left individual parameters very poorly constrained.
	They also showed that their model had a 'sloppy' spectrum of parameter
	sensitivities: roughly linearly spaced in the logarithm over a huge
	range. Here we use a collection of models from the literature to
	demonstrate the apparent universality of such sloppy spectra in systems
	biology. This sloppiness has several consequences for building predictive
	models. We predict and verify that collective fits to even large
	amounts of ideal time-series data will often leave many parameters
	poorly constrained. This may seem to argue for direct parameter measurements,
	but we demonstrate using a particular model that such measurements
	must be formidably precise and complete to usefully constrain model
	predictions. The prevalence of sloppiness in complex biology suggests
	that collective fits are powerful and that modelers should focus
	on their desired predictions rather than on their parameters.},
  file = {0701039:http\://arxiv.org/pdf/q-bio/0701039:PDF},
  group = {pesb},
  label1 = {Supplementary Information},
  link1 = {http://pages.physics.cornell.edu/~rgutenkunst/universal_suppl/},
  linkps = {http://arxiv.org/ps/q-bio/0701039}
}

@ARTICLE{Vargas:coregionalization02,
  author = {Jos\'e Antonio Vargas Guzm\'{a}n and Arthur W. Warrick and Donald
	E. Myers},
  title = {Coregionalization by Linear Combination of Nonorthogonal Components},
  journal = {Mathematical Geology},
  year = {2002},
  volume = {34},
  pages = {405-419},
  number = {4}
}

@BOOK{Hormander:analysis83,
  title = {The analysis of Linear Partial Differential Operators {I}},
  publisher = {Springer-Verlag},
  year = {1983},
  author = {Lars H\"ormander},
  address = {Berlin Hiedelberg},
  edition = {First}
}

@INPROCEEDINGS{Hadsell:dimred06,
  author = {Raia Hadsell and Sumit Chopra and Yann {LeCun}},
  title = {Dimensionality Reduction by Learning an Invariant Mapping},
  booktitle = pCVPR,
  year = {2006},
  address = {New York, NY, U.S.A.},
  month = {17--22 Jun.},
  publisher = ieeecomp,
  abstract = {Dimensionality reduction involves mapping a set of high dimensional
	input points onto a low dimensional manifold so that ``similar''
	points in input space are mapped to nearby points on the manifold.
	Most existing techniques for solving the problem suffer from two
	drawbacks. First, most of them depend on a meaningful and computable
	distance metric in input space. Second, they do not compute a "function"
	that can accurately map new input samples whose relationship to the
	training data is unknown. We present a method - called Dimensionality
	Reduction by Learning an Invariant Mapping (DrLIM) - for learning
	a globally coherent non-linear function that maps the data evenly
	to the output manifold. The learning relies solely on neighborhood
	relationships and does not require any distance measure in the input
	space. The method can learn mappings that are invariant to certain
	transformations of the inputs, as is demonstrated with a number of
	experiments. Comparisons are made to other techniques, in particular
	LLE.},
  file = {hadsell-chopra-lecun-06.pdf:http\://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf:PDF},
  group = {dimensional reduction},
  linkdjvu = {http://yann.lecun.com/exdb/publis/djvu/hadsell-chopra-lecun-06.djvu}
}

@ARTICLE{Haft:mft99,
  author = {M. Haft and R. Hoffmann and Volker Tresp},
  title = {Model-Independent Mean Field Theory as a Local Method for Approximate
	Propagation of Information},
  journal = network,
  year = {1999},
  volume = {10},
  pages = {93--105}
}

@TECHREPORT{Hamerly:learning02,
  author = {Greg Hamerly and Charles Elkan},
  title = {Learning the $k$ in $k$-means},
  institution = {Computer Science and Engineering Department, University of California
	at San Diego},
  year = {2002},
  number = {CS2002-0716},
  linkps = {http://www.cs.ucsd.edu/Dienst/Repository/2.0/Body/ncstrl.ucsd_cse/CS2002-0716/postscript}
}

@TECHREPORT{Hammersley:markov71,
  author = {John M. Hammersley and Peter Clifford},
  title = {Markov fields on finite graphs and lattices},
  year = {1971},
  owner = {neil},
  timestamp = {2012.01.03},
  url = {http://www.statslab.cam.ac.uk/~grg/books/hammfest/hamm-cliff.pdf}
}

@ARTICLE{Hand:nn78,
  author = {D. J. Hand and B. G. Batchelor},
  title = {Experiments on the edited condensed nearest neighbour rule},
  journal = {Information Sciences},
  year = {1978},
  volume = {14},
  pages = {171--180}
}

@INPROCEEDINGS{Hanson:minkow88,
  author = {S. J. Hanson and D. J. Burr},
  title = {Minkowski-r back-propagation: learning in connectionist models with
	non-{E}uclidean error signals},
  booktitle = {Neural Information Processing Systems},
  year = {1988},
  editor = {D. Anderson},
  pages = {348--357},
  address = {New York},
  publisher = {American Institute of Physics}
}

@ARTICLE{Harbison:transcriptional04,
  author = {Christopher T. Harbison and D. Benjamin Gordon and Tong Ihn Lee and
	Nicola J. Rinaldi and Kenzie D. Macisaac and Timothy W. Danford and
	Nancy M. Hannet and Jean-Bosco Tagne and David B. Reynolds and Jane
	Yoo and Ezra G. Jennings and Julia Zeitlinger and Dmitry K. Pokholok
	and Manolis Kellis and P. Alex Rolfe and Ken T. Takusagawa and Eric
	S. Lander and David K. Gifford and Ernest Fraenkel and Richard A.
	Young},
  title = {Transcriptional Regulatory Code of a Eukaryotic Genome},
  journal = {Nature},
  year = {2004},
  volume = {431},
  pages = {99--104}
}

@TECHREPORT{Harmeling:exploring07,
  author = {Stefan Harmeling},
  title = {Exploring model selection techniques for nonlinear dimensionality
	reduction},
  institution = {University of Edinburgh},
  year = {2007},
  number = {EDI-INF-RR-0960},
  abstract = {Nonlinear dimensionality reduction (NLDR) methods have become useful
	tools for practitioners who are faced with the analysis of high-dimensional
	data. Of course, not all NLDR methods are equally applicable to a
	particular dataset at hand. Thus it would be useful to come up with
	model selection criteria that help to choose among different NLDR
	algorithms. This paper explores various approaches to this problem
	and evaluates them on controlled data sets. Comprehensive experiments
	will show that model selection scores based on stability are not
	useful, while scores based on Gaussian processes are helpful for
	the NLDR problem.},
  group = {gplvm},
  optfile = {techreport.pdf:http\://homepages.inf.ed.ac.uk/sharmeli/pubs/techreport.pdf:PDF}
}

@ARTICLE{Hart:CNN68,
  author = {P. Hart},
  title = {The Condensed Nearest Neighbor Rule},
  journal = TIT,
  year = {1968},
  volume = {14},
  pages = {515--516}
}

@ARTICLE{Hart:nn68,
  author = {P. E. Hart},
  title = {The condensed nearest neighbor rule},
  journal = {IEEE Transactions on Information Theory},
  year = {1968},
  volume = {14},
  pages = {515--516}
}

@ARTICLE{Hartman:rbfs90,
  author = {E. J. Hartman and J. D. Keeler and J. M. Kowalski},
  title = {Layered neural networks with {G}aussian hidden units as universal
	approximations},
  journal = NC,
  year = {1990},
  volume = {2},
  pages = {210--215},
  number = {2}
}

@INPROCEEDINGS{Hassibi:surgeon93,
  author = {B. Hassibi and D. G. Stork},
  title = {Second order derivatives for network pruning: optimal brain surgeon.},
  booktitle = nips,
  year = {1993},
  editor = {S. J. Hanson and J. D. Cowan and C. L. Giles},
  volume = {5},
  pages = {164--171},
  address = {San Mateo, CA},
  publisher = {Morgan Kaufmann}
}

@ARTICLE{Hastie:pcurves89,
  author = {Trevor Hastie and W. Stuetzle},
  title = {Principal curves},
  journal = {Journal of the American Statistical Association},
  year = {1989},
  volume = {84},
  pages = {502--516},
  number = {406}
}

@TECHREPORT{Haussler:convolutional99,
  author = {David Haussler},
  title = {Convolutional Kernels on Discrete Structures},
  institution = {Computer Science Department, University of California at Santa Cruz},
  year = {1999},
  number = {UCSC-CRL-99-10}
}

@INCOLLECTION{HechtNielsen:bp90,
  author = {Robert Hecht-Nielsen},
  title = {On the algebraic structure of feedforward network weight spaces},
  booktitle = {Advanced Neural Computers},
  publisher = {North Holland},
  year = {1990},
  editor = {R. Eckmiller},
  pages = {129--136},
  address = {Amsterdam}
}

@INPROCEEDINGS{HechtNielsen:bp89,
  author = {Robert Hecht-Nielsen},
  title = {Theory of the Back-propagation Neural Network},
  booktitle = ijcnn,
  year = {1989},
  volume = {1},
  pages = {593--605},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@UNPUBLISHED{Hein:bgx05,
  author = {Anne-Mette K. Hein and Sylvia Richardson and H. C. Causton and Graeme
	K. Ambler and Peter J. Green},
  title = {{BGX}: a fully {B}ayesian gene expression index for {A}ffymetrix
	{GeneChip} data},
  note = {To appear in Biostatistics},
  year = {2005},
  file = {BGXpaperSubmit.pdf:http\://www.bgx.org.uk/papers/BGXpaperSubmit.pdf:PDF},
  label1 = {Zipped PS},
  label2 = {Software and Supplementary Material},
  link1 = {http://www.bgx.org.uk/papers/BGXpaperSubmit.zip},
  link2 = {http://www.stats.bris.ac.uk/BGX/supplementary.html}
}

@ARTICLE{Heisenberg:uncertainty27,
  author = {Werner Heisenberg},
  title = {Uber den anschaulichen {I}nhalt der quantentheoretischen {K}inematik
	und {M}echanik},
  journal = {Zeitschrift f\"ur {P}hysik},
  year = {1927},
  volume = {43},
  pages = {172--198},
  note = {Reprinted in \cite{Wheeler:quantum83}}
}

@ARTICLE{Helterbrand:universalCR94,
  author = {Jeffrey D. Helterbrand and Noel A. C. Cressie},
  title = {Universal cokriging under intrinsic coregionalization },
  journal = {Mathematical Geology},
  year = {1994},
  volume = {26},
  pages = {205-226},
  number = {2}
}

@ARTICLE{Helyer:model07,
  author = {Richard Helyer and Daniela Cacciabue-Rivolta and Dawn Davies and
	Marcelo N. Rivolta and Corne J. Kros and Matthew C. Holley},
  title = {A model for mammalian cochlear hair cell differentiation in vitro:
	effects of retinoic acid on cytoskeletal proteins and potassium conductances},
  journal = {Eur J Neurosci},
  year = {2007},
  volume = {25},
  pages = {957--973},
  number = {4},
  month = {Feb},
  abstract = {We have established a model for the in-vitro differentiation of mouse
	cochlear hair cells and have used it to explore the influence of
	retinoic acid on proliferation, cytoskeletal proteins and voltage-gated
	potassium conductances. The model is based on the conditionally immortal
	cell line University of Sheffield/ventral otocyst-epithelial cell
	line clone 36 (US/VOT-E36), derived from ventral otic epithelial
	cells of the mouse at embryonic day 10.5 and transfected with a reporter
	for myosin VIIa. Retinoic acid did not increase cell proliferation
	but led to up-regulation of myosin VIIa and formation of prominent
	actin rings that gave rise to numerous large, linear actin bundles.
	Cells expressing myosin VIIa had larger potassium conductances and
	did not express the cyclin-dependent kinase inhibitor p27(kip1).
	US/VOT-E36 endogenously expressed the voltage-gated potassium channel
	alpha-subunits Kv1.3 and Kv2.1, which we subsequently identified
	in embryonic and neonatal hair cells in both auditory and vestibular
	sensory epithelia in vivo. These subunits could underlie the embryonic
	and neonatal delayed-rectifiers recorded in nascent hair cells in
	vivo. Kv2.1 was particularly prominent on the basolateral membrane
	of cochlear inner hair cells. Kv1.3 was distributed throughout all
	hair cells but tended to be localized to the cuticular plates. US/VOT-E36
	recapitulates a coherent pattern of cell differentiation under the
	influence of retinoic acid and will provide a convenient model for
	screening the effects of other extrinsic factors on the differentiation
	of cochlear epithelial cell types in vitro.},
  doi = {10.1111/j.1460-9568.2007.05338.x},
  institution = {Department of Biomedical Science, Addison Building, Western Bank,
	Sheffield, UK.},
  keywords = {Animals; Bone Morphogenetic Protein 4; Bone Morphogenetic Proteins,
	antagonists /&/ inhibitors/pharmacology; Cell Count; Cell Differentiation,
	drug effects; Cell Line; Cochlea, cytology; Culture Media, Serum-Free,
	pharmacology; Cytoskeletal Proteins, metabolism; Drug Interactions;
	Embryo, Mammalian; Enzyme Inhibitors, pharmacology; Epithelial Cells,
	drug effects; Gene Expression Regulation, drug effects; Green Fluorescent
	Proteins, metabolism; Membrane Potentials, drug effects/physiology;
	Mice; Models, Animal; Potassium Channels, Voltage-Gated, metabolism;
	Potassium, metabolism; Transfection, methods; Tretinoin, pharmacology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pii = {EJN5338},
  pmid = {17331193},
  timestamp = {2010.04.08}
}

@ARTICLE{Herbst:egfr04,
  author = {Roy S. Herbst},
  title = {Review of Epidermal Growth Factor Receptor Biology},
  journal = {International Journal of Radiation Oncology},
  year = {2004},
  volume = {59},
  pages = {S21--S26},
  number = {2},
  abstract = {The epidermal growth factor receptor (EGFR) is a transmembrane glycoprotein
	that constitutes one of four members of the erbB family of tyrosine
	kinase receptors. Binding of EGFR to its cognate ligands leads to
	autophosphorylation of receptor tyrosine kinase and subsequent activation
	of signal transduction pathways that are involved in regulating cellular
	proliferation, differentiation, and survival. Although present in
	normal cells, EGFR is overexpressed in a variety of tumor cell lines
	and has been associated with poor prognosis and decreased survival.
	EGFR activation also plays a role in resistance to chemotherapy and
	radiation treatment in tumor cells. Over the past two decades, much
	effort has been directed at developing anticancer agents that can
	interfere with EGFR activity. The most common pharmacologic approaches
	to inhibiting EGFR have been to develop monoclonal antibodies and
	small-molecule inhibitors. Monoclonal antibodies block ligand binding
	to the extra- cellular domain, whereas the small-molecule inhibitors
	exert their effects at the intracellular portion of the receptor
	to prevent tyrosine kinase phosphorylation and subsequent activation
	of signal transduction pathways. A number of EGFR inhibitors have
	been developed that can arrest tumor growth and, in some cases, cause
	tumor regression. When used in combination with cytotoxic treatments,
	chemotherapy, and radiation, EGFR inhibitors have been able to potentiate
	their anticancer activity. © 2004 Elsevier Inc. },
  doi = {10.1016/j.ijrobp.2003.11.041},
  group = {EGFR},
  pmid = {15142631}
}

@ARTICLE{Herrero2002,
  author = {Carmen Herrero and Carlos Sebastián and Laura Marqués and Mònica
	Comalada and Jordi Xaus and Annabel F Valledor and Jorge Lloberas
	and Antonio Celada},
  title = {Immunosenescence of macrophages: reduced MHC class II gene expression.},
  journal = {Exp Gerontol},
  year = {2002},
  volume = {37},
  pages = {389--394},
  number = {2-3},
  abstract = {In order to determine the effect of aging on macrophages, we produced
	bone marrow-derived macrophages in vitro from young and aged mice.
	We analyzed the effect of aging on the genomic expression of macrophages
	in these conditions, without the influence of other cell types that
	may be affected by aging. Macrophages from young and aged mice were
	present in similar numbers and showed an identical degree of differentiation,
	cell size, DNA content and cell surface markers. After incubation
	with interferon-gamma (IFN-gamma), the expression at the cell surface
	of the MHC class II gene IA complex product and the levels of intracellular
	IAbeta protein and mRNA were lower in aged macrophages. Moreover,
	the transcription of IAbeta gene was impaired in aged macrophages.
	The amount of transcription factors that bound to the W and X boxes,
	but not to the Y box of the IAbeta promoter gene were lower in aged
	macrophages. Similar levels of CIITA mRNA were found after IFN-gamma
	treatment of both young and aged macrophages. This shows that neither
	the initial cascade that starts after the interaction of IFN-gamma
	with the receptor, nor the second signals involved in the expression
	of CIITA, are impaired in aged macrophages. These data could explain,
	at least in part, the impaired immune response associated to senescence.},
  institution = {Departament de Fisiologia (Biologia del Macrofag), Facultat de Biologia
	and Fundació August Pi i Sunyer, Universitat de Barcelona, Avenida
	Diagonal 645, E-08028 Barcelona, Spain.},
  keywords = {Aging, blood/immunology; Animals; Gene Expression; Genes, MHC Class
	II; Humans; Macrophages, immunology; Mice; Models, Immunological;
	Transcription, Genetic},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {S0531556501002054},
  pmid = {11772525},
  timestamp = {2011.09.14}
}

@ARTICLE{Hertz:nlbp97,
  author = {J. Hertz and Anders Krogh and B. Lautrup and T. Lehmann},
  title = {Non-linear back-propagation: Doing back-propagation without derivatives
	of the activation function.},
  journal = IEEE,
  year = {1997},
  volume = {8},
  pages = {1321--1327}
}

@INPROCEEDINGS{Heskes:generalized03,
  author = {Tom Heskes and Onno Zoeter},
  title = {Generalized belief propagation for approximate inference in hybrid
	{B}ayesian Networks},
  file = {121.pdf:http\://research.microsoft.com/conferences/AIStats2003/proceedings/121.pdf:PDF},
  group = {EP},
  linkps = {http://research.microsoft.com/conferences/AIStats2003/proceedings/121.ps},
  crossref =	 {Bishop:aistats03}
}

@Article{Nelder:glm72,
  author = 	 {John Nelder and Robert Wedderburn},
  title = 	 {Generalized Linear Models},
  journal = 	 JRSSa,
  year = 	 {1972},
  OPTkey = 	 {},
  volume =	 {135},
  number =	 {3},
  OPTpages = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.2307/2344614},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@InProceedings{Schein:generalized03,
  author = 	 {Andrew I. Schein and Lawrence K. Saul and Lyle H. Ungar},
  title = 	 {A Generalized Linear Model for Principal Component Analysis of Binary Data},
  crossref =	 {Bishop:aistats03},
  OPTkey = 	 {},
  OPTbooktitle = {},
  OPTpages = 	 {},
  OPTyear = 	 {},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@ARTICLE{Hestenes:conjugate52,
  author = {Magnus R. Hestenes and Eduard Stiefel},
  title = {Methods of conjugate gradients for solving linear systems},
  journal = {Journal of Research of the National Bureau of Standards},
  year = {1952},
  volume = {49},
  pages = {409--436},
  number = {6},
  file = {V49.N06.A08.pdf:http\://nvl.nist.gov/pub/nistpubs/jres/049/6/V49.N06.A08.pdf:PDF},
  linkpdf = {http://nvl.nist.gov/pub/nistpubs/jres/049/6/V49.N06.A08.pdf}
}

@INPROCEEDINGS{Higdon:convolutions02,
  author = {David M. Higdon},
  title = {Space and space-time modelling using process convolutions},
  booktitle = {Quantitative methods for current environmental issues},
  year = {2002},
  editor = {C. Anderson and V. Barnett and P. Chatwin and A. El-Shaarawi},
  pages = {37--56},
  publisher = springer
}

@ARTICLE{Higdon:ocean98,
  author = {David M. Higdon},
  title = {A Process-Convolution Approach to Modeling Temperatures in the North
	Atlantic Ocean},
  journal = {Journal of Ecological and Environmental Statistics},
  year = {1998},
  volume = {5},
  pages = {173-190}
}

@TECHREPORT{Higdon:high05,
  author = {David M. Higdon and Jim Gattiker and Brian Williams and Maria Rightley},
  title = {Computer Model Calibration using High Dimensional Output},
  institution = {Los Alamos National Laboratory, U.S.A.},
  year = {2--5},
  linkpdf = {http://www.stat.lanl.gov/ccs6/staff/DHigdon/Papers/nedd05-6410.pdf},
  optnumber = {LAUR-05-6410}
}

@ARTICLE{Higdon:high08,
  author = {David M. Higdon and Jim Gattiker and Brian Williams and Maria Rightley},
  title = {Computer Model Calibration using High Dimensional Output},
  journal = jasa,
  year = {2008},
  volume = {103},
  pages = {570-583},
  number = {482}
}

@ARTICLE{Hilbert:1900,
  author = {David Hilbert},
  title = {Mathematische Probleme},
  journal = {Nachrichten der Akademie der Wissenschaften G{\"{o}}ttingen},
  year = {1900},
  pages = {290--329}
}

@INPROCEEDINGS{Hinton:inv87,
  author = {Geoffrey E. Hinton},
  title = {Learning translation invariant recognition in massively parallel
	networks},
  booktitle = {Proceedings PARLE Conference on Parallel Architectures and Languages
	Europe},
  year = {1987},
  editor = {J. W. {de Bakker} and A. J. Nijman and P. C. Treleaven},
  pages = {1--13},
  address = {Berlin},
  publisher = springer
}

@TECHREPORT{Hinton:poe00,
  author = {Geoffrey E. Hinton},
  title = {Training Products of Experts by Minimizing Contrastive Divergence},
  institution = {Gatsby Computational Neuroscience Unit, Univ. College London},
  year = {2000},
  group = {products of experts},
  optnumber = {GCNU TR 2000-004}
}

@INPROCEEDINGS{Hinton:product99,
  author = {Geoffrey E. Hinton},
  title = {Products of Experts},
  booktitle = {ICANN 99: Ninth international conference on artificial neural networks},
  year = {1999},
  volume = {1},
  pages = {1--6},
  publisher = {IEE Press},
  linkps = {http://www.cs.toronto.edu/~hinton/absps/icann-99.ps}
}

@ARTICLE{Hinton:detboltz89,
  author = {Geoffrey E. Hinton},
  title = {Deterministic {B}oltzmann Machine Performs Steepest Descent in Weight-space.},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {143--150},
  number = {1}
}

@ARTICLE{Hinton:learning89,
  author = {Geoffrey E. Hinton},
  title = {Connectionist learning procedures},
  journal = {Artificial Intelligence},
  year = {1989},
  volume = {40},
  pages = {185--234}
}

@INPROCEEDINGS{Hinton:simple93,
  author = {Geoffrey E. Hinton and Drew {v}an~Camp},
  title = {Keeping Neural Networks Simple by Minimizing the Description Length
	of the Weights},
  booktitle = {Proceedings of the Sixth Anuual Conference on Computational Learning
	Theory},
  year = {1993},
  pages = {5--13},
  linkps = {http://www.cs.toronto.edu/~hinton/absps/colt93.ps},
  place = {Santa Cruz}
}

@ARTICLE{Hinton:science95,
  author = {Geoffrey E. Hinton and Peter Dayan and Brendan J. Frey and Radford
	M. Neal},
  title = {The wake-sleep algorithm for unsupervised neural networks},
  journal = {Science},
  year = {1995},
  volume = {268},
  pages = {1158--1161},
  linkps = {http://www.cs.toronto.edu/~hinton/absps/ws.ps}
}

@ARTICLE{Hinton:manifold97,
  author = {Geoffrey E. Hinton and Peter Dayan and Michael D. Revow},
  title = {Modeling the Manifolds of Images of Handwritten Digits},
  journal = IEEE,
  year = {1997},
  volume = {8},
  pages = {65--74},
  number = {1},
  linkpsgz = {http://www.cs.toronto.edu/~hinton/absps/manifold.ps.gz}
}

@ARTICLE{Hinton:reducing06,
  author = {Geoffrey E. Hinton and Ruslan R. Salakhutdinov},
  title = {Reducing the Dimensionality of Data with Neural Networks},
  journal = {Science},
  year = {2006},
  volume = {303},
  pages = {504--507},
  number = {5786},
  abstract = {High-dimensional data can be converted to low-dimensional codes by
	training a multilayer neural network with a small central layer to
	reconstruct high-dimensional input vectors. Gradient descent can
	be used for fine-tuning the weights in such "autoencoder" networks,
	but this works well only if the initial weights are close to a good
	solution. We describe an effective way of initializing the weights
	that allows deep autoencoder networks to learn low-dimensional codes
	that work much better than principal components analysis as a tool
	to reduce the dimensionality of data.},
  linkpdf = {http://www.cs.toronto.edu/~hinton/science.pdf},
  linksoftware = {http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html}
}

@INPROCEEDINGS{Hinton:optimal83,
  author = {Geoffrey E. Hinton and Terrence J. Sejnowski},
  title = {Optimal Perceptual Inference},
  booktitle = pCVPR,
  year = {1983},
  pages = {448--453},
  address = {Arlington, VA, U.S.A.},
  month = {19--23 Jun.},
  publisher = ieeecomp
}

@INPROCEEDINGS{Hochberg:abbot95,
  author = {M. Hochberg and Steven Renals and A. J. Robinson},
  title = {Abbot: The {CUED} Hybrid Connectionist-{HMM} Large Vocabulary Recognition
	System},
  booktitle = {Proceedings of the Spoken Language Technology Workshop},
  year = {1995},
  pages = {170--178},
  address = {San Fransisco, CA},
  publisher = mk
}

@ARTICLE{Hoeting:bayesian99,
  author = {Jennifer A. Hoeting and David Madigan and Adrian E. Raftery and Chris
	T. Volinsky},
  title = {{B}ayesian Model Averaging: A Tutorial (with discussion)},
  journal = {Statistical Science},
  year = {1999},
  volume = {14},
  pages = {382--417},
  number = {4},
  abstract = {Standard statistical practice ignores model uncertainty. Data analysts
	typically select a model from some class of models and then proceed
	as if the selected model had generated the data. This approach ignores
	the uncertainty in model selction, leading to over-confident inferences
	and deciswions that are more risky than one thinks they are. Bayesian
	model averaging (BMA) provides a coherent mechanism for accounting
	for this model uncertainty. Several methods for implementing BMA
	have recently emerged. We discuss these methods and present a number
	of examples. In these examples, BMA provides improved out-of-sample
	predictive performance. We also provide a catalogue of currently
	available BMA software.},
  file = {hoeting1999.pdf:http\://www.stat.washington.edu/www/research/online/hoeting1999.pdf:PDF}
}

@ARTICLE{Holstege:dissecting98,
  author = {F. C. Holstege and E. G. Jennings and J. J. Wyrick and T. I. Lee
	and C. J. Hengartner and M. R. Green and T. R. Golub and E. S. Lander
	and R. A. Young},
  title = {Dissecting the regulatory circuitry of a eukaryotic genome},
  journal = {Cell},
  year = {1998},
  volume = {95},
  pages = {717--728},
  group = {gene networks}
}

@ARTICLE{Holyroyd:waxes03,
  author = {Geoffrey H. Holyroyd and Alistair M. Hetherington and Julie E. Gray},
  title = {A Role for the cuticle waxes in the environmental control of stomatal
	development},
  journal = {New Phytologist},
  year = {2003},
  volume = {153},
  pages = {433--439}
}

@ARTICLE{Hoops:copasi06,
  author = {S. Hoops and S. Sahle and C. Lee and J. Pahle and N. Simus and M.
	Singhal and L. Xu and Pedro Mendes and U. Kummer},
  title = {{COPASI}: a {CO}mplex {PA}thway {SI}mulator},
  journal = bioinf,
  year = {2006},
  volume = {22},
  pages = {3067--3074},
  number = {24}
}

@ARTICLE{Hopfield:learn87,
  author = {J. J. Hopfield},
  title = {Learning algorithms and probability distributions in feed-forward
	and feed-back networks},
  journal = {Proceedings of the National Academy of Sciences},
  year = {1987},
  volume = {84},
  pages = {8429--8433}
}

@ARTICLE{Hornik:approx91,
  author = {K. Hornik},
  title = {Approximation capabilities of multilayer feedforward networks},
  journal = NN,
  year = {1991},
  volume = {4},
  pages = {251--257},
  number = {2}
}

@ARTICLE{Hornik:deriv90,
  author = {K. Hornik and M. Stinchcombe and H. White},
  title = {Universal approximation of an unknown mapping and its derivatives
	using multilayer feedforward networks},
  journal = NN,
  year = {1990},
  volume = {3},
  pages = {551--560},
  number = {5}
}

@ARTICLE{Hornik:univ89,
  author = {K. Hornik and M. Stinchcombe and H. White},
  title = {Multilayer feedforward networks are universal approximators},
  journal = NN,
  year = {1989},
  volume = {2},
  pages = {359--366},
  number = {5}
}

@ARTICLE{Hotelling:analysis33,
  author = {Harold Hotelling},
  title = {Analysis of a complex of statistical variables into principal components},
  journal = {Journal of Educational Psychology},
  year = {1933},
  volume = {24},
  pages = {417--441},
  number = {6},
  abstract = {The problem is stated in detail, a method of analysis is derived and
	its geometrical meaning shown, methods of solution are illustrated
	and certain derivative problems are discussed.}
}

@HTML{JournalPapers,
  author = {HTML},
  note = {<hr><H2>Journal Papers</H2>}
}

@HTML{MainHeading,
  author = {HTML},
  note = {<H1>Publications</H1>}
}

@HTML{RefereedConferences,
  author = {HTML},
  note = {<hr><H2>Refereed Conference Papers</H2>}
}

@HTML{TechReports,
  author = {HTML},
  note = {<hr><H2>Technical Reports</H2>}
}

@HTML{ThesisHeading,
  author = {HTML},
  note = {<hr><H2>PhD Thesis</H2>}
}

@INPROCEEDINGS{Huang:class87,
  author = {W. Y. Huang and R. P. Lippmann},
  title = {Neural Net and Traditional Classifiers},
  booktitle = {Neural Information Processing Systems},
  year = {1988},
  editor = {D. Z. Anderson},
  pages = {387--396},
  address = {New York},
  publisher = {American Institute of Physics}
}

@ARTICLE{Huber:ppr85,
  author = {P. J. Huber},
  title = {Projection pursuit},
  journal = {Annals of Statistics},
  year = {1985},
  volume = {13},
  pages = {435--475},
  number = {2}
}

@Article{Maaten:tsne08,
  author = 	 {Larens J. P. {van der Maaten} and Geoffrey E. Hinton},
  title = 	 {Visualizing Data using t-{SNE}},
  journal = 	 jmlr,
  year = 	 2008,
  OPTkey = 	 {},
  volume =	 {9},
  OPTnumber = 	 {},
  pages =	 {2579--2605},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  linkpdf =	 {http://www.cs.toronto.edu/~hinton/absps/tsnefinal.pdf},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@ARTICLE{Huber:variance02,
  author = {Wolfgang Huber and Anja {von Heydebreck} and Holger S\"ultmann and
	Annemarie Poustka and Martin Vingron},
  title = {Variance Stabilization applied to Microarray Data Calibration and
	to the Quantification of Differential Expression},
  journal = bioinf,
  year = {2002},
  volume = {18},
  pages = {S96--S104},
  file = {huber_ismb2002.pdf:http\://www.dkfz-heidelberg.de/abt0840/whuber/publicat/huber_ismb2002.pdf:PDF}
}

@INPROCEEDINGS{Hughes:spring09,
  author = {Shannon M. Hughes and Peter J. Ramadge},
  title = {Connecting spectral and spring methods for manifold learning
	
	},
  booktitle = {Proceedings of the IEEE Conference on Acoustics, Speech and Signal
	Processing},
  year = {2009},
  pages = {1565--1568},
  abstract = {Diffusion Maps (DiffMaps) has recently provided a general framework
	that unites many other spectral manifold learning algorithms, including
	Laplacian Eigenmaps, and it has become one of the most successful
	and popular frameworks for manifold learning to date. However, Diffusion
	Maps still often creates unnecessary distortions, and its performance
	varies widely in response to parameter value changes. In this paper,
	we draw a previously unnoticed connection between DiffMaps and spring-motivated
	methods. We show that DiffMaps has a physical interpretation: it
	finds the arrangement of high-dimensional objects in low-dimensional
	space that minimizes the elastic energy of a particular spring network.
	Within this interpretation, we recognize the root cause of a variety
	of problems that are commonly observed in the Diffusion Maps output,
	including sensitivity to user-specified parameters, sensitivity to
	sampling density, and distortion of boundaries. We then show how
	to exploit the connection between Diffusion Map and spring criteria
	to create a method that can be efficiently applied post hoc to alleviate
	these commonly observed deficiencies in the Diffusion Maps output.}
}

@ARTICLE{Hughes:functional00,
  author = {Timothy R. Hughes and Matthew J. Marton and Allan R. Jones and Christopher
	J. Roberts and Roland Stoughton and Christopher D Armour and Holly
	A. Bennett and Ernest Coffey and Hongyue Dai and Yudong D. He and
	Matthew J. Kidd and Amy M. King and Michael R. Meyer and David Slade
	and Pek Y. Lum and Sergey B. Stepaniants and Daniel D. Shoemaker
	and Daniel Gachotte and Kalpana Chakrabutty and Julian Simon and
	Martin Bard and Stephen H. Friend},
  title = {Functional Discovery via a Compendium of Expression Profiles},
  journal = {Cell},
  year = {2000},
  volume = {102},
  pages = {109--126}
}

@ARTICLE{Hull:CEDAR94,
  author = {J. J. Hull},
  title = {A database for handwritten text recognition research},
  journal = PAMI,
  year = {1994},
  volume = {16},
  pages = {550--554}
}

@ARTICLE{Humphreys:improvemf98,
  author = {K. Humphreys and David M. Titterington},
  title = {Improving the Mean-Field Approximation in Belief Networks Using {B}ahadur's
	Reparameterisation of the Multivariate Binary Distribution},
  journal = {Neural Processing Letters},
  year = {2000},
  volume = {12},
  pages = {183--197},
  number = {2}
}

@ARTICLE{Hunt:phospholipase03,
  author = {Lee Hunt and Lewis N. Mills and Christophe Pical and Calum P. Leckie
	and Fiona L. Aitken and Joachim Kopka and Bern Mueller-Roeber and
	Martin R. {McA}insh and Alistair M. Hetherington and Julie E. Gray},
  title = {Phospholipase {C} is required for the control of stomatal aperture
	by {ABA}},
  journal = {The Plant Journal},
  year = {2003},
  volume = {34},
  pages = {47--55}
}

@INPROCEEDINGS{Hush:reuse88,
  author = {D. R. Hush and J. M. Salas},
  title = {Improving the learning rate of back-propagation with the gradient
	re-use algorithm},
  booktitle = {IEEE International Conference on Neural Networks},
  year = {1988},
  volume = {1},
  pages = {441--447},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@ARTICLE{Husmeier:reverse03,
  author = {Dirk Husmeier},
  title = {Reverse engineering of genetic networks with {B}ayesian networks},
  journal = {Biochemical Society Transactions},
  year = {2003},
  volume = {31},
  pages = {1516--1518},
  number = {6},
  group = {gene networks}
}

@ARTICLE{Husmeier:sensitivity03,
  author = {Dirk Husmeier},
  title = {Sensitivity and specificity of inferring genetic regulatory interactions
	from microarray experiments with dynamic {B}ayesian networks},
  journal = bioinf,
  year = {2003},
  volume = {19},
  pages = {2271--2282},
  number = {17},
  group = {gene networks},
  label1 = {Bioinformatics Issue},
  link1 = {http://bioinformatics.oupjournals.org/cgi/content/abstract/19/17/2271}
}

@INPROCEEDINGS{Husmeier:empirical98,
  author = {Dirk Husmeier and William D. Penny and Stephen J. Roberts},
  title = {Empirical Evaluation of {B}ayesian Sampling for Neural Classifiers},
  booktitle = {Proceedings of the 8th International Conference on Artificial Neural
	Networks},
  year = {1998},
  editor = {L. Niklason and M. Boden and T. Ziemke},
  series = {Perspectives in Neural Computing},
  pages = {323--328},
  publisher = {Springer Verlag}
}

@ARTICLE{Hwang:ppr94,
  author = {J. N. Hwang and S. R. Lay and M. Maechler and R. D. Martin and J.
	Schimert},
  title = {Regression modelling in back-propagation and projection pursuit learning},
  journal = IEEE,
  year = {1994},
  volume = {5},
  pages = {342--353},
  number = {3}
}

@ARTICLE{Hyvarinen:ICA00,
  author = {Aapo Hyv\"arinen and Erkki Oja},
  title = {Independent Component Analysis: Algorithms and Applications},
  journal = {Neural Networks},
  year = {2000},
  volume = {13},
  pages = {411--430},
  number = {4--5}
}

@ARTICLE{Hyvarinen:fastica97,
  author = {Aapo Hyv\"arinen and Erkki Oja},
  title = {A Fast Fixed-Point Algorithm for Independent Component Analysis},
  journal = NC,
  year = {1997},
  volume = {9},
  pages = {1483--1492}
}

@ARTICLE{Hyvarinen:nonlinear99,
  author = {Aapo Hyv\"arinen and Petteri Pajunen},
  title = {Nonlinear independent component analysis: {E}xistence and uniqueness
	results},
  journal = NN,
  year = {1999},
  volume = {12},
  pages = {429--439}
}

@ARTICLE{Ihaka:r96,
  author = {Ross Ihaka and Robert C Gentleman},
  title = {{R}: {A} Language for Data Analysis and Graphics},
  journal = {Journal of Computational and Graphical Statistics},
  year = {1996},
  volume = {5},
  pages = {299--314}
}

@ARTICLE{Infante:familysize01,
  author = {Claire Infante-Rivard and Devendra Amre and Denyse Gautrin and Jean-Luc
	Malo},
  title = {Family Size, Day-Care Attendance, and Breastfeeding in Relation to
	the Incidence of Childhood Asthma},
  journal = {American Journal of Epidemiology},
  year = {2001},
  volume = {153},
  pages = {653--658},
  number = {7},
  abstract = {A hypothesis has been suggested stating that children exposed early
	to infections are less likely to develop atopy or asthma. The authors
	investigated the relation between risk of childhood asthma and number
	of siblings as well as day-care attendance, as factors possibly increasing
	the likelihood of early infections, and breastfeeding as a factor
	reducing them. A case-control study was carried out in Montréal,
	Canada, between 1988 and 1995 that included 457 children diagnosed
	with asthma at 3–4 years of age and 457 healthy controls. Cases followed
	for 6 years were later classified as persistent or transient by the
	symptoms and use of medication after diagnosis. Among cases diagnosed
	at 3–4 years of age, the adjusted odds ratio for asthma was 0.54
	(95\% confidence interval (CI): 0.36, 0.80) for one sibling and 0.49
	(95\% CI: 0.30, 0.81) for two or more. The adjusted odds ratio for
	day-care attendance before 1 year of age was 0.59 (95\% CI: 0.40,
	0.87). Results were similar with persistent cases. Among transient
	cases (who possibly had an infection with wheezing at 3–4 years of
	age), day-care attendance and a short duration of breastfeeding resulted
	in increased risk. The results support the hypothesis that opportunity
	for early infections reduces the risk of asthma.},
  doi = {10.1093/aje/153.7.653},
  pmid = {11282792}
}

@ARTICLE{Ingham:molecular,
  author = {Philip W. Ingham},
  title = {The molecular genetics of embryonic pattern formation in Drosophila},
  journal = {Nature},
  year = {1988},
  volume = {335},
  pages = {25--34},
  abstract = {Analysis of the genes that control the early events of \emph{Drosophila}
	embryogenesis is providing details of the molecular processes underlying
	the positional specification of cells. There are two distinct phases:
	the first precedes the cellularization of the blastoderm embryo and
	is associated with a cascade of interactions between transcriptional
	regulators, the second occurs after cellularization and depends on
	communication between cells. These processes may be conserved in
	a wide range of invertebrates and vertebrates.},
  doi = {doi:10.1038/335025a0},
  group = {Drosophila segmentation},
  pmid = {2901040}
}

@INPROCEEDINGS{Ioffe:mixtures01,
  author = {Sergey Ioffe and David A. Forsyth},
  title = {Mixtures of Trees for Object Recognition},
  booktitle = pCVPR,
  year = {2001},
  volume = {2},
  pages = {180--185},
  address = {Hawaii, U.S.A.},
  month = {11--13 Dec.},
  publisher = ieeecomp,
  abstract = {Efficient detection of objects in images is complicated by variations
	of object appearance due to intra-class object differences, articulation,
	lighting, occlusions, and aspect variations. To reduce the search
	required for detection, we employ the bottom-up approach where we
	find candidate image features and associate some of them with parts
	of the object model. We represent objects as collections of local
	features, and would like to allow any of them to be absent, with
	only a small subset sufficient for detection; furthermore, our model
	should allow efficient correspondence search. We propose a model,
	Mixture of Trees, that achieves these goals. With a mixture of trees,
	we can model the individual appearances of the features, relationships
	among them, and the aspect, and handle occlusions. Independences
	captured in the model make efficient inference possible. In our earlier
	work, we have shown that mixtures of trees can be used to model objects
	with a natural tree structure, in the context of human tracking.
	Now we show that a natural tree structure is not required, and use
	a mixture of trees for both frontal and view-invariant face detection.
	We also show that by modeling faces as collections of features we
	can establish an intrinsic coordinate frame for a face, and estimate
	the out-of-plane rotation of a face.},
  doi = {10.1109/CVPR.2001.990953},
  file = {cvpr.pdf:http\://http.cs.berkeley.edu/~daf/cvpr.pdf:PDF},
  group = {tree}
}

@ARTICLE{Irish:drosophila89,
  author = {Vivian Irish and Ruth Lehmann and Michael Akam},
  title = {The \emph{Drosophila} posterior-group gene \emph{nanos} functions
	by repressing \emph{hunchback} activity},
  journal = {Nature},
  year = {1989},
  pages = {646--648},
  number = {338},
  abstract = {The development of the body plan in the \emph{Drosophila} embryo depends
	on the activity of maternal determinants localized at the anterior
	and posterior of the egg. These activities define both the polarity
	of the anterior-posterior (AP) axis and the spatial domains of expression
	of the zygotic gap genes [1,2], which in turn control the subsequent
	steps in segmentation [2,3]. The nature and mode of action of one
	anterior determinant, the \emph{bicoid (bcd)} gene product, has recently
	been defined [4–8], but the posterior determinants are less well
	characterized. At least seven maternally acting genes are required
	for posterior development [1,9–11]. Mutations in these maternal posterior-group
	genes result in embryos lacking all abdominal segments. Cytoplasmic
	transplantation studies indicate that the maternally encoded product
	of the \emph{nanos (nos)} gene may act as an abdominal determinant,
	whereas the other maternal posterior-group genes appear to be required
	for the appropriate localization and stabilization of this signal1,
	[9–12]. Here we show that the lack of the \emph{nos} gene product
	can be compensated for by eliminating the maternal activity of the
	gap gene \emph{hunchback (hb)}. Embryos lacking both of these maternally
	derived gene products are viable and can survive as fertile adults.
	These results suggest that the \emph{nos} gene product functions
	by repressing the activity of the maternal \emph{hb} products in
	the posterior of the egg.},
  doi = {doi:10.1038/338646a0},
  group = {Drosophila segmentation},
  pmid = {2704419}
}

@ARTICLE{Irizarry:summaries03,
  author = {Rafael A. Irizarry and B. M. Bolstad and F. Collin and L. M. Cope
	and B. Hobbs and Terrence P. Speed},
  title = {Summaries of {A}ffymetrix {G}ene{C}hip Probe Level Data},
  journal = nar,
  year = {2003},
  volume = {31},
  pages = {e15},
  number = {4}
}

@ARTICLE{Irizarry:exploration03,
  author = {Rafael A. Irizarry and Bridget Hobbs and Francois Collin and Yasmin
	D. Beazer-Barclay and Kristen J. Antonellis and Uwe Scherf and Terence
	P. Speed },
  title = {Exploration, normalization, and summaries of high density oligonucleotide
	array probe level data},
  journal = {Biostatistics},
  year = {2003},
  volume = {4},
  pages = {249--264},
  number = {2},
  abstract = {In this paper we report exploratory analyses of high-density oligonucleotide
	array data from the Affymetrix GeneChip® system with the objective
	of improving upon currently used measures of gene expression. Our
	analyses make use of three data sets: a small experimental study
	consisting of five MGU74A mouse GeneChip® arrays, part of the data
	from an extensive spike-in study conducted by Gene Logic and Wyeth's
	Genetics Institute involving 95 HG-U95A human GeneChip® arrays; and
	part of a dilution study conducted by Gene Logic involving 75 HG-U95A
	GeneChip® arrays. We display some familiar features of the perfect
	match and mismatch probe (PM and MM) values of these data, and examine
	the variance?mean relationship with probe-level data from probes
	believed to be defective, and so delivering noise only. We explain
	why we need to normalize the arrays to one another using probe level
	intensities. We then examine the behavior of the PM and MM using
	spike-in data and assess three commonly used summary measures: Affymetrix's
	(i) average difference (AvDiff) and (ii) MAS 5.0 signal, and (iii)
	the Li and Wong multiplicative model-based expression index (MBEI).
	The exploratory data analyses of the probe level data motivate a
	new summary measure that is a robust multi-array average (RMA) of
	background-adjusted, normalized, and log-transformed PM values. We
	evaluate the four expression summary measures using the dilution
	study data, assessing their behavior in terms of bias, variance and
	(for MBEI and RMA) model fit. Finally, we evaluate the algorithms
	in terms of their ability to detect known levels of differential
	expression using the spike-in data. We conclude that there is no
	obvious downside to using RMA and attaching a standard error (SE)
	to this quantity using a linear model which removes probe-specific
	affinities.},
  file = {249:http\://biostatistics.oxfordjournals.org/cgi/reprint/4/2/249:PDF},
  group = {affy}
}

@ARTICLE{Isard:condensation98,
  author = {Michael Isard and Andrew Blake},
  title = {CONDENSATION --- Conditional Density Propagation for Visual Tracking
	},
  journal = ijcv,
  volume = {29},
  pages = {5--28},
  number = {1}
}

@INPROCEEDINGS{Isard:bramble01,
  author = {Michael Isard and John {MacCormick}},
  title = {{BraMBLe}: A {B}ayesian Multiple-Blob Tracker},
  booktitle = iccv,
  year = {2001},
  pages = {II: 34--41},
  month = {July},
  publisher = ieeecomp
}

@ARTICLE{Ito:approx91,
  author = {Y. Ito},
  title = {Approximation of functions on a compact set by finite sums of a sigmoid
	function without scaling},
  journal = NN,
  year = {1991},
  volume = {4},
  pages = {817--826},
  number = {6}
}

@ARTICLE{Ito:sigmoid91,
  author = {Y. Ito},
  title = {Representation of functions by superpositions of a step or sigmoid
	function and their applications to neural network theory},
  journal = NN,
  year = {1991},
  volume = {4},
  pages = {385--394},
  number = {3}
}

@ARTICLE{Ivakhnenko:poly71,
  author = {A. G. Ivakhnenko},
  title = {Polynomial theory of complex systems},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  year = {1971},
  volume = {1},
  pages = {364--378},
  number = {4}
}

@PHDTHESIS{Jaakkola:thesis97,
  author = {Tommi S. Jaakkola},
  title = {Variational Methods for Inference and Estimation in Graphical Models},
  school = {MIT},
  year = {1997}
}

@ARTICLE{Jaakkola:fisher99,
  author = {Tommi S Jaakkola and M. Diekhaus and David Haussler},
  title = {Using the {F}isher kernel method to detect remote protein homologies.},
  journal = {7th Intell. Sys. Mol. Biol.},
  year = {1999},
  pages = {149--158}
}

@INPROCEEDINGS{Jaakkola:regression96,
  author = {Tommi S. Jaakkola and Michael I. Jordan},
  title = {A Variational Approach to {B}ayesian Logistic Regression Problems
	and their Extensions},
  booktitle = {Proceedings of the Sixth International Workshop on Artificial Intelligence
	and Statistics},
  year = {1996}
}

@ARTICLE{Jabri:pert91,
  author = {M. Jabri and B. Flower},
  title = {Weight Perturbation: An Optimal Architecture and Learning Technique
	for Analog {VLSI} Feedforward and Recurrent Multilayer Networks},
  journal = NC,
  year = {1991},
  volume = {3},
  pages = {546--565},
  number = {4}
}

@ARTICLE{Jacob:protein61,
  author = {F. Jacob and J. Monod},
  title = {Genetic regulatory mechanism in the synstesis of protein },
  journal = JMB,
  year = {1961},
  volume = {3},
  pages = {318--356}
}

@ARTICLE{Jacobs:learn88,
  author = {R. A. Jacobs},
  title = {Increased Rates of Convergence through Learning Rate Adaptation},
  journal = NN,
  year = {1988},
  volume = {1},
  pages = {295--307},
  number = {4}
}

@ARTICLE{Jacobs:piece93,
  author = {R. A. Jacobs and Michael I. Jordan},
  title = {Learning Piecewise Control Strategies in a Modular Neural Network
	Architecture},
  journal = {IEEE Transactions on Systems, Man and Cybernetics},
  year = {1993},
  volume = {23},
  pages = {337--345},
  number = {2}
}

@ARTICLE{Jacobs:experts91,
  author = {R. A. Jacobs and Michael I. Jordan and S. J. Nowlan and Geoffrey
	E. Hinton},
  title = {Adaptive Mixtures of Local Experts},
  journal = NC,
  year = {1991},
  volume = {3},
  pages = {79--87},
  number = {1},
  file = {mixtures-of-experts.pdf:http\://www.cs.berkeley.edu/~jordan/papers/mixtures-of-experts.pdf:PDF},
  linkps = {http://www.cs.toronto.edu/~hinton/absps/jjnh91.ps}
}

@ARTICLE{Jaeger:dynamical04,
  author = {Johannes Jaeger and Maxim Blagov and David Kosman and Konstantin
	N. Kozlov and Manu and Ekaterina Myasnikova and Svetlana Surkova
	and Carlos E. Vanario-Alonso and Maria Samsonova and David H. Sharp
	and John Reinitz},
  title = {Dynamical Analysis of Regulatory Interactions in the Gap Gene System
	of \emph{{D}rosophila melanogaster}},
  journal = {Genetics},
  year = {2004},
  volume = {167},
  pages = {1721--1737},
  abstract = {Genetic studies have revealed that segment determination in \emph{Drosophila
	melanogaster} is based on hierarchical regulatory interactions among
	maternal coordinate and zygotic segmentation genes. The gap gene
	system constitutes the most upstream zygotic layer of this regulatory
	hierarchy, responsible for the initial interpretation of positional
	information encoded by maternal gradients. We present a detailed
	analysis of regulatory interactions involved in gap gene regulation
	based on gap gene circuits, which are mathematical gene network models
	used to infer regulatory interactions from quantitative gene expression
	data. Our models reproduce gap gene expression at high accuracy and
	temporal resolution. Regulatory interactions found in gap gene circuits
	provide consistent and sufficient mechanisms for gap gene expression,
	which largely agree with mechanisms previously inferred from qualitative
	studies of mutant gene expression patterns. Our models predict activation
	of \emph{Kr} by Cad and clarify several other regulatory interactions.
	Our analysis suggests a central role for repressive feedback loops
	between complementary gap genes. We observe that repressive interactions
	among overlapping gap genes show anteroposterior asymmetry with posterior
	dominance. Finally, our models suggest a correlation between timing
	of gap domain boundary formation and regulatory contributions from
	the terminal maternal system.},
  file = {1721.pdf:http\://www.genetics.org/cgi/reprint/167/4/1721.pdf:PDF},
  group = {gene networks, Drosophila segmentation},
  pmid = {15342511}
}

@ARTICLE{Jaeger:gap06,
  author = {Johannes Jaeger and David H Sharp and John Reinitz},
  title = {Known Maternal Gradients are not Sufficient for the Establishment
	of Gap Domains in \emph{{D}rosophila melanogaster}},
  journal = {Mechanisms of Development},
  year = {2007},
  volume = {124},
  pages = {108--128},
  number = {2},
  abstract = {Gap genes are among the first transcriptional targets of maternal
	morphogen gradients in the early \emph{Drosophila} embryo. However,
	it remains unclear whether these gradients are indeed sufficient
	to establish the boundaries of localized gap gene expression patterns.
	In this study, we address this question using gap gene circuits,
	which are data-driven mathematical tools for extracting regulatory
	information from quantitative wild-type gene expression data. We
	present new, quantitative data on the mRNA expression patterns for
	the gap genes \emph{Kr\"uppel} (\emph{Kr}), \emph{knirps} (\emph{kni})
	and \emph{giant} (\emph{gt}) during the early blastoderm stage of
	\emph{Drosophila} development. This data set shows significant differences
	in timing of gap gene expression compared to previous observations,
	and reveals that early gap gene expression is highly variable in
	both space and time. Gene circuit models fit to this data set were
	used for a detailed regulatory analysis of early gap gene expression.
	Our analysis shows that the proper balance of maternal repression
	and activation is essential for the correct positioning of gap domains,
	and that such balance can only be achieved for early expression of
	kni. In contrast, our results suggest that early expression of gt
	requires local neutralization of repressive input in the anterior
	region of the embryo, and that known maternal gradients are completely
	insufficient to position the boundaries of the early central Kr domain,
	or in fact any Kr-like domain in the central region of the blastoderm
	embryo. Based on this, we propose that unknown additional regulators
	must be involved in early gap gene regulation.},
  pmid = {1992814}
}

@ARTICLE{Jaeger:dynamic04,
  author = {Johannes Jaeger and Svetlana Surkova and Maxim Blagov and Hilde Janssens
	and David Kosman and Konstantin N. Kozlov and Manu and Ekaterina
	Myasnikova and Carlos E. Vanario-Alonso and Maria Samsonova and David
	H. Sharp and John Reinitz},
  title = {Dynamic control of positional information in the early \emph{{D}rosophila}
	embryo},
  journal = {Nature},
  year = {2004},
  volume = {430},
  pages = {368--371},
  abstract = {Morphogen gradients contribute to pattern formation by determining
	positional information in morphogenetic fields. Interpretation of
	positional information is thought to rely on direct, concentration-threshold-dependent
	mechanisms for establishing multiple differential domains of target
	gene expression. In \emph{Drosophila}, maternal gradients establish
	the initial position of boundaries for zygotic gap gene expression,
	which in turn convey positional information to pair-rule and segment-polarity
	genes, the latter forming a segmental pre-pattern by the onset of
	gastrulation. Here we report, on the basis of quantitative gene expression
	data, substantial anterior shifts in the position of gap domains
	after their initial establishment. Using a data-driven mathematical
	modelling approach, we show that these shifts are based on a regulatory
	mechanism that relies on asymmetric gap-gap cross-repression and
	does not require the diffusion of gap proteins. Our analysis implies
	that the threshold-dependent interpretation of maternal morphogen
	concentration is not sufficient to determine shifting gap domain
	boundary positions, and suggests that establishing and interpreting
	positional information are not independent processes in the \emph{Drosophila}
	blastoderm.},
  file = {nature02678.pdf:http\://www.nature.com/nature/journal/v430/n6997/pdf/nature02678.pdf:PDF},
  group = {gene networks, Drosophila segmentation},
  pmid = {15254541}
}

@ARTICLE{Jakobsen:biniou07,
  author = {J. S. Jakobsen and M. Braun and J. Astorga and E. H. Gustafson and
	T. Sandmann and M. Karzynski and P. Carlsson and E. E. Furlong},
  title = {{T}emporal {C}h{I}{P}-on-chip reveals {B}iniou as a universal regulator
	of the visceral muscle transcriptional network},
  journal = {Genes Dev.},
  year = {2007},
  volume = {21},
  pages = {2448--2460},
  abstract = {Smooth muscle plays a prominent role in many fundamental processes
	and diseases, yet our understanding of the transcriptional network
	regulating its development is very limited. The FoxF transcription
	factors are essential for visceral smooth muscle development in diverse
	species, although their direct regulatory role remains elusive. We
	present a transcriptional map of Biniou (a FoxF transcription factor)
	and Bagpipe (an Nkx factor) activity, as a first step to deciphering
	the developmental program regulating Drosophila visceral muscle development.
	A time course of chromatin immunoprecipitatation followed by microarray
	analysis (ChIP-on-chip) experiments and expression profiling of mutant
	embryos reveal a dynamic map of in vivo bound enhancers and direct
	target genes. While Biniou is broadly expressed, it regulates enhancers
	driving temporally and spatially restricted expression. In vivo reporter
	assays indicate that the timing of Biniou binding is a key trigger
	for the time span of enhancer activity. Although bagpipe and biniou
	mutants phenocopy each other, their regulatory potential is quite
	different. This network architecture was not apparent from genetic
	studies, and highlights Biniou as a universal regulator in all visceral
	muscle, regardless of its developmental origin or subsequent function.
	The regulatory connection of a number of Biniou target genes is conserved
	in mice, suggesting an ancient wiring of this developmental program.},
  group = {Drosophila},
  optmonth = {Oct},
  pmid = {17908931}
}

@ARTICLE{Jansson:economic07,
  author = {Sven-Arne Jansson and Eva R\"onmarka and Bertil Forsberga and Curt
	and L\"ofgrena and Anne Lindberga and Bo Lundb\"ack},
  title = {The economic consequences of asthma among adults in Sweden},
  journal = {Respiratory Medicine},
  year = {2007},
  volume = {101},
  pages = {2263--2270},
  number = {11},
  abstract = {{\bf Objectives}\\\\ Asthma is a common disease in most countries.
	The objective of this study was to estimate the societal costs for
	subjects with asthma.\\\\ {\bf Methods}\\\\ Telephone interviews
	regarding resource utilization were made in a representative sample
	of 115 randomly selected subjects with asthma derived from a large
	population study of obstructive airway diseases. Direct and indirect
	costs were measured, and the costs were also transformed with the
	estimated prevalence of asthma in Sweden.\\\\ {\bf Results}\\\\ Average
	annual costs were SEK 15 919 (USD 1592; EUR 1768) per subject with
	asthma in the ages between 25 and 56 years. The direct and indirect
	costs were SEK 4931 (31.0\%) and SEK 10 988 (69.0\%), respectively,
	and were highly dependent of age and disease severity. Assuming that
	the prevalence is representative for Sweden as a whole, the asthmatics
	would amount to 226 000 in the ages between 25 and 56 years, corresponding
	to an overall prevalence in Sweden of 6–7\%. The total costs of asthma
	for the society amounted thus to SEK 3.7 billion in these ages. {\bf
	Conclusions}\\\\ The total costs of asthma for the society could
	be estimated at 3.7 billion SEK in the age range of 25–56 years,
	and thus approximately twice as high in the whole population of Sweden.
	The costs were strongly dependent on disease severity and increasing
	age.},
  doi = {doi:10.1016/j.rmed.2007.06.029},
  group = {asthma},
  pmid = {17689234}
}

@ARTICLE{Jansson2007,
  author = {Sven-Arne Jansson and Eva Rönmark and Bertil Forsberg and Curt Löfgren
	and Anne Lindberg and Bo Lundbäck},
  title = {The economic consequences of asthma among adults in Sweden.},
  journal = {Respir Med},
  year = {2007},
  volume = {101},
  pages = {2263--2270},
  number = {11},
  month = {Nov},
  abstract = {Asthma is a common disease in most countries. The objective of this
	study was to estimate the societal costs for subjects with asthma.Telephone
	interviews regarding resource utilization were made in a representative
	sample of 115 randomly selected subjects with asthma derived from
	a large population study of obstructive airway diseases. Direct and
	indirect costs were measured, and the costs were also transformed
	with the estimated prevalence of asthma in Sweden.Average annual
	costs were SEK 15919 (USD 1592; EUR 1768) per subject with asthma
	in the ages between 25 and 56 years. The direct and indirect costs
	were SEK 4931 (31.0\%) and SEK 10988 (69.0\%), respectively, and
	were highly dependent of age and disease severity. Assuming that
	the prevalence is representative for Sweden as a whole, the asthmatics
	would amount to 226000 in the ages between 25 and 56 years, corresponding
	to an overall prevalence in Sweden of 6-7\%. The total costs of asthma
	for the society amounted thus to SEK 3.7 billion in these ages.The
	total costs of asthma for the society could be estimated at 3.7 billion
	SEK in the age range of 25-56 years, and thus approximately twice
	as high in the whole population of Sweden. The costs were strongly
	dependent on disease severity and increasing age.},
  doi = {10.1016/j.rmed.2007.06.029},
  institution = {Karolinska Institutet, National Institute of Environmental Medicine,
	Stockholm, Sweden. svenarne.jansson@holmsund.nu},
  keywords = {Adult; Asthma, economics/epidemiology; Cost of Illness; Epidemiologic
	Methods; Female; Health Care Costs; Humans; Male; Middle Aged; Prevalence;
	Sweden, epidemiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {S0954-6111(07)00281-8},
  pmid = {17689234},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1016/j.rmed.2007.06.029}
}

@ARTICLE{Jayawardhana:bayesian08,
  author = {Bayu Jayawardhana and Douglas B. Kell and Magnus Rattray},
  title = {Bayesian Inference of the Sites of Perturbations in Metabolic Pathways
	via {M}arkov chain {M}onte {C}arlo},
  journal = bioinf,
  year = {2008},
  volume = {24},
  pages = {1191-1197},
  number = {9},
  doi = {10.1093/bioinformatics/btn103},
  group = {mlo}
}

@INCOLLECTION{Jaynes:bayes86,
  author = {Edwin T. Jaynes},
  title = {{B}ayesian Methods: General Background},
  booktitle = {Maximum Entropy and {B}ayesian Methods in Applied Statistics},
  publisher = cup,
  year = {1986},
  editor = {J. H. Justice},
  pages = {1--25}
}

@ARTICLE{Ji:smooth90,
  author = {C. Ji and R. R. Snapp and D. Psaltis},
  title = {Generalizing Smoothness Constraints from Discrete Samples},
  journal = NC,
  year = {1990},
  volume = {2},
  pages = {188--197},
  number = {2}
}

@ARTICLE{Jina:role06,
  author = {Hai-Xiao Jina and Tian-Xing Wua and Yong-Jun Jiangb},
  title = {Role of phosphorylated Thr-197 in the catalytic subunit of cAMP-dependent
	protein kinase},
  journal = {Journal of Molecular Structure: THEOCHEM},
  year = {2006},
  abstract = {Protein phosphorylation of Thr-197 in the activation loop of
	
	 the catalytic subunit (C-subunit) of cAMP-dependent protein kinase
	(PKA) is an essential step for its proper biological function. In
	order to explore the influences triggered by phosphorylation of Thr-197,
	comparative molecular dynamics (MD) simulation studies with or without
	phosphate group on Thr-197 and Ser-338 were performed on the complex
	of C-subunit bound to ATP and two Mg2+ ions (C/Mg2ATP complex) and
	on the complex of C-subunit bound to substrate peptide (C/substrate
	complex). The results present a decreased flexibility of the activation
	loop in the phosphorylated state, because of several critical interactions
	formed by the phosphorylated Thr-197 with His-87, Arg-165, Lys-189
	and Thr-195. The unphosphorylated activation loop does not block
	the substrate-binding site, which is in good agreement with experimental
	result. In unphosphorylated state, the crucial interaction between
	Thr-197 and His-87 of C-helix does not exist, which eventually makes
	glycine-rich loop run away from its original position and displaces
	the phosphates group of ATP. We suggest that the reduction in rate
	of phosphoryl transfer may be caused by the displacement of γ-phosphate
	group that demolish phosphoryl transfer in-line mechanism.},
  doi = {doi:10.1016/j.theochem.2006.10.020}
}

@ARTICLE{Johansson:conjugate92,
  author = {E. M. Johansson and F. U. Dowla and D. M. Goodman},
  title = {Backpropagation Learning for Multilayer Feedforward Neural Networks
	Using the Conjugate Gradient Method},
  journal = IJNS,
  year = {1992},
  volume = {2},
  pages = {291--301},
  number = {4}
}

@ARTICLE{Jones:greedy92,
  author = {L. K. Jones},
  title = {A Simple Lemma on Greedy Approximation in {H}ilbert Space and Convergence
	Rates for Projection Pursuit Regression and Neural Network Training},
  journal = {Annals of Statistics},
  year = {1992},
  volume = {20},
  pages = {608--613},
  number = {1}
}

@ARTICLE{Jones:approx90,
  author = {L. K. Jones},
  title = {Constructive Approximations for Neural Networks by Sigmoidal Functions},
  journal = {Proceedings of the IEEE},
  year = {1990},
  volume = {78},
  pages = {1586--1589},
  number = {10}
}

@ARTICLE{Jones:ppr87,
  author = {L. K. Jones},
  title = {On a Conjecture of {H}uber Concerning the Convergence of Projection
	Pursuit Regression},
  journal = {Annals of Statistics},
  year = {1987},
  volume = {15},
  pages = {880--882},
  number = {2}
}

@INPROCEEDINGS{Jones:rbf90,
  author = {R. D. Jones and Y. C. Lee and C. W. Barnes and G. W. Flake and K.
	Lee and P. S. Lewis and S. Qian},
  title = {Function Approximation and Time Series Prediction with Neural Networks},
  booktitle = ijcnn,
  year = {1990},
  volume = {1},
  pages = {649--665},
  address = {New York},
  publisher = {IEEE}
}

@INCOLLECTION{Bishop:crc97,
  author = {Michael I. Jordan and Christopher M. Bishop},
  title = {Neural networks},
  booktitle = {The Computer Science and Engineering Handbook},
  publisher = {CRC Press},
  year = {1997},
  editor = {A. B. Tucker},
  pages = {536--556}
}

@Article{Tucker:battery58,
  author = 	 {Ledyard R. Tucker},
  title = 	 {An inter-battery method of factor analysis},
  journal = 	 {Psychometrika},
  year = 	 {1958},
  OPTkey = 	 {},
  volume =	 {23},
  number =	 {2},
  pages =	 {111--136},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  abstract =	 {The inter-battery method of factor analysis was devised to provide information relevant to the stability of factors over different selections of tests. Two batteries of tests, postulated to depend on the same common factors, but not parallel tests, are given to one sample of individuals. Factors are determined from the correlation of the tests in one battery with the tests in the other battery. These factors are only those that are common to the two batteries. No communality estimates are required. A statistical test is provided for judging the minimum number of factors involved. Rotation of axes is carried out independently for the two batteries. A final step provides the correlation between factors determined by scores on the tests in the two batteries. The correlations between corresponding factors are taken as factor reliability coefficients.},
  OPTgroup = 	 {}
}

@ARTICLE{Jordan:hierarchy94,
  author = {M. I. Jordan and R. A. Jacobs},
  title = {Hierarchical Mixtures of Experts and the {EM} Algorithm},
  journal = NC,
  year = {1994},
  volume = {6},
  pages = {181--214},
  number = {2},
  file = {AIM-1440.pdf:ftp\://publications.ai.mit.edu/ai-publications/pdf/AIM-1440.pdf:PDF}
}

@ARTICLE{Jutten:bss91,
  author = {C. Jutten and J. Herault},
  title = {Blind Separation of Sources},
  journal = {Signal Processing},
  year = {1991},
  volume = {24},
  pages = {1--10}
}

@MISC{Koerner:essay,
  author = {T. W. K\"orner},
  title = {How to Write a Part {III} Essay},
  howpublished = {Avaliable on-line.},
  group = {researchComputing},
  linkps = {http://www.dpmms.cam.ac.uk/~twk/Essay.ps}
}

@ARTICLE{Kunsch:generalizedCrossCovariance97,
  author = {Hans-Rudolf K\"{u}nsch and Andreas J\"urg Papritz and Franco Bassi},
  title = {Generalized Cross-Covariances and Their Estimation},
  journal = {Mathematical Geology},
  year = {1997},
  volume = {29},
  pages = {779-799},
  number = {6}
}

@ARTICLE{Kaderbhai:functional03,
  author = {Naheed N. Kaderbhai and David I. Broadhurst and David I. Ellis and
	Royston Goodacre and Douglas B. Kell},
  title = {Functional Genomics via metabolic footprinting: Monitoring metabolite
	secretion by \emph{Escherichia coli} Tryptophan Metabolism Mutants
	Using FT-1R and Direct Injection Electrospray Mass Spectrometry},
  journal = {Comp. Func. Genomics},
  year = {2003},
  volume = {4},
  pages = {376--391},
  number = {4},
  abstract = {We sought to test the hypothesis that mutant bacterial strains could
	be discriminated from each other on the basis of the metabolites
	they secrete into the medium (their metabolic footprint), using two
	methods of global metabolite analysis (FT-IR and direct injection
	electrospray mass spectrometry). The biological system used was based
	on a published study of Escherichia coli tryptophan mutants that
	had been analysed and discriminated by Yanofsky and colleagues using
	transcriptome analysis. Wild-type strains supplemented with tryptophan
	or analogues could be discriminated from controls using FT-IR of
	24 h broths, as could each of the mutant strains in both minimal
	and supplemented media. Direct injection electrospray mass spectrometry
	with unit mass resolution could also be used to discriminate the
	strains from each other, and had the advantage that the discrimination
	required the use of just two or three masses in each case. These
	were determined via a genetic algorithm. Both methods are rapid,
	reagentless, reproducible and cheap, and might beneficially be extended
	to the analysis of gene knockout libraries.},
  doi = {10.1002/cfg.302},
  file = {PDFSTART:http\://www3.interscience.wiley.com/cgi-bin/fulltext/104547153/PDFSTART:PDF},
  group = {metabolic footprint}
}

@INPROCEEDINGS{Kadirkamanathan:dynamicnet92,
  author = {V. Kadirkamanathan and Mahesan Niranjan},
  title = {Application of an architecturally Dynamic Network for Speech Pattern
	Classification},
  booktitle = {Proceedings of the Institute of Acoustics},
  year = {1992},
  volume = {14},
  pages = {343--350}
}

@ARTICLE{Kahane:kolmog75,
  author = {J. P. Kahane},
  title = {Sur le Theoreme de Superposition de {K}olmogorov},
  journal = {Journal of Approximation Theory},
  year = {1975},
  volume = {13},
  pages = {229--234}
}

@InProceedings{Lee:binary98,
  author = 	 {Daniel D. Lee and Haim Sompolinsky},
  title = 	 {Learning a Continuous Hidden Variable Model for Binary Data},
  crossref =	 {Kearns:nips98},
  OPTkey = 	 {},
  OPTbooktitle = {},
  OPTpages = 	 {},
  OPTyear = 	 {},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Kanaujia:ambiguities06,
  author = {Atul Kanaujia and Dimitris Metaxas},
  title = {Learning Ambiguities Using Bayesian Mixture of Experts},
  booktitle = {18th IEEE International Conference on Tools with Artificial Intelligence},
  abstract = {Mixture of Experts(ME) is an ensemble of function approximators that
	fit the clustered data set locally rather than globally. ME provides
	a useful tool to learn multi-valued mappings(ambiguities) in the
	data set. Mixture of Experts training involve learning a multi-category
	classifier for the gates distribution and fitting a regressor within
	each of the clusters. The learning of ME is based on divide and conquer
	which is known to increase the error due to variance. In order to
	avoid overfitting several researchers have proposed using linear
	experts. However in the absence of any knowledge of non-linearities
	existing in the data set, it is not clear how many linear experts
	could accurately model the data.
	
	 In this work we propose a bayesian learning framework for learning
	Mixture of Experts. Bayesian learning intrinsically embodies regularization
	and model selection using Occam's razor. In the past Bayesian learning
	methods have been applied to classification and regression in order
	to avoid scale sensitivity and orthodox model selection procedure
	of cross validation. Although true Bayesian learning is computationally
	intractable, approximations do result in sparser and more compact
	models.},
  group = {human motion, mixtures},
  optdoi = {10.1109/ICTAI.2006.73},
  optpages = {436--440}
}

@TECHREPORT{Kappen:boltz98,
  author = {Hilbert J. Kappen and F. B. Rodriguez},
  title = {Efficient Learning in {B}oltzmann Machines Using Linear Response
	Theory},
  institution = {Department of Biophysics},
  year = {1998},
  address = {University of Nijmegen}
}

@ARTICLE{Kashtan:generalization04,
  author = {N. Kashtan and Shalev Itzkovitz and Ron Milo and Uri Alon},
  title = {Topological generalizations of network motifs},
  journal = PRe,
  year = {2004},
  volume = {70},
  pages = {031909},
  group = {gene networks, network motifs}
}

@ARTICLE{Kass:bayes95,
  author = {Robert E. Kass and Adrian E. Raftery},
  title = {Bayes Factors},
  journal = jasa,
  year = {1995},
  volume = {90},
  pages = {773--795},
  abstract = {In a 1935 paper and in his book Theory of Probability, Jeffreys developed
	a methodology for quantifying the evidence in favor of a scientific
	theory. The centerpiece was a number, now called the Bayes factor,
	which is the posterior odds of the null hypothesis when the prior
	probability on the null is one-half Although there has been much
	discussion of Bayesian hypothesis testing in the context of criticism
	of P-values, less attention has been given to the Bayes factor as
	a practical tool of applied statistics. In this article we review
	and discuss the uses of Bayes factors in the context of five scientific
	applications in genetics, sports, ecology, sociology, and psychology.\\\\
	
	 We emphasize the following points:\\\\
	
	 * From Jeffreys' Bayesian viewpoint, the purpose of hypothesis testing
	is to evaluate the evidence in favor of a scientific theory.\\\\
	
	
	 * Bayes factors offer a way of evaluating evidence in favor of a
	null hypothesis. * Bayes factors provide a way of incorporating external
	information into the evaluation of evidence about a hypothesis.\\\\
	
	 * Bayes factors are very general and do not require alternative models
	to be nested. \\\\
	
	 * Several techniques are available for computing Bayes factors, including
	asymptotic approximations that are easy to compute using the output
	from standard packages that maximize likelihoods. \\\\
	
	 * In "nonstandard" statistical models that do not satisfy common
	regularity conditions, it can be technically simpler to calculate
	Bayes factors than to derive non-Bayesian significance tests. \\\\
	
	 * The Schwarz criterion (or BIC) gives a rough approximation to the
	logarithm of the Bayes factor, which is easy to use and does not
	require evaluation of prior distributions.\\\\
	
	 * When one is interested in estimation or prediction, Bayes factors
	may be converted to weights to be attached to various models so that
	a composite estimate or prediction may be obtained that takes account
	of structural or model uncertainty.\\\\
	
	 * Algorithms have been proposed that allow model uncertainty to be
	taken into account when the class of models initially considered
	is very large.\\\\
	
	 * Bayes factors are useful for guiding an evolutionary model-building
	process.\\\\
	
	 * It is important, and feasible, to assess the sensitivity of conclusions
	to the prior distributions used.},
  file = {kass1995.pdf:http\://www.stat.washington.edu/raftery/Research/PDF/kass1995.pdf:PDF},
  group = {sampling, Bayes}
}

@ARTICLE{Kass:approximate89,
  author = {Robert E. Kass and Duane Steffey},
  title = {Approximate Bayesian Inference in Conditionally Independent Hierarchical
	Models (Parametric Empirical Bayes Models)},
  journal = {Journal of the American Statistical Association},
  year = {1989},
  volume = {84},
  pages = {717--726}
}

@ARTICLE{Kell:metabolic05,
  author = {Douglas B. Kell and Marie Brown and Hazel M. Davey and Warwick B.
	Dunn and Irena Spasic and Stephen G. Oliver},
  title = {Metabolic footprinting and Systems Biology: the medium is the message},
  journal = {Nat Rev Microbiol},
  year = {2005},
  volume = {3},
  pages = {557--565},
  abstract = {One element of classical systems analysis treats a system as a black
	or grey box, the inner structure and behaviour of which can be analysed
	and modelled by varying an internal or external condition, probing
	it from outside and studying the effect of the variation on the external
	observables. The result is an understanding of the inner make-up
	and workings of the system. The equivalent of this in biology is
	to observe what a cell or system excretes under controlled conditions
	- the 'metabolic footprint' or exometabolome - as this is readily
	and accurately measurable. Here, we review the principles, experimental
	approaches and scientific outcomes that have been obtained with this
	useful and convenient strategy.},
  doi = {10.1038/nrmicro1177},
  file = {NatRevMicrobiol2005.pdf:http\://dbkgroup.org/Papers/NatRevMicrobiol2005.pdf:PDF},
  group = {metabolic footprint},
  pmid = {15953932}
}

@ARTICLE{Kelly:models00,
  author = {Frank P. Kelly},
  title = {Models for a Self-Managed Internet},
  journal = {Philosophical Transactions of the Royal Society},
  year = {2000},
  volume = {A358},
  pages = {2335--2348}
}

@ARTICLE{Kelly2007,
  author = {Jennifer Kelly and Aslam Ali Khan and Jiyi Yin and Thomas A Ferguson
	and Rajendra S Apte},
  title = {Senescence regulates macrophage activation and angiogenic fate at
	sites of tissue injury in mice.},
  journal = {J Clin Invest},
  year = {2007},
  volume = {117},
  pages = {3421--3426},
  number = {11},
  month = {Nov},
  abstract = {Abnormal angiogenesis plays a key role in diseases of aging such as
	heart disease, certain cancers, and eye diseases including age-related
	macular degeneration. Macrophages have been shown previously to be
	both anti- and proangiogenic, and their role in regulating angiogenesis
	at sites of tissue injury is critical and complex. In this study,
	we analyzed cytokine gene expression patterns of mouse macrophages
	by real-time quantitative PCR and tested the functional effects of
	senescence on gene expression and macrophage polarization. Following
	laser injury to the retina, IL-10 was upregulated and Fas ligand
	(FasL), IL-12, and TNF-alpha were downregulated in ocular macrophages
	of old mice (>18 months of age). Downregulation of FasL on macrophages
	led to a loss of the antiangiogenic phenotype, as evidenced by the
	inability of these macrophages to inhibit vascular endothelial cells.
	Our results demonstrate that senescence, FasL, and IL-10 are key
	determinants of macrophage function that alter the growth of abnormal
	postdevelopmental blood vessels in disease processes including blinding
	eye disease.},
  doi = {10.1172/JCI32430},
  institution = {Department of Ophthalmology and Visual Sciences, Washington University
	School of Medicine, St. Louis, Missouri 63110, USA.},
  keywords = {Aging, physiology; Animals; Cell Aging, physiology; Choroidal Neovascularization,
	immunology/pathology; Cytokines, genetics/immunology/metabolism;
	Gene Expression Regulation; Humans; Interleukin-10, genetics/metabolism;
	Lasers; Macrophage Activation, physiology; Macrophages, metabolism;
	Mice; Mice, Inbred C57BL; Mice, Knockout; Retina, immunology/pathology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {17975672},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1172/JCI32430}
}

@ARTICLE{Kelly2009,
  author = {Michael C. Kelly and Ping Chen},
  title = {Development of form and function in the mammalian cochlea},
  journal = {Curr Opin Neurobiol},
  year = {2009},
  volume = {19},
  pages = {395--401},
  number = {4},
  month = {Aug},
  abstract = {The cochlea possesses specialized features to receive sound signals
	and to resolve and convert the frequency and intensity components
	within each signal for auditory perception. It consists of precisely
	patterned and polarized sensory cells adorned with a highly specialized
	mechanotransduction apparatus for sensitivity and adaptation, and
	discrete nonsensory cellular networks for biochemical and mechanical
	support to drive an integrated cellular response and mechanotransduction.
	This review summarizes recent discoveries about the roles of FGF,
	Notch, and Hedgehog signaling and transcriptional factors in the
	differentiation and patterning of the auditory sensory organ, the
	Usher complex, and the planar cell polarity pathway in the formation
	and polarization of mechanotransduction component hair bundles, and
	the contribution of nonsensory cell networks in the stria vascularis
	and the sensory region toward the maturation of the mammalian cochlea.},
  doi = {10.1016/j.conb.2009.07.010},
  institution = {Department of Cell Biology, Emory University, 615 Michael Street,
	Atlanta, GA 30322, USA.},
  keywords = {Animals; Cell Differentiation; Cell Polarity; Cochlea; Hair Cells,
	Auditory, Outer; Hearing; Mechanotransduction, Cellular},
  owner = {neil},
  pii = {S0959-4388(09)00095-6},
  pmid = {19683914},
  timestamp = {2010.04.12}
}


@Article{Tenenbaum:theory06,
  author = 	 {Johsua B. Tenenbaum and Thomas L. Griffiths and Charles Kemp},
  title = 	 {Theory-based Bayesian Models of Inductive Learning and Reasoning},
  journal = 	 trendscog,
  year = 	 2006,
  OPTkey = 	 {},
  volume =	 {10},
  number =	 {7},
  pages =	 {309--318},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1016/j.tics.2006.05.009},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@ARTICLE{Kemp:form08,
  author = {Charles Kemp and Joshua B. Tenenbaum},
  title = {The Discovery of Structural Form},
  journal = pnasusa,
  year = {2008},
  volume = {105},
  number = {31},
  optdoi = {10.1073/pnas0802631105}
}

@ARTICLE{Khanin:repression06,
  author = {Raya Khanin and Veronica Viciotti and Ernst Wit},
  title = {Reconstructing Repressor Protein Levels from Expression of Gene Targets
	in \emph{E. Coli}},
  journal = pnasusa,
  year = {2006},
  volume = {103},
  pages = {18592--18596},
  number = {49},
  abstract = {The basic underlying problem in reverse engineering of gene regulatory
	networks from gene expression data is that the expression of a gene
	encoding the regulator provides only limited information about its
	protein activity. The proteins, which result from translation, are
	subject to stringent posttranscriptional control and modification.
	Often, it is only the modified version of the protein that is capable
	of activating or repressing its regulatory targets. At present there
	exists no reliable high-throughput technology to measure the protein
	activity levels in real-time, and therefore they are, so-to-say,
	lost in translation. However, these activity levels can be recovered
	by studying the gene expression of their targets. Here, we describe
	a computational approach to predict temporal regulator activity levels
	from the gene expression of its transcriptional targets in a network
	motif with one regulator and many targets. We consider an example
	of an SOS repair system, and computationally infer the regulator
	activity of its master repressor, LexA. The reconstructed activity
	profile of LexA exhibits a behavior that is similar to the experimentally
	measured profile of this repressor: after UV irradiation, the amount
	of LexA substantially decreases within a few minutes, followed by
	a recovery to its normal level. Our approach can easily be applied
	to known single-input motifs in other organisms.},
  doi = {10.1073/pnas.0603390103},
  file = {18592.pdf:http\://www.pnas.org/cgi/reprint/103/49/18592.pdf:PDF},
  group = {gene networks, repressor},
  pmid = {17121995}
}

@ARTICLE{Khotanzad:zernike90,
  author = {A. Khotanzad and Y. H. Hong},
  title = {Invariant Image Recognition by {Z}ernike Moments},
  journal = PAMI,
  year = {1990},
  volume = {12},
  pages = {489--497},
  number = {5}
}

@ARTICLE{Kiefer:stoch52,
  author = {J. Kiefer and J. Wolfowitz},
  title = {Stochastic Estimation of the Maximum of a Regression Function},
  journal = {Annals of Mathematical Statistics},
  year = {1952},
  volume = {23},
  pages = {462--466}
}

@INPROCEEDINGS{Kim:nonnegative07,
  author = {Yong-Deok Kim and Seungjin Choi},
  title = {Nonnegative Tucker Decomposition},
  booktitle = {Proc. IEEE Conference on Computer Vision and Pattern Recognition
	CVPR '07},
  year = {2007},
  pages = {1--8},
  month = {17--22 June },
  doi = {10.1109/CVPR.2007.383405},
  owner = {neil},
  timestamp = {2009.08.01}
}

@ARTICLE{Kimeldorf:correspondence70,
  author = {George S. Kimeldorf and Grace Wahba},
  title = {A Correspondence Between {B}ayesian Estimation of Stochastic Processes
	and Smoothing by Splines},
  journal = {Annals of Mathematical Statistics},
  year = {1970},
  volume = {41},
  pages = {495--502}
}

@ARTICLE{Kirkpatrick:anneal83,
  author = {S. Kirkpatrick and C. D. Gelatt and M. P. Vecchi},
  title = {Optimization by Simulated Annealing},
  journal = {Science},
  year = {1983},
  volume = {220},
  pages = {671--680},
  number = {4598}
}

@INPROCEEDINGS{Kiviluoto:icafinancial98,
  author = {Kimmo Kiviluoto and Erkki Oja},
  title = {Independent Component Analysis for Parallel Financial Time Series},
  booktitle = {Proceedings of the International Conference on Neural Information
	Processing, ICONIP'98},
  year = {1998},
  pages = {895--898},
  address = {Kitakyushu, Japan},
  month = {Oct 21--23}
}

@MISC{Kleiman:writing99,
  author = {Steven L. Kleiman and Glenn P. Tesler},
  title = {Writing a Math Phase Two Paper},
  howpublished = {Available on-line.},
  year = {1999},
  group = {researchComputing},
  label1 = {Link},
  link1 = {http://www.mit.edu/afs/athena.mit.edu/course/other/mathp2/www/piil.html}
}

@ARTICLE{Ko:learning11,
   author = {Jonathan Ko and Dieter Fox},
   title = {Learning {GP-BayesFilters} via {G}aussian process latent variable models},
   journal = {Autonomous Robots},
   publisher = springer,
   issn = {0929-5593},
   keyword = {Computer Science},
   pages = {3-23},
   volume = {30},
   issue = {1},
   doi = {10.1007/s10514-010-9213-0},
   year = {2011}
}

@article{Ko:bayesian09,
 author = {Jonathan Ko and Dieter Fox},
 title = {{GP-BayesFilters}: {B}ayesian filtering using {G}aussian process prediction and observation models},
 journal = {Autonomous Robots},
 volume = {27},
 issue = {1},
 month = {July},
 year = {2009},
 issn = {0929-5593},
 pages = {75--90},
 numpages = {16},
 doi = {10.1007/s10514-009-9119-x},
 acmid = {1569255},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Bayesian filtering, Dynamic modelling, Gaussian process, Machine learning, Regression},
} 

@INPROCEEDINGS{Ko:bayesfilter09,
  author = {Jonathan Ko and Dieter Fox},
  title = {Learning {GP-BayesFilters} via {Gaussian} Process Latent Variable Models},
  booktitle = {Robotics: Science and Systems},
  year = {2009}
}

@ARTICLE{Kohonen:ieee90,
  author = {Teuvo Kohonen},
  title = {The Self-Organizing Map},
  journal = {Proceedings of the {IEEE}},
  year = {1990},
  volume = {78},
  pages = {1464--1480},
  number = {9}
}

@ARTICLE{Kohonen:map82,
  author = {Teuvo Kohonen},
  title = {Self-Organized Formation of Topologically Correct Feature Maps},
  journal = {Biological Cybernetics},
  year = {1982},
  volume = {43},
  pages = {59--69}
}

@INPROCEEDINGS{Kohonen:benchmark88,
  author = {Teuvo Kohonen and Gyorgy Barna and Ronald Chrisley},
  title = {Statistical pattern recognition with neural networks: benchmarking
	studies},
  booktitle = {Proceedings IEEE International Conference on Neural Networks},
  year = {1988},
  pages = {61--68},
  address = {San Diego, CA},
  publisher = {IEEE Press}
}

@ARTICLE{Kohut2004,
  author = {Marian L Kohut and David S Senchina and Kelley S Madden and Aisha
	E Martin and David L Felten and Jan A Moynihan},
  title = {Age effects on macrophage function vary by tissue site, nature of
	stimulant, and exercise behavior.},
  journal = {Exp Gerontol},
  year = {2004},
  volume = {39},
  pages = {1347--1360},
  number = {9},
  month = {Sep},
  abstract = {We explored the effects of aging on macrophage function in male BALB/c
	mice from three age groups: young (2 months), middle-aged (12 months),
	and old (21 months). Macrophages were collected from alveoli, peritonea,
	and spleens of each age group. Cells were cultured in vitro with
	LPS or LPS+IFN-gamma and assayed for production of IL-1, IL-12, NO,
	and TNF-alpha. Using herpes simplex virus-1, age-related changes
	in intrinsic antiviral resistance (plaque assay) and extrinsic antiviral
	resistance (NO and TNF-alpha production) were determined in alveolar
	and/or peritoneal macrophages. Effects of chronic exercise on age-related
	macrophage changes were examined. In vitro, macrophages from the
	alveoli and spleen of older mice generally produced more cytokine
	and NO compared to younger counterparts. Conversely, macrophages
	from the peritonea of older mice generally produced less cytokine
	and NO in vitro compared to younger counterparts. Alveolar macrophages
	from both old and young mice showed higher intrinsic antiviral resistance
	to HSV-1 compared to middle-aged mice, while peritoneal macrophages
	from young mice showed reduced intrinsic resistance compared to those
	from both middle-aged and old mice. When challenged with HSV-1, a
	trend towards decreased peritoneal macrophage production of TNF-alpha
	and decreased alveolar macrophage production of IL-12 with advancing
	age was found. Chronic moderate exercise tended to reverse age-associated
	changes in macrophage function in old mice.},
  doi = {10.1016/j.exger.2004.07.001},
  institution = {Department of Health and Human Performance, Iowa State University,
	235 Forker, Ames, IA 50011-1160, USA. mkohut@iastate.edu},
  keywords = {Aging, immunology; Animals; Cells, Cultured; Cytokines, biosynthesis;
	Herpes Simplex, immunology; Herpesvirus 1, Human; Macrophage Activation;
	Macrophages, Alveolar, immunology; Macrophages, Peritoneal, immunology/virology;
	Macrophages, immunology; Male; Mice; Mice, Inbred BALB C; Motor Activity,
	immunology; Nitric Oxide, biosynthesis; Spleen, immunology; Virus
	Replication, immunology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {S0531-5565(04)00218-9},
  pmid = {15489058},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1016/j.exger.2004.07.001}
}

@INPROCEEDINGS{Kolda2008,
  author = {Kolda, T.G. and Jimeng Sun},
  title = {Scalable Tensor Decompositions for Multi-aspect Data Mining},
  booktitle = {Proc. Eighth IEEE International Conference on Data Mining ICDM '08},
  year = {2008},
  pages = {363--372},
  month = {15--19 Dec. },
  doi = {10.1109/ICDM.2008.89},
  owner = {neil},
  timestamp = {2009.08.01}
}

@ARTICLE{Kolmogorov:57,
  author = {A. N. Kolmogorov},
  title = {On the Representation of Continuous Functions of Several Variables
	by Superposition of Continuous Functions of One Variable and Addition},
  journal = DOKLADY,
  year = {1957},
  volume = {114},
  pages = {953--956},
  number = {5}
}

@ARTICLE{Kondo2004,
  author = {Yutaka Kondo and Lanlan Shen and Pearlly S Yan and Tim Hui-Ming Huang
	and Jean-Pierre J Issa},
  title = {Chromatin immunoprecipitation microarrays for identification of genes
	silenced by histone H3 lysine 9 methylation.},
  journal = {Proc Natl Acad Sci U S A},
  year = {2004},
  volume = {101},
  pages = {7398--7403},
  number = {19},
  month = {May},
  abstract = {Switching from acetylation to methylation at histone H3 lysine 9 (K9)
	has recently been shown to contribute to euchromatin gene silencing.
	To identify genes silenced by K9 modifications, we probed a human
	CpG island microarray with DNA obtained by chromatin immunoprecipitation
	(ChIP) in a cancer cell line using an anti-H3-K9 methylated antibody
	or an anti-H3-K9 acetylated antibody. Of the 27 clones with the highest
	signal ratio of K9 methylation over acetylation (Me/Ac), 13 contained
	repetitive sequences. Among 14 nonrepetitive clones, we identified
	11 genes (seven known and four previously undescribed), one EST,
	and two unknown fragments. Using ChIP-PCR, all 18 examined clones
	showed higher ratios of H3-K9 Me/Ac than the active gene control,
	P21, thus confirming the microarray data. In addition, we found a
	strong correlation between the K9 Me/Ac ratio and CpG island DNA
	methylation (R = 0.92, P < 0.01), and five of seven genes examined
	(megalin, thrombospondin-4, KR18, latrophilin-3, and phosphatidylinositol-3-OH
	kinase P101 subunit) showed lack of expression by RT-PCR and reactivation
	by DNA methylation and/or histone deacetylase inhibition, suggesting
	that these genes are true targets of silencing through histone modifications.
	All five genes also showed significant DNA methylation in a cell
	line panel and in primary colon cancers. Our data suggest that CpG
	island microarray coupled with ChIP can identify novel targets of
	gene silencing in cancer. This unbiased approach confirms the tight
	coupling between DNA methylation and histone modifications in cancer
	and could be used to probe gene silencing in nonneoplastic conditions
	as well.},
  doi = {10.1073/pnas.0306641101},
  institution = {Department of Leukemia, University of Texas M. D. Anderson Cancer
	Center, Houston, TX 77030, USA.},
  keywords = {Acetylation; Cell Line, Tumor; Chromatin, metabolism; DNA Methylation;
	Gene Silencing; Histones, chemistry/metabolism; Humans; Lysine, metabolism;
	Oligonucleotide Array Sequence Analysis; Precipitin Tests; Reverse
	Transcriptase Polymerase Chain Reaction},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {0306641101},
  pmid = {15123805},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1073/pnas.0306641101}
}

@ARTICLE{Kooperberg:improved02,
  author = {C. Kooperberg and T. G. Fazzio and J. J. Delrow and T. Tsukiyama},
  title = {Improved Background Correction for Spotted {DNA} Microarrays},
  journal = {J. Comp. Biol.},
  year = {2002},
  volume = {9},
  pages = {55--66},
  number = {1}
}

@INPROCEEDINGS{Koren:multifaceted08,
  author = {Yohuda Koren},
  title = {Factorization Meets the Neighborhood: a Multifaceted Collaborative
	Filtering Model},
  booktitle = {KDD '08: Proceeding of the 14th ACM SIGKDD international conference
	on Knowledge discovery and data mining},
  year = {2008},
  pages = {426--434},
  file = {kdd08koren.pdf:http\://public.research.att.com/~volinsky/netflix/kdd08koren.pdf:PDF}
}

@INPROCEEDINGS{Kraijveld:kernel91,
  author = {M. Kraaijveld and R. Duin},
  title = {Generalization Capabilities of Minimal Kernel-Based Networks},
  booktitle = ijcnn,
  year = {1991},
  volume = {1},
  pages = {843--848},
  address = {New York},
  publisher = {IEEE}
}

@ARTICLE{Kramer:pca91,
  author = {M. A. Kramer},
  title = {Nonlinear Principal Component Analysis Using Autoassociative Neural
	Networks},
  journal = {AIChe Journal},
  year = {1991},
  volume = {37},
  pages = {233--243},
  number = {2}
}

@ARTICLE{Kreegipuu:phosphobase99,
  author = {A. Kreegipuu and N. Blom and S. Brunak},
  title = {PhosphoBase, a database of phosphorylation sites: release 2.0},
  journal = nar,
  year = {1999},
  optpages = {273--279},
  optvolume = {27}
}

@ARTICLE{Kreinovich:univ91,
  author = {V. Y. Kreinovich},
  title = {Arbitrary Nonlinearity is Sufficient to Represent All Functions by
	Neural Networks: a Theorem},
  journal = NN,
  year = {1991},
  volume = {4},
  pages = {381--383},
  number = {3}
}

@INPROCEEDINGS{Krogh:comm95,
  author = {A. Krogh and J. Vedelsby},
  title = {Neural network ensembles, cross validation and active learning},
  booktitle = nips,
  year = {1995},
  editor = {D. S. Touretzky and G. Tesauro and T. K. Leen},
  volume = {7},
  address = {Cambridge, MA},
  publisher = mit
}

@ARTICLE{Kruskal:mds64,
  author = {Joseph B. Kruskal},
  title = {Multidimensional Scaling by Optimizing Goodness-of-Fit to a Nonmetric
	Hypothesis},
  journal = {Psychometrika},
  year = {1964},
  volume = {29},
  pages = {1--28},
  number = {1},
  abstract = {Multidimensional scaling is the problem of representing $n$ objects
	geometrically by $n$ points, so that the interpoint distances correspond
	in some sense to experimental dissimilarities between objects. In
	just what sense distances and dissimilarities should correspond has
	been left rather vague in most approaches, thus leaving these approaches
	logically incomplete. Our fundamental hypothesis is that dissimilarities
	and distances are monotonically related. We define a quantitative,
	intuitively satisfying measure of goodness of fit to this hypothesis.
	Our technique of multidimensional scaling is to compute that configuration
	of points which optimizes the goodness of fit. A practical computer
	program for doing the calculations is described in a companion paper.},
  doi = {10.1007/BF02289565},
  file = {fulltext.pdf:http\://www.springerlink.com/content/010q1x323915712x/fulltext.pdf:PDF},
  group = {mds}
}

@ARTICLE{Kullback:info51,
  author = {Solomon Kullback and Richard A. Leibler},
  title = {On Information and Sufficiency},
  journal = {Annals of Mathematical Statistics},
  year = {1951},
  volume = {22},
  pages = {79--86}
}

@TECHREPORT{Kuss:geometry03,
  author = {Malte Kuss and Thore Graepel},
  title = {The Geometry of Kernel Canonical Correlation Analysis},
  institution = {Max Planck Institute for Biological Cybernetics},
  year = {2003},
  number = {TR-108},
  address = {T{\"u}bingen, Germany},
  abstract = {Canonical correlation analysis (CCA) is a classical multivariate method
	concerned with describing linear dependencies between sets of variables.
	After a short exposition of the linear sample CCA problem and its
	analytical solution, the article proceeds with a detailed characterization
	of its geometry. Projection operators are used to illustrate the
	relations between canonical vectors and variates. The article then
	addresses the problem of CCA between spaces spanned by objects mapped
	into kernel feature spaces. An exact solution for this kernel canonical
	correlation (KCCA) problem is derived from a geometric point of view.
	It shows that the expansion coefficients of the canonical vectors
	in their respective feature space can be found by linear CCA in the
	basis induced by kernel principal component analysis. The effect
	of mappings into higher dimensional feature spaces is considered
	critically since it simplifies the CCA problem in general. Then two
	regularized variants of KCCA are discussed. Relations to other methods
	are illustrated, e.g., multicategory kernel Fisher discriminant analysis,
	kernel principal component regression and possible applications thereof
	in blind source separation.},
  file = {upload_22685_TR-108.pdf:http\://www.kernel-machines.org/papers/upload_22685_TR-108.pdf:PDF},
  group = {cca}
}

@ARTICLE{Kuss:assessing05,
  author = {Malte Kuss and Carl Edward Rasmussen},
  title = {Assessing Approximate Inference for Binary {G}aussian Process Classification},
  journal = jmlr,
  year = {2005},
  volume = {6},
  pages = {1679--1704},
  abstract = {Gaussian process priors can be used to define flexible, probabilistic
	classification models. Unfortunately exact Bayesian inference is
	analytically intractable and various approximation techniques have
	been proposed. In this work we review and compare Laplace's method
	and Expectation Propagation for approximate Bayesian inference in
	the binary Gaussian process classification model. We present a comprehensive
	comparison of the approximations, their predictive performance and
	marginal likelihood estimates to results obtained byMCMC sampling.
	We explain theoretically and corroborate empirically the advantages
	of Expectation Propagation compared to Laplace's method. Keywords:
	Gaussian process priors, probabilistic classification, Laplace's
	approximation, expectation propagation, marginal likelihood, evidence,
	MCMC},
  file = {kuss05a.pdf:http\://jmlr.csail.mit.edu/papers/volume6/kuss05a/kuss05a.pdf:PDF},
  group = {gp}
}

@ARTICLE{Kyriakidis:spacetimemodelsReview99,
  author = {Phaedon C. Kyriakidis and Andr\'{e} G. Journel},
  title = {Geostatistical Space-Time Models: A Review},
  journal = {Mathematical Geology},
  year = {1999},
  volume = {31},
  pages = {651-684},
  number = {6}
}

@ARTICLE{Kurkova:kolmog92,
  author = {V. K{\.u}rkov{\'a}},
  title = {{K}olmogorov's Theorem and Multilayer Neural Networks},
  journal = NN,
  year = {1992},
  volume = {5},
  pages = {501--506},
  number = {3}
}

@ARTICLE{Kurkova:kolmog91,
  author = {V. K{\.u}rkov{\'a}},
  title = {{K}olmogorov's Theorem is Relevant},
  journal = NC,
  year = {1991},
  volume = {3},
  pages = {617--622},
  number = {4}
}

@ARTICLE{Kurkova:func94,
  author = {V. K{\.u}rkov{\'a} and P. C. Kainen},
  title = {Functionally Equivalent Feed-forward Neural Networks},
  journal = NC,
  year = {1994},
  volume = {6},
  pages = {543--558},
  number = {3}
}

@ARTICLE{Lai:kernelcca00,
  author = {Pei Ling Lai and Colin Fyfe},
  title = {Kernel and nonlinear Canonical Correlation Analysis},
  journal = IJNS,
  year = {2001},
  volume = {10},
  pages = {365--377},
  number = {5},
  abstract = {We review a neural implementation of the statistical technique of
	Canonical Correlation Analysis (CCA) and extend it to nonlinear CCA.
	We then derive the method of kernel-based CCA and compare these two
	methods on real and artificial data sets before using both on the
	Blind Separation of Sources.},
  doi = {10.1142/S012906570000034X},
  group = {cca, ica}
}

@INPROCEEDINGS{Lan:beyond05,
  author = {Xiangyang Lan and Daniel P. Huttenlocher},
  title = {Beyond Trees: Common-Factor Models for 2{D} Human Pose Recovery},
  booktitle = iccv,
  year = {2005},
  volume = {1},
  pages = {470--477},
  address = {Bejing, China},
  month = {17--21 Oct.},
  publisher = ieeecomp,
  abstract = {Tree structured models have been widely used for determining the pose
	of a human body, from either 2D or 3D data. While such models can
	effectively represent the kinematic constraints of the skeletal structure,
	they do not capture additional constraints such as coordination of
	the limbs. Tree structured models thus miss an important source of
	information about human body pose, as limb coordination is necessary
	for balance while standing, walking, or running, as well as being
	evident in other activities such as dancing and throwing. In this
	paper, we consider the use of undirected graphical models that augment
	a tree structure with latent variables in order to account for coordination
	between limbs. We refer to these as common-factor models, since they
	are constructed by using factor analysis to identify additional correlations
	in limb position that are not accounted for by the kinematic tree
	structure. These common-factor models have an underlying tree structure
	and thus a variant of the standard Viterbi algorithm for a tree can
	be applied for efficient estimation. We present some experimental
	results contrasting common-factor models with tree models, and quantify
	the improvement in pose estimation for 2D image data.},
  doi = {10.1109/ICCV.2005.48},
  file = {lan-pose-iccv05.pdf:http\://www.cs.cornell.edu/~dph/papers/lan-pose-iccv05.pdf:PDF},
  group = {tree, human pose}
}

@ARTICLE{Lang:word90,
  author = {K. J. Lang and A. H. Waibel and G. E. Hinton},
  title = {A Time-delay Neural Network Architecture for Isolated Word Recognition},
  journal = NN,
  year = {1990},
  volume = {3},
  pages = {23--43},
  number = {1}
}

@INPROCEEDINGS{Lapedes:net88,
  author = {A. Lapedes and R. Farber},
  title = {How Neural Nets Work},
  booktitle = {Neural Information Processing Systems},
  year = {1988},
  editor = {D. Z. Anderson},
  pages = {442--456},
  address = {New York},
  publisher = {American Institute of Physics}
}
@article{Jaynes:gibbs65,
    abstract = {The status of the Gibbs and Boltzmann expressions for entropy has been a matter of someconfusion in the literature. We show that: (1) the Gibbs H function yields the correct entropyas defined in phenomenological thermodynamics; (2) the Boltzmann H yields an "entropy" thatis in error by a nonnegligible amount whenever interparticle forces affect thermodynamicproperties; (3) Boltzmann's other interpretation of entropy, S = k log W, is consistent with theGibbs H, and derivable from it; (4) the Boltzmann H theorem does not constitute a demonstrationof the second law for dilute gases; (5) the dynamical invariance of the Gibbs H givesa simple proof of the second law for arbitrary interparticle forces; (6) the second law is a specialcase of a general requirement for any macroscopic process to be experimentally reproducible.Finally, the "anthropomorphic" nature of entropy, on both the statistical and phenomenologicallevels, is stressed. {\copyright}1965 American Association of Physics Teachers},
    author = {Edward T. Jaynes},
    doi = {10.1119/1.1971557},
    journal = {American Journal of Physics},
    keywords = {statistics, statmech, thermodynamics},
    number = {5},
    pages = {391--398},
    publisher = {AAPT},
    title = {{G}ibbs vs {B}oltzmann Entropies},
    url = {http://dx.doi.org/10.1119/1.1971557},
    volume = {33},
    year = {1965}
}

@Book{Gauss:theoriaMotus,
  author =	 {Carl Friederich Gauss},
  ALTeditor = 	 {},
  title = 	 {Theoria Motus Corporum Coelestium},
  publisher = 	 {Friedrich Perthes and I.H. Besser},
  year = 	 {1809},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {Hamburg},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Misc{Gauss:astronomische02,
  OPTkey = 	 {},
  author =	 {Carl Friederich Gauss},
  title =	 {Astronomische Untersuchungen und Rechnungen vornehmlich über die Ceres Ferdinandea},
  OPThowpublished = {},
  OPTmonth = 	 {},
  year =	 {1802},
  note =	 {Nachlass Gauss, Handbuch 4, Bl. 1},
  annote =	 {see \url{http://webdoc.sub.gwdg.de/ebook/e/2005/gausscd/html/kapitel_astro_ceres.htm}.},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}


@Article{Legendre:nouvelles05,
  author = 	 {Adrien Marie Legendre},
  title = 	 {Nouvelles m\'ethodes pour la d\'etermination des orbites des com\`etes},
  journal = 	 {},
  year = 	 {1805},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTpages = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {In the appendix, pg 72: `Sur la M\'ethode des moidres quarr\'es'},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  url =		 {http://books.google.co.uk/books?id=spcAAAAAMAAJ&dq=Nouvelles%20m%C3%A9thodes%20pour%20la%20d%C3%A9termination%20des%20orbites%20des%20com%C3%A8tes%20%2F%20Adrien%20Marie%20Legendre&pg=PA72#v=onepage&q&f=false},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}
@INPROCEEDINGS{Laplace:nombres10,
  author = {Pierre Simon Laplace},
  title = {M\'emoire sur les approximations des formules qui sont fonctions
	de tre\`s grands nombres et sur leur application aux probabilit\'es},
  booktitle = {M\'emoires de l'Acad\'emie des sciences de Paris},
  year = {1810},
  pages = {353--415}
}

@INPROCEEDINGS{Laplace:memoire74,
  author = {Pierre Simon Laplace},
  title = {M\'emoire sur la probabilit\'e des causes par les \'ev\`enemens},
  booktitle = {M\'emoires de math\`ematique et de physique, present\'es \`a lAcad\'emie
	Royale des Sciences, par divers savans, \& l\`u dans ses assembl\'ees
	6},
  year = {1774},
  pages = {621--656},
  note = {Translated in \cite{Stigler:laplace86}}
}

@INPROCEEDINGS{Lappalainen:ensemble99,
  author = {Harri Lappalainen},
  title = {Ensemble Learning for Independent Component Analysis},
  booktitle = {Proceedings of the First International Workshop on Independent Component
	Analysis and Blind Signal Separation},
  year = {1999},
  pages = {7--12}
}

@TECHREPORT{Lappalainen:fixed00,
  author = {Harri Lappalainen},
  title = {Fast Fixed-Point Algorithms for {B}ayesian Blind Source Separation},
  institution = {Neural Networks Research Centre, Helsinki University of Technology},
  year = {1999}
}

@INPROCEEDINGS{Lappalainen:fast00,
  author = {Harri Lappalainen and Petteri Pajunen},
  title = {Fast Algorithms for {B}ayesian Independent Component Analysis},
  booktitle = {Proceedings of the Second International Workshop on Independent Component
	Analysis and Blind Signal Separation (ICA 2000)},
  year = {2000},
  pages = {233--237},
  address = {Helsinki, Finland}
}

@ARTICLE{Lark:fitting03,
  author = {Richard Murray Lark and Andreas J\"urg Papritz},
  title = {Fitting a linear model of coregionalization for soil properties using
	simulated annealing},
  journal = {Geoderma},
  year = {2003},
  volume = {115},
  pages = {245-260}
}

@ARTICLE{larochelle2011,
  author = {Hugo Larochelle and Iain Murray},
  title = {The Neural Autoregressive Distribution Estimator},
  journal = {JMLR: W\&CP},
  year = {2011},
  volume = {15},
  pages = {29--37}
}

@ARTICLE{Lartillot:thermodynamic06,
  author = {Nicolas Lartillot and Herv\'e Philippe},
  title = {Computing {B}ayes Factors Using Thermodynamic Integration},
  journal = {Syst. Biol.},
  year = {2006},
  volume = {55},
  pages = {195--207},
  number = {2}
}

@INPROCEEDINGS{Delathauwer:fetal95,
  author = {Lieven De Lathauwer and Bart De Moor and Joos Vandewalle},
  title = {Fetal Electrocardiogram Extraction by Source Subspace Separation},
  booktitle = {Proc. IEEE-SP Workshop on Higher-order Statistics (HOS'95)},
  year = {1995},
  pages = {134--138}
}

@ARTICLE{Laub:global00,
  author = {M. T. Laub and H. H. McAdams and T. Feldblyum and C. M. Fraser},
  title = {Global Analysis of the genetic network controlling a bacterial cell
	cycle},
  journal = {Science},
  year = {2000},
  pages = {2144--2148},
  group = {gene networks, network motifs}
}

@ARTICLE{Lauritzen:local88,
  author = {Steffen L. Lauritzen and David J. Spiegelhalter},
  title = {Local Computations with Probabilities on Graphical Structures and
	the Application to Expert Systems},
  journal = JRSSb,
  year = {1988},
  volume = {50},
  pages = {154--227}
}

@ARTICLE{Lazebnik:radio02,
  author = {Yuri Lazebnik},
  title = {Can a biologist fix a radio? Or, what {I} learned while studying
	apoptosis},
  journal = {Cancer Cell},
  year = {2002},
  volume = {2},
  pages = {179--182},
  file = {bcm_1403.pdf:http\://protein.bio.msu.ru/biokhimiya/contents/v69/pdf/bcm_1403.pdf:PDF},
  pmid = {12242150}
}

@ARTICLE{Lee:target05,
  author = {Andrew M. Lee and Christian T. Ross and Bu-Bing Zeng and and Scott
	F. Singleton.},
  title = {A Molecular Target for Suppression of the Evolution of Antibiotic
	Resistance: Inhibition of the \emph{Escherichia coli} {RecA} Protein
	by {N6-(1-Naphthyl)-ADP}},
  journal = {J. Med. Chem.},
  year = {2005},
  volume = {48},
  number = {17},
  group = {SOS response, E. Coli},
  optpages = {5408--5411}
}

@ARTICLE{Lee:intrinsicConvolution05,
  author = {Herbert K. H. Lee and David M. Higdon and Catherine A. Calder and
	Christopher H. Holloman},
  title = {Efficient models for correlated data via convolutions of intrinsic
	processes},
  journal = statmod,
  year = {2005},
  volume = {5},
  pages = {53-74},
  number = {1}
}

@ARTICLE{Lee:trascriptional02,
  author = {Tong Ihn Lee and Nicola J. Rinaldi and Francois Robert and Duncan
	T. Odom and Ziv Bar-Joseph and Georg K. Gerber and Nancy M. Hannett
	and Christopher T. Harbison and Craig M. Thompson and Itamar Simon
	and Julia Zeitlinger and Ezra G. Jennings and Heather L. Murray and
	D. Benjamin Gordon and Bing Ren and John J. Wyrick and Jean-Bosco
	Tagne and Thomas L. Volkert and Ernest Fraenkel and David K. Gifford
	and Richard A. Young},
  title = {Transcriptional Regulatory Networks in {S}accharomyces cerevisiae},
  journal = {Science},
  year = {2002},
  volume = {298},
  pages = {799--804},
  number = {5594},
  group = {gene networks}
}

@INPROCEEDINGS{Leen:gplvmcca06,
  author = {Gayle Leen and Colin Fyfe},
  title = {A {G}aussian Process Latent Variable Model Formulation of Canonical
	Correlation Analysis},
  year = {2006},
  address = {Bruges (Belgium)},
  month = {26-28 April 2006},
  abstract = {We investigate a nonparameteric model with which to visualize the
	relationship between two datasets. We base our model on Gaussian
	Process Latent Variable Models (GPLVM) \cite{Lawrence:gplvm03,Lawrence:pnpca05},
	a probabilistcally defined latent variable model which takes the
	alternative approach of marginalizing the parameters and optimizing
	the latent variables; we optimize a latent variable set for each
	dataset, which preserves the correlations between the datasets, resulting
	in a GPLVM formulation of canonical correlation analysis which can
	be nonlinearised by choice of covariance function.},
  file = {es2006-104.pdf:http\://www.dice.ucl.ac.be/Proceedings/esann/esannpdf/es2006-104.pdf:PDF},
  group = {CCA, dimensional reduction, gplvm},
  optbooktitle = {European Symposium on Artificial Neural Networks}
}

@ARTICLE{Leisch:sweave02,
  author = {Friedrich Leisch},
  title = {Sweave, {Part I}: Mixing {R} and {LaTeX}: {A} short introduction
	to the {S}weave file format and corresponding {R} functions},
  journal = {R News},
  year = {2002},
  volume = {2},
  pages = {28--31},
  number = {3}
}

@ARTICLE{Levenberg:lms44,
  author = {K. Levenberg},
  title = {A method for the solution of certain non-linear problems in least
	squares},
  journal = {Quarterly Journal of Applied Mathematics},
  year = {1944},
  volume = {II},
  pages = {164--168},
  number = {2}
}

@article{Levine:control12,
  author = {Segey Levine and Jack M. Wang and Alexis Haraux and Zoran Popovi\'c
	and Vladlen Koltun},
  title = {Continuous Character Control with Low-Dimensional Embeddings},
  journal = {ACM Transactions on Graphics (SIGGRAPH 2012)},
  pdf = {http://graphics.stanford.edu/projects/ccclde/ccclde.pdf},
  number =	 {4},
  volume =	 {31},
  year =	 {2012}

}

@ARTICLE{Tibshirani:surfaces94,
  author = {M. Le{B}lanc and R. Tibshirani},
  title = {Adaptive principal surfaces},
  journal = {Journal of the American Statistical Association},
  year = {1994},
  volume = {89},
  pages = {53--64},
  number = {425}
}

@PHDTHESIS{LeCun:thesis87,
  author = {Yann {Le~Cun}},
  title = {Mod\`{e}les Connexionnistes de l'Apprentissage},
  school = {Universit\'{e} Pierre et Marie Curie, Paris},
  year = {1987}
}

@ARTICLE{LeCun:zip89,
  author = {Yann {Le~Cun} and Bernhard E. Boser and J. S. Denker and D. Henderson
	and R. E. Howard and W. Hubbard and L. D. Jackel},
  title = {Backpropagation Applied to Handwritten Zip Code Recognition},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {541--551},
  number = {4},
  pdflink = {http://www.lecun.com/exdb/publis/pdf/lecun-89e.pdf}
}

@ARTICLE{LiN2003,
  author = {Na Li and Matthew Stephens},
  title = {Modeling linkage disequilibrium and identifying recombination hotspots
	using single-nucleotide polymorphism data},
  journal = {Genetics},
  year = {2003},
  volume = {165},
  pages = {2213--2233},
  url = {http://www.genetics.org/cgi/content/abstract/165/4/2213}
}

@UNPUBLISHED{Liang:nonparametric09,
  author = {Feng Liang and Kai Mao and Ming Liao and Sayan Mukherjee and Mike
	West},
  title = {Non-parametric {B}ayesian kernel models},
  note = {Department of Statistical Science, Duke University, Discussion Paper
	07-10. (Submitted for publication)},
  year = {2009}
}

@ARTICLE{Liao:nca03,
  author = {James C. Liao and Riccardo Boscolo and Young-Lyeol Yang and Linh
	My Tran and Chiara Sabatti and Vwani P. Roychowdhury},
  title = {Network Component Analysis: Reconstruction of Regulatory Signals
	in Biological Systems},
  journal = {Proceedings of the National Academy of Sciences USA},
  year = {2003},
  volume = {100},
  pages = {15522--15527},
  number = {26},
  group = {gene networks}
}

@ARTICLE{Licastro2005,
  author = {Federico Licastro and Giuseppina Candore and Domenico Lio and Elisa
	Porcellini and Giuseppina Colonna-Romano and Claudio Franceschi and
	Calogero Caruso},
  title = {Innate immunity and inflammation in ageing: a key for understanding
	age-related diseases.},
  journal = {Immun Ageing},
  year = {2005},
  volume = {2},
  pages = {8},
  month = {May},
  abstract = {The process of maintaining life for the individual is a constant struggle
	to preserve his/her integrity. This can come at a price when immunity
	is involved, namely systemic inflammation. Inflammation is not per
	se a negative phenomenon: it is the response of the immune system
	to the invasion of viruses or bacteria and other pathogens. During
	evolution the human organism was set to live 40 or 50 years; today,
	however, the immune system must remain active for much a longer time.
	This very long activity leads to a chronic inflammation that slowly
	but inexorably damages one or several organs: this is a typical phenomenon
	linked to ageing and it is considered the major risk factor for age-related
	chronic diseases. Alzheimer's disease, atherosclerosis, diabetes
	and even sarcopenia and cancer, just to mention a few - have an important
	inflammatory component, though disease progression seems also dependent
	on the genetic background of individuals. Emerging evidence suggests
	that pro-inflammatory genotypes are related to unsuccessful ageing,
	and, reciprocally, controlling inflammatory status may allow a better
	chance of successful ageing. In other words, age-related diseases
	are "the price we pay" for a life-long active immune system: this
	system has also the potential to harm us later, as its fine tuning
	becomes compromised. Our immune system has evolved to control pathogens,
	so pro-inflammatory responses are likely to be evolutionarily programmed
	to resist fatal infections with pathogens aggressively. Thus, inflammatory
	genotypes are an important and necessary part of the normal host
	responses to pathogens in early life, but the overproduction of inflammatory
	molecules might also cause immune-related inflammatory diseases and
	eventually death later. Therefore, low responder genotypes involved
	in regulation of innate defence mechanisms, might better control
	inflammatory responses and age-related disease development, resulting
	in an increased chance of long life survival in a "permissive" environment
	with reduced pathogen load, medical care and increased quality of
	life.},
  doi = {10.1186/1742-4933-2-8},
  institution = {Dipartimento di Patologia Sperimentale, Università di Bologna, Italy.
	licastro@alma.unibo.it},
  language = {eng},
  medline-pst = {epublish},
  owner = {neil},
  pii = {1742-4933-2-8},
  pmid = {15904534},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1186/1742-4933-2-8}
}

@ARTICLE{Lin:identification04,
  author = {Kevin K. Lin and Darya Chudova and G. Wesley Hatfield and Padhraic
	Smyth and and Bogi Andersen},
  title = {Identification of hair cycle-associated genes from time-course gene
	expression profile data by using replicate variance},
  journal = pnasusa,
  year = {2004},
  volume = {101},
  pages = {15955--15960},
  number = {45},
  abstract = {The hair-growth cycle is an example of a cyclic process that is well
	characterized morphologically but understood incompletely at the
	molecular level. As an initial step in discovering regulators in
	hair-follicle morphogenesis and cycling, we used DNA microarrays
	to profile mRNA expression in mouse back skin from eight representative
	time points. We developed a statistical algorithm to identify the
	set of genes expressed within skin that are associated specifically
	with the hair-growth cycle. The methodology takes advantage of higher
	replicate variance during asynchronous hair cycles in comparison
	with synchronous cycles. More than one-third of genes with detectable
	skin expression showed hair-cycle-related changes in expression,
	suggesting that many more genes may be associated with the hair-growth
	cycle than have been identified in the literature. By using a probabilistic
	clustering algorithm for replicated measurements, these genes were
	grouped into 30 time-course profile clusters, which fall into four
	major classes. Distinct genetic pathways were characteristic for
	the different time-course profile clusters, providing insights into
	the regulation of hair-follicle cycling and suggesting that this
	approach is useful for identifying hair follicle regulators. In addition
	to revealing known hair-related genes, we identified genes that were
	not previously known to be hair cycle-associated and confirmed their
	temporal and spatial expression patterns during the hair-growth cycle
	by quantitative real-time PCR and in situ hybridization. The same
	computational approach should be generally useful for identifying
	genes associated with cyclic processes from complex tissues.},
  file = {15955:http\://www.pnas.org/cgi/reprint/101/45/15955:PDF}
}

@ARTICLE{Linde:vquant80,
  author = {Y. Linde and A. Buzo and R. M. Gray},
  title = {An Algorithm for Vector Quantizer Design},
  journal = {IEEE Transactions on Communications},
  year = {1980},
  volume = {28},
  pages = {84--95},
  number = {1}
}

@ARTICLE{Linsker:son88,
  author = {R. Linsker},
  title = {Self-organization in a Perceptual Network},
  journal = {IEEE Computer},
  year = {1988},
  volume = {21},
  pages = {105--117}
}

@ARTICLE{Lippmann:review87,
  author = {R. P. Lippmann},
  title = {An Introduction to Computing with Neural Nets},
  journal = {IEEE ASSP Magazine, {\rm April}},
  year = {1987},
  pages = {4--22}
}

@ARTICLE{Little:missing92,
  author = {R. J. A. Little},
  title = {Regression with missing {X}'s: a review},
  journal = {Journal of the American Statistical Association},
  year = {1992},
  volume = {87},
  pages = {1227--1237},
  number = {420}
}

@PHDTHESIS{Liu:microarray06,
  author = {Xuejun Liu},
  title = {Microarray Data Analysis using Probabilistic Methods},
  school = {School of Computer Science, University of Manchester},
  year = {2006},
  abstract = {Affymetrix microarrays are currently the most widely used 
	
	 microarray technology. Due to the complexity of microarray experiments,
	the experimental data is very noisy. Many summarization methods have
	been developed to provide gene expression levels from Affymetrix
	probe-level data. Most of the currently popular methods do not provide
	a measure of uncertainty for the estimated ex- pression level of
	each gene. The use of probabilistic models can overcome this limitation.
	This thesis extends a previously developed probabilistic model, mg-
	MOS, to obtain an improved model, multi-mgMOS. This new model provides
	improved accuracy and is more computationally e±cient than other
	alternatives. It also provides a level of uncertainty associated
	with the measured gene expres- sion level. This probe-level measurement
	error provides useful information to help in the downstream analysis
	of gene expression data.\\\\
	
	 In order to show the advantage of the probe-level probabilistic model,
	the obtained uncertainty is propagated in two downstream analyses
	of gene expression data. One is detecting differential gene expression,
	another is clustering. A Bayesian hierarchical model is proposed
	to include probe-level measurement error into the detection of differential
	gene expression from replicated experiments and a standard model-based
	clustering method is augmented to incorporate probe-level measurement
	error. Due to the inclusion of the probe-level measurement error,
	the downstream probabilistic models become more complicated or intractable.
	In order to perform inference with these augmented models efficiently,
	various inference approximation approaches are compared in this thesis,
	including Maximum a Posteriori, Laplace approximation, a variational
	method and Markov chain Monte Carlo. Results from both benchmark
	data sets and a real-world data set demonstrate that the incorporation
	of the probe-level measurement error improves the performance of
	the downstream probabilistic analysis.},
  file = {liu_xuejun.pdf:http\://www.cs.manchester.ac.uk/ai/theses/2006/liu_xuejun.pdf:PDF},
  group = {puma},
  linksoftware = {http://umber.sbs.man.ac.uk/resources/puma/}
}

@ARTICLE{Liu:clustering07,
  author = {Xuejun Liu and Kevin K. Lin and Bogi Andersen and Magnus Rattray},
  title = {Including probe-level uncertainty in model-based gene expression
	clustering},
  journal = bmcbioinf,
  year = {2007},
  volume = {8},
  number = {98},
  abstract = {{\bf Background}\\\\
	
	 Clustering is an important analysis performed on microarray gene
	expression data since it groups genes which have similar expression
	patterns and enables the exploration of unknown gene functions. Microarray
	experiments are associated with many sources of experimental and
	biological variation and the resulting gene expression data are therefore
	very noisy. Many heuristic and model-based clustering approaches
	have been developed to cluster this noisy data. However, few of them
	include consideration of probe-level measurement error which provides
	rich information about technical variability.\\\\
	
	 {\bf Results}\\\\
	
	 We augment a standard model-based clustering method to incorporate
	probe-level measurement error. Using probe-level measurements from
	a recently developed Affymetrix probe-level model, multi-mgMOS, we
	include the probe-level measurement error directly into the standard
	Gaussian mixture model. Our augmented model is shown to provide improved
	clustering performance on simulated datasets and a real mouse time-course
	dataset.\\\\
	
	 {\bf Conclusion}\\\\
	
	 The performance of model-based clustering of gene expression data
	is improved by including probe-level measurement error and more biologically
	meaningful clustering results are obtained.},
  doi = {10.1186/1471-2105-8-98},
  file = {1471-2105-8-98.pdf:http\://www.biomedcentral.com/content/pdf/1471-2105-8-98.pdf:PDF},
  group = {puma}
}

@ARTICLE{Lloyd:cluster82,
  author = {S. P. Lloyd},
  title = {Least squares quantization in {PCM}},
  journal = {IEEE Transactions on Information Theory},
  year = {1982},
  volume = {28},
  pages = {129--137},
  number = {2}
}

@ARTICLE{Locke:extension05,
  author = {J. C. W. Locke and M. M. Southern and L. Kozma-Bognar and V. Hibberd
	and P. E. Brown P.E. and M. S. Turner and A. J. Millar},
  title = {Extension of a genetic network model by iterative experimentation
	and mathematical analysis},
  journal = {Molecular Systems Biology},
  year = {2005},
  volume = {1},
  number = {13},
  doi = {10.1038/msb4100018},
  group = {systems biology}
}

@ARTICLE{Longstaff:mlp87,
  author = {I. D. Lonstaff and J. F. Cross},
  title = {A Pattern Recognition Approach to Understanding the Multi-layer Perceptron},
  journal = {Pattern Recognition Letters},
  year = {1987},
  volume = {5},
  pages = {315--319},
  publisher = nholland
}

@INPROCEEDINGS{Lorentz:hilbert76,
  author = {G. G. Lorentz},
  title = {On the 13th Problem of {H}ilbert},
  booktitle = {Proceedings of Symposia in Pure Mathematics},
  year = {1976},
  pages = {419--429},
  address = {Providence, RI},
  publisher = {American Mathematical Society}
}

@INCOLLECTION{Lowe:rbfs93,
  author = {David Lowe},
  title = {Radial basis function networks},
  booktitle = {The Handbook of Brain Theory and Neural Networks},
  publisher = mit,
  year = {1995},
  editor = {M. A. Arbib},
  address = {Cambridge, MA}
}

@INPROCEEDINGS{Lowe:invers91,
  author = {David Lowe},
  title = {On the iterative inversion of {RBF} networks: a statistical interpretation},
  booktitle = {Proceedings of the Second Interntational Conference on Artificial
	Neural Networks},
  year = {1991},
  pages = {29--33},
  address = {Bournemouth},
  month = Nov,
  publisher = {IEE}
}

@INPROCEEDINGS{Lowe:spr91,
  author = {David Lowe},
  title = {What have neural networks to offer statistical pattern processing?},
  booktitle = {SPIE Proceedings on Adaptive Signal Processing},
  year = {1991},
  volume = {1565},
  pages = {460--471},
  address = {San Diego},
  month = {July},
  publisher = {SPIE}
}

@INPROCEEDINGS{Lowe:general89,
  author = {David Lowe},
  title = {Adaptive radial basis function non-linearities, and the problem of
	generalisation},
  booktitle = {Proceedings of the First Interntational Conference on Artificial
	Neural Networks},
  year = {1989},
  pages = {171--175},
  address = {London},
  month = Oct,
  publisher = {IEE}
}

@ARTICLE{Lowe:feedforward96,
  author = {David Lowe and Michael E. Tipping},
  title = {Feed-forward neural networks and topographic mappings for exploratory
	data analysis},
  journal = {Neural Computing and Applications},
  year = {1996},
  volume = {4},
  number = {83},
  linkpsgz = {ftp://ftp.research.microsoft.com/users/mtipping/ncaf.ps.gz}
}

@ARTICLE{Lowe:feature91,
  author = {David Lowe and A. R. Webb},
  title = {Optimized Feature Extraction and the {B}ayes Decision in Feed-forward
	Classifier Networks},
  journal = PAMI,
  year = {1991},
  volume = {13},
  pages = {355--364},
  number = {4}
}

@ARTICLE{Lowe:prior90,
  author = {David Lowe and A. R. Webb},
  title = {Exploiting Prior Knowledge in Network Optimization: an Illustration
	from Medical Prognosis},
  journal = NW,
  year = {1990},
  volume = {1},
  pages = {299--323},
  number = {3}
}

@INPROCEEDINGS{Lowe:IEE97_2,
  author = {David Lowe and Krzysztof Zapart},
  title = {Validation of Neural Networks in Automotive Engine Calibration},
  booktitle = {5th IEE International Conference on Artificial Neural Networks},
  year = {1997},
  pages = {221--226},
  publisher = {The Institute of Electrical Engineers}
}

@ARTICLE{Lowe:distinctive04,
  author = {David G. Lowe},
  title = {Distinctive image features from scale-invariant keypoints},
  journal = ijcv,
  year = {2004},
  volume = {60},
  pages = {91--110},
  number = {2},
  abstract = {This paper presents a method for extracting distinctive invariant
	features from images that can be used to perform reliable matching
	between different views of an object or scene. The features are invariant
	to image scale and rotation, and are shown to provide robust matching
	across a a substantial range of affine distortion, change in 3D viewpoint,
	addition of noise, and change in illumination. The features are highly
	distinctive, in the sense that a single feature can be correctly
	matched with high probability against a large database of features
	from many images. This paper also describes an approach to using
	these features for object recognition. The recognition proceeds by
	matching individual features to a database of features from known
	objects using a fast nearest-neighbor algorithm, followed by a Hough
	transform to identify clusters belonging to a single object, and
	finally performing verification through least-squares solution for
	consistent pose parameters. This approach to recognition can robustly
	identify objects among clutter and occlusion while achieving near
	real-time performance.},
  file = {ijcv04.pdf:http\://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf:PDF},
  linksoftware = {http://www.cs.ubc.ca/~lowe/keypoints/}
}

@INPROCEEDINGS{Lowe:object99,
  author = {David G. Lowe},
  title = {Object recognition from local scale-invariant features},
  booktitle = iccv,
  year = {1999},
  pages = {1150--1157},
  address = {Corfu, Greece},
  publisher = ieeecomp,
  abstract = {An object recognition system has been developed that uses a new class
	of local image features. The features are invariant to image scaling,
	translation, and rotation, and partially invariant to illumination
	changes and affine or 3D projection. These features share similar
	properties with neurons in inferior temporal cortex that are used
	for object recognition in primate vision. Features are efficiently
	detected through a staged filtering approach that identifies stable
	points in scale space. Image keys are created that allow for local
	geometric deformations by representing blurred image gradients in
	multiple orientation planes and at multiple scales. The keys are
	used as input to a nearest-neighbor indexing method that identifies
	candidate object matches. Final verification of each match is achieved
	by finding a low-residual least-squares solution for the unknown
	model parameters. Experimental results show that robust object recognition
	can be achieved in cluttered partially-occluded images with a computation
	time of under 2 seconds.},
  file = {iccv99.pdf:http\://www.cs.ubc.ca/~lowe/papers/iccv99.pdf:PDF},
  linksoftware = {http://www.cs.ubc.ca/~lowe/keypoints/}
}

@ARTICLE{Lowitzsch:density05,
  author = {Svenja Lowitzsch},
  title = {A density theorem for matrix-valued radial basis functions},
  journal = {Numerical Algorithms},
  year = {2005},
  volume = {39},
  pages = {253--256},
  number = {1},
  file = {Lowitzsch:density05.pdf:Statistical Learning/Vector-valued/Lowitzsch:density05.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Luo:hybrid97,
  author = {Zhen Luo and Grace Wahba},
  title = {Hybrid Adaptive Splines},
  journal = jasa,
  year = {1997},
  volume = {92},
  pages = {107--116},
  abstract = {An adaptive spline method for smoothing is proposed that combines
	features from both regression spline and smoothing spline approaches.
	One of its advantages is the ability to vary the amount of smoothing
	in response to the inhomogeneous "curvature" of true functions at
	different locations. This method can be applied to many multivariate
	function estimation problems, which is illustrated by an application
	to smoothing temperature data on the globe. The method's performance
	in a simulation study is found to be comparable to the wavelet shrinkage
	methods proposed by Donoho and Johnstone. The problem of how to count
	the degrees of freedom for an adaptively chosen set of basis functions
	is addressed. This issue arises also in the MARS procedure proposed
	by Friedman and other adaptive regression spline procedures.},
  group = {spgp},
  label1 = {Earlier Technical Report},
  label2 = {JASA Abstract},
  link1 = {ftp://ftp.stat.wisc.edu/pub/wahba/has.ps},
  link2 = {http://www.amstat.org/publications/JASA/index.cfm?fuseaction=luomar1997}
}

@ARTICLE{Luo:lms91,
  author = {Z. Q. Luo},
  title = {On the Convergence of the {LMS} Algorithm with Adaptive Learning
	Rate for Linear Feedforward Networks},
  journal = NC,
  year = {1991},
  volume = {3},
  pages = {226--245},
  number = {2}
}

@ARTICLE{Luscombe:genomic04,
  author = {Nicholas M. Luscombe and M. Madan Babu and Haiyuan Yu and Michael
	Snyder and Sarah A. Teichmann and Mark Gerstein},
  title = {Genomic analysis of regulatory network dynamics reveals large topological
	changes},
  journal = {Nature},
  year = {2004},
  volume = {431},
  pages = {308--312},
  group = {yeast}
}

@INPROCEEDINGS{Luttrell:radar95,
  author = {S. P. Luttrell},
  title = {Using self-organizing maps to classify radar range profiles},
  booktitle = {Proceedings IEE Fourth International Conference on Artificial Neural
	Networks},
  year = {1995},
  pages = {335--340},
  address = {London},
  publisher = {IEE}
}

@ARTICLE{Luttrell:partition94,
  author = {S. P. Luttrell},
  title = {Partitioned mixture distribution: an adaptive {B}ayesian network
	for low-level image processing},
  journal = {IEE Proceedings on Vision, Image and Signal Processing},
  year = {1994},
  volume = {141},
  pages = {251--260},
  number = {4}
}

@ARTICLE{Luttrell:som94,
  author = {S. P. Luttrell},
  title = {A {B}ayesian analysis of self-organizing maps},
  journal = NC,
  year = {1994},
  volume = {6},
  pages = {767--794},
  number = {5}
}

@ARTICLE{Luttrell:code91,
  author = {S. P. Luttrell},
  title = {Code vector density in topographic mappings: scalar case},
  journal = IEEE,
  year = {1991},
  volume = {2},
  pages = {427--436},
  number = {4}
}

@ARTICLE{Luttrell:derivation90,
  author = {S. P. Luttrell},
  title = {Derivation of a class of training algorithms},
  journal = IEEE,
  year = {1990},
  volume = {1},
  pages = {229--232},
  number = {2}
}

@TECHREPORT{Macedo:divfree08,
  author = {Ives Mac\^{e}do and Rener Castro},
  title = {Learning Divergence-free and Curl-free Vector Fields with Matrix-valued
	Kernels},
  institution = {Instituto Nacional de Matematica Pura e Aplicada},
  year = {2008}
}

@ARTICLE{Mackay:hierarchical94,
  author = {David J. C. MacKay and Linda C. Bauman Peto},
  title = {A Hierarchical {D}irichlet Language Model},
  journal = nle,
  year = {1994},
  volume = {1},
  pages = {1--19},
  number = {3},
  abstract = {We discuss a hierarchical probabilistic model whose predictions are
	similar to those of the popular language modelling procedure known
	as `smoothing'. A number of interesting differences from smoothing
	emerge. The insights gained from a probabilistic view of this problem
	point towards new directions for language modelling. The ideas of
	this paper are also applicable to other problems such as the modelling
	of triphomes in speech, and DNA and protein sequences in molecular
	biology.\\\\
	
	 The new algorithm is compared with smoothing on a two million word
	corpus. The methods prove to be about equally accurate, with the
	hierarchical model using fewer computational resources. },
  file = {lang4.pdf:http\://www.inference.phy.cam.ac.uk/mackay/lang4.pdf:PDF},
  group = {hierarchical Dirichlet, language model}
}

@ARTICLE{MacKay:probmds89,
  author = {David B. {MacKay}},
  title = {Probabilistic Multidimensional Scaling: An Anisotropic Model for
	Distance Judgements},
  journal = {Journal of Mathematical Psychology},
  year = {1989},
  pages = {187--205}
}

@ARTICLE{MacKay:proximity86,
  author = {David B. {MacKay} and J. L. Zinnes},
  title = {A Probabilistic Model for the Multidimensional Scaling of Proximity
	and Preference Data},
  journal = {Marketing Sciences},
  year = {1986},
  volume = {5},
  pages = {325--334}
}

@INCOLLECTION{MacKay:springer94,
  author = {D. J. C. {MacKay}},
  title = {{B}ayesian Methods for Backpropagation Networks},
  booktitle = {Models of Neural Networks III},
  publisher = springer,
  year = {1994},
  editor = {E. Domany and J. L. {van Hemmen} and K. Schulten},
  chapter = {6},
  address = {New York}
}

@INPROCEEDINGS{MacKay:gibbs95,
  author = {David J. C. {MacKay}},
  title = {Probabilistic networks: new models and new methods},
  booktitle = {Proceedings ICANN'95 International Conference on Artificial Neural
	Networks},
  year = {1995},
  editor = {F. Fogelman-Souli\'{e} and P. Gallinari},
  pages = {331--337},
  address = {Paris},
  publisher = {EC2 \& Cie}
}

@INPROCEEDINGS{MacKay:energy94,
  author = {David J. C. {MacKay}},
  title = {{B}ayesian non-linear modelling for the 1993 energy prediction competition},
  booktitle = {Maximum Entropy and {B}ayesian Methods, {S}anta {B}arbara 1993},
  year = {1995},
  editor = {G. Heidbreder},
  address = {Dordrecht},
  publisher = {Kluwer}
}

@INPROCEEDINGS{MacKay:ev94,
  author = {David J. C. {MacKay}},
  title = {Hyperparameters: optimise or integrate out?},
  booktitle = {Maximum Entropy and {B}ayesian Methods, {S}anta {B}arbara 1993},
  year = {1994},
  editor = {G. Heidbreder},
  address = {Dordrecht, The Netherlands},
  publisher = {Kluwer}
}

@ARTICLE{MacKay:alpha_nc94,
  author = {David J. C. {MacKay}},
  title = {Comparison of Approximate Methods for Handling Hyperparameters},
  journal = NC,
  year = {1999},
  volume = {11},
  pages = {1035--1068},
  number = {5},
  month = Jul,
  linkpsgz = {http://wol.ra.phy.cam.ac.uk/mackay/alpha.ps.gz}
}

@UNPUBLISHED{MacKay:enshmm97,
  author = {David J. C. {MacKay}},
  title = {Ensemble Learning for Hidden {M}arkov models.},
  note = {Unpublished manuscript, available from \url{ http://wol.ra.phy.cam.ac.uk/mackay/homepage.html}},
  year = {1997},
  institution = {Cavendish Laboratory, Cambridge, U.K.}
}

@UNPUBLISHED{MacKay:ica96,
  author = {David J. C. {MacKay}},
  title = {Maximum likelihood and covariant algorithms for independent component
	analysis},
  note = {Unpublished manuscript, available from \url{ http://wol.ra.phy.cam.ac.uk/mackay/homepage.html}},
  year = {1996},
  institution = {Cavendish Laboratory, Cambridge, U.K.}
}

@INPROCEEDINGS{MacKay:ensemble95,
  author = {David J. C. {MacKay}},
  title = {Developments in Probabilistic Modelling with Neural Networks---Ensemble
	Learning},
  booktitle = {Neural Networks: Artificial Intelligence and Industrial Applications.
	Proceedings of the 3rd Annual Symposium on Neural Networks, Nijmegen,
	Netherlands, 14-15 September 1995},
  year = {1995},
  pages = {191--198},
  address = {Berlin},
  publisher = {Springer},
  annote = {MRAO 1926},
  editors = {Hilbert J. Kappen and S. Gielen}
}

@ARTICLE{MacKay:review95,
  author = {David J. C. {MacKay}},
  title = {Probable Networks and Plausible Predictions -- A Review of Practical
	{B}ayesian Methods for Supervised Neural Networks},
  journal = network,
  year = {1995},
  volume = {6},
  pages = {469--505},
  number = {3}
}

@ARTICLE{MacKay:wondsa95,
  author = {David J. C. {MacKay}},
  title = {{B}ayesian neural networks and density networks},
  journal = {Nuclear Instruments and Methods in Physics Research, A},
  year = {1995},
  volume = {354},
  pages = {73--80},
  number = {1},
  abstract = {This paper reviews the Bayesian approach to learning in neural networks,
	then introduces a new adaptive model, the density network. This is
	a neural network for which target outputs are provided, but the inputs
	are unspecified. When a probability distribution is placed on the
	unknown inputs, a latent variable model is defined that is capable
	of discovering the underlying dimensionality of a data set. A Bayesian
	learning algorithm for these networks is derived and demonstrated.},
  doi = {10.1016/0168-9002(94)00931-7},
  linkpsgz = {ftp://wol.ra.phy.cam.ac.uk/pub/mackay/ch_learning.ps.gz}
}

@ARTICLE{MacKay:backprop92,
  author = {David J. C. {MacKay}},
  title = {A Practical {B}ayesian Framework for Back-propagation Networks},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {448--472},
  number = {3}
}

@ARTICLE{MacKay:class92,
  author = {David J. C. {MacKay}},
  title = {The Evidence Framework Applied to Classification Networks},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {720--736},
  number = {5}
}

@ARTICLE{MacKay:interp92,
  author = {David J. C. {MacKay}},
  title = {{B}ayesian Interpolation},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {415--447},
  number = {3}
}

@ARTICLE{MacKay:select92,
  author = {David J. C. {MacKay}},
  title = {Information-based Objective Functions for Active Data Selection},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {589--603},
  number = {4}
}

@PHDTHESIS{MacKay:thesis91,
  author = {David J. C. {MacKay}},
  title = {{B}ayesian Methods for Adaptive Models},
  school = {California Institute of Technology},
  year = {1991}
}

@ARTICLE{Mackie2011,
  author = {S. L. Mackie and J. C. Taylor and S. G. Martin and Y. E. A. R. Consortium
	and U. K. R. A. G. Consortium and P. Wordsworth and S. Steer and
	A. G. Wilson and J. Worthington and P. Emery and J. H. Barrett and
	A. W. Morgan},
  title = {A spectrum of susceptibility to rheumatoid arthritis within HLA-DRB1:
	stratification by autoantibody status in a large UK population.},
  journal = {Genes Immun},
  year = {2011},
  month = {Sep},
  abstract = {Previously-proposed rheumatoid arthritis (RA) HLA-DRB1 susceptibility
	and protective models were compared, based on amino acids at positions
	67-74 and autoantibody combinations. 3 657 RA patients and 1 357
	controls were studied using logistic regression, with secondary stratification
	by anti-citrullinated peptide antibodies(ACPA) and rheumatoid factor(RF).
	Susceptibility models were based on previously defined HLA-DRB1 shared
	epitope(SE) subgroups. (70)DERAA(74), D(70) and I(67) protective
	models were compared, adjusting for HLA-DRB1 SE. A hierarchy of risk
	was observed within the HLA-DRB1 SE, particularly for ACPA-positive
	and RF-positive RA: HLA-DRB1(*)0401∼(*)0404>(*)0101∼(*)1001 ((*)0404>(*)0101:
	P=0.0003). HLA-DRB1(*)0401/(*)0404 compound heterozygosity conferred
	a risk similar to (*)0401 homozygosity (P=0.70). Protective effects
	of D(70) and I(67) were similar. Predictions of the D(70) model fitted
	the data better than those of the I(67) model. The protective effect
	of D(70) showed a gene-dose effect (OR 0.82, 95\% CI 0.73-0.92, P=5.8
	× 10(-4)), but was only seen in RA patients positive for RF or ACPA.
	HLA-DRB1 SE alleles were also associated with ACPA-negative, RF-positive
	RA (OR 1.42 (1.15-1.76), P=0.0012). In conclusion, HLA-DRB1 SE alleles
	show heterogeneity in RA susceptibility; their major effect appears
	to be mediated by ACPA positivity, but a significant association
	of HLA-DRB1 SE with RF-positive, ACPA-negative RA was also observed.
	D(70) specifically protected against antibody-positive RA.Genes and
	Immunity advance online publication, 1 September 2011; doi:10.1038/gene.2011.60.},
  doi = {10.1038/gene.2011.60},
  institution = {NIHR-Leeds Musculoskeletal Biomedical Research Unit, Leeds Institute
	of Molecular Medicine, University of Leeds, Leeds, UK.},
  language = {eng},
  medline-pst = {aheadofprint},
  owner = {neil},
  pii = {gene201160},
  pmid = {21881596},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1038/gene.2011.60}
}

@INPROCEEDINGS{MacQueen:cluster67,
  author = {J. {MacQueen}},
  title = {Some methods for classification and analysis of multivariate observations},
  booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics
	and Probability},
  year = {1967},
  editor = {L. M. {LeCam} and J. Neyman},
  volume = {I},
  pages = {281--297},
  address = {Berkeley},
  publisher = {University of California Press}
}

@ARTICLE{Majumdar:convolved07,
  author = {Anandamayee Majumdar and Alan E. Gelfand},
  title = {Multivariate spatial modeling for geostatistical data using convolved
	covariance functions},
  journal = {Mathematical Geology},
  year = {2007},
  volume = {39},
  pages = {225-244},
  number = {2}
}

@INPROCEEDINGS{Makram:bp89,
  author = {S. Makram-Ebeid and J. A. Sirat and J. R. Viala},
  title = {A rationalized backpropagation learning algorithm},
  booktitle = ijcnn,
  year = {1989},
  volume = {2},
  pages = {373--380},
  address = {New Jersey},
  publisher = {IEEE}
}

@ARTICLE{Malioutov:walksum06,
  author = {Dmitry M. Malioutov and Jason K. Johnson and Alan S. Willsky},
  title = {Walk-Sums and Belief Propagation in {G}aussian Graphical Models},
  journal = jmlr,
  year = {2006},
  pages = {2031--2064},
  abstract = {We present a new framework based on walks in a graph for analysis
	and inference in Gaussian graphical models. The key idea is to decompose
	the correlation between each pair of variables as a sum over all
	walks between those variables in the graph. The weight of each walk
	is given by a product of edgewise partial correlation coefficients.
	This representation holds for a large class of Gaussian graphical
	models which we call walk-summable. We give a precise characterization
	of this class of models, and relate it to other classes including
	diagonally dominant, attractive, non-frustrated, and pairwise-normalizable.
	We provide a walk-sum interpretation of Gaussian belief propagation
	in trees and of the approximate method of loopy belief propagation
	in graphs with cycles. The walk-sum perspective leads to a better
	understanding of Gaussian belief propagation and to stronger results
	for its convergence in loopy graphs.},
  linkpdf = {http://www.jmlr.org/papers/volume7/malioutov06a/malioutov06a.pdf},
  optvolume = {7}
}

@ARTICLE{Mallows:cp73,
  author = {C. L. Mallows},
  title = {Some comments on {$C_p$}},
  journal = {Technometrics},
  year = {1973},
  volume = {15},
  pages = {661--675}
}

@ARTICLE{Maltson:65,
  author = {R L Maltson and J E Dammann},
  title = {A technique for determining and coding subclasses in pattern recognition
	problems},
  journal = {IBM Journal},
  year = {1965},
  volume = {9},
  pages = {294--302}
}

@ARTICLE{Mangan:ffl03,
  author = {Shmoolik Mangan and Uri Alon},
  title = {Structure and function of the feed-forward loop network motif},
  journal = pnasusa,
  year = {2003},
  volume = {100},
  pages = {11980--11985},
  abstract = {Engineered systems are often built of recurring circuit modules that
	carry out key functions. Transcription networks that regulate the
	responses of living cells were recently found to obey similar principles:
	they contain several biochemical wiring patterns, termed network
	motifs, which recur throughout the network. One of these motifs is
	the feed-forward loop (FFL). The FFL, a three-gene pattern, is composed
	of two input transcription factors, one of which regulates the other,
	both jointly regulating a target gene. The FFL has eight possible
	structural types, because each of the three interactions in the FFL
	can be activating or repressing. Here, we theoretically analyze the
	functions of these eight structural types. We find that four of the
	FFL types, termed incoherent FFLs, act as sign-sensitive accelerators:
	they speed up the response time of the target gene expression following
	stimulus steps in one direction (e.g., off to on) but not in the
	other direction (on to off). The other four types, coherent FFLs,
	act as sign-sensitive delays. We find that some FFL types appear
	in transcription network databases much more frequently than others.
	In some cases, the rare FFL types have reduced functionality (responding
	to only one of their two input stimuli), which may partially explain
	why they are selected against. Additional features, such as pulse
	generation and cooperativity, are discussed. This study defines the
	function of one of the most significant recurring circuit elements
	in transcription networks.},
  group = {gene networks, network motifs},
  pmid = {14530388}
}

@ARTICLE{Marchand:conv90,
  author = {M. Marchand and M. Golea and P. Rujan},
  title = {A Convergence Theorem for Sequential Learning in Two-layer Perceptrons},
  journal = {Europhysics Letters},
  year = {1990},
  volume = {11},
  pages = {487--492},
  number = {6}
}

@ARTICLE{Marinou2007,
  author = {I. Marinou and J. Healy and D. Mewar and D. J. Moore and M. C. Dickson
	and M. H. Binks and D. S. Montgomery and K. Walters and A. G. Wilson},
  title = {Association of interleukin-6 and interleukin-10 genotypes with radiographic
	damage in rheumatoid arthritis is dependent on autoantibody status.},
  journal = {Arthritis Rheum},
  year = {2007},
  volume = {56},
  pages = {2549--2556},
  number = {8},
  month = {Aug},
  abstract = {Recent evidence has highlighted a major genetic contribution to radiographic
	damage in rheumatoid arthritis (RA). The objective of this study
	was to determine whether genetic variants in the loci for interleukin-1
	(IL-1), IL-6, IL-10, protein tyrosine phosphatase N22 (PTPN22), and
	selenoprotein S are associated with radiographic damage.Modified
	Larsen scores of radiographic damage were determined in a cross-sectional
	population of patients with RA (n = 964). Rheumatoid factor (RF)
	and anti-cyclic citrullinated peptide (anti-CCP) were also assayed.
	The Kruskal-Wallis nonparametric test was used to compare median
	radiographic damage scores across genotype groups, followed by the
	Cuzick nonparametric test for trend to assess gene-dose effects.An
	allele-dose association of IL-6 -174G with increasing radiographic
	damage was present (P = 0.005), but only in patients who were RF
	positive (P = 0.004) or anti-CCP positive (P = 0.01). Patients with
	the IL-10 -592CC genotype had more extensive radiographic damage
	than did those with the AC or AA genotype (P = 0.006), but this was
	observed only among patients who were RF negative (P = 0.002) or
	anti-CCP negative (P = 0.002). However, RF status and anti-CCP status
	were not associated with the IL-6 or IL-10 genotype. No other genetic
	associations were detected, apart from a marginal association of
	PTPN22 +1858T with increased radiographic damage.The reported associations
	of IL-6 -174G with high IL-6 production and IL-10 -592 with low IL-10
	production and our own results support a role of genetically determined
	dysregulated cytokine production in disease severity. The lack of
	association of these genotypes with RF and anti-CCP antibody status
	suggests that they act downstream of autoantibody production. We
	conclude that IL-6 and IL-10 genotypes may be useful in predicting
	disease severity in autoantibody-positive and autoantibody-negative
	patients, respectively.},
  doi = {10.1002/art.22814},
  institution = {School of Medicine and Biomedical Sciences, University of Sheffield,
	Royal Hallamshire Hospital, Sheffield, UK.},
  keywords = {Arthritis, Rheumatoid, blood/genetics/radiography; Autoantibodies,
	blood; Cohort Studies; Cross-Sectional Studies; Female; Genetic Predisposition
	to Disease; Genotype; Humans; Interleukin-10, genetics/metabolism;
	Interleukin-6, genetics/metabolism; Male; Middle Aged; Peptides,
	Cyclic, immunology; Polymorphism, Single Nucleotide; Rheumatoid Factor,
	blood},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {17665434},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1002/art.22814}
}

@ARTICLE{Marinou2010a,
  author = {I. Marinou and K. Walters and J. Winfield and D. E. Bax and A. G.
	Wilson},
  title = {A gain of function polymorphism in the interleukin 6 receptor influences
	RA susceptibility.},
  journal = {Ann Rheum Dis},
  year = {2010},
  volume = {69},
  pages = {1191--1194},
  number = {6},
  month = {Jun},
  abstract = {To investigate the possible role of a functional polymorphism in the
	soluble interleukin 6 receptor (sIL-6R) gene in the genetic background
	of rheumatoid arthritis (RA).An association between disease status
	and the sIL-6R rs8192284 (A358D) variant was tested in 965 patients
	with RA and 988 unrelated healthy controls. Odds ratios (ORs) for
	disease were calculated with asymptotic 95\% CI; p values <0.05 were
	considered statistically significant after adjustment for multiple
	testing. To determine the relationship between protein levels and
	IL-6R A358D genotype, the protein levels of sIL-6R in 100 plasma
	samples from healthy controls were measured using an ELISA and compared
	across the genotype groups.The allele frequency of the C allele (alanine)
	was lower in cases than in controls (38.4\% vs 41.7\%, p=0.04, OR
	0.9, 95\% CI 0.8 to 1.0), as were the CC/AC genotypes compared with
	AA genotype frequencies (61.0\% in RA cases vs 67.5\% in controls,
	p=0.004, OR 0.8, 95\% CI 0.6 to 0.9). Plasma levels of sIL-6R differed
	significantly according to genotype in the controls: 17.00 + or -
	2.03 ng/ml for A/A, 20.08 + or - 1.83 ng/ml for A/C and 21.57 + or
	- 2.10 ng/ml for C/C (p=0.0001).These data suggest a role for genetically
	determined lower sIL-6R levels as a risk factor for RA. The proinflammatory
	role of the IL6 system in established RA has been highlighted by
	the use of anti-sIL-6R antibodies. However, the findings of this
	study suggest a protective effect of IL6 on the risk of developing
	RA.},
  doi = {10.1136/ard.2008.100644},
  institution = {Section of Musculoskeletal Sciences, School of Medicine and Biomedical
	Sciences, The University of Sheffield, Royal Hallamshire Hospital,
	Sheffield S10 2JF, UK.},
  keywords = {Arthritis, Rheumatoid, blood/genetics; Case-Control Studies; Gene
	Frequency; Genetic Predisposition to Disease; Genotype; Humans; Polymorphism,
	Single Nucleotide; Receptors, Interleukin-6, blood/genetics},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ard.2008.100644},
  pmid = {19713205},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1136/ard.2008.100644}
}

@ARTICLE{Marquardt:63,
  author = {D. W. Marquardt},
  title = {An Algorithm for Least-squares Estimation of Nonlinear Parameters},
  journal = {Journal of the Society of Industrial and Applied Mathematics},
  year = {1963},
  volume = {11},
  pages = {431--441},
  number = {2}
}

@ARTICLE{Martinis2005,
  author = {Massimo De Martinis and Claudio Franceschi and Daniela Monti and
	Lia Ginaldi},
  title = {Inflamm-ageing and lifelong antigenic load as major determinants
	of ageing rate and longevity.},
  journal = {FEBS Lett},
  year = {2005},
  volume = {579},
  pages = {2035--2039},
  number = {10},
  month = {Apr},
  abstract = {Immunosenescence is the consequence of the continuous attrition caused
	by chronic antigenic stress. The most important characteristics of
	immunosenescence (accumulation of memory and effector T cells, reduction
	of naive T cells, shrinkage of T cell repertoire, reduction of the
	immunological space) are compatible with this assumption. Immunosenescence
	can be taken as proof that the beneficial effects of the immune system,
	devoted to the neutralization of harmful agents early in life, become
	detrimental late in life, in a period not foreseen by evolution.
	This perspective could explain the mechanisms of the ageing process
	as well as the pathogenesis of age-related diseases.},
  doi = {10.1016/j.febslet.2005.02.055},
  institution = {Department of Internal Medicine, University of L'Aquila, Via S. Sisto,
	22/E, 67100 L'Aquila, Italy.},
  keywords = {Aging, physiology; Antigens, immunology; Humans; Inflammation, physiopathology;
	Longevity; Oxidative Stress; T-Lymphocytes, immunology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {S0014-5793(05)00293-0},
  pmid = {15811314},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1016/j.febslet.2005.02.055}
}

@UNPUBLISHED{Mason:generalization99,
  author = {Llew Mason and Peter Bartlett and Mostefa Golea},
  title = {Generalization error of combined classifiers},
  note = {to appear in \emph{Journal of Computer and System Sciences}},
  year = {1999}
}

@ARTICLE{Matheron:variogram73,
  author = {Georges Matheron},
  title = {The Intrinsic Random Functions and Their Applications},
  journal = {Advances in Applied Probability},
  year = {1973},
  volume = {5},
  pages = {439-468},
  number = {3}
}

@ARTICLE{Maurer:aurich99,
  author = {F. Maurer and M. Tierney and R. L. Medcalf },
  title = {An {AU}-rich sequence in the {3'-UTR} of plasminogen activator inhibitor
	type 2 ({PAI-2}) {mRNA} promotes {PAI-2} {mRNA} decay and provides
	a bining site for nuclear {HuR}},
  journal = nar,
  year = {1999},
  volume = {27},
  pages = {1664--1673},
  number = {7},
  month = {Apr},
  abstract = {The plasminogen activator inhibitor type 2 (PAI-2) gene is regulated
	by transcriptional and post-transcriptional processes. We have previously
	shown that insertion of the 3'-untranslated region (3'-UTR) of PAI-2
	mRNA into the 3'-UTR of a beta-globin reporter mRNA reduces constitutive
	beta-globin mRNA expression and that this requires, at least in part,
	an AU-rich motif. Here we have directly assessed the role of this
	motif in PAI-2 mRNA stability using both chimeric and non- chimeric
	reporter systems. We first show that the full-length PAI-2 mRNA is
	indeed unstable with a half-life of 1 h. Using the c-fos promoter-driven
	human growth hormone (HGH) mRNA as a reporter, we demonstrate that
	the 580 nt 3'-UTR of PAI-2 accelerates chimeric HGH mRNA decay in
	a process which is dependent on the intact AU-rich sequence. Furthermore,
	disruption of this motif within a constitutively expressed PAI-2
	cDNA produces a 2.5- and 2. 7-fold increase in PAI-2 mRNA and protein
	levels in HT-1080 cells, respectively. RNA electrophoretic mobility
	shift and supershift assays indicate that this motif provides a specific
	binding site for cellular proteins that include nuclear HuR. Taken
	together, these data show that a correlation exists between the binding
	of HuR to the AU-rich motif in vitro and the destabilizing properties
	conferred by this sequence in vivo. },
  file = {1664:http\://nar.oxfordjournals.org/cgi/reprint/27/7/1664:PDF},
  group = {AU-rich, nuclear hormone},
  pmid = {10075998}
}

@ARTICLE{Maxwell2008,
  author = {James R Maxwell and Catherine Potter and Kimme L Hyrich and Biologics
	in Rheumatoid Arthritis Genetics and Genomics Study Syndicate and
	Anne Barton and Jane Worthington and John D Isaacs and Ann W Morgan
	and Anthony G Wilson},
  title = {Association of the tumour necrosis factor-308 variant with differential
	response to anti-TNF agents in the treatment of rheumatoid arthritis.},
  journal = {Hum Mol Genet},
  year = {2008},
  volume = {17},
  pages = {3532--3538},
  number = {22},
  month = {Nov},
  abstract = {Anti-tumour necrosis factor (TNF) agents have revolutionized the treatment
	of patients with rheumatoid arthritis (RA). These therapies are,
	however, expensive and 30\% of patients fail to respond. In a large
	cohort of Caucasian RA patients treated with anti-TNF medications
	(total n = 1050, etanercept n = 455, infliximab n = 450), we investigated
	whether genotypes of eight single nucleotide polymorphisms in the
	region containing the TNF gene were associated with response to anti-TNF
	therapy. Linear regression analyses adjusted for baseline 28 joint
	disease activity score (DAS28), baseline health assessment questionnaire
	score, gender and concurrent disease modifying anti-rheumatic drug
	treatment were used to assess association of these polymorphisms
	with treatment response, defined by change in DAS28 after 6 months.
	Analyses were performed in the entire cohort, and also stratified
	by anti-TNF agent. Association between DAS28 response and TNF-308
	(rs1800629) genotype (P = 0.001) was detected across the whole cohort.
	After stratification by anti-TNF agent, the rare TNF-308AA genotype
	was associated with a significantly poorer response compared with
	TNF-308GG in etanercept (P = 0.001, n = 7) but not infliximab (P
	= 0.8, n = 17) treated patients. Conversely, the GA genotype at TNF-238
	(rs361525) was associated with a poorer response to infliximab (P
	= 0.028, n = 40), but not etanercept (P = 0.6, n = 33). Owing to
	the small numbers of patients in some of the genotype groups examined,
	our data must be regarded as preliminary and will require replication
	in further large cohorts of anti-TNF-treated patients. If confirmed,
	our findings suggest the potential for genotype at these markers
	to aid selection of anti-TNF agent in patients with RA.},
  doi = {10.1093/hmg/ddn245},
  institution = {Academic Rheumatology Group, University of Sheffield, D Floor Medical
	School, Sheffield, UK. j.maxwell@sheffield.ac.uk},
  keywords = {Analysis of Variance; Antibodies, Monoclonal, therapeutic use; Antirheumatic
	Agents, therapeutic use; Arthritis, Rheumatoid, drug therapy; Cohort
	Studies; England; Female; Haplotypes; Humans; Immunoglobulin G, therapeutic
	use; Linear Models; Male; Middle Aged; Polymorphism, Single Nucleotide;
	Questionnaires; Receptors, Tumor Necrosis Factor, therapeutic use;
	Tumor Necrosis Factor-alpha, genetics/metabolism},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ddn245},
  pmid = {18713756},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1093/hmg/ddn245}
}

@ARTICLE{Mayraz:recognizing02,
  author = {Guy Mayraz and Geoffrey HInton},
  title = {Recognizing Handwritten Digits using Hierarchical Products of Experts},
  journal = PAMI,
  year = {2002},
  volume = {24},
  pages = {189--197},
  number = {2},
  abstract = {The product of experts learning procedure \cite{Hinton:poe00} can
	discover a set of stochastic binary features that constitute a nonlinear
	generative model of handwritten images of digits. The quality of
	generative models learned in this way can be assessed by learning
	a separate model for each class of digit and then comparing the unnormalized
	probabilities of test images under the 10 different class specific
	models. To improve discriminative performance, a hierarchy of separate
	models can be learned for each digit class. Each model in the hierarchy
	learns a layer of binary feature detectors that model the probability
	distribution of vectors of activity of feature detectors in the layer
	below. The models in the hierarchy are trained sequentially and each
	model uses a layer of binary feature detectors to learn a generative
	model of the patterns of feature activities in the preceding layer.
	After training, each layer of feature dectectors produces a separate,
	unnormalized log probabilty score. With three layers of feature detectors
	for each of the 10 digit classes, a test image produces 30 scores
	which can be used as inputs to a supervised, logistic classification
	network that is trained on separate data. On the MNIST database,
	our system is comparable with current state-of-the-art discriminative
	methods, demonstrating that the product of experts learning procedure
	can produce effective hierarchies of generative models of high-dimensional
	data.},
  doi = {10.1109/34.982899},
  file = {guypami.pdf:http\://www.cs.toronto.edu/~hinton/absps/guypami.pdf:PDF},
  group = {neural networks, products of experts, handwriting recognition, shap
	recognition, Boltzmann machines, model-based recognition, generative
	models}
}

@ARTICLE{McCulloch:neuron43,
  author = {Warren S. McCulloch and Walter Pitts},
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  journal = {Bulletin of Mathematical Biophysics},
  year = {1943},
  volume = {5},
  pages = {115--133},
  note = {Reprinted in \cite{Anderson:collect88}}
}

@ARTICLE{McDermott:rule82,
  author = {John McDermott},
  title = {R1: A Rule Based Configurer of Computer Systems},
  journal = {Artificial Intelligence},
  year = {1982},
  volume = {19},
  pages = {39--88}
}

@ARTICLE{McDonald:general62,
  author = {Roderick P. McDonald},
  title = {A general approach to nonlinear factor analysis},
  journal = {Psychometrika},
  year = {1962},
  volume = {27},
  pages = {397--415}
}

@ARTICLE{McFarland:calibration08,
  author = {John McFarland and Sankaran Mahadevan and Vicente Romero and Laura
	Swiler},
  title = {Calibration and {U}ncertainty {A}nalysis for {C}omputer {S}imulations
	with {M}ultivariate {O}utput},
  journal = {AIAA Journal},
  year = {2008},
  volume = {46},
  pages = {1253-1265},
  number = {5}
}

@ARTICLE{McLachlan:estimating77,
  author = {Geoffrey John {McLachlan}},
  title = {Estimating the Linear Discriminant Function from Initial Samples
	Containing a Small Number of Unclassified Observations},
  journal = jasa,
  year = {1977},
  volume = {72},
  pages = {403--406},
  number = {358},
  abstract = {Estimation of the linear discriminant function $L$ is considered in
	the case where there are $n_1$ and $n_2$ observations from the populaitons
	$\Pi_1$ and $\Pi_2$ and $M$ unclassified observations. Estimates
	of $L$ using all $n_1 + n_2 + M$ observations are proposed and evaluated
	in terms of the expected error rate under the assumption that $M$
	is small relative to $n_1 + n_2$. By appropriately weighting the
	sample means of the unclassified observations, an estimate of $L$
	is given which dominates the usual estimate based on just the $n_1
	+ n_2$ classified observations},
  group = {semi-supervised learning}
}

@ARTICLE{Medalia:architecture02,
  author = {Ohad Medalia and Igor Weber and Achilleas S. Frangakis and Daniela
	Nicastro and G\"unther Gerisch and Wolfgang Baumeister},
  title = {Macromolecular Architecture in Eukaryotic Cells Visualized by Cryoelectron
	Tomography},
  journal = {Science},
  year = {2002},
  volume = {298},
  number = {5596},
  abstract = {Electron tomography of vitrified cells is a noninvasive three-dimensional
	imaging technique that opens up new vistas for exploring the supramolecular
	organization of the cytoplasm. We applied this technique to Dictyostelium
	cells, focusing on the actin cytoskeleton. In actin networks reconstructed
	without prior removal of membranes or extraction of soluble proteins,
	the cross-linking of individual microfilaments, their branching angles,
	and membrane attachment sites can be analyzed. At a resolution of
	5 to 6 nanometers, single macromolecules with distinct shapes, such
	as the 26S proteasome, can be identified in an unperturbed cellular
	environment.},
  doi = {10.1126/science.1076184},
  group = {cell structure},
  optpmid = {12424373}
}

@ARTICLE{Metropolis:mc53,
  author = {N. Metropolis and A. W. Rosenbluth and M. N. Rosenbluth and A. H.
	Teller and E. Teller},
  title = {Equation of State Calculations by Fast Computing Machines},
  journal = {Journal of Chemical Physics},
  year = {1953},
  volume = {21},
  pages = {1087--1092},
  number = {6}
}

@ARTICLE{Mewar2008,
  author = {D. Mewar and I. Marinou and A. L. Coote and D. J. Moore and M. Akil
	and D. Smillie and M. C. Dickson and M. H. Binks and D. S. Montgomery
	and A. G. Wilson},
  title = {Association between radiographic severity of rheumatoid arthritis
	and shared epitope alleles: differing mechanisms of susceptibility
	and protection.},
  journal = {Ann Rheum Dis},
  year = {2008},
  volume = {67},
  pages = {980--983},
  number = {7},
  month = {Jul},
  abstract = {To investigate the association of a recently described classification
	of Human leukocyte antigen (HLA)-DRB1 shared epitope alleles with
	rheumatoid factors (RF) and anti-cyclic citrullinated peptide (CCP)
	production and radiological severity in rheumatoid arthritis (RA).Patients
	with RA (n = 962) were studied. Genotyping of DRB1 alleles and assays
	for RF and anti-CCP were performed. Radiological severity was measured
	using the modified Larsen score.In accordance with previous reports,
	we found carriage of S2 alleles (K-R-A-A at positions 71-74) to be
	associated with more severe disease with a gene-dose effect (p =
	0.0059), and also associated with the presence of anti-CCP and RF
	(p<0.001). Carriage of S1 alleles (D-E-R-A-A at positions 70-74)
	was associated with less severe disease (p = 0.01), however there
	was no association between S1 and either anti-CCP or RF, suggesting
	that the basis for this possible protective effect was not related
	to autoantibody-producing B cells.These data suggest that multiple
	biological mechanisms underlie the DRB1 association with rheumatoid
	arthritis severity.},
  doi = {10.1136/ard.2007.075382},
  institution = {School of Medicine and Biomedical Sciences, University of Sheffield,
	Beech Hill Road, Sheffield, UK.},
  keywords = {Alleles; Arthritis, Rheumatoid, genetics/immunology/radiography; Autoantibodies,
	blood; Epitopes, genetics; Female; Genetic Predisposition to Disease;
	Genotype; HLA-DR Antigens, genetics; Humans; Male; Peptides, Cyclic,
	immunology; Rheumatoid Factor, blood; Severity of Illness Index},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ard.2007.075382},
  pmid = {17901090},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1136/ard.2007.075382}
}

@ARTICLE{Mezard:tiling89,
  author = {M. Mezard and J. P. Nadal},
  title = {Learning in Feedforward Layered Networks: The Tiling Algorithm},
  journal = {Journal of Physics, A},
  year = {1989},
  volume = {22},
  pages = {2191--2203}
}

@ARTICLE{Michelli:matrix86,
  author = {C. A. Micchelli},
  title = {Interpolation of scattered data: distance matrices and conditionally
	positive definite functions},
  journal = {Constructive Approximations},
  year = {1986},
  volume = {2},
  pages = {11--22}
}

@ARTICLE{Micchelli:vector05,
  author = {Charles A. Micchelli and Massimiliano Pontil},
  title = {On learning vector--valued functions},
  journal = {Neural Computation},
  year = {2005},
  volume = {17},
  pages = {177-204}
}

@INPROCEEDINGS{Micchelli:kernels04,
  author = {Charles A. Micchelli and Massimiliano Pontil},
  title = {Kernels for Multi-task Learning},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year = {2004},
  publisher = {MIT Press}
}

@ARTICLE{Milo2009,
  author = {Marta Milo and Daniela Cacciabue-Rivolta and Adam Kneebone and Hikke
	Van Doorninck and Claire Johnson and Grace Lawoko-Kerali and Mahesan
	Niranjan and Marcelo Rivolta and Matthew Holley},
  title = {Genomic analysis of the function of the transcription factor {G}ata3
	during development of the mammalian inner ear},
  journal = {PLoS One},
  year = {2009},
  volume = {4},
  pages = {e7144},
  number = {9},
  abstract = {We have studied the function of the zinc finger transcription factor
	gata3 in auditory system development by analysing temporal profiles
	of gene expression during differentiation of conditionally immortal
	cell lines derived to model specific auditory cell types and developmental
	stages. We tested and applied a novel probabilistic method called
	the gamma Model for Oligonucleotide Signals to analyse hybridization
	signals from Affymetrix oligonucleotide arrays. Expression levels
	estimated by this method correlated closely (p<0.0001) across a 10-fold
	range with those measured by quantitative RT-PCR for a sample of
	61 different genes. In an unbiased list of 26 genes whose temporal
	profiles clustered most closely with that of gata3 in all cell lines,
	10 were linked to Insulin-like Growth Factor signalling, including
	the serine/threonine kinase Akt/PKB. Knock-down of gata3 in vitro
	was associated with a decrease in expression of genes linked to IGF-signalling,
	including IGF1, IGF2 and several IGF-binding proteins. It also led
	to a small decrease in protein levels of the serine-threonine kinase
	Akt2/PKBbeta, a dramatic increase in Akt1/PKBalpha protein and relocation
	of Akt1/PKBalpha from the nucleus to the cytoplasm. The cyclin-dependent
	kinase inhibitor p27(kip1), a known target of PKB/Akt, simultaneously
	decreased. In heterozygous gata3 null mice the expression of gata3
	correlated with high levels of activated Akt/PKB. This functional
	relationship could explain the diverse function of gata3 during development,
	the hearing loss associated with gata3 heterozygous null mice and
	the broader symptoms of human patients with Hearing-Deafness-Renal
	anomaly syndrome.},
  doi = {10.1371/journal.pone.0007144},
  institution = {eaching Hospitals NHS Trust, Sheffield, United Kingdom.},
  keywords = {Animals; Cell Nucleus, metabolism; Cyclin-Dependent Kinase Inhibitor
	p27, metabolism; Cytoplasm, metabolism; Ear, Inner, embryology/physiology;
	GATA3 Transcription Factor, metabolism; Gene Expression Profiling;
	Gene Expression Regulation, Developmental; Genomics; Mice; Oligonucleotide
	Array Sequence Analysis; Oligonucleotides, metabolism; Reverse Transcriptase
	Polymerase Chain Reaction; Signal Transduction; Somatomedins, metabolism},
  language = {eng},
  medline-pst = {epublish},
  owner = {ahonkela},
  pmid = {19774072},
  timestamp = {2010.04.09}
}

@TECHREPORT{Minka:divergence05,
  author = {Thomas Minka},
  title = {Divergence Measures and Message Passing},
  institution = {Microsoft Research},
  year = {2005},
  number = {MSR-TR-2005-173},
  abstract = {This paper presents a unifying view of message passing algorithms,
	as methods to approximate a complex Bayesian network by a simpler
	network with minimum information divergence. In this view, the difference
	between mean-field methods and belief propagation is not the amount
	of structure they model, but only the measure of loss they minimize
	(`exclusive' versus `inclusive' Kullback-Leibler divergence). In
	each case, meessage-passing arises by minimizing a localized version
	of the divergence, local to each factor. By examining these divergence
	measures, we can intuit the types of solution they prefer (symmetry-breaking,
	for example) and their suitability for different tasks. Furthermore,
	by considering a wider variety of divergence measures (such as alpha-divergences),
	we can achieve different complexity and performance goals.},
  group = {EP, variational}
}

@MISC{InferNET10,
  author = {Minka, T. and Winn, J.M. and Guiver, J.P. and Knowles, D.A.},
  title = {{Infer.NET 2.4}},
  year = {2010},
  note = {Microsoft Research Cambridge. http://research.microsoft.com/infernet}
}

@PHDTHESIS{Minka:thesis01,
  author = {Thomas P. Minka},
  title = {A family of algorithms for approximate {B}ayesian inference},
  school = {Massachusetts Institute of Technology},
  year = {2001},
  linkpsgz = {https://beta.research.microsoft.com/~minka/papers/ep/minka-thesis.ps.gz}
}

@MISC{Minka:matrix00,
  author = {Thomas P. Minka},
  title = {Old and New Matrix Algebra Useful for Statistics},
  howpublished = {Available from \url{http://research.microsoft.com/en-us/um/people/minka/papers/matrix/minka-matrix.pdf}},
  month = {December},
  year = {2000},
  file = {minka-matrix.pdf:http\://research.microsoft.com/en-us/um/people/minka/papers/matrix/minka-matrix.pdf:PDF},
  owner = {neil},
  timestamp = {2009.08.01}
}

@MISC{Minka:learningtolearn97,
  author = {Thomas P. Minka and Rosalind W. Picard},
  title = {Learning How to Learn is Learning With Point Sets},
  howpublished = {Available on-line.},
  year = {1997},
  note = {Revised 1999, available at \url{http://www.stat.cmu.edu/\~{ }minka/}},
  file = {minka-point-sets.ps.gz:http\://research.microsoft.com/en-us/um/people/minka/papers/minka-point-sets.ps.gz:PostScript},
  linkpsgz = {http://scholar.google.com/url?sa=U&q=http://research.microsoft.com/users/minka/papers/minka-point-sets.ps.gz},
  url = {http://research.microsoft.com/en-us/um/people/minka/papers/point-sets.html}
}

@PHDTHESIS{Miskin:thesis01,
  author = {James W. Miskin},
  title = {Ensemble Learning for Independent Component Analysis},
  school = {Selwyn College, Cambridge},
  year = {2001},
  linkpsgz = {http://www.inference.phy.cam.ac.uk/jwm1003/thesis.ps.gz}
}

@ARTICLE{Mjolsness:genecircuit91,
  author = {Eric Mjolsness and D. H. Sharp and J. Reinitz},
  title = {A Connectionist Model of Development},
  journal = jtheoretbio,
  year = {1991},
  volume = {152},
  pages = {429--453},
  number = {4},
  abstract = {We present a phenomenological modeling framework for development.
	Our purpose is to provide a systematic method for discovering and
	expressing correlations in experimental data on gene expression and
	other developmental processes. The modeling framework is based on
	a connectionist or "neural net" dynamics for biochemical regulators,
	coupled to "grammatical rules" which describe certain features of
	the birth, growth, and death of cells, synapses and other biological
	entities. We outline how spatial geometry can be included, although
	this part of the model is not complete. As an example of the application
	of our results to a specific biological system, we show in detail
	how to derive a rigorously testable model of the network of segmentation
	genes operating in the blastoderm of \emph{Drosophila}. To further
	illustrate our methods, we sketch how they could be applied to two
	other important developmental processes: cell cycle control and cell-cell
	induction. We also present a simple biochemical model leading to
	our assumed connectionist dynamics which shows that the dynamics
	used is at least compatible with known chemical mechanisms.},
  group = {gene networks, Drosophila},
  pmid = {1758194}
}

@BOOKLET{DeMoivre:approximatio33,
  title = {Approximatio ad Summam Terminorum Binomii $(a+b)^n$ in Seriem expansi},
  author = {Abraham de Moivre},
  howpublished = {Reprinted in \cite{Archibald:rare26}},
  year = {1733}
}

@ARTICLE{Monk:gap04,
  author = {Nicholas A. M. Monk},
  title = {Dissecting the dynamics of segment determination},
  journal = {Current Biology},
  year = {2004},
  volume = {14},
  pages = {R705--R707},
  group = {gene networks, Drosphila}
}

@ARTICLE{Monk:delay03,
  author = {Nicholas A. M. Monk},
  title = {Oscillatory expression of Hes1, p53 and NF-$\kappa$B driven by transcriptional
	time delays},
  journal = {Current Biology},
  year = {2003},
  volume = {13},
  pages = {1409--1413},
  group = {gene networks, delays}
}

@ARTICLE{Moody:rbf89,
  author = {J. Moody and C. J. Darken},
  title = {Fast Learning in Networks of Locally-Tuned Processing Units},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {281--294},
  number = {2}
}

@INPROCEEDINGS{Mori:recovering04,
  author = {Greg Mori and Xiaofeng Ren and Alexei A. Efros and Jitendra Malik},
  title = {Recovering Human Body Configurations: Combining Segmentation and
	Recognition},
  booktitle = pCVPR,
  year = {2004},
  volume = {2},
  address = {Washington, DC, U.S.A.},
  month = {29 Jun.--1 Jul.},
  publisher = ieeecomp,
  abstract = {The goal of this work is to detect a human figure image and localize
	his joints and limbs along with their associated pixel masks. In
	this work we attempt to tackle this problem in a general setting.
	The dataset we use is a collection of sports news photographs of
	baseball players, varying dramatically in pose and clothing. The
	approach that we take is to use segmentation to guide our recognition
	algorithm to salient bits of the image. We use this segmentation
	approach to build limb and torso detectors, the outputs of which
	are assembled into human figures. We present quantitative results
	on torso localization, in addition to shortlisted full body configurations.},
  doi = {10.1109/CVPR.2004.1315182},
  file = {mori-cvpr04.pdf:http\://www.eecs.berkeley.edu/Research/Projects/CS/vision/human/mori-cvpr04.pdf:PDF},
  group = {pose estimation},
  optpages = {326--333}
}

@ARTICLE{Muggleton:ILP94,
  author = {Stephen Muggleton and Luc {de Raedt}},
  title = {Inductive Logic Programming: Theory and Methods},
  journal = {Journal of Logic Programming},
  year = {1994},
  volume = {19,20},
  pages = {629--679}
}

@ARTICLE{Mulier:soms95,
  author = {F. Mulier and V. Cherkassky},
  title = {Self-organization as an iterative kernel smoothing process},
  journal = NC,
  year = {1995},
  volume = {7},
  pages = {1165--1177},
  number = {6}
}

@ARTICLE{Mullen:yeast05,
  author = {Janet R. Mullen and Ferez S. Nallaseth and Yan Q. Lan and Christopher
	E. Slagle and Steven J. Brill},
  title = {Yeast Rmi1/Nce4 Controls Genome Stability as a Subunit of the Sgs1-Top3
	Complex},
  journal = {Molecular and Cellular Biology},
  year = {2005},
  volume = {25},
  pages = {4476--4487},
  number = {11},
  abstract = {Genome stability requires a set of RecQ-Top3 DNA helicase-topoisomerase
	complexes whose sole budding yeast homolog is encoded by SGS1-TOP3.
	RMI1/NCE4 was identified as a potential intermediate in the SGS1-TOP3
	pathway, based on the observation that strains lacking any one of
	these genes require MUS81 and MMS4 for viability. This idea was tested
	by confirming that sgs1 and rmi1 mutants display the same spectrum
	of synthetic lethal interactions, including the requirements for
	SLX1, SLX4, SLX5, and SLX8, and by demonstrating that rmi1 mus81
	synthetic lethality is dependent on homologous recombination. On
	their own, mutations in RMI1 result in phenotypes that mimic those
	of sgs1 or top3 strains including slow growth, hyperrecombination,
	DNA damage sensitivity, and reduced sporulation. And like top3 strains,
	most rmi1 phenotypes are suppressed by mutations in SGS1. We show
	that Rmi1 forms a heteromeric complex with Sgs1-Top3 in yeast and
	that these proteins interact directly in a recombinant system. The
	Rmi1-Top3 complex is stable in the absence of the Sgs1 helicase,
	but the loss of either Rmi1 or Top3 in yeast compromises its partner's
	interaction with Sgs1. Biochemical studies demonstrate that recombinant
	Rmi1 is a structure-specific DNA binding protein with a preference
	for cruciform structures. We propose that the DNA binding specificity
	of Rmi1 plays a role in targeting Sgs1-Top3 to appropriate substrates.},
  file = {4476:http\://mcb.asm.org/cgi/reprint/25/11/4476:PDF},
  group = {yeast}
}

@ARTICLE{Murdoch:exact98,
  author = {D. J. Murdoch and P. J. Green},
  title = {Exact sampling from a continuous state space},
  journal = {Scandinavian Journal of Statistics},
  year = {1998},
  volume = {25},
  pages = {483--502},
  number = {3},
  abstract = {Abstract: Propp and Wilson (1995) described a protocol, 
	
	 called coupling from the past, for exact sampling from a finite distribution
	using a coupled Markov chain Monte Carlo algorithm. In this paper
	we extend coupling from the past to various MCMC samplers on a continuous
	state space; rather than following the monotone sampling device of
	Propp and Wilson, our approach uses methods related to gamma-coupling
	and rejection sampling to simulate the chain, and direct accounting
	of sample paths to check whether they have coupled.
	
	 Remarks: Describes a variety of scenarios for which CFTP may be applied
	to a (non-monotone) continuous state space, giving a sequence of
	algorithms that start out simple, but become increasingly sophisticated.
	The methods used are related to gamma-coupling and rejection sampling,
	and appear to be applicable to Bayesian parameter estimation. Includes
	a case study comparing the performance of each technique when used
	to sample from the posterior distribution of a set of pump reliability
	parameters.},
  linkpsgz = {http://www.stats.bris.ac.uk/~peter/papers/coupl.letter.1809.ps.gz}
}

@ARTICLE{Murray:MLP92,
  author = {Alan F. Murray},
  title = {Multi-Layer Perceptron Learning Optimised for On-Chip Implementation
	--- a Noise-Robust System},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {366--381},
  number = {3}
}

@ARTICLE{Murray:circuits94,
  author = {Alan F. Murray and S. Churcher and A. Hamilton and A. Holmes and
	J. Jackson and H. Reekie and R. Woodburn},
  title = {Circuits, Algorithms, Memory Technology and Applications for Pulse-Stream
	{VLSI} Neural Networks},
  journal = {IEEE Micro},
  year = {1994},
  pages = {29--39}
}

@INCOLLECTION{Murraysmith:transformation0505,
  author = {Roderick Murray-Smith and Barak A. Pearlmutter},
  title = {Transformation of {G}aussian Process Priors},
  booktitle = {Deterministic and Statistical Methods in Machine Learning},
  publisher = {LNAI 3635, Springer-Verlag},
  year = {2005},
  editor = {Joab Winkler and Mahesan Niranjan and Neil Lawrence},
  pages = {110-123}
}

@INPROCEEDINGS{Murray-Smith:transformations05,
  author = {Roderick Murray-Smith and Barak A. Pearlmutter},
  title = {Transformations of {G}aussian Process priors}
}

@ARTICLE{Myasnikova:registration01,
  author = {Ekaterina Myasnikova and Anastassia Samsonova and Konstantin Kozlov
	and Maria Samsonova and John Reinitz},
  title = {Registration of the expression patterns of {D}rosophila segmentation
	genes by two independent methods},
  journal = bioinf,
  year = {2001},
  volume = {17},
  pages = {3--12},
  number = {1},
  abstract = {{\bf Motivation}: To construct an integrated map of \emph{Drosophila}
	segmentation gene expression from partial data taken from individual
	embryos. \\\\
	
	 {\bf Results}: Spline and wavelet based registration techniques were
	developed to register Drosophila segmentation gene expression data.
	As ground control points for registration we used the locations of
	extrema on gene expression patterns, represented in 1D. The registration
	method was characterized by unprecedented high accuracy. A method
	for constructing the integrated pattern of gene expression at cellular
	resolution was designed. These patterns were constructed for 9 segmentation
	genes belonging to gap and pair-rule classes.
	
	 {\bf Availability}: Programs running on SPARC/SunOS 5.0 platform
	or Alpha/DU 4.0E systems may be obtained from the authors.
	
	 {\bf Contact:} myasnikova@fn.csa.ru},
  doi = {10.1093/bioinformatics/17.1.3},
  file = {3.pdf:http\://bioinformatics.oxfordjournals.org/cgi/reprint/17/1/3.pdf:PDF},
  group = {Drosophila segmentation},
  pmid = {11222257}
}

@PHDTHESIS{Moller:phd93,
  author = {Martin F. M{\o}ller},
  title = {Efficient Training of Feed-Forward Neural Networks},
  school = {Aarhus University, Denmark},
  year = {1993}
}

@ARTICLE{Moller:scg93,
  author = {Martin F. M{\o}ller},
  title = {A scaled conjugate gradient algorithm for fast supervised learning},
  journal = NN,
  year = {1993},
  volume = {6},
  pages = {525--533},
  number = {4},
  linkpsgz = {ftp://ftp.cs.ubc.ca/mirror1/x-contrib.R5/scg.paper.ps.gz}
}

@INPROCEEDINGS{Bishop:iee_periodic95,
  author = {Ian T. Nabney and Christopher M. Bishop and C. Legleye},
  title = {Modelling conditional probability distributions for periodic variables},
  booktitle = {Proceedings Fourth IEE International Conference on Artificial Neural
	Networks},
  year = {1995},
  pages = {177--182},
  address = {Cambridge, U.K.},
  publisher = {IEE}
}

@INPROCEEDINGS{Nabney:safecomp97,
  author = {I. T. Nabney and M. Paven and R. Eldridge and C. Lee},
  title = {Practical assessment of neural network applications},
  booktitle = {SafeComp},
  year = {1997},
  editor = {J. E. Moody and S. J. Hanson and R. P. Lippmann},
  publisher = {Springer}
}

@PHDTHESIS{Nachman:thesis04,
  author = {Iftach Nachman},
  title = {Probabilistic Modeling of Gene Regulatory Networks from Data},
  school = {Hebrew University},
  year = {2004},
  abstract = {The living cell consists of a complex system of interacting networks,
	involved in signal transduction, metabolism, and regulation. Regulatory
	networks can be thought of as the core brain, or master plan, controlling
	and operating all the functions of the cell. In this dissertation
	we try to gain better understanding of such networks by analyzing
	experimental data. Our approach is based on probabilistic generative
	modeling of experimental observations.\\\\
	
	 The challenge of learning about regulatory networks includes both
	unraveling their structure (a qualitative aspect) and the precise
	nature of local interactions in them (a quantitative aspect). Both
	these aspects are important for understanding how these networks
	work, what dynamic behaviour they display under different conditions
	and what is their expected response to specific stimuli. New experimental
	methods that have emerged in the past few years have made the exploration
	of such networks possible. These methods include parallel measurement
	of mRNA abundance, or alternatively regulator binding location, for
	many thousands of genes simultaneously. However, learning from such
	data sources poses several challenges. First, both the biological
	processes that generated the observed data and the processes involved
	in measuring those phenomena involve stochastic aspects, and are
	therefore not deterministic, nor exactly replicable. Second, most
	of the stages and quantities in the regulatory pathways are not observed,
	and many of the design details are not known. Finally, current data
	sets are sparse, while the number of participating genes in those
	networks can be very large. \\\\
	
	 The model-based approach we present tries to describe how such data
	sets were generated. To cope with the above challenges, it has to
	account for stochasticity at all levels, to allow the use of unobserved
	entities, and to be able to search for the "correct" design diagram.
	In the theoretical part of this work we present our choice of modeling
	language, which is based on probabilistic graphical models, as well
	as novel representation schemes, model assessment methods and search
	algorithms which are needed to adapt this language to our task, coping
	with its specific difficulties. We then present two approaches for
	using these tools to learn regulatory networks from data. \\\\
	
	 We first introduce a novel representation scheme for Bayesian networks
	based on Gaussian processes priors. These priors are semi-parametric
	in nature and can learn almost arbitrary noisy functional relations.
	We develop the Bayesian score of Gaussian Process Networks and describe
	how to learn them from data. We present empirical results on artificial
	and real-life domains with non-linear dependencies.\\\\
	
	 Next, we introduce two novel methods for learning the structure of
	Bayesian networks, which address specific difficulties: The first
	enables handling very large domains, and the second allows learning
	continuous variable networks with non-linear interactions as well
	as handling new hidden variables. The \emph{Sparse Candidate} algorithm
	achieves faster learning by restricting the search space. It iteratively
	restricts the parents of each variable to belong to a small subset
	of candidates, and then searches for a network that satisfies these
	constraints. We evaluate this algorithm both on synthetic and real-life
	data. Our results show that it is significantly faster than alternative
	search procedures without loss of quality in the learned structures.
	The \emph{Ideal Parent} method is a general method for significantly
	speeding the structure search for continuous variable networks with
	common parametric distributions. Importantly, this method facilitates
	the efficient addition of new hidden variables into the network structure.
	We demonstrate the method on several data sets, both for learning
	structure on fully observable data, and for introducing new hidden
	variables during structure search. \\\\
	
	 In the second part of the thesis we apply the tools from probabilistic
	modeling for the task of learning regulatory networks from gene expression
	data. We begin by introducing the first application of Bayesian networks
	for modeling gene regulatory networks. We show how such networks
	can describe interactions between genes. We then describe a method
	for recovering gene interactions from microarray data using Bayesian
	network learning techniques, and demonstrate the method on real data
	from yeast.\\\\
	
	 Finally, we introduce a more realistic modeling approach. Unlike
	most previous works in the field, here we employ quantitative transcription
	rates, and simultaneously estimate both the kinetic parameters that
	govern these rates, and the activity levels of unobserved regulators
	that control them. We apply our approach to expression data sets
	from yeast and E. Coli and show that we can learn the unknown regulator
	activity profiles, as well as the binding affinity parameters. We
	also show how the "Ideal Parent" method enables us to improve initial
	guesses of regulation topology, as well as reconstruct ab initio
	the regulatory network from those data sets.},
  file = {thesis.pdf:http\://cgr.harvard.edu/Regev_lab/people/iftach/papers/thesis.pdf:PDF},
  group = {gene networks}
}

@ARTICLE{Nachman:inferring04,
  author = {Iftach Nachman and Aviv Regev and Nir Friedman},
  title = {Inferring quantitative models of regulatory networks from expression
	data},
  journal = bioinf,
  year = {2004},
  volume = {20},
  pages = {248--256},
  number = {Suppl. 1},
  abstract = {{\bf Motivation:} Genetic networks regulate key processes in living
	cells. Various methods have been suggested to reconstruct network
	architecture from gene expression data. However, most approaches
	are based on qualitative models that provide only rough approximations
	of the underlying events, and lack the quantitative aspects that
	are critical for understanding the proper function of biomolecular
	systems.\\\\
	
	 {\bf Results:} We present fine-grained dynamical models of gene transcription
	and develop methods for reconstructing them from gene expression
	data within the framework of a generative probabilistic model. Unlike
	previous works, we employ quantitative transcription rates, and simultaneously
	estimate both the kinetic parameters that govern these rates, and
	the activity levels of unobserved regulators that control them. We
	apply our approach to expression data sets from yeast and show that
	we can learn the unknown regulator activity profiles, as well as
	the binding affinity parameters.We also introduce a novel structure
	learning algorithm, and demonstrate its power to accurately reconstruct
	the regulatory network from those data sets.\\\\
	
	 {\bf Keywords:} transcription regulation, parameter learning, structure
	learning, regulatory networks\\\\
	
	 {\bf Contact:} nir@cs.huji.ac.il},
  group = {gene networks}
}

@ARTICLE{Nadal:growth89,
  author = {J. P. Nadal},
  title = {Study of a growth algorithm for a feedforward network},
  journal = IJNS,
  year = {1989},
  volume = {1},
  pages = {55--59},
  number = {1}
}

@ARTICLE{Nadaraya:kernel64,
  author = {{\'{E}}. A. Nadaraya},
  title = {On estimating regression},
  journal = {Theory of Probability and its Applications},
  year = {1964},
  volume = {9},
  pages = {141--142},
  number = {1}
}

@ARTICLE{Narcowich:generalized94,
  author = {Francis J. Narcowich and Joseph D. Ward},
  title = {Generalized Hermite interpolation via matrix-valued conditionally
	positive definite functions},
  journal = {Mathematics of Computation},
  year = {1994},
  volume = {63},
  pages = {661--687},
  number = {208},
  file = {narcowich1994generalized.pdf:Statistical Learning/Vector-valued/narcowich1994generalized.pdf:PDF},
  publisher = {American Mathematical Society}
}

@ARTICLE{Narendra:bab77,
  author = {P. M. Narendra and K. Fukunaga},
  title = {A branch and bound algorithm for feature subset selection},
  journal = {IEEE Transactions on Computers},
  year = {1977},
  volume = {26},
  pages = {917--922},
  number = {9}
}

@INPROCEEDINGS{Navaratnam:joint07,
  author = {Ram Navaratnam and Andrew Fitzgibbon and Roberto Cipolla},
  title = {The Joint Manifold Model for Semi-supervised Multi-valued Regression},
  booktitle = iccv,
  year = {2007},
  publisher = ieeecomp,
  abstract = {Many computer vision tasks may be expressed as the problem of learning
	a mapping between image space and a parameter space. For example,
	in human body pose estimation, recent research has directly modelled
	the mapping from image features ($z$) to joint angles ($\theta$).
	Fitting such models requires training data in the form of labelled
	($z$,$\theta$) pairs, from which are learned the conditional densities
	$p(\theta | z)$. Inference is then simple: given test image features
	$z$, the conditional $p(\theta | z)$ is immediately computed. However
	large amounts of training data are required to fit the models, particularly
	in the case where the spaces are high dimensional.
	
	 We show how the use of unlabelled data-samples from the marginal
	distributions $p(z)$ and $p(\theta)$ may be used to improve fitting.
	This is valuable because it is often significantly easier to obtain
	unlabelled than labelled samples. We use a Gaussian process latent
	variable model to learn the mapping from a shared latent low-dimensional
	manifold to the feature and parameter spaces. This extends existing
	approaches to (a) use unlabelled data, and (b) represent one-to-many
	mappings.
	
	 Experiments on synthetic and real problems demonstrate how the use
	of unlabelled data improves over existing techniques. In our comparisons,
	we include existing approaches that are explicitly semi-supervised
	as well as those which implicitly make use of unlabelled examples.},
  group = {gplvm}
}

@MISC{Neal:code99,
  author = {Radford M. Neal},
  title = {Software for flexible {B}ayesian modeling and {M}arkov chain sampling},
  year = {1999},
  note = {Available from \url{http://www.cs.utoronto.ca/\~{ }radford/fbm.software.html}}
}

@TECHREPORT{Neal:montecarlogp97,
  author = {Radford M. Neal},
  title = {{M}onte {C}arlo implementation of {G}aussian process models for {B}ayesian
	Regression and Classification},
  institution = {Dept of Computer Science, University of Toronto},
  year = {1997},
  number = {9702},
  abstract = {Gaussian processes are a natural way of defining prior distributions
	over functions of one or more input variables. In a simple nonparametric
	regression problem, where such a function gives the mean of a Gaussian
	distribution for an observed response, a Gaussian process model can
	easily be implemented using matrix computations that are feasible
	for datasets of up to about a thousand cases. Hyperparameters that
	define the covariance function of the Gaussian process can be sampled
	using Markov chain methods. Regression models where the noise has
	a $t$-distribution and logistic or probit models for classification
	applications can be implemented by sampling as well for latent values
	underlying the observations. Software is now available that implements
	these methods using covariance functions with hierarchical parameterizations.
	Models defined in this way can discover high-level properties of
	the data, such as which inputs are relevant to predicting the response.},
  group = {gp},
  linkps = {http://www.cs.toronto.edu/~radford/ftp/mc-gp.ps},
  linksoftware = {http://www.cs.toronto.edu/~radford/fbm.software.html}
}

@PHDTHESIS{Neal:thesis94,
  author = {Radford M. Neal},
  title = {{B}ayesian Learning for Neural Networks},
  school = {University of Toronto, Canada},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&rep=rep1&type=pdf},
  year = {1994}
}

@TECHREPORT{Neal:markov93,
  author = {Radford M. Neal},
  title = {Probabilistic inference using {M}arkov chain {M}onte {C}arlo methods},
  institution = {Department of Computer Science, University of Toronto, Cananda},
  year = {1993},
  number = {CRG-TR-93-1}
}

@ARTICLE{Neal:belief92,
  author = {Radford M. Neal},
  title = {Connectionist Learning of Belief Networks},
  journal = {Artificial Intelligence},
  year = {1992},
  volume = {56},
  pages = {71--113}
}

@TECHREPORT{Neal:hmc92,
  author = {Radford M. Neal},
  title = {{B}ayesian training of backpropagation networks by the hybrid {M}onte
	{C}arlo method},
  institution = {Department of Computer Science, University of Toronto, Canada},
  year = {1992},
  number = {CRG-TR-92-1}
}

@INPROCEEDINGS{Neuneier:cond94,
  author = {R. Neuneier and F. Hergert and W. Finnof and D. Ormoneit},
  title = {Estimation of conditional densities: a comparison of approaches},
  booktitle = {Proceedings ICANN*94 International Conference on Artificial Neural
	Networks},
  year = {1994},
  editor = {M. Marinaro and P. G. Morasso},
  volume = {1},
  pages = {689--692},
  publisher = springer
}

@ARTICLE{Nguyen:tumor02,
  author = {D. V. Nguyen and D. M. Rocke},
  title = {Tumor Classification by Partial Least Squares Using Microarray Gene
	Expression Data},
  journal = bioinf,
  year = {2002},
  volume = {18},
  pages = {1216--26},
  number = {9},
  label1 = {Bioinformatics Issue},
  link1 = {http://bioinformatics.oupjournals.org/cgi/pmidlookup?view=reprint&pmid=11836210}
}

@InProceedings{Wilson:gprn12,
  author = 	 {Andrew Gordon Wilson and David A. Knowles and Zoubin Ghahramani},
  title = 	 {Gaussian Process Regression Networks},
  crossref =	 {Langford:icml12}
}

@InProceedings{Wilson:gpatt13,
  author    = {Andrew Gordon Wilson and Ryan Prescott Adams},
  title     = {Gaussian Process Kernels for Pattern Discovery and Extrapolation},
  year      = {2013},
  pages     = {1067-1075},
  ee        = {http://jmlr.org/proceedings/papers/v28/wilson13.html},
  crossref  = {icml13},
}

@InProceedings{Duvenaud:structure13,
  title={Structure Discovery in Nonparametric Regression through Compositional Kernel Search},
  author={David Duvenaud and James Robert Lloyd and Roger Grosse and Joshua B. Tenenbaum and Zoubin Ghahramani},
  booktitle={Proceedings of the 30th International Conference on Machine Learning},
  pages={1166--1174},
  year      = {2013},
  crossref  = {icml13},
}

@ARTICLE{Nile2008,
  author = {Christoper J Nile and Robert C Read and Mohammed Akil and Gordon
	W Duff and Anthony G Wilson},
  title = {Methylation status of a single CpG site in the IL6 promoter is related
	to IL6 messenger RNA levels and rheumatoid arthritis.},
  journal = {Arthritis Rheum},
  year = {2008},
  volume = {58},
  pages = {2686--2693},
  number = {9},
  month = {Sep},
  abstract = {Genetic variation in the gene for interleukin-6 (IL-6) contributes
	to the pathogenesis of inflammatory arthritis, but the role, if any,
	of epigenetic variability has not been reported. The aims of this
	study were to compare the DNA methylation status of the IL6 promoter
	in rheumatoid arthritis (RA) patients and control subjects and to
	study the effects on gene expression.Genomic DNA was isolated from
	peripheral blood mononuclear cells (PBMCs) obtained from RA patients
	and healthy controls. Macrophages from healthy controls were isolated
	and stimulated with lipopolysaccharide (LPS). Methylation status
	was determined using bisulfite genomic sequencing and IL6 messenger
	RNA (mRNA) levels by quantitative polymerase chain reaction. Gel
	shift assays were performed with methylated or unmethylated probes
	and HeLa cell nuclear extract.The proximal CpG motifs (-666 to +27)
	were predominantly unmethylated and the upstream motifs (-1099 to
	-1001) were highly methylated in PBMCs from patients and controls.
	Methylation of individual CpG motifs was similar, except at -1099C,
	which was less methylated in the patients than in the controls (58\%
	versus 98\%; P = 1 x 10(-6)). To test whether this observation might
	relate to gene regulation, LPS-stimulated macrophages were grouped
	according to their IL6 mRNA stimulation index (SI). The level of
	methylation at -1099C was significantly lower in the group with high
	(SI >75) compared with the group with low (SI <10) induced mRNA levels
	(71\% versus 93\%; P = 0.007). Gel shift assays revealed decreased
	protein binding to the -1099C unmethylated probe.These data suggest
	that methylation of a single CpG in the IL6 promoter region may affect
	IL6 gene regulation and may play a role in the pathogenesis of RA.},
  doi = {10.1002/art.23758},
  institution = { Royal Hallamshire Hospital, Sheffield, UK.},
  keywords = {Adult; Arthritis, Rheumatoid, genetics; Cells, Cultured; Chi-Square
	Distribution; CpG Islands, genetics; DNA Methylation, genetics; Electrophoretic
	Mobility Shift Assay; Gene Expression Regulation; Genetic Predisposition
	to Disease; Humans; Interleukin-6, genetics; Leukocytes, Mononuclear,
	physiology; Promoter Regions, Genetic, genetics; RNA, Messenger,
	genetics; Reverse Transcriptase Polymerase Chain Reaction; Statistics,
	Nonparametric},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {18759290},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1002/art.23758}
}

@INPROCEEDINGS{Niranjan:potential89,
  author = {M. Niranjan and A. J. Robinson and F. Fallside},
  title = {Pattern recognition with potential functions in the context of neural
	networks},
  booktitle = {Proceedings Sixth Scandinavian Conference on Image Analysis, Oulu,
	Finland},
  year = {1989},
  editor = {M. Pietik{\"a}inen and J. R{\"o}ning},
  volume = {1},
  pages = {96--103},
  publisher = {Pattern Recognition Society of Finland}
}

@INPROCEEDINGS{Nix:variance94,
  author = {A. D. Nix and A. S. Weigend},
  title = {Estimating the mean and variance of the target probability distribution},
  booktitle = {Proceedings of the {IEEE} International Conference on Neural Networks},
  year = {1994},
  volume = {1},
  pages = {55--60},
  address = {New York},
  publisher = {IEEE}
}

@ARTICLE{Nowlan:soft92,
  author = {S. J. Nowlan and G. E. Hinton},
  title = {Simplifying neural networks by soft weight sharing},
  journal = NC,
  year = {1992},
  volume = {4},
  pages = {473--493},
  number = {4}
}

@ARTICLE{Ohagan:bacco06,
  author = {Anthony O'Hagan},
  title = {Bayesian analysis of computer code outputs: A tutorial},
  journal = {Reliability Engineering and System Safety},
  year = {2006},
  volume = {91},
  pages = {1290-1300}
}

@ARTICLE{Ohagan:curve78,
  author = {Anthony O'Hagan},
  title = {Curve Fitting and Optimal Design for Prediction},
  journal = JRSSb,
  year = {1978},
  volume = {40},
  pages = {1--42}
}

@ARTICLE{O'Mahony1998,
  author = {L. O'Mahony and J. Holland and J. Jackson and C. Feighery and T.
	P. Hennessy and K. Mealy},
  title = {Quantitative intracellular cytokine measurement: age-related changes
	in proinflammatory cytokine production.},
  journal = {Clin Exp Immunol},
  year = {1998},
  volume = {113},
  pages = {213--219},
  number = {2},
  month = {Aug},
  abstract = {The proinflammatory cytokines play a central role in mediating cellular
	and physiological responses, and levels may reflect immune system
	effectiveness. In this study, the effect of ageing on the inflammatory
	response was examined using a novel method to detect production of
	the proinflammatory cytokines, i.e. tumour necrosis factor-alpha
	(TNF-alpha), IL-6 and IL-1beta. Peripheral blood mononuclear cells
	(PBMC) obtained from healthy donors of different ages were incubated
	for 0, 24, 48 and 72 h with or without phorbol 12-myristate 13-acetate
	(PMA) stimulation. At each time point these cells were permeabilized
	and incubated with secondary conjugated FITC MoAbs specific for each
	cytokine. A flow cytometric system was developed to quantify specific
	intracellular fluorescence in T cells (CD3+) and monocytes (CD14+).
	TNF-alpha, IL-6 and IL-1beta production in cell culture supernatants
	was also measured using ELISAs. In older subjects, flow cytometry
	detected significant increases in intracellular T cell TNF-alpha
	and IL-6 (P < 0.05). IL-1beta was not detected in any of the T cell
	samples. Likewise, the monocytes of older subjects demonstrated increased
	intracellular levels of all three cytokines, but these increases
	were not significant (P > 0.05). These changes in intracellular proinflammatory
	cytokine levels may explain some of the exaggerated inflammatory
	responses seen in elderly patients.},
  institution = {Department of Surgery, St James's Hospital, Dublin, Ireland.},
  keywords = {Adult; Aged; Aging, immunology; Analysis of Variance; Antigens, CD14;
	Antigens, CD3; Cytokines, biosynthesis; Enzyme-Linked Immunosorbent
	Assay; Flow Cytometry; Humans; Interleukin-1, biosynthesis; Interleukin-6,
	biosynthesis; Leukocytes, Mononuclear, drug effects/immunology; Middle
	Aged; Tetradecanoylphorbol Acetate, pharmacology; Tumor Necrosis
	Factor-alpha, biosynthesis},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {9717970},
  timestamp = {2011.09.14}
}

@ARTICLE{ONeill:improved03,
  author = {P. O'Neill and G. D. Magoulas and X. Liu},
  title = {Improved Processing of Microarray Data using Image Reconstruction
	Techniques},
  year = {2003},
  note = {Submitted to IEEE Transactions in NanoBiosystems}
}

@ARTICLE{Oakley:computer02,
  author = {Jeremey Oakley and Anthony O'Hagan},
  title = {Bayesian Inference for the Uncertainty Distribution of Computer Model
	Outputs},
  journal = {Biometrika},
  year = {2002},
  volume = {89},
  pages = {769--784},
  number = {4},
  abstract = {We consider a problem of inference for the output of a computationally
	expensive computer model.We suppose that the model is to be used
	in a context where the values of one or more inputs are uncertain,
	so that the input configuration is a random variable. We require
	to make inference about the induced distribution of the output. This
	distribution is called the uncertainty distribution, and the general
	problem is known to users of computer models as uncertainty analysis.
	To be specific, we develop Bayesian inference for the distribution
	and density functions of the model output. Modelling the output,
	as a function of its inputs, as a Gaussian process, we derive expressions
	for the posterior mean and variance of the distribution and density
	functions, based on data comprising observed outputs at a sample
	of input configurations. We show that direct computation of these
	expressions may encounter numerical difficulties. We develop an alternative
	approach based on simulating approximate realisations from the posterior
	distribution of the output function. Two examples are given to illustrate
	our methods.
	
	 Key Words: Computer experiment; Gaussian process; Uncertainty analysis},
  group = {gp},
  label1 = {Biometrika Abstract},
  link1 = {http://biomet.oxfordjournals.org/cgi/content/abstract/89/4/769}
}

@INPROCEEDINGS{Oba:prior03,
  author = {Shigeyuki Oba and Masa-aki Sato and Shin Ishii},
  title = {Prior hyperparameters in {B}ayesian PCA},
  booktitle = {ICANN/ICONIP 2003},
  year = {2003},
  pages = {271--279}
}

@ARTICLE{Oba:bayesian03,
  author = {Shigeyuki Oba and Masa-aki Sato and Ichiro Takemasa and Morito Monden
	and Ken-ichi Matsubara and Shin Ishii},
  title = {A {B}ayesian missing value estimation method for gene expression
	data},
  journal = bioinf,
  year = {2003},
  volume = {19},
  pages = {2088--2096},
  number = {16}
}

@ARTICLE{Obozinski:joint10,
  author = {Guillaume Obozinski and Benjamin Taskar and Michael I. Jordan},
  title = {Joint covariate selection and joint subspace selection for multiple
	classification problems},
  journal = {Statistics and Computing},
  year = {2010},
  volume = {20},
  pages = {231--252},
  number = {2},
  file = {Obozinski:joint10.pdf:Statistical Learning/Multitask/Obozinski:joint10.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Oda:egrf05,
  author = {Kanae Oda and Yukiko Matsuoka and Akira Funahashi and Hiroaki Kitano},
  title = {A Comprehensive Pathway Map of Epidermal Growth Factor Receptor Signaling},
  journal = {Molecular Systems Biology},
  year = {2005},
  abstract = {The epidermal growth factor receptor (EGFR) signaling pathway is one
	of the most important pathways that regulate growth, survival, proliferation,
	and differentiation in mammalian cells. Reflecting this importance,
	it is one of the best-investigated signaling systems, both experimentally
	and computationally, and several computational models have been developed
	for dynamic analysis. A map of molecular interactions of the EGFR
	signaling system is a valuable resource for research in this area.
	In this paper, we present a comprehensive pathway map of EGFR signaling
	and other related pathways. The map reveals that the overall architecture
	of the pathway is a bow-tie (or hourglass) structure with several
	feedback loops. The map is created using CellDesigner software that
	enables us to graphically represent interactions using a well-defined
	and consistent graphical notation, and to store it in Systems Biology
	Markup Language (SBML).},
  doi = {10.1038/msb4100014},
  file = {msb4100014.pdf:http\://www.nature.com/msb/journal/v1/n1/pdf/msb4100014.pdf:PDF},
  group = {ERK,EGFR}
}

@ARTICLE{Raftery:bayesianmds01,
  author = {Man-Suk Oh and Adrian E. Raftery},
  title = {Bayesian Multidimensional Scaling and Choice of Dimension},
  journal = jasa,
  year = {2001},
  volume = {96},
  pages = {1031--1044},
  file = {oh2001.pdf:http\://www.stat.washington.edu/raftery/Research/PDF/oh2001.pdf:PDF}
}

@ARTICLE{Oja:pca89,
  author = {E. Oja},
  title = {Neural networks, principal components, and subspaces},
  journal = IJNS,
  year = {1989},
  volume = {1},
  pages = {61--68},
  number = {1}
}

@ARTICLE{Oja:pca82,
  author = {E. Oja},
  title = {A simplified neuron model as a principal component analyzer},
  journal = {Journal of Mathematical Biology},
  year = {1982},
  volume = {15},
  pages = {267--273}
}

@ARTICLE{Omohundro:eff87,
  author = {S. M. Omohundro},
  title = {Efficient algorithms with neural network behaviour},
  journal = {Complex Systems},
  year = {1987},
  volume = {1},
  pages = {273--347}
}

@ARTICLE{Opper:exactsol88,
  author = {Manfred Opper},
  title = {Learning Time of Neural Networks: Exact Solution For a Perceptron
	Algorithm},
  journal = PRa,
  year = {1988},
  volume = {38},
  pages = {2824--2826},
  number = {7}
}

@ARTICLE{Opper:EC05,
  author = {Manfred Opper and Ole Winther},
  title = {Expectation Consistent Approximate Inference},
  journal = jmlr,
  year = {2005},
  volume = {6},
  pages = {2177--2204},
  abstract = {We propose a novel framework for approximations to intractable probabilistic
	models which is based on a free energy formulation. The approximation
	can be understood as replacing an average over the original intractable
	distribution with a tractable one. It requires two tractable probability
	distributions which are made consistent on a set of moments and encode
	different features of the original intractable distribution. In this
	way we are able to use Gaussian approximations for models with discrete
	or bounded variables which allow us to include non-trivial correlations.
	These are neglected in many other methods. We test the framework
	on toy benchmark problems for binary variables on fully connected
	graphs and 2D grids and compare with other methods, such as loopy
	belief propagation. Good performance is already achieved by using
	single nodes as tractable substructures. Significant improvements
	are obtained when a spanning tree is used instead.},
  file = {opper05a.pdf:http\://www.jmlr.org/papers/volume6/opper05a/opper05a.pdf:PDF},
  group = {EP,EC}
}

@ARTICLE{Opper:gpc00,
  author = {Manfred Opper and Ole Winther},
  title = {Gaussian Processes for Classification: Mean Field Algorithms},
  journal = NC,
  year = {2000},
  volume = {12},
  pages = {2655--2684},
  linkpsgz = {http://isp.imm.dtu.dk/staff/winther/opper.neuralcomp.ps.gz}
}

@ARTICLE{Orozco2010,
  author = {Gisela Orozco and Steve Eyre and Anne Hinks and Xiayi Ke and Wellcome
	Trust Case Control consortium YEAR Consortium and Anthony G Wilson
	and Deborah E Bax and Ann W Morgan and Paul Emery and Sophia Steer
	and Lynne Hocking and David M Reid and Paul Wordsworth and Pille
	Harrison and Wendy Thomson and Anne Barton and Jane Worthington},
  title = {Association of CD40 with rheumatoid arthritis confirmed in a large
	UK case-control study.},
  journal = {Ann Rheum Dis},
  year = {2010},
  volume = {69},
  pages = {813--816},
  number = {5},
  month = {May},
  abstract = {A recent meta-analysis of published genome-wide association studies
	(GWAS) in populations of European descent reported novel associations
	of markers mapping to the CD40, CCL21 and CDK6 genes with rheumatoid
	arthritis (RA) susceptibility while a large-scale, case-control association
	study in a Japanese population identified association with multiple
	single nucleotide polymorphisms (SNPs) in the CD244 gene. The aim
	of the current study was to validate these potential RA susceptibility
	markers in a UK population.A total of 4 SNPs (rs4810485 in CD40,
	rs2812378 in CCL21, rs42041 in CDK6 and rs6682654 in CD244) were
	genotyped in a UK cohort comprising 3962 UK patients with RA and
	3531 healthy controls using the Sequenom iPlex platform. Genotype
	counts in patients and controls were analysed with the chi(2) test
	using Stata.Association to the CD40 gene was robustly replicated
	(p=2 x 10(-4), OR 0.86, 95\% CI 0.79 to 0.93) and modest evidence
	was found for association with the CCL21 locus (p=0.04, OR 1.08,
	95\% CI 1.01 to 1.16). However, there was no evidence for association
	of rs42041 (CDK6) and rs6682654 (CD244) with RA susceptibility in
	this UK population. Following a meta-analysis including the original
	data, association to CD40 was confirmed (p=7.8 x 10(-8), OR 0.87
	(95\% CI 0.83 to 0.92).In this large UK cohort, strong association
	of the CD40 gene with susceptibility to RA was found, and weaker
	evidence for association with RA in the CCL21 locus.},
  doi = {10.1136/ard.2009.109579},
  institution = {Epidemiology Unit, Faculty of Medical and Human Sciences, University
	of Manchester, Stopford Building, Oxford Road, Manchester M13 9PT,
	UK. gisela.orozco@manchester.ac.uk},
  keywords = {Antigens, CD40, genetics; Arthritis, Rheumatoid, genetics/immunology;
	Case-Control Studies; Chemokine CCL21, genetics; Cyclin-Dependent
	Kinase 6, genetics; Female; Gene Frequency; Genetic Markers; Genetic
	Predisposition to Disease; Genotype; Humans; Male; Polymorphism,
	Single Nucleotide},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ard.2009.109579},
  pmid = {19435719},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1136/ard.2009.109579}
}

@TECHREPORT{Osborne:multiGPs07,
  author = {Michael A. Osborne and Stephen J. Roberts},
  title = {Gaussian Processes for Prediction},
  institution = {Department of Engineering Science, University of Oxford},
  year = {2007}
}

@INPROCEEDINGS{Rogers:towards08,
  author = {Michael A. Osborne and Alex Rogers and Sarvapali D. Ramchurn and
	Stephen J. Roberts and Nicholas R. Jennings},
  title = {Towards Real-Time Information Processing of Sensor Network Data using
	Computationally Efficient Multi-output {G}aussian Processes},
  booktitle = {Proceedings of the International Conference on Information Processing
	in Sensor Networks (IPSN 2008)},
  year = {2008}
}

@TECHREPORT{Osborne:gpreport2007,
  author = {Michael Osborne and Stephen J. Roberts},
  title = {Gaussian Processes for Prediction},
  institution = {Department of Engineering Science, University of Oxford},
  year = {2007}
}

@INPROCEEDINGS{Osuna:facedet97,
  author = {Edgar Osuna and Robert Freund and Federico Girosi},
  title = {Training Support Vector Machines: an Application to Face Detection},
  booktitle = pCVPR,
  year = {1997},
  pages = {130--136},
  month = {17--19 Jun.},
  publisher = ieeecomp,
  abstract = {We investigate the application of Support Vector Machines (SVMs) in
	computer vision. SVM is a learning technique developed by V. Vapnik
	and his team (AT\&T Bell Labs.) that can be seen as a new method
	for training polynomial, neural network, or Radial Basis Functions
	classifiers. The decision surfaces are found by solving a linearly
	constrained quadratic programming problem. This optimization problem
	is challenging because the quadratic form is completely dense and
	the memory requirements grow with the square of the number of data
	points.We present a decomposition algorithm that guarantees global
	optimality, and can be used to train SVM's over very large data sets.
	The main idea behind the decomposition is the iterative solution
	of sub-problems and the evaluation of optimality conditions which
	are used both to generate improved iterative values, and also establish
	the stopping criteria for the algorithm.We present experimental results
	of our implementation of SVM, and demonstrate the feasibility of
	our approach on a face detection problem that involves a data set
	of 50,000 data points.},
  doi = {10.1109/CVPR.1997.609310}
}

@INPROCEEDINGS{Owens:ode89,
  author = {A. J. Owens and D. L. Filkin},
  title = {Efficient training of the backpropagation network by solving a system
	of stiff ordinary differential equations},
  booktitle = ijcnn,
  year = {1989},
  volume = {2},
  pages = {381--386},
  address = {San Diego},
  publisher = {IEEE}
}

@INPROCEEDINGS{Padmanabhan:content00,
  author = {Venkata N. Padmanabhan and Lili Qiu},
  title = {The Content and Access Dynamics of a Busy Web Server},
  booktitle = {Extended abstract in Proceedings of ACM SIGMETRICS 2000},
  year = {2000}
}

@INPROCEEDINGS{Padmanabhan:contentb00,
  author = {Venkata N. Padmanabhan and Lili Qiu},
  title = {The Content and Access Dynamics of a Busy Web Site: Findings and
	Implications},
  booktitle = {ACM SIGCOMM 2000},
  year = {2000}
}

@INPROCEEDINGS{Pajunen:gtmica97,
  author = {P. Pajunen and J Karhunen},
  title = {A maximum likelihood approach to nonlinear blind source separation},
  booktitle = {Proceedings 1997 International Conference on Artificial Neural Networks,
	ICANN'97},
  year = {1997},
  pages = {541--546},
  address = {Lausanne, Switzerland}
}

@ARTICLE{Pan:survey10,
  author = {Sinno Jialin Pan and Qiang Yang},
  title = {A Survey on Transfer Learning},
  journal = {Knowledge and Data Engineering, IEEE Transactions on},
  year = {2010},
  volume = {22},
  pages = {1345 -1359},
  number = {10},
  month = {oct. },
  doi = {10.1109/TKDE.2009.191},
  issn = {1041-4347},
  keywords = {data mining;inductive transfer learning;knowledge transfer;machine
	learning;transductive transfer learning;unsupervised transfer learning;knowledge
	engineering;learning by example;optimisation;unsupervised learning;}
}

@ARTICLE{Papp:genomewide05,
  author = {Bal\'azs Papp and Stephen Oliver},
  title = {Genome-wide analysis of the context dependence of regulatory networks},
  journal = {Genome Biology},
  year = {2005},
  volume = {6},
  number = {2},
  abstract = {Genome-wide analytical tools are now allowing the discovery of the
	design rules that govern regulatory networks. Two recent studies
	in yeast have helped reveal the relatively small number of transcription-factor
	control strategies that cells employ to maximize their regulatory
	options using only a small number of components.},
  group = {yeast, gene networks}
}

@ARTICLE{Papritz:pseudo93,
  author = {Andreas J\"urg Papritz and Hans-Rudolf K\"{u}nsch and Richard Webster},
  title = {On the Pseudo Cross-variogram},
  journal = {Mathematical Geology},
  year = {1993},
  volume = {25},
  pages = {1015-1026},
  number = {8}
}

@ARTICLE{Park:rbf93,
  author = {J. Park and I. W. Sandberg},
  title = {Approximation and radial basis function networks},
  journal = NC,
  year = {1993},
  volume = {5},
  pages = {305--316},
  number = {2}
}

@ARTICLE{Park:rbf91,
  author = {J. Park and I. W. Sandberg},
  title = {Universal approximation using radial basis function networks},
  journal = NC,
  year = {1991},
  volume = {3},
  pages = {246--257},
  number = {2}
}

@INPROCEEDINGS{Park:applying07,
  author = {Sueng-Taek Park and David M. Pennock},
  title = {Applying Collaborative Filtering Techniques to Movie Search for Better
	Ranking and Browsing },
  booktitle = {13th ACM SIGKDD},
  year = {2007},
  file = {ft_gateway.cfm?id=1281252&type=pdf&coll=GUIDE&dl=GUIDE&CFID=29247597&CFTOKEN=33938639:http\://portal.acm.org/ft_gateway.cfm?id=1281252&type=pdf&coll=GUIDE&dl=GUIDE&CFID=29247597&CFTOKEN=33938639:PDF}
}

@TECHREPORT{Parker:bp85,
  author = {D. B. Parker},
  title = {Learning Logic},
  institution = {Cambridge, MA: MIT Center for Research in Computational Economics
	and Management Science},
  year = {1985},
  number = {TR-47}
}

@ARTICLE{Parts2011,
  author = {Leopold Parts and Oliver Stegle and John Winn and Richard Durbin},
  title = {Joint genetic analysis of gene expression data with inferred cellular
	phenotypes.},
  journal = {PLoS Genet},
  year = {2011},
  volume = {7},
  pages = {e1001276},
  number = {1},
  abstract = {Even within a defined cell type, the expression level of a gene differs
	in individual samples. The effects of genotype, measured factors
	such as environmental conditions, and their interactions have been
	explored in recent studies. Methods have also been developed to identify
	unmeasured intermediate factors that coherently influence transcript
	levels of multiple genes. Here, we show how to bring these two approaches
	together and analyse genetic effects in the context of inferred determinants
	of gene expression. We use a sparse factor analysis model to infer
	hidden factors, which we treat as intermediate cellular phenotypes
	that in turn affect gene expression in a yeast dataset. We find that
	the inferred phenotypes are associated with locus genotypes and environmental
	conditions and can explain genetic associations to genes in trans.
	For the first time, we consider and find interactions between genotype
	and intermediate phenotypes inferred from gene expression levels,
	complementing and extending established results.},
  doi = {10.1371/journal.pgen.1001276},
  institution = {Wellcome Trust Sanger Institute, Hinxton, Cambridge, United Kingdom.
	leopold.parts@sanger.ac.uk},
  keywords = {Algorithms; Biosynthetic Pathways, genetics; Data Interpretation,
	Statistical; Databases, Protein, statistics /&/ numerical data; Environment;
	Epistasis, Genetic, genetics; Gene Expression, genetics; Gene Regulatory
	Networks; Genetic Association Studies, statistics /&/ numerical data;
	Genetic Variation, genetics; Genotype; Models, Statistical; Phenotype;
	Quantitative Trait Loci, genetics; Saccharomyces cerevisiae, cytology/genetics},
  language = {eng},
  medline-pst = {epublish},
  owner = {neil},
  pmid = {21283789},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1371/journal.pgen.1001276}
}

@ARTICLE{Parzen:est62,
  author = {E. Parzen},
  title = {On estimation of a probability density function and mode},
  journal = AMS,
  year = {1962},
  volume = {33},
  pages = {1065--1076}
}

@MISC{Pawlowic:M_Map00,
  author = {Rich Pawlowicz},
  title = {M\_Map MATLAB Mapping Toolbox vs 1.3f},
  howpublished = {Available on-line.},
  year = {2000},
  label1 = {Website},
  link1 = {http://www2.ocgy.ubc.ca/~rich/private/mapug.html}
}

@INCOLLECTION{Pearl:causality95,
  author = {Judea Pearl},
  title = {From {B}ayesian Networks to Causal Networks},
  booktitle = {Probabilistic Reasoning and {B}ayesian Belief Networks},
  publisher = {Alfred Waller},
  year = {1995},
  editor = {A. Gammerman},
  pages = {1--31}
}

@ARTICLE{Pearl:belief93,
  author = {Judea Pearl},
  title = {Belief Networks Revisited},
  journal = {Artificial Intelligence},
  year = {1993},
  volume = {59},
  pages = {49--56}
}

@MISC{Pearl:causality93,
  author = {Judea Pearl},
  title = {Graphical Models, Causality and Intervention},
  year = {1993},
  note = {Contribution to the discussion of Spiegelhalter et al.},
  pages = {266--269}
}

@ARTICLE{Pearl:fusion86,
  author = {Judea Pearl},
  title = {Fusion, Propagation, and Structuring in Belief Networks},
  journal = {Artificial Intelligence},
  year = {1986},
  volume = {29},
  pages = {241--288}
}

@ARTICLE{Pearlmutter:hess94,
  author = {Barak A. Pearlmutter},
  title = {Fast exact multiplication by the {H}essian},
  journal = NC,
  year = {1994},
  volume = {6},
  pages = {147--160},
  number = {1}
}

@INPROCEEDINGS{Pearlmutter:ica96,
  author = {Barak A. Pearlmutter and L. C. Parra},
  title = {A context-sensitive generalization of {ICA}},
  booktitle = {International Conference on Neural Information Processing},
  year = {1996},
  notes = {To appear.}
}

@ARTICLE{Pearson:01,
  author = {Karl Pearson},
  title = {On lines and planes of closest fit to systems of points in space},
  journal = {The London, Edinburgh and Dublin Philosophical Magazine and Journal
	of Science, Sixth Series},
  year = {1901},
  volume = {2},
  pages = {559--572},
  linkpdf = {http://stat.smmu.edu.cn/history/pearson1901.pdf}
}

@ARTICLE{Pearson:golden08,
  author = {Richard D. Pearson},
  title = {A comprehensive re-analysis of the Golden Spike data: towards a benchmark
	for differential expression methods},
  journal = {BMC Bioinformatics},
  year = {2008},
  volume = {9},
  number = {164},
  abstract = {BACKGROUND: The Golden Spike data set has been used to validate a
	number of methods for summarizing Affymetrix data sets, sometimes
	with seemingly contradictory results. Much less use has been made
	of this data set to evaluate differential expression methods. It
	has been suggested that this data set should not be used for method
	comparison due to a number of inherent flaws. \\\\ 
	
	 RESULTS: We have used this data set in a comparison of methods which
	is far more extensive than any previous study. We outline six stages
	in the analysis pipeline where decisions need to be made, and show
	how the results of these decisions can lead to the apparently contradictory
	results previously found. We also show that, while flawed, this data
	set is still a useful tool for method comparison, particularly for
	identifying combinations of summarization and differential expression
	methods that are unlikely to perform well on real data sets. We describe
	a new benchmark, AffyDEComp, that can be used for such a comparison.
	\\\\
	
	 CONCLUSION: We conclude with recommendations for preferred Affymetrix
	analysis tools, and for the development of future spike-in data sets.},
  doi = {10.1186/1471-2105-9-164},
  file = {1471-2105-9-164.pdf:http\://www.biomedcentral.com/content/pdf/1471-2105-9-164.pdf:PDF},
  group = {microarray, puma},
  pmid = {18366762}
}

@ARTICLE{Pelletier:fitting04,
  author = {Bernard Pelletier and Pierre Dutilleul and Guillaume Larocque and
	James W. Fyles},
  title = {Fitting the linear model of coregionalization by Generalized least
	squares},
  journal = {Mathematical Geology},
  year = {2004},
  volume = {36},
  pages = {323-343},
  number = {3}
}

@ARTICLE{Penny:evidence98,
  author = {William D. Penny and Stephen J. Roberts},
  title = {{B}ayesian Neural Networks for Classification: How Useful is the
	Evidence Framework?},
  journal = {Neural Networks},
  year = {1999},
  volume = {12},
  pages = {877--892},
  linkpsgz = {http://scholar.google.com/url?sa=U&q=http://www.robots.ox.ac.uk/~sjrob/Pubs/evidence-tech.ps.gz}
}

@ARTICLE{Perantonis:inv92,
  author = {S. J. Perantonis and P. J. G. Lisboa},
  title = {Translation, rotation, and scale invariant pattern recognition by
	high-order neural networks and moment classifiers},
  journal = IEEE,
  year = {1992},
  volume = {3},
  pages = {241--251},
  number = {2}
}

@ARTICLE{Perkins:reverse06,
  author = {Theodore J. Perkins and Johannes Jaeger and John Reinitz and Leon
	Glass},
  title = {Reverse Engineering the Gap Gene Network of {D}rosophila melanogaster},
  journal = {PLoS Comput Biol},
  year = {2006},
  volume = {2},
  pages = {e51},
  number = {5},
  month = {May},
  abstract = {A fundamental problem in functional genomics is to determine the structure
	and dynamics of genetic networks based on expression data. We describe
	a new strategy for solving this problem and apply it to recently
	published data on early Drosophila melanogaster development. Our
	method is orders of magnitude faster than current fitting methods
	and allows us to fit different types of rules for expressing regulatory
	relationships. Specifically, we use our approach to fit models using
	a smooth nonlinear formalism for modeling gene regulation (gene circuits)
	as well as models using logical rules based on activation and repression
	thresholds for transcription factors. Our technique also allows us
	to infer regulatory relationships de novo or to test network structures
	suggested by the literature. We fit a series of models to test several
	outstanding questions about gap gene regulation, including regulation
	of and by hunchback and the role of autoactivation. Based on our
	modeling results and validation against the experimental literature,
	we propose a revised network structure for the gap gene system. Interestingly,
	some relationships in standard textbook models of gap gene regulation
	appear to be unnecessary for or even inconsistent with the details
	of gap gene expression during wild-type development.},
  doi = {10.1371/journal.pcbi.0020051},
  file = {?request=get-pdf&file=10.1371_journal.pcbi.0020051-L.pdf:http\://compbiol.plosjournals.org/perlserv/?request=get-pdf&file=10.1371_journal.pcbi.0020051-L.pdf:PDF},
  group = {gene networks, Drosophila},
  pmid = {16710449}
}

@ARTICLE{Perrin:genenetworks03,
  author = {B. Perrin and L. Ralaivola and A. Mazurie and S. Bottani and J. Mallet
	and F. {D'Alche-Buc}},
  title = {Gene networks inference using dynamic {B}ayesian networks},
  journal = bioinf,
  year = {2003},
  volume = {19 (Suppl 2)},
  pages = {II138--II148},
  group = {gene networks}
}

@INPROCEEDINGS{Perrone:committee94,
  author = {M. P. Perrone},
  title = {General averaging results for convex optimization},
  booktitle = {Proceedings 1993 Connectionist Models Summer School},
  year = {1994},
  editor = {Michael C. Mozer and others},
  pages = {364--371},
  address = {Hillsdale, NJ},
  publisher = {Lawrence Erlbaum}
}

@INPROCEEDINGS{Perrone:disagree94,
  author = {M. P. Perrone and L. N. Cooper},
  title = {When networks disagree: ensemble methods for hybrid neural networks},
  booktitle = {Artificial Neural Networks for Speech and Vision},
  year = {1993},
  editor = {R. J. Mammone},
  pages = {126--142},
  address = {London},
  publisher = {Chapman and Hall}
}

@ARTICLE{Peterson:meanfield87,
  author = {C. Peterson and J. R. Anderson},
  title = {A mean field learning algorithm for neural networks},
  journal = {Complex Systems},
  year = {1987},
  volume = {1},
  pages = {995--1019}
}

@ARTICLE{Peterson:studyvow52,
  author = {G. E. Peterson and H. L. Barney},
  title = {Control Methods used in a Study of the Vowels},
  journal = {Journal of the Acoustic Soceity, America},
  year = {1952},
  volume = {24},
  pages = {175--194},
  number = {2}
}

@ARTICLE{Pic:forkhead00,
  author = {Aline Pic and Fei-Ling Lim and Sarah J. Ross and Elizabeth A. Veal
	and Anthony L. Johnson and Mohammad R. A. Sultan and Adam G. West
	and Leland H. Johnston and Andrew D. Sharrocks and Brian A. Morgan},
  title = {The Forkhead Protein Fkh2 is a component of the yeast cell cycle
	transcription factor SFF},
  journal = {The EMBO Journal},
  year = {2000},
  volume = {19},
  pages = {3750--3761},
  number = {14},
  group = {yeast}
}

@ARTICLE{Pillai:kernelHilbert07,
  author = {Natesh S. Pillai and Qiang Wu and Feng Liang and Sayan Mukherjee
	and Robert L. Wolpert},
  title = {Characterizing the Function Space for {B}ayesian Kernel Models},
  journal = jmlr,
  year = {2007},
  volume = {8},
  pages = {1769-1797}
}

@ARTICLE{Pinney:reconstruction07,
  author = {J. Pinney and G. Amoutzias and M. Rattray and D. Robertson },
  title = {Reconstruction of ancestral protein interaction networks for the
	bZIP transcription factors},
  journal = pnasusa,
  year = {2007},
  volume = {104},
  number = {51},
  group = {mlo}
}

@ARTICLE{Plamondon:survey00,
  author = {R. Plamondon and S. N. Srihari},
  title = {Online and off-line handwriting recognition: a comprehensive survey},
  journal = PAMI,
  year = {2000},
  volume = {22},
  pages = {63--84},
  number = {1},
  abstract = {Handwriting has continued to persist as a means of communication and
	recording information in day-to-day life even with the introduction
	of new technologies. Given its ubiquity in human transactions, machine
	recognition of handwriting has practical significance, as in reading
	handwritten notes in a PDA, in postal addresses on envelopes, in
	amounts in bank checks, in handwritten fields in forms, etc. This
	overview describes the nature of handwritten language, how it is
	transduced into electronic data, and the basic concepts behind written
	language recognition algorithms. Both the online case (which pertains
	to the availability of trajectory data during writing) and the off-line
	case (which pertains to scanned images) are considered. Algorithms
	for preprocessing, character and word recognition, and performance
	with practical systems are indicated. Other fields of application,
	like signature verification, writer authentification, handwriting
	learning tools are also considered},
  group = {hand writing},
  label1 = {IEEE Xplore},
  link1 = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=824821}
}

@TECHREPORT{Platt:nystrom04,
  author = {John C. Platt},
  title = {{FastMap}, {MetricMap} and Landmark {MDS} are all {N}ystr\"om Algorithms},
  institution = {Microsoft Research},
  year = {2004},
  number = {MSR-TR-2004-26},
  file = {TR-2004-26.pdf:ftp\://ftp.research.microsoft.com/pub/tr/TR-2004-26.pdf:PDF}
}

@TECHREPORT{Plaut:mom86,
  author = {D. Plaut and S. Nowlan and G. E. Hinton},
  title = {Experiments on learning by back propagation},
  institution = {Department of Computer Science, Carnegie Mellon University, Pittsburgh,
	PA},
  year = {1986},
  number = {CMU-CS-86-126}
}

@ARTICLE{Poggio:approx90,
  author = {Tomaso Poggio and Federico Girosi},
  title = {Networks for Approximation and Learning},
  journal = {Proceedings of the IEEE},
  year = {1990},
  volume = {78},
  pages = {1481--1497},
  number = {9},
  abstract = {The problem of the approximation of nonlinear mapping, (especially
	continuous mappings) is considered. Regularization theory and a theoretical
	framework for approximation (based on regularization techniques)
	that leads to a class of three-layer networks called regularization
	networks are discussed. Regularization networks are mathematically
	related to the radial basis functions, mainly used for strict interpolation
	tasks. Learning as approximation and learning as hypersurface reconstruction
	are discussed. Two extensions of the regularization approach are
	presented, along with the approach's corrections to splines, regularization,
	Bayes formulation, and clustering. The theory of regularization networks
	is generalized to a formulation that includes task-dependent clustering
	and dimensionality reduction. Applications of regularization networks
	are discussed.},
  group = {spgp},
  label1 = {IEEE Xplore},
  link1 = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?tp=&arnumber=58326&isnumber=2115}
}

@ARTICLE{Poggio:reg90,
  author = {T. Poggio and F. Girosi},
  title = {Regularization algorithms for learning that are equivalent to multilayer
	networks},
  journal = {Science},
  year = {1990},
  volume = {247},
  pages = {978--982}
}

@ARTICLE{Poggio:vis85,
  author = {T. Poggio and V. Torre and C. Koch},
  title = {Computational vision and regularization theory},
  journal = {Nature},
  year = {1985},
  volume = {317},
  pages = {314--319},
  number = {26}
}

@INBOOK{Popper:science63,
  chapter = {1},
  title = {Science: Conjectures and Refutations},
  crossref={Popper:conjectures63},
}

@ARTICLE{Potter2009,
  author = {C. Potter and K. L. Hyrich and A. Tracey and M. Lunt and D. Plant
	and D. P M Symmons and W. Thomson and J. Worthington and P. Emery
	and A. W. Morgan and A. G. Wilson and J. Isaacs and A. Barton and
	B. R. A. G. G. S. S.},
  title = {Association of rheumatoid factor and anti-cyclic citrullinated peptide
	positivity, but not carriage of shared epitope or PTPN22 susceptibility
	variants, with anti-tumour necrosis factor response in rheumatoid
	arthritis.},
  journal = {Ann Rheum Dis},
  year = {2009},
  volume = {68},
  pages = {69--74},
  number = {1},
  month = {Jan},
  abstract = {To determine whether rheumatoid factor (RF), anti-cyclic citrullinated
	peptide (CCP) antibodies, or carriage of shared epitope (SE) and
	PTPN22 genetic susceptibility variants predict response to therapy
	in patients with rheumatoid arthritis (RA) treated with anti-tumour
	necrosis factor (TNF) agents.UK-wide multicentre collaborations were
	established to recruit a large cohort of patients treated with anti-TNF
	drugs for RA. Serum RF, anti-CCP antibody and SE status were determined
	using commercially available kits. PTPN22 R620W genotyping was performed
	by Sequenom MassArray. Linear regression analyses were performed
	to investigate the role of these four factors in predicting response
	to treatment by 6 months, defined as the absolute change in 28-joint
	Disease Activity Score (DAS28).Of the 642 patients analysed, 46\%
	received infliximab, 43\% etanercept and 11\% adalimumab. In all,
	89\% and 82\% of patients were RF and anti-CCP positive, respectively.
	Patients that were RF negative had a 0.48 (95\% CI 0.08 to 0.87)
	greater mean improvement in DAS28 compared to patients that were
	RF positive. A better response was also seen among patients that
	were anti-CCP negative. No association was demonstrated between drug
	response and SE or PTPN22 620W carriage.The presence of RF or anti-CCP
	antibodies was associated with a reduced response to anti-TNF drugs.
	However, these antibodies only account for a small proportion of
	the variance in treatment response. It is likely that genetic factors
	will contribute to treatment response, but these do not include the
	well established RA susceptibility loci, SE and PTPN22.},
  doi = {10.1136/ard.2007.084715},
  institution = {Arthritis Research Campaign Epidemiology Unit, University of Manchester,
	Manchester, UK.},
  keywords = {Aged; Alleles; Antirheumatic Agents, therapeutic use; Arthritis, Rheumatoid,
	blood/drug therapy/genetics; Autoantibodies, blood; Epitopes; Female;
	Follow-Up Studies; Genetic Predisposition to Disease; Great Britain;
	HLA-DR Antigens, analysis; Humans; Immunoglobulin G, therapeutic
	use; Linear Models; Male; Middle Aged; Peptides, Cyclic, immunology;
	Protein Tyrosine Phosphatase, Non-Receptor Type 22, genetics; Receptors,
	Tumor Necrosis Factor, therapeutic use; Rheumatoid Factor, blood;
	Severity of Illness Index; Tumor Necrosis Factor-alpha, antagonists
	/&/ inhibitors},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ard.2007.084715},
  pmid = {18375541},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1136/ard.2007.084715}
}

@MISC{Poustelnikova:flyex06,
  author = {Ekaterina Poustelnikova and Andrei Pisarev and Maxim Blagov and Maria
	Samsonova and John Reinitz},
  title = {{FlyEx} Database},
  howpublished = {\url{http://urchin.spbcas.ru/flex}},
  year = {2006}
}
@MISC{Jaeger:mRNA06,
  author = {Johanes Jaeger},
  howpublished = {\url{http://flyex.ams.sunysb.edu/lab/gaps.html}}
}

@ARTICLE{Poustelnikova:database04,
  author = {Ekaterina Poustelnikova and Andrei Pisarev and Maxim Blagov and Maria
	Samsonova and and John Reinitz},
  title = {A database for management of gene expression data \emph{in situ}},
  journal = bioinf,
  year = {2004},
  volume = {20},
  pages = {2212--2221},
  number = {14},
  abstract = {{\bf Motivation}: To create a spatiotemporal atlas of \emph{Drosophila}
	segmentation gene expression at cellular resolution.\\\\
	
	 {\bf Results}: The expression of segmentation genes plays a crucial
	role in the establishment of the \emph{Drosophila} body plan. Using
	the IBM DB2 Relational Database Management System we have designed
	and implemented the FlyEx database. FlyEx contains 2832 images of
	14 segmentation gene expression patterns obtained from 954 embryos
	and 2 073 662 quantitative data records. The averaged data is available
	for most of segmentation genes at eight time points. FlyEx supports
	operations on images of gene expression patterns. The database can
	be used to examine the quality of data, analyze the dynamics of formation
	of segmentation gene expression domains, as well as estimate the
	variability of gene expression patterns. We also provide the capability
	to download data of interest.\\\\
	
	 {\bf Availability}: \url{http://urchin.spbcas.ru/flyex}, \url{http://flyex.ams.sunysb.edu/flyex}\\\\
	
	 {\bf Contact}: samson@spbcas.ru},
  file = {bth222v1.pdf:http\://scholar.google.com/url?sa=U&q=http\://www.bioinformatics.oupjournals.org/cgi/reprint/bth222v1.pdf:PDF},
  group = {Drosophila, databases},
  pmid = {15059825}
}

@INPROCEEDINGS{Powell:rbf88,
  author = {M. J. D. Powell},
  title = {Radial basis function approximations to polynomials},
  booktitle = {Numerical Analysis 1987 Proceedings},
  year = {1988},
  editor = {D. F. Griffiths and G. A. Watson},
  pages = {223--241},
  address = {New York},
  publisher = {Longman}
}

@INPROCEEDINGS{Powell:rbfs87,
  author = {M. J. D. Powell},
  title = {Radial basis functions for multivariable interpolation: a review},
  booktitle = {Algorithms for Approximation},
  year = {1987},
  editor = {J. C. Mason and M. G. Cox},
  pages = {143--167},
  address = {Oxford},
  publisher = {Clarendon Press}
}

@ARTICLE{Powell:restart77,
  author = {M. J. D. Powell},
  title = {Restart procedures for the conjugate gradient method},
  journal = {Mathematical Programming},
  year = {1977},
  volume = {12},
  pages = {241--254}
}

@INPROCEEDINGS{Priacuriu:nonlinear11,
  author = {Victor Priacuriu and Ian D Reid},
  title = {Nonlinear Shape Manifolds as Shape Priors in Level set Segmentation
	and Tracking},
  booktitle = pCVPR,
  year = {2011}
}

@INPROCEEDINGS{Priacuriu:shared11,
  author = {Victor Priacuriu and Ian D Reid},
  title = {Shared Shape Spaces},
  booktitle = iccv,
  year = {2011}
}

@INPROCEEDINGS{Prisacariu:contour11,
  author = {Victor Prisacariu and Ian Reid},
  booktitle = iccv,
  optyear = {2011}
}

@PHDTHESIS{Qazaz:thesis97,
  author = {Cazhaow S. Qazaz},
  title = {{B}ayesian Error Bars for Regression},
  school = {Aston Univerity},
  year = {1997},
  address = {Birmingham, U.K.}
}

@ARTICLE{Qian:gaussian08,
  author = {Peter Z. G. Qian and Huaiqing Wu and C. F. Jeff Wu},
  title = {Gaussian process models for computer experiments with qualitative
	and quantitative factors},
  journal = {Technometrics},
  year = {2008},
  volume = {50},
  pages = {383-396},
  number = {3}
}

@ARTICLE{Quinonero:unifying05,
  author = {Joaquin {Qui\~nonero Candela} and Carl Edward Rasmussen},
  title = {A Unifying View of Sparse Approximate {G}aussian Process Regression},
  journal = jmlr,
  year = {2005},
  volume = {6},
  pages = {1939--1959},
  abstract = {We provide a new unifying view, including all existing proper probabilistic
	sparse approximations for Gaussian process regression. Our approach
	relies on expressing the \emph{effective prior} which the methods
	are using. This allows new insights to be gained, and highlights
	the relashionship between existing methods. It also allows for a
	clear theoretically justified ranking of the closeness of the known
	approximations to the corresponding full GPs. Finally we point directly
	to designs of new better sparse approximations, combining the best
	of the existing strategies, within attractive computational constraints.},
  file = {quinonero-candela05a.pdf:http\://jmlr.csail.mit.edu/papers/volume6/quinonero-candela05a/quinonero-candela05a.pdf:PDF},
  group = {spgp}
}

@INCOLLECTION{Quinonero:analysis05,
  author = {Joaquin {Qui\~nonero-Candela} and Carl Edward Rasmussen},
  title = {Analysis of some methods for reduced rank {G}aussian process regression},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer},
  year = {2005},
  editor = {R. Murray-Smith and R. Shorten},
  volume = {3355},
  pages = {98-127}
}

@ARTICLE{Quinlan:tree86,
  author = {J. R. Quinlan},
  title = {Induction of decision trees},
  journal = {Machine Learning},
  year = {1986},
  volume = {1},
  pages = {81--106}
}

@ARTICLE{Raetsch:soft01,
  author = {Gunnar R\"atsch and T. Onoda and Klaus-Robert M\"uller},
  title = {Soft Margins for AdaBoost},
  journal = {Machine Learning},
  year = {2001},
  volume = {42},
  pages = {287--320},
  number = {3},
  linkpsgz = {http://ida.first.gmd.de/~raetsch/ps/RaeOnoMue00a.ps.gz}
}

@ARTICLE{Rabiner:hmm89,
  author = {L. R. Rabiner},
  title = {A Tutorial on Hidden {M}arkov Models and Selected Applications in
	Speech Recognition},
  journal = {Proceedings of the IEEE},
  year = {1989},
  volume = {77},
  pages = {257--285},
  number = {2}
}

@INPROCEEDINGS{Ramanan:finding03,
  author = {Deva Ramanan and David A. Forsyth},
  title = {Finding and Tracking People from the Bottom Up},
  booktitle = pCVPR,
  year = {2003},
  volume = {2},
  pages = {467--474},
  address = {Madison, Wisconsin, U.S.A.},
  month = {18--20 Jun.},
  publisher = ieeecomp,
  abstract = {We describe a tracker that can track moving people in long sequences
	without manual initialization. Moving people are modeled with the
	assumption that, while configuration can vary quite substantially
	from frame to frame, appearance does not. This leads to an algorithm
	that firstly builds a model of the appearance of the body of each
	individual by clustering candidate body segments, and then uses this
	model to find all individuals in each frame. Unusually, the tracker
	does not rely on a model of human dynamics to identify possible instances
	of people; such models are unreliable, because human motion is fast
	and large accelerations are common. We show our tracking algorithm
	can be interpreted as a loopy inference procedure on an underlying
	Bayes net. Experiments on video of real scenes demonstrate that this
	tracker can (a) count distinct individuals; (b) identify and track
	them; (c) recover when it loses track, for example, if individuals
	are occluded or briefly leave the view; (d) identify the configuration
	of the body largely correctly; and (e) is not dependent on particular
	models of human motion.},
  file = {ramanan-cvpr03.pdf:http\://www.eecs.berkeley.edu/Research/Projects/CS/vision/human/ramanan-cvpr03.pdf:PDF},
  group = {tracking, pose estimation, tree}
}

@ARTICLE{Ramsay:parameter07,
  author = {J. O. Ramsay and G. Hooker and D. Campbell and J. Cao},
  title = {Parameter estimation for differential equations: a generalized smoothing
	approach},
  journal = JRSSb,
  year = {2007},
  volume = {69},
  pages = {741--796},
  number = {56},
  month = {Nov},
  group = {collocation}
}

@ARTICLE{Rao:55,
  author = {C. R. Rao},
  title = {Estimation and tests of significance in factor analysis},
  journal = {Psychometrika},
  year = {1955},
  volume = {20},
  pages = {93-111}
}

@MISC{Rasmussen:speed03,
  author = {Carl Edward Rasmussen},
  title = {Gaussian processes to speed up Hybrid {M}onte {C}arlo for expensive
	{B}ayesian integrals},
  howpublished = {Available on-line.},
  year = {2003},
  linkpsgz = {http://www.gatsby.ucl.ac.uk/\~{ }edward/pub/gphmc.ps.gz}
}

@PHDTHESIS{Rasmussen:thesis96,
  author = {Carl Edward Rasmussen},
  title = {Evaluation of {G}aussian Processes and Other Methods for Nonlinear
	Regression},
  school = {University of Toronto},
  year = {1996},
  linkpsgz = {ftp://ftp.cs.toronto.edu/pub/carl/thesis.ps.gz}
}

@INPROCEEDINGS{Quinonero:healing05,
  author = {Carl E. Rasmussen and Joaquin {Qui\~nonero Candela}},
  title = {Healing the Relevance Vector Machine through Augmentation},
  note = {To appear at ICML 2005},
  linkps = {http://www.kyb.mpg.de/publications/pss/ps2576.ps}
}

@ARTICLE{Redner:EM84,
  author = {R. A. Redner and H. F. Walker},
  title = {Mixture densities, maximum likelihood and the {EM} algorithm},
  journal = {SIAM Review},
  year = {1984},
  volume = {26},
  pages = {195--239},
  number = {2}
}

@ARTICLE{Reed:jitter95,
  author = {R. Reed and R. J. {Marks II} and S. Oh},
  title = {Similarities of error regularization, sigmoid gain scaling, target
	smoothing, and training with jitter},
  journal = IEEE,
  year = {1995},
  volume = {6},
  pages = {529--538},
  number = {3}
}

@INPROCEEDINGS{Reid:honn89,
  author = {M. B. Reid and L. Spirkovska and E. Ochoa},
  title = {Rapid training of higher-order neural networks for invariant pattern
	recognition},
  booktitle = ijcnn,
  year = {1989},
  volume = {1},
  pages = {689--692},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@ARTICLE{Richard:bayes91,
  author = {M. D. Richard and R. P. Lippmann},
  title = {Neural network classifiers estimate {B}ayesian a-posteriori probabilities
	},
  journal = NC,
  year = {1991},
  volume = {3},
  pages = {461--483},
  number = {4}
}

@ARTICLE{Domingos:markovlogic06,
  author = {Matt Richardson and Pedro Domingos},
  title = {Markov Logic Networks},
  journal = {Machine Learning},
  year = {2006},
  pages = {107--136},
  abstract = {We consider problems involving groups of data, where each observation
	within a group is a draw from a mixture model, and where it is desirable
	to share mixture components between groups. We assume that the number
	of mixture components is unknown a priori and is to be inferred from
	the data. In this setting it is natural to consider sets of Dirichlet
	processes, one for each group, where the well-known clustering property
	of the Dirichlet process provides a nonparametric prior for the number
	of mixture componentswithin each group. Given our desire to tie the
	mixture models in the various groups, we consider a hierarchical
	model, specifically one in which the base measure for the child Dirichlet
	processes is itself distributed according to a Dirichlet process.
	Such a base measure being discrete, the child Dirichlet processes
	necessarily share atoms. Thus, as desired, the mixture models in
	the different groups necessarily share mixture components. We discuss
	representations of hierarchical Dirichlet processes in terms of a
	stick-breaking process, and a generalization of the Chinese restaurant
	process that we refer to as the âChinese restaurant franchise.â We
	present Markov chain Monte Carlo algorithms for posterior inference
	in hierarchical Dirichlet process mixtures, and describe applications
	to problems in information retrieval and text modelling.},
  file = {mlj05.pdf:http\://www.cs.washington.edu/homes/pedrod/papers/mlj05.pdf:PDF},
  group = {Markov logic networks}
}

@INPROCEEDINGS{Ricotti:2bp88,
  author = {L. P. Ricotti and S. Ragazzini and G. Martinelli},
  title = {Learning of word stress in a sub-optimal secondorder backpropagation
	neural network},
  booktitle = {Proceedings of the IEEE International Conference on Neural Networks},
  year = {1988},
  volume = {1},
  pages = {355--361},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@ARTICLE{Rioja2008,
  author = {Inmaculada Rioja and Fiona J Hughes and Catriona H Sharp and Linda
	C Warnock and Doug S Montgomery and Mohammed Akil and Anthony G Wilson
	and Michael H Binks and Marion C Dickson},
  title = {Potential novel biomarkers of disease activity in rheumatoid arthritis
	patients: CXCL13, CCL23, transforming growth factor alpha, tumor
	necrosis factor receptor superfamily member 9, and macrophage colony-stimulating
	factor.},
  journal = {Arthritis Rheum},
  year = {2008},
  volume = {58},
  pages = {2257--2267},
  number = {8},
  month = {Aug},
  abstract = {To determine whether the plasma levels of a range of inflammatory
	proteins have utility as biomarkers of disease activity in rheumatoid
	arthritis (RA) patients.Plasma proteins (n = 163) were profiled in
	44 patients with RA diagnosed according to the American College of
	Rheumatology 1987 criteria (22 with active and 22 with quiescent
	disease) and in 16 age- and sex-matched healthy controls. The utility
	of a subset of differentially expressed proteins as predictors of
	RA disease activity was investigated using partial least-squares
	discriminant analysis, and their response to therapeutic intervention
	was evaluated in plasma from an additional cohort of 16 patients
	with active RA treated with anti-tumor necrosis factor alpha (anti-TNFalpha).The
	protein profiling study identified 25 proteins that were differentially
	expressed in plasma samples from patients with active RA (P for the
	false discovery rate < or = 0.01) compared with those with quiescent
	RA, including the previously described interleukin-6 (IL-6), oncostatin
	M, and IL-2, and the 5 less-established markers macrophage colony-stimulating
	factor (M-CSF), tumor necrosis factor receptor superfamily member
	9, CCL23, transforming growth factor alpha, and CXCL13. Systemic
	levels of these 5 markers correlated with the C-reactive protein
	level, erythrocyte sedimentation rate, rheumatoid factor level, tender
	joint count in 68 joints, and Disease Activity Score in 28 joints
	(DAS28), and their combined plasma levels were shown to be good predictors
	of disease activity (kappa = 0.64). In anti-TNFalpha-treated RA patients,
	plasma levels of CXCL13 were reduced after 1 and 7 days of therapy,
	and levels of CCL23, M-CSF, and CXCL13 showed a statistically significant
	positive correlation with the DAS28 score.This exploratory study
	for biomarker discovery led to the identification of several proteins
	predictive of RA disease activity that may be useful in the definition
	of disease subphenotypes and in the measurement of response to therapy
	in clinical studies.},
  doi = {10.1002/art.23667},
  institution = {GlaxoSmithKline, Stevenage, UK.},
  keywords = {Adult; Aged; Aged, 80 and over; Antigens, CD137, blood; Antirheumatic
	Agents, therapeutic use; Arthritis, Rheumatoid, blood/diagnosis/drug
	therapy; Biological Markers, blood; Case-Control Studies; Chemokine
	CXCL13, blood; Chemokines, CC, blood; Female; Humans; Macrophage
	Colony-Stimulating Factor, blood; Male; Middle Aged; Predictive Value
	of Tests; Severity of Illness Index; Transforming Growth Factor alpha,
	blood; Treatment Outcome; Tumor Necrosis Factor-alpha, antagonists
	/&/ inhibitors},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {18668547},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1002/art.23667}
}

@ARTICLE{Ripley:rss94,
  author = {Brian D. Ripley},
  title = {Neural networks and related methods for classification},
  journal = JRSSb,
  year = {1994},
  volume = {56},
  pages = {409--456},
  number = {3}
}

@ARTICLE{Rissanen:mdl78,
  author = {J. Rissanen},
  title = {Modelling by shortest data description},
  journal = {Automatica},
  year = {1978},
  volume = {14},
  pages = {465--471}
}

@INPROCEEDINGS{Ritter:psoms93,
  author = {H. Ritter},
  title = {Parametrized self-organizing maps},
  booktitle = {Proceedings ICANN'93 International Conference on Artificial Neural
	Networks},
  year = {1993},
  pages = {568--575},
  address = {Amsterdam},
  publisher = springer
}

@ARTICLE{Ritter:asymptotic91,
  author = {R. Ritter},
  title = {Asymptotic level density for a class of vector quantization processes},
  journal = IEEE,
  year = {1991},
  volume = {2},
  pages = {173--175},
  number = {1}
}

@ARTICLE{Ritter:converge88,
  author = {R. Ritter and K. Schulten},
  title = {Convergence properties of {K}ohonen's topology conserving maps: fluctuations,
	stability and dimension selection},
  journal = {Biological Cybernetics},
  year = {1988},
  volume = {60},
  pages = {69--71}
}

@ARTICLE{Ritter:stationary86,
  author = {R. Ritter and K. Schulten},
  title = {On the stationary state of {K}ohonen's self-organizing sensory mapping},
  journal = {Biological Cybernetics},
  year = {1986},
  volume = {54},
  pages = {99--106}
}

@ARTICLE{Rivolta2002,
  author = {Marcelo N. Rivolta and Antony Halsall and Claire M. Johnson and Michael
	A. Tones and Matthew C. Holley},
  title = {Transcript profiling of functionally related groups of genes during
	conditional differentiation of a mammalian cochlear hair cell line},
  journal = {Genome Res},
  year = {2002},
  volume = {12},
  pages = {1091--1099},
  number = {7},
  month = {Jul},
  abstract = {We have used Affymetrix high-density gene arrays to generate a temporal
	profile of gene expression during differentiation of UB/OC-1, a conditionally
	immortal cell line derived from the mouse cochlea. Gene expression
	was assessed daily for 14 days under differentiating conditions.
	The experiment was replicated in two separate populations of cells.
	Profiles for selected genes were correlated with those obtained by
	RT-PCR, TaqMan analysis, immunoblotting, and immunofluorescence.
	The results suggest that UB/OC-1 is derived from a population of
	nonsensory epithelial cells in the greater epithelial ridge that
	have the potential to differentiate into a hair-cell-like phenotype,
	without the intervention of Math1. Elements of the Notch signaling
	cascade were identified, including the receptor Notch3, with a transient
	up-regulation that suggests a role in hair cell differentiation.
	Several genes showed a profile similar to Notch3, including the transcriptional
	co-repressor Groucho1. UB/OC-1 also expressed Me1, a putative partner
	of Math1 that may confer competence to differentiate into hair cells.
	Cluster analysis revealed expression profiles for neural guidance
	genes associated with Gata3. The temporal dimension of this analysis
	provides a powerful tool to study genetic mechanisms that underlie
	the conversion of nonsensory epithelial cells into hair cells.},
  doi = {10.1101/gr.225602},
  institution = {Institute of Molecular Physiology, Department of Biomedical Sciences,
	University of Sheffield, Sheffield S10 2TN, United Kingdom. m.n.rivolta@sheffield.ac.uk},
  keywords = {Animals; Cell Differentiation; Cell Division; Cell Line; Cochlear
	Duct; Gene Expression Profiling; Genes; Hair Cells, Auditory; Membrane
	Proteins; Mice; Multigene Family; Oligonucleotide Array Sequence
	Analysis; Receptors, Cell Surface; Receptors, Notch; Signal Transduction;
	Temperature},
  owner = {neil},
  pmid = {12097346},
  timestamp = {2010.04.12}
}

@ARTICLE{Robbins:stoch51,
  author = {H. Robbins and S. Monro},
  title = {A stochastic approximation method},
  journal = {Annals of Mathematical Statistics},
  year = {1951},
  volume = {22},
  pages = {400--407}
}

@ARTICLE{Roberts:rannovelty94,
  author = {Stephen Roberts and Lionel Tarassenko},
  title = {A probabilistic resource allocating network for novelty detection},
  journal = NC,
  year = {1994},
  volume = {6},
  pages = {270--284},
  number = {2},
  label1 = {ACM Digital Library},
  link1 = {http://portal.acm.org/citation.cfm?id=188104.188116&dl=portal&dl=ACM}
}

@ARTICLE{Roberts:novel94,
  author = {Stephen J. Roberts and L. Tarassenko},
  title = {A probabilistic resource allocating network for novelty detection},
  journal = NC,
  year = {1994},
  volume = {6},
  pages = {270--284},
  number = {2}
}

@MISC{Rogers:model06a,
  author = {Simon Rogers and Mark Girolami},
  title = {Model Based Identification of Transcription Factor Regulatory Activity
	via {M}arkov Chain {M}onte {C}arlo},
  howpublished = {Presentation at MASAMB '06},
  year = {2006},
  group = {gene networks}
}

@INPROCEEDINGS{Rogers:model06b,
  author = {Simon Rogers and Raya Khanin and Mark Girolami},
  title = {Model Based Identification of Transcription Factor Activity from
	Microarray Data},
  booktitle = {Probabilistic Modeling and Machine Learning in Structural and Systems
	Biology},
  year = {2006},
  address = {Tuusula, Finland},
  month = {17-18th June},
  file = {rogers_et_al.pdf:http\://www.cs.helsinki.fi/group/bioinfo/events/pmsb06/final/rogers_et_al.pdf:PDF},
  group = {gene networks}
}

@ARTICLE{Rosenblatt:dens56,
  author = {M. Rosenblatt},
  title = {Remarks on some nonparametric estimates of a density function},
  journal = AMS,
  year = {1956},
  volume = {27},
  pages = {832--837}
}

@ARTICLE{Rougier:multi08,
  author = {Jonathan Rougier},
  title = {Efficient Emulators for Multivariate Deterministic Functions},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2008},
  volume = {17},
  pages = {827-834},
  number = {4}
}

@ARTICLE{Rougier:efficient08,
  author = {Jonathan C. Rougier},
  title = {Efficient Emulators for Multivariate Deterministic Functions},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2008},
  volume = {17},
  number = {4},
  doi = { doi:10.1198/106186008X384032},
  linksoftware = {http://www.maths.bris.ac.uk/~MAZJCR/OPE_0.8.tar.gz},
  optpages = {827--843}
}

@ARTICLE{Roweis:unifying,
  author = {Sam T. Roweis and Zoubin Ghahramani},
  title = {A Unifying Review of Linear {G}aussian Models},
  journal = NC,
  year = {1999},
  volume = {11},
  pages = {305--345},
  number = {2},
  linkpsgz = {http://www.gatsby.ucl.ac.uk/~zoubin/papers/lds.ps.gz}
}

@ARTICLE{Roweis:lle00,
  author = {Sam T. Roweis and Lawrence K. Saul},
  title = {Nonlinear Dimensionality Reduction by Locally Linear Embedding},
  journal = {Science},
  year = {2000},
  volume = {290},
  pages = {2323--2326},
  number = {5500},
  abstract = {Many areas of science depend on exploratory data analysis and visualization.
	The need to analyze large amounts of multivariate data raises the
	fundamental problem of dimensionality reduction: how to discover
	compact representations of high-dimensional data. Here, we introduce
	locally linear embedding (LLE), an unsupervised learning algorithm
	that computes low-dimensional, neighborhood-preserving embeddings
	of high-dimensional inputs. Unlike clustering methods for local dimensionality
	reduction, LLE maps its inputs into a single global coordinate system
	of lower dimensionality, and its optimizations do not involve local
	minima. By exploiting the local symmetries of linear reconstructions,
	LLE is able to learn the global structure of nonlinear manifolds,
	such as those generated by images of faces or documents of text.},
  doi = {10.1126/science.290.5500.2323},
  group = {dimensional reduction},
  label1 = {Science Issue},
  link1 = {http://www.sciencemag.org/content/vol290/issue5500/}
}

@ARTICLE{Rubin:EMFA82,
  author = {D. B. Rubin and D. T. Thayer},
  title = {{EM} algorithms for {ML} factor analysis},
  journal = {Psychometrika},
  year = {1982},
  volume = {47},
  pages = {69--76},
  number = {1}
}

@ARTICLE{Ruck:bayes90,
  author = {D. W. Ruck and S. K. Rogers and M. Kabrisky and M. E. Oxley and B.
	W. Suter},
  title = {The multi-layer perceptron as an approximation to a {B}ayes optimal
	discriminant function },
  journal = IEEE,
  year = {1990},
  volume = {1},
  pages = {296--298},
  number = {4}
}

@INCOLLECTION{Rumelhart:bp95,
  author = {David E. Rumelhart and R. Durbin and R. Golden and Y. Chauvin},
  title = {Backpropagation: the basic theory},
  booktitle = {Backpropagation: Theory, Architectures, and Applications},
  publisher = {Lawrence Erlbaum},
  year = {1995},
  editor = {Y. Chauvin and David E. Rumelhart},
  pages = {1--34},
  address = {Hillsdale, NJ}
}

@ARTICLE{Saad:on-line95,
  author = {David Saad and Sara A. Solla},
  title = {Exact solution for on-line learning in multilayer neural networks},
  journal = PRL,
  year = {1995},
  pages = {4337--4340},
  number = {74}
}

@ARTICLE{Sabatti:bayesian06,
  author = {Chiara Sabatti and Gareth M. James},
  title = {Bayesian Sparse Hidden Components Analysis for Transcription Regulation
	Networks},
  journal = bioinf,
  year = {2006},
  volume = {22},
  pages = {739--746},
  number = {6},
  abstract = {{\bf Motivation}: In systems like \emph{Escherichia Coli}, the abundance
	of sequence information, gene expression array studies and small
	scale experiments allows one to reconstruct the regulatory network
	and to quantify the effects of transcription factors on gene expression.
	However, this goal can only be achieved if all information sources
	are used in concert.\\\\
	
	 {\bf Results}: Our method integrates literature information, DNA
	sequences and expression arrays. A set of relevant transcription
	factors is defined on the basis of literature. Sequence data are
	used to identify potential target genes and the results are used
	to define a prior distribution on the topology of the regulatory
	network. A Bayesian hidden component model for the expression array
	data allows us to identify which of the potential binding sites are
	actually used by the regulatory proteins in the studied cell conditions,
	the strength of their control, and their activation profile in a
	series of experiments. We apply our methodology to 35 expression
	studies in \emph{E.Coli} with convincing results.\\\\
	
	 {\bf Availability}: \url{www.genetics.ucla.edu/labs/sabatti/software.html}\\\\
	
	 {\bf Supplementary information}: The supplementary material are available
	at Bioinformatics online.\\\\
	
	 {\bf Contact}: csabatti@mednet.ucla.edu},
  file = {739:http\://bioinformatics.oxfordjournals.org/cgi/reprint/22/6/739:PDF},
  group = {gene networks, E coli},
  linksoftware = {http://www.genetics.ucla.edu/labs/sabatti/software.html}
}

@INPROCEEDINGS{Sahami:email98,
  author = {M. Sahami and Susan Dumais and David Heckerman and Eric Horvitz},
  title = {A {B}ayesian approach to filtering junk e-mail},
  booktitle = {AAAI Workshop on Learning for Text Categorization},
  year = {1998},
  month = Jul,
  note = {Available from \url{http://research.microsoft.com/\~{ }heckerman/}}
}

@INPROCEEDINGS{Salzmann:fols10,
  author = {Matthieu Salzmann and Carl Henrik Ek and Raquel Urtasun and Trevor
	Darrell},
title = {Factorized Orthogonal Latent Spaces},
  crossref = {Teh:aistats10}
}

@INPROCEEDINGS{Salzmann:deformation08,
  author = {Matthieu Salzmann and Raquel Urtasun and Pascal Fua},
  booktitle = pCVPR,
  title = {Local Deformation Models for Monocular 3D Shape Recovery},
  year = {2008}
}

@ARTICLE{Samard:som_missing92,
  author = {T. Samard and S. A. Harp},
  title = {Self-organization with partial data},
  journal = {Network: Computation in Neural Systems},
  year = {1992},
  volume = {3},
  pages = {205--212},
  number = {2}
}

@ARTICLE{Sammon:nonlinear69,
  author = {John W. Sammon},
  title = {A nonlinear mapping for data structure analysis},
  journal = {{IEEE} Transactions on Computers},
  year = {1969},
  volume = {C-18},
  pages = {401--409},
  number = {5},
  doi = {10.1109/T-C.1969.222678}
}

@ARTICLE{Sandler:optics91,
  author = {D. G. Sandler and T. K. Barrett and D. A. Palmer and R. Q. Fugate
	and W. J. Wild},
  title = {Use of a neural network to control an adaptive optics system for
	an astronomical telescope},
  journal = {Nature},
  year = {1991},
  volume = {351},
  pages = {300--302}
}

@ARTICLE{Sandmann:core07,
  author = {T. Sandmann and C. Girardot and M. Brehme and W. Tongprasit and V.
	agathStolc and E. E. Furlong},
  title = {{A} core transcriptional network for early mesoderm development in
	{D}rosophila melanogaster},
  journal = {Genes Dev.},
  year = {2007},
  pages = {436--449},
  month = {Feb},
  abstract = {2000 Twist-bound cis-regulatory modules (CRMs) and almost 500 direct
	target genes. Unexpectedly, Twist regulates an almost complete cassette
	of genes required for cell proliferation in addition to genes essential
	for morophogenesis and cell migration. Twist targets almost 25\%
	of all annotated Drosophila transcription factors, which may represent
	the entire set of regulators necessary for the early development
	of this system. By combining in vivo binding data from Twist, Mef2,
	Tinman, and Dorsal we have constructed an initial transcriptional
	network of early mesoderm development. The network topology reveals
	extensive combinatorial binding, feed-forward regulation, and complex
	logical outputs as prevalent features. In addition to binary activation
	and repression, we suggest that Twist binds to almost all mesodermal
	CRMs to provide the competence to integrate inputs from more specialized
	transcription factors.},
  group = {Drosophila},
  optvolume = {21},
  pmid = {17322403}
}

@ARTICLE{Sandmann:chiponchip06,
  author = {T. Sandmann and J. S. Jakobsen and E. E. Furlong},
  title = {{C}h{I}{P}-on-chip protocol for genome-wide analysis of transcription
	factor binding in {D}rosophila melanogaster embryos},
  journal = {Nat. Protoc.},
  year = {2006},
  volume = {1},
  pages = {2839--2855},
  abstract = {This protocol describes a method to detect in vivo associations between
	proteins and DNA in developing Drosophila embryos. It combines formaldehyde
	crosslinking and immunoprecipitation of protein-bound sequences with
	genome-wide analysis using microarrays. After crosslinking, nuclei
	are enriched using differential centrifugation and the chromatin
	is sheared by sonication. Antibodies specifically recognizing wild-type
	protein or, alternatively, a genetically encoded epitope tag are
	used to enrich for specifically bound DNA sequences. After purification
	and polymerase chain reaction-based amplification, the samples are
	fluorescently labeled and hybridized to genomic tiling microarrays.
	This protocol has been successfully used to study different tissue-specific
	transcription factors, and is generally applicable to in vivo analysis
	of any DNA-binding proteins in Drosophila embryos. The full protocol,
	including the collection of embryos and the collection of raw microarray
	data, can be completed within 10 days.},
  group = {Drosophila},
  pmid = {17406543}
}

@ARTICLE{Sandmann:temporal06,
  author = {T. Sandmann and L. J. Jensen and J. S. Jakobsen and M. M. Karzynski
	and M. P. Eichenlaub and P. Bork and E. E. Furlong},
  title = {{A} temporal map of transcription factor activity: mef2 directly
	regulates target genes at all stages of muscle development},
  journal = {Dev. Cell},
  year = {2006},
  volume = {10},
  pages = {797--807},
  month = {Jun},
  abstract = {Dissecting components of key transcriptional networks is essential
	for understanding complex developmental processes and phenotypes.
	Genetic studies have highlighted the role of members of the Mef2
	family of transcription factors as essential regulators in myogenesis
	from flies to man. To understand how these transcription factors
	control diverse processes in muscle development, we have combined
	chromatin immunoprecipitation analysis with gene expression profiling
	to obtain a temporal map of Mef2 activity during Drosophila embryonic
	development. This global approach revealed three temporal patterns
	of Mef2 enhancer binding, providing a glimpse of dynamic enhancer
	use within the context of a developing embryo. Our results provide
	mechanistic insight into the regulation of Mef2's activity at the
	level of DNA binding and suggest cooperativity with the bHLH protein
	Twist. The number and diversity of new direct target genes indicates
	a much broader role for Mef2, at all stages of myogenesis, than previously
	anticipated.},
  group = {Drosophila},
  pmid = {16740481}
}

@ARTICLE{Sanger:89,
  author = {T. D. Sanger},
  title = {Optimal unsupervised learning in a single-layer linear feed-forward
	neural network},
  journal = NN,
  year = {1989},
  volume = {2},
  pages = {459--473},
  number = {6}
}

@MISC{Satchwell:94,
  author = {C. Satchwell},
  title = {Neural networks for stochastic problems: more than one outcome for
	the input space},
  year = {1994},
  note = {Presentation at the Neural Computing Applications Forum conference,
	Aston University, September}
}

@ARTICLE{Saul:mft96,
  author = {Lawrence K. Saul and Tommi S. Jaakkola and Michael I. Jordan},
  title = {Mean Field Theory for Sigmoid Belief Networks},
  journal = jair,
  year = {1996},
  volume = {4},
  pages = {61--76},
  file = {saul96a.pdf:http\://www-2.cs.cmu.edu/afs/cs/project/jair/pub/volume4/saul96a.pdf:PDF}
}

@ARTICLE{Saul:trees94,
  author = {Lawrence K. Saul and Michael I. Jordan},
  title = {Learning in {B}oltzmann Trees},
  journal = NC,
  year = {1994},
  volume = {6},
  pages = {1174--1184},
  number = {6},
  group = {tree},
  linkpsz = {http://www.cs.berkeley.edu/~jordan/papers/boltzmann.trees.ps.Z}
}

@INPROCEEDINGS{Scalettar:Zee88,
  author = {R. Scalettar and A. Zee},
  title = {Emergence of grandmother memory in feed-forward networks: learning
	with noise and forgetfulness},
  booktitle = {Connectionist Models and their Implications},
  year = {1988},
  editor = {D. Waltz and J. A. Feldman},
  pages = {309--327},
  address = {Norwood, N.J.},
  publisher = {A. Blex}
}

@ARTICLE{Schaefer:empirical05,
  author = {Juliane Sch\"afer and Korbinian Strimmer},
  title = {An empirical {B}ayes approach to inferring large-scale gene association
	networks},
  journal = bioinf,
  year = {2005},
  volume = {21},
  pages = {754--764},
  number = {6},
  abstract = {{\bf Motivation:} Genetic networks are often described statistically
	using graphical models (e.g. Bayesian networks). However, inferring
	the network structure offers a serious challenge in microarray analysis
	where the sample size is small compared to the number of considered
	genes. This renders many standard algorithms for graphical models
	inapplicable, and inferring genetic networks an 'ill-posed' inverse
	problem.\\\\
	
	 {\bf Methods:} We introduce a novel framework for small-sample inference
	of graphical models from gene expression data. Specifically, we focus
	on the so-called graphical Gaussian models (GGMs) that are now frequently
	used to describe gene association networks and to detect conditionally
	dependent genes. Our new approach is based on (1) improved (regularized)
	small-sample point estimates of partial correlation, (2) an exact
	test of edge inclusion with adaptive estimation of the degree of
	freedom and (3) a heuristic network search based on false discovery
	rate multiple testing. Steps (2) and (3) correspond to an empirical
	Bayes estimate of the network topology.\\\\
	
	 {\bf Results:} Using computer simulations, we investigate the sensitivity
	(power) and specificity (true negative rate) of the proposed framework
	to estimate GGMs from microarray data. This shows that it is possible
	to recover the true network topology with high accuracy even for
	small-sample datasets. Subsequently, we analyze gene expression data
	from a breast cancer tumor study and illustrate our approach by inferring
	a corresponding large-scale gene association network for 3883 genes.\\\\
	
	 {\bf Availability:} The authors have implemented the approach in
	the R package 'GeneTS' that is freely available from \url{http://www.stat.uni-muenchen.de/\~{
	}strimmer/genets/}, from the R archive (CRAN) and from the Bioconductor
	website.\\\\
	
	 {\bf Contact:} korbinian.strimmer@lmu.de},
  group = {gene networks}
}

@INPROCEEDINGS{Schoelkopf:invariances96,
  author = {Bernhard Sch\"olkopf and Chris J. C. Burges and Vladimir N. Vapnik},
  title = {Incorporating invariances in support vector learning machines},
  booktitle = {Artificial Neural Networks --- ICANN'96},
  year = {1996},
  volume = {1112},
  pages = {47--52},
  linkpsgz = {http://research.microsoft.com/~cburges/papers/icann96_2.ps.gz}
}

@INPROCEEDINGS{Scholkopf:extracting,
  author = {Bernhard Sch\"olkopf and Chris J. C. Burges and Vladimir N. Vapnik},
  title = {Extracting support data for a given task},
  booktitle = {Proceedings of the International Conference on Data Mining and Knowledge
	Discovery},
  year = {1995},
  volume = {1},
  address = {Menlo Park, CA},
  publisher = {AAAI Press},
  institution = {AT\&T Bell Laboratories}
}

@ARTICLE{Scholkopf:estimating00,
  author = {Bernhard Sch\"olkopf and John Platt and John Shawe-Taylor and Alex
	J. Smola and Robert C. Williamson},
  title = {Estimating the Support of a High-dimensional Distribution},
  journal = NC,
  year = {2001},
  volume = {13},
  pages = {1443--1472},
  number = {7},
  linkpsgz = {http://www.kernel-machines.org/papers/oneclass-tr.ps.gz}
}

@InCollection{Twain:chapters06,
  author = 	 {Mark Twain},
  title = 	 {Chapters from My Autobiography},
  booktitle = 	 {North American Review},
  OPTcrossref =  {},
  OPTkey = 	 {},
  OPTpages = 	 {},
  OPTpublisher = {},
  year =	 {1906},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTtype = 	 {},
  OPTchapter = 	 {},
  OPTaddress = 	 {},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@ARTICLE{Scholkopf:nonlinear98,
  author = {Bernhard Sch\"olkopf and Alexander Smola and Klaus-Robert M\"uller},
  title = {Nonlinear Component Analysis as a Kernel Eigenvalue Problem},
  journal = NC,
  year = {1998},
  volume = {10},
  pages = {1299--1319},
  doi = {10.1162/089976698300017467},
  file = {SchSmoMul98.pdf:http\://users.rsise.anu.edu.au/~smola/papers/SchSmoMul98.pdf:PDF},
  linkpsgz = {http://www.first.gmd.de/persons/Mueller.Klaus-Robert/TR-044.ps.gz}
}

@INPROCEEDINGS{Scholkopf:kernelpca97,
  author = {Bernhard Sch\"olkopf and Alex J. Smola and Klaus-Robert M\"uller},
  title = {Kernel Principal Component Analysis},
  booktitle = {Proceedings 1997 International Conference on Artificial Neural Networks,
	ICANN'97},
  year = {1997},
  pages = {583},
  address = {Lausanne, Switzerland}
}

@ARTICLE{Scholkopf:comparing97,
  author = {Bernhard Sch\"olkopf and Kah-Kay Sung and Chris J. C. Burges and
	Federico Girosi and Partha Niyogi and Tomaso Poggio and Vladimir
	N. Vapnik},
  title = {Comparing Support Vector Machines with {G}aussian Kernels to Radial
	Basis Function Classifiers},
  journal = {IEEE Transactions on Signal Processing},
  year = {1997},
  volume = {45},
  pages = {2758--2765},
  number = {11}
}

@ARTICLE{Schena:quantitative95,
  author = {Mark Schena and D. Shalon and R. W. Davis and P. O. Brown},
  title = {Quantitiative Monitoring of Gene Expression Patterns with Complementary
	{DNA} Microarray},
  journal = {Science},
  year = {1995},
  volume = {270},
  pages = {467--470}
}

@ARTICLE{Schioler:parzen92,
  author = {H. Schi{\o}ler and U. Hartmann},
  title = {Mapping neural network derived from the {P}arzen window estimator},
  journal = NN,
  year = {1992},
  volume = {5},
  pages = {903--909},
  number = {6}
}

@INPROCEEDINGS{Schmidt:speaker96,
  author = {M. Schmidt and H. Gish},
  title = {Speaker Identification via Support Vector Classifiers},
  booktitle = {Proceedings of the IEEE Conference on Acoustics, Speech and Signal
	Processing},
  year = {1996},
  volume = {1},
  pages = {105--108}
}

@ARTICLE{Schuss:narrow07,
  author = {Z. Schuss and A. Singer and D. Holcman},
  title = {The narrow escape problem for diffusion in cellular microdomains},
  journal = pnasusa,
  year = {2007},
  volume = {104},
  pages = {16098--16103},
  number = {41},
  abstract = {The study of the diffusive motion of ions or molecules in confined
	biological microdomains requires the derivation of the explicit dependence
	of quantities, such as the decay rate of the population or the forward
	chemical reaction rate constant on the geometry of the domain. Here,
	we obtain this explicit dependence for a model of a Brownian particle
	(ion, molecule, or protein) confined to a bounded domain (a compartment
	or a cell) by a reflecting boundary, except for a small window through
	which it can escape. We call the calculation of the mean escape time
	the narrow escape problem. This time diverges as the window shrinks,
	thus rendering the calculation a singular perturbation problem. Here,
	we present asymptotic formulas for the mean escape time in several
	cases, including regular domains in two and three dimensions and
	in some singular domains in two dimensions. The mean escape time
	comes up in many applications, because it represents the mean time
	it takes for a molecule to hit a target binding site. We present
	several applications in cellular biology: calcium decay in dendritic
	spines, a Markov model of multicomponent chemical reactions in microdomains,
	dynamics of receptor diffusion on the surface of neurons, and vesicle
	trafficking inside a cell.},
  doi = {10.1073/pnas.0706599104},
  group = {diffusion},
  pmid = {17901203}
}

@ARTICLE{Schab:reproducible00,
  author = {Matthias Schwab and Martin Karrenbach and Jon Claerbout},
  title = {Making Scientific Computations Reproducible},
  journal = {Computing in Science and Engineering},
  year = {2000},
  volume = {2},
  pages = {61---67},
  number = {6},
  linkhtml = {http://sep.stanford.edu/research/redoc/cip.html},
  linkps = {http://sep.stanford.edu/research/redoc/cip.ps}
}

@ARTICLE{Schwartz:espaces64,
  author = {Laurent Schwartz},
  title = {Sous-espaces hilbertiens d'espaces vectoriels topologiques et noyaux
	associ\'es (Noyaux reproduisants)},
  journal = {Journal D'Analyse Math\'ematique},
  year = {1964},
  volume = {13},
  pages = {115--256},
  doi = {10.1007/BF02786620},
  mrclass = {46.01 (46.15)},
  mrnumber = {31 \#3835},
  mrreviewer = {J. Dieudonn{\'e}}
}

@TECHREPORT{Seeger:EPforExp05,
  author = {Matthias Seeger},
  title = {Expectation Propagation for Exponential Families},
  year = {2005},
  abstract = {This is a tutorial describing the Expectation Propagation (EP) algorithm
	for a general exponential family. Our focus is on simplicity of exposition.
	Although the overhead of translating a specific model into its exponential
	family representation can be considerable, many apparent complications
	of EP can simply be sidestepped by working in this canonical representation.},
  file = {epexpfam.pdf:http\://www.kyb.tuebingen.mpg.de/bs/people/seeger/papers/epexpfam.pdf:PDF},
  group = {EP}
}

@PHDTHESIS{Seeger:thesis04,
  author = {Matthias Seeger},
  title = {{B}ayesian {G}aussian Process Models: {PAC-B}ayesian Generalisation
	Error Bounds and Sparse Approximations},
  school = {The University of Edinburgh},
  year = {2004},
  abstract = {Non-parametric models and techniques enjoy a growing popularity in
	the field of machine learning, and among these Bayesian inference
	for Gaussian process (GP) models has recently received significant
	attention. We feel that GP priors should be part of the standard
	toolbox for constructing models relevant to machine learning in the
	same way as parametric linear models are, and the results in this
	thesis help to remove some obstacles on the way towards this goal.
	
	
	 In the first main chapter, we provide a distribution-free finite
	sample bound on the difference between generalisation and empirical
	(training) error for GP classification methods. While the general
	theorem (the PAC-Bayesian bound) is not new, we give a much simplified
	and somewhat generalised derivation and point out the underlying
	core technique (convex duality) explicitly. Furthermore, the application
	to GP models is novel (to our knowledge). A central feature of this
	bound is that its quality depends crucially on task knowledge being
	encoded faithfully in the model and prior distributions, so there
	is a mutual benet between a sharp theoretical guarantee and empirically
	well-established statistical practices. Extensive simulations on
	real-world classification tasks indicate an impressive tightness
	of the bound, in spite of the fact that many previous bounds for
	related kernel machines fail to give non-trivial guarantees in this
	practically relevant regime.
	
	 In the second main chapter, sparse approximations are developed to
	address the problem of the unfavourable scaling of most GP techniques
	with large training sets. Due to its high importance in practice,
	this problem has received a lot of attention recently. We demonstrate
	the tractability and usefulness of simple greedy forward selection
	with information-theoretic criteria previously used in active learning
	(or sequential design) and develop generic schemes for automatic
	model selection with many (hyper)parameters. We suggest two new generic
	schemes and evaluate some of their variants on large real-world classfication
	and regression tasks. These schemes and their underlying principles
	(which are clearly stated and analysed) can be applied to obtain
	sparse approximations for a wide regime of GP models far beyond the
	special cases we studied here.},
  file = {thesis.pdf:http\://www.dai.ed.ac.uk/homes/seeger/papers/thesis.pdf:PDF},
  linkpsgz = {http://www.dai.ed.ac.uk/homes/seeger/papers/thesis.ps.gz}
}

@ARTICLE{Segal:module03,
  author = {E. Segal and M. Shapira and A. Regev and D. Pe'er and D Botstein
	and D. Koller and Nir Friedman },
  title = {Module Networks: identifying regulatory modules and their condition-
	specific regulators from gene expression data},
  journal = {Nature Genetics},
  year = {2003},
  volume = {34},
  pages = {166--176},
  number = {2},
  abstract = {Much of a cell's activity is organized as a network of interacting
	modules: sets of genes coregulated to respond to different conditions.
	We present a probabilistic method for identifying regulatory modules
	from gene expression data. Our procedure identifies modules of coregulated
	genes, their regulators and the conditions under which regulation
	occurs, generating testable hypotheses in the form 'regulator X regulates
	module Y under conditions W'. We applied the method to a Saccharomyces
	cerevisiae expression data set, showing its ability to identify functionally
	coherent modules and their correct regulators. We present microarray
	experiments supporting three novel predictions, suggesting regulatory
	roles for previously uncharacterized proteins.}
}

@INPROCEEDINGS{Seung:query92,
  author = {H. S. Seung and Manfred Opper and Haim Sompolinsky},
  title = {Query by committee},
  booktitle = {Conference on Computational Learning Theory 10},
  year = {1992},
  pages = {287--294},
  publisher = mk
}

@ARTICLE{Shanno:conj78,
  author = {D. F. Shanno},
  title = {Conjugate gradient methods with inexact searches},
  journal = {Mathematics of Operations Research},
  year = {1978},
  volume = {3},
  pages = {244--256},
  number = {3}
}

@ARTICLE{Shannon:info48,
  author = {Claude E. Shannon},
  title = {A mathematical theory of communication},
  journal = {The Bell System Technical Journal},
  year = {1948},
  volume = {27},
  pages = {379--423 and 623--656},
  number = {3}
}

@TECHREPORT{Sheldon:graphical08,
  author = {Daniel R. Sheldon},
  title = {Graphical Multi-Task Learning},
  institution = {Cornell University},
  year = {2008},
  note = {Preprint},
  url = {http://www.cs.cornell.edu/~dsheldon}
}

@ARTICLE{Shen-Orr:Ecolimotifs02,
  author = {Shai Shen-Orr and Ron Milo and Shmoolik Mangan and Uri Alon},
  title = {Network Motifs in the Transcriptional Regulation Network of \emph{Escherichia
	coli}},
  journal = {Nature Genetics},
  year = {2002},
  volume = {31},
  pages = {64--68},
  number = {1},
  abstract = {Little is known about the design principles of transcriptional regulation
	networks that control gene expression in cells. Recent advances in
	data collection and analysis however, are generating unprecedented
	amounts of information about gene regulation networks. To understand
	these complex wiring diagrams, we sought to break down such networks
	into basic building blocks. We generalize the notion of motifs, widely
	used for sequence analysis, to the level of networks. We define 'network
	motifs' as patterns of interconnections that recur in many different
	parts of a network at frequencies much higher than those found in
	randomized networks. We applied new algorithms for systematically
	detecting network motifs to one of the best-characterized regulation
	networks, that of direct transcriptional interactions in \emph{Escherichia
	coli}. We find that much of the network is composed of repeated appearances
	of three highly significant motifs. Each network motif has a specific
	function in determining gene expression, such as generating temporal
	expression programs and governing the responses to fluctuating external
	signals. The motif structure also allows an easily interpretable
	view of the entire known transcriptional network of the organism.
	This approach may help define the basic computational elements of
	other biological networks.},
  file = {network_motifs_in_coli.pdf:http\://www.weizmann.ac.il/mcb/UriAlon/Papers/network_motifs_in_coli.pdf:PDF},
  group = {gene networks, E. coli},
  pmid = {11967538}
}

@ARTICLE{Sherrington:spin75,
  author = {D. Sherrington and S. Kirkpatrick},
  title = {Solvable Model of a Spin Glass},
  journal = PRL,
  year = {1975},
  volume = {35},
  pages = {1792--1796}
}

@ARTICLE{Shi:normalized00,
  author = {Jianbo Shi and Jitendra Malik},
  title = {Normalized Cuts and Image Segmentation},
  journal = PAMI,
  year = {2000},
  volume = {22},
  pages = {888--905},
  number = {8},
  file = {SM-ncut.pdf:http\://www.cs.berkeley.edu/~malik/papers/SM-ncut.pdf:PDF},
  group = {image segmentation}
}

@INPROCEEDINGS{Shichiri:eigenvoices02,
  author = {K. Shichiri and A. Sawabe and K. Tokuda and T. Masuko and T. Kobayashi
	and T. Kitamura},
  title = {Eigenvoices for HMM-based Speech Synthesis},
  booktitle = {7th International Conference on Spoken Language Processing},
  year = {2002},
  pages = {1269--1272}
}

@INPROCEEDINGS{Shon:robotic05,
  author = {Aaron P. Shon and Keith Grochow and Rajesh P. N. Rao},
  title = {Robotic Imitation from Human Motion Capture using {G}aussian Processes},
  booktitle = {5th IEEE-RAS International Conference on Humanoid Robots},
  year = {2005},
  abstract = {Programming by demonstration, also called imitation learning, offers
	the possibility of flexible, easily modifiable robotic systems. Full-fledged
	robotic imitation learning comprises many difficult subtasks. However,
	we argue that, at its core, imitation learning reduces to a regression
	problem. We propose a two-step framework in which an imitating agent
	first performs a regression from a high-dimensional observation space
	to a low dimensional latent variable space. In the second step, the
	agent performs a regression from the latent variable space to a high
	dimensional space representing degrees of freedom of its motor system.
	We demonstrate the validity of the approach by learning to map motion
	capture data from human actors to a humanoid robot. We also contrast
	use of several low-dimensional latent variable spaces, each covering
	a subset of agentsâ degrees of freedom, with use of a single, higher-dimensional
	latent variable space. Our findings suggest that compositing several
	regression models together yields qualitatively better imitation
	results than using a single, more complex regression model.},
  doi = {10.1109/ICHR.2005.1573557},
  file = {humanoids2005.pdf:http\://www.cs.washington.edu/homes/aaron/pub/humanoids2005.pdf:PDF},
  group = {gplvm, robotics}
}

@ARTICLE{Siedlecki:88,
  author = {W. Siedlecki and J. Sklansky},
  title = {On automatic feature selection},
  journal = {International Journal of Pattern Recognition and Artificial Intelligence},
  year = {1988},
  volume = {2},
  pages = {197--220},
  number = {2}
}

@ARTICLE{Sietsma:noise91,
  author = {J. Sietsma and R. J. F. Dow},
  title = {Creating artificial neural networks that generalize},
  journal = NN,
  year = {1991},
  volume = {4},
  pages = {67--79},
  number = {1}
}

@INPROCEEDINGS{Sigal:loose04,
  author = {Leonid Sigal and Sidharth Bhatia and Stefan Roth and Michael J. Black
	and Michael Isard},
  title = {Tracking Loose-Limbed People},
  booktitle = pCVPR,
  year = {2004},
  pages = {421--428},
  address = {Washington, DC, U.S.A.},
  month = {29 Jun.--1 Jul.},
  publisher = ieeecomp,
  abstract = {We pose the problem of 3D human tracking as one of inference in a
	graphical model. Unlike traditional kinematic tree representations,
	our model of the body is a collection of loosely-connected limbs.
	Conditional probabilities relating the 3D pose of connected limbs
	are learned from motion-captured training data. Similarly, we learn
	probabilistic models for the temporal evolution of each limb (forward
	and backward in time). Human pose and motion estimation is then solved
	with non-parametric belief propagation using a variation of particle
	filtering that can be applied over a general loopy graph. The loose-limbed
	model and decentralized graph structure facilitate the use of low-level
	visual cues. We adopt simple limb and head detectors to provide "bottom-up"
	information that is incorporated into the inference process at every
	time-step; these detectors permit automatic initialization and aid
	recovery from transient tracking failures. We illustrate the method
	by automatically tracking a walking person in video imagery using
	four calibrated cameras. Our experimental apparatus includes a marker-based
	motion capture system aligned with the coordinate frame of the calibrated
	cameras with which we quantitatively evaluate the accuracy of our
	3D person tracker.},
  file = {looselimbed.pdf:http\://research.microsoft.com/research/sv/sv-pubs/looselimbed.pdf:PDF},
  group = {tracking, pose estimation, tree}
}

@ARTICLE{Silverman:splines85,
  author = {Silverman, B. W.},
  title = {{Some aspects of the spline smoothing approach to non-parametric
	regression curve fitting (with discussion)}},
  journal = JRSSb,
  year = {1985},
  volume = {47(1)},
  pages = {1-52}
}

@ARTICLE{Simcox:determination83,
  author = {Amanda A. Simcox and J. H. Sang},
  title = {When does determination occur in Drosophila embryos?},
  journal = {Developmental Biology},
  year = {1983},
  volume = {97},
  pages = {212--221},
  number = {1},
  abstract = {Small groups of blastoderm cells were transplanted from wild-type
	donor embryos into genetically marked host embryos of the same age.
	Donor cells were injected either into an homologous or an ectopic
	region of the recipient, and both donor and recipient embryos were
	allowed to develop. Donor flies were examined for defects in external
	structures. Recipients were scored for patches of donor-type marked
	tissue derived from the injected cells. After ectopic transfer, the
	donor cells recovered in chimaeric recipients differentiated structures
	consistent with the donor site of cell removal. No apparent fate
	change was observed. In the rare cases when both individuals of a
	donor/host pair survived, a direct correspondence could be made between
	the deleted region in the donor and the chimaeric patch in the host.
	The results show that blastoderm cells are stably determined to within
	a segment.},
  group = {Drosophila},
  pmid = {6404675}
}

@ARTICLE{Smale2003d,
  author = {Stephen T Smale},
  title = {The establishment and maintenance of lymphocyte identity through
	gene silencing.},
  journal = {Nat Immunol},
  year = {2003},
  volume = {4},
  pages = {607--615},
  number = {7},
  month = {Jul},
  abstract = {Cell identity is determined by selective gene activation and by the
	maintenance of other regulated genes in a silent state. Although
	activation mechanisms have been dissected in considerable depth,
	great strides towards an understanding of the molecular control of
	gene silencing have been made only recently. Molecular hallmarks
	of silent chromatin and proteins involved in its assembly and maintenance
	have been identified through genetic, cytological and biochemical
	studies in a variety of organisms. Immunologists are now beginning
	to use this knowledge to elucidate mechanisms underlying cell fate
	decisions and key developmental steps. This review surveys the current
	knowledge of gene silencing, with an emphasis on studies in lymphocytes
	that are advancing our general understanding of silencing mechanisms
	during development.},
  doi = {10.1038/ni0703-607},
  institution = {Howard Hughes Medical Institute and Department of Microbiology, Immunology,
	and Molecular Genetics, University of California, Los Angeles, California
	90095-1662, USA. smale@mednet.ucla.edu},
  keywords = {Animals; Antigens, CD4, genetics; Chromatin, physiology; CpG Islands;
	DNA Methylation; Gene Expression Regulation; Gene Silencing; Humans;
	Lymphocytes, metabolism; Transcriptional Activation},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ni0703-607},
  pmid = {12830135},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/ni0703-607}
}

@INPROCEEDINGS{Sminchisescu:discriminative05,
  author = {Cristian Sminchisescu and Atul Kanaujia and Zhiguo Li and Dimitris
	Metaxas},
  title = {Discriminative Density Propagation for 3{D} Human Motion Estimation},
  booktitle = pCVPR,
  year = {2005},
  pages = {390--397},
  abstract = {We describe a mixture density propagation algorithm to estimate 3D
	human motion in monocular video sequences based on observations encoding
	the appearance of image silhouettes. Our approach is discriminative
	rather than generative, therefore it does not require the probabilistic
	inversion of a predictive observation model. Instead, it uses a large
	human motion capture data-base and a 3D computer graphics human model
	in order to synthesize training pairs of typical human configurations
	together with their realistically rendered 2D silhouettes. These
	are used to directly learn to predict the conditional state distributions
	required for 3D body pose tracking and thus avoid using the generative
	3D model for inference (the learned discriminative predictors can
	also be used, complementary, as importance samplers in order to improve
	mixing or initialize generative inference algorithms). We aim for
	probabilistically motivated tracking algorithms and for models that
	can represent complex multivalued mappings common in inverse, uncertain
	perception inferences. Our paper has three contributions: (1) we
	establish the density propagation rules for discriminative inference
	in continuous, temporal chain models; (2) we propose flexible algorithms
	for learning multimodal state distributions based on compact, conditional
	Bayesian mixture of experts models; and (3) we demonstrate the algorithms
	empirically on real and motion capture-based test sequences and compare
	against nearest-neighbor and regression methods. },
  doi = {10.1109/CVPR.2005.132},
  file = {discriml_cvpr05.pdf:http\://www.cs.toronto.edu/~crismin/PAPER/discriml_cvpr05.pdf:PDF},
  group = {human motion, mixtures}
}

@ARTICLE{Soinov:towards03,
  author = {Lev A Soinov and Maria A Krestyaninova and Alvis Brazma},
  title = {Towards reconstruction of gene networks from expression data by supervised
	learning},
  journal = {Genome Biology},
  year = {2003},
  volume = {4},
  pages = {R6},
  number = {1},
  abstract = {{\bf Background}\\\\
	
	 Microarray experiments are generating datasets that can help in reconstructing
	gene networks. One of the most important problems in network reconstruction
	is finding, for each gene in the network, which genes can affect
	it and how. We use a supervised learning approach to address this
	question by building decision-tree-related classifiers, which predict
	gene expression from the expression data of other genes.\\\\
	
	 {\bf Results}\\\\
	
	 We present algorithms that work for continuous expression levels
	and do not require a priori discretization. We apply our method to
	publicly available data for the budding yeast cell cycle. The obtained
	classifiers can be presented as simple rules defining gene interrelations.
	In most cases the extracted rules confirm the existing knowledge
	about cell-cycle gene expression, while hitherto unknown relationships
	can be treated as new hypotheses.\\\\
	
	 {\bf Conclusions}\\\\
	
	 All the relations between the considered genes are consistent with
	the facts reported in the literature. This indicates that the approach
	presented here is valid and that the resulting rules can be used
	as elements for building and explaining gene networks.},
  file = {gb-2003-4-1-r6.pdf:http\://genomebiology.com/content/pdf/gb-2003-4-1-r6.pdf:PDF},
  group = {gene networks},
  linkhtml = {http://genomebiology.com/2003/4/1/R6}
}

@ARTICLE{Soinov:unraveling03,
  author = {Lev Soinov and Misha Kapushesky},
  title = {Unraveling nature's networks},
  journal = {Genome Biology},
  year = {2003},
  volume = {4},
  number = {341}
}

@ARTICLE{Solla:learn88,
  author = {S. A. Solla and E. Levin and M. Fleisher},
  title = {Accelerated learning in layered neural networks},
  journal = {Complex Systems},
  year = {1988},
  volume = {2},
  pages = {625--640}
}

@INPROCEEDINGS{Sollich:probabilisticICANN99,
  author = {Peter Sollich},
  title = {Probabilistic interpretation and {B}ayesian methods for Support Vector
	Machines},
  booktitle = {Proceedings 1999 International Conference on Artificial Neural Networks,
	ICANN'99},
  year = {1999},
  pages = {91--96},
  address = {London, U.K.},
  publisher = {The Institution of Electrical Engineers},
  linkpsgz = {http://www.mth.kcl.ac.uk/~psollich/papers/SVM_ICANNIX.ps.gz}
}

@ARTICLE{Sorenson:bayes71,
  author = {H. W. Sorenson and D. L. Alspach},
  title = {Recursive {B}ayesian estimation using {G}aussian sums},
  journal = {Automatica},
  year = {1971},
  volume = {7},
  pages = {465--479}
}

@ARTICLE{Specht:parz90,
  author = {D. F. Specht},
  title = {Probabilistic neural networks},
  journal = NN,
  year = {1990},
  volume = {3},
  pages = {109--118},
  number = {1}
}

@InProceedings{Lasserre:hybrid06,
  author = 	 {Julia A. Lasserre and Christopher M. Bishop and Thomas P. Minka},
  title = 	 {Principled Hybrids of Generative and Discriminative Models},
  booktitle =	 pCVPR,
  OPTpages = 	 {},
  OPTcrossref =  {},
  OPTkey = 	 {},
  OPTbooktitle = {},
  OPTpages = 	 {},
  year =	 {2006},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {New York, NY, USA},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@ARTICLE{Spellman:yeastcellcy98,
  author = {Paul T. Spellman and Gavin Sherlock and Michael Q. Zhang and Vishwanath
	R. Iyer and Kirk Anders and Michael B. Eisen and Patrick O. Brown
	and David Botstein and Bruce Futcher},
  title = {Comprehensive Identification of Cell Cycle-Regulated Genes of the
	Yeast {{\em Saccharomyces}} {\em cerevisiae} by Microarray Hybridization},
  journal = {Molecular Biology of the Cell},
  year = {1998},
  volume = {9},
  pages = {3273--3297},
  number = {12},
  file = {Spellman1998Comprehensive.pdf:Spellman1998Comprehensive.pdf:PDF},
  group = {Quach Minh},
  url = {http://www.molbiolcell.org/cgi/content/full/9/12/3273}
}

@ARTICLE{Spiegelhalter:expert93,
  author = {David J. Spiegelhalter and A. Phillip Dawid and Steffen L. Lauritzen
	and R. Cowell},
  title = {{B}ayesian analysis in expert systems},
  journal = {Stat.\ Sci.},
  year = {1993},
  volume = {8},
  pages = {219--283},
  number = {3}
}

@MISC{Spiegelhalter:bugs94,
  author = {David J. Spiegelhalter and A. Thomas and N. G. Best and W. R. Gilks},
  title = {BUGS: {B}ayesian inference using {G}ibbs sampling, Version 0.5, (version
	ii)},
  howpublished = {Available from \url{http://www.mrc-bsu.cam.ac.uk/bugs/}.},
  year = {1996}
}

@ARTICLE{Sprecher:func65,
  author = {D. A. Sprecher},
  title = {On the structure of continuous functions of several variables},
  journal = {Transactions of the American Mathematical Society},
  year = {1965},
  volume = {115},
  pages = {340--355}
}

@ARTICLE{Stahl2010,
  author = {Eli A Stahl and Soumya Raychaudhuri and Elaine F Remmers and Gang
	Xie and Stephen Eyre and Brian P Thomson and Yonghong Li and Fina
	A S Kurreeman and Alexandra Zhernakova and Anne Hinks and Candace
	Guiducci and Robert Chen and Lars Alfredsson and Christopher I Amos
	and Kristin G Ardlie and B. I. R. A. C. Consortium and Anne Barton
	and John Bowes and Elisabeth Brouwer and Noel P Burtt and Joseph
	J Catanese and Jonathan Coblyn and Marieke J H Coenen and Karen H
	Costenbader and Lindsey A Criswell and J. Bart A Crusius and Jing
	Cui and Paul I W de Bakker and Philip L De Jager and Bo Ding and
	Paul Emery and Edward Flynn and Pille Harrison and Lynne J Hocking
	and Tom W J Huizinga and Daniel L Kastner and Xiayi Ke and Annette
	T Lee and Xiangdong Liu and Paul Martin and Ann W Morgan and Leonid
	Padyukov and Marcel D Posthumus and Timothy R D J Radstake and David
	M Reid and Mark Seielstad and Michael F Seldin and Nancy A Shadick
	and Sophia Steer and Paul P Tak and Wendy Thomson and Annette H M
	van der Helm-van Mil and Irene E van der Horst-Bruinsma and C. Ellen
	van der Schoot and Piet L C M van Riel and Michael E Weinblatt and
	Anthony G Wilson and Gert Jan Wolbink and B. Paul Wordsworth and
	Y. E. A. R. Consortium and Cisca Wijmenga and Elizabeth W Karlson
	and Rene E M Toes and Niek de Vries and Ann B Begovich and Jane Worthington
	and Katherine A Siminovitch and Peter K Gregersen and Lars Klareskog
	and Robert M Plenge},
  title = {Genome-wide association study meta-analysis identifies seven new
	rheumatoid arthritis risk loci.},
  journal = {Nat Genet},
  year = {2010},
  volume = {42},
  pages = {508--514},
  number = {6},
  month = {Jun},
  abstract = {To identify new genetic risk factors for rheumatoid arthritis, we
	conducted a genome-wide association study meta-analysis of 5,539
	autoantibody-positive individuals with rheumatoid arthritis (cases)
	and 20,169 controls of European descent, followed by replication
	in an independent set of 6,768 rheumatoid arthritis cases and 8,806
	controls. Of 34 SNPs selected for replication, 7 new rheumatoid arthritis
	risk alleles were identified at genome-wide significance (P < 5 x
	10(-8)) in an analysis of all 41,282 samples. The associated SNPs
	are near genes of known immune function, including IL6ST, SPRED2,
	RBPJ, CCR6, IRF5 and PXK. We also refined associations at two established
	rheumatoid arthritis risk loci (IL2RA and CCL21) and confirmed the
	association at AFF3. These new associations bring the total number
	of confirmed rheumatoid arthritis risk loci to 31 among individuals
	of European ancestry. An additional 11 SNPs replicated at P < 0.05,
	many of which are validated autoimmune risk alleles, suggesting that
	most represent genuine rheumatoid arthritis risk alleles.},
  doi = {10.1038/ng.582},
  institution = {Division of Rheumatology, Immunology and Allergy, Brigham and Women's
	Hospital, Boston, Massachusetts, USA.},
  keywords = {Arthritis, Rheumatoid, genetics; Autoantibodies, administration /&/
	dosage; Genetic Loci; Genetic Predisposition to Disease; Genome-Wide
	Association Study; Humans; Polymorphism, Single Nucleotide; Risk
	Factors},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ng.582},
  pmid = {20453842},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1038/ng.582}
}

@ARTICLE{Stark:reconstructing03,
  author = {Jaroslav Stark and D. Brewer and Martino Barenco and D. Tomescu and
	R. Callard and M. Hubank},
  title = {Reconstructing gene networks: what are the limits?},
  journal = {Biochemical Society Transactions},
  year = {2003},
  volume = {31},
  pages = {1519--1525},
  number = {6},
  abstract = {To fully realize the benefits of high-throughput post-genomic technologies
	it is necessary to reconstruct and analyse the complicated network
	of interactions through which most genes operate. We briefly summarize
	the mathematical frameworks that can be used to model such networks,
	and the types of algorithms available for their reconstruction. We
	then focus on dynamic models, typically described using differential
	equations, and explain the two main reconstruction approaches in
	current use. We discuss the data requirements of these algorithms
	and ask how well they correspond to current microarray data.},
  file = {0311519.pdf:http\://www.biochemsoctrans.org/bst/031/1519/0311519.pdf:PDF},
  group = {gene networks}
}

@ARTICLE{Stegle2010,
  author = {Oliver Stegle and Leopold Parts and Richard Durbin and John Winn},
  title = {A Bayesian framework to account for complex non-genetic factors in
	gene expression levels greatly increases power in eQTL studies.},
  journal = {PLoS Comput Biol},
  year = {2010},
  volume = {6},
  pages = {e1000770},
  number = {5},
  month = {May},
  abstract = {Gene expression measurements are influenced by a wide range of factors,
	such as the state of the cell, experimental conditions and variants
	in the sequence of regulatory regions. To understand the effect of
	a variable of interest, such as the genotype of a locus, it is important
	to account for variation that is due to confounding causes. Here,
	we present VBQTL, a probabilistic approach for mapping expression
	quantitative trait loci (eQTLs) that jointly models contributions
	from genotype as well as known and hidden confounding factors. VBQTL
	is implemented within an efficient and flexible inference framework,
	making it fast and tractable on large-scale problems. We compare
	the performance of VBQTL with alternative methods for dealing with
	confounding variability on eQTL mapping datasets from simulations,
	yeast, mouse, and human. Employing Bayesian complexity control and
	joint modelling is shown to result in more precise estimates of the
	contribution of different confounding factors resulting in additional
	associations to measured transcript levels compared to alternative
	approaches. We present a threefold larger collection of cis eQTLs
	than previously found in a whole-genome eQTL scan of an outbred human
	population. Altogether, 27\% of the tested probes show a significant
	genetic association in cis, and we validate that the additional eQTLs
	are likely to be real by replicating them in different sets of individuals.
	Our method is the next step in the analysis of high-dimensional phenotype
	data, and its application has revealed insights into genetic regulation
	of gene expression by demonstrating more abundant cis-acting eQTLs
	in human than previously shown. Our software is freely available
	online at http://www.sanger.ac.uk/resources/software/peer/.},
  doi = {10.1371/journal.pcbi.1000770},
  institution = {Max Planck Institutes Tübingen, Tübingen, Germany. oliver.stegle@tuebingen.mpg.de},
  keywords = {Animals; Bayes Theorem; Databases, Genetic; Gene Expression; Humans;
	Internet; Markov Chains; Mice; Models, Genetic; Models, Statistical;
	Phenotype; Quantitative Trait Loci; Reproducibility of Results; Software;
	Yeasts},
  language = {eng},
  medline-pst = {epublish},
  owner = {neil},
  pmid = {20463871},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1371/journal.pcbi.1000770}
}

@INCOLLECTION{Stein:dnamicro98,
  author = {L. D. Stein},
  title = {Genetic Analysis on {DNA} microarrays},
  booktitle = {Current Protocols in Human Genetics},
  publisher = wiley,
  year = {1998},
  editor = {Nicholas C. Dracopoli and Jonathan L. Haines and Bruce R. Korf and
	Donald T. Moir Cynthia C. Morton and Christine E. Seidman and Douglas
	R. Smith},
  pages = {7.9.1--7.9.8}
}

@Article{Wu:pivot07,
  author = 	 {Hua Wu and Haifeng Wang},
  title = 	 {Pivot Language Approach for Phrase-based Statistical Machine Translation},
  journal = 	 {Machine Translation},
  year = 	 {2007},
  OPTkey = 	 {},
  volume =	 {21},
  number =	 {3},
  OPTpages = 	 {165--181},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1007/s10590-008-9041-6},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@ARTICLE{Stigler:laplace86,
  author = {Stephen M. Stigler},
  title = {Laplace's 1774 Memoir on Inverse Probability},
  journal = {Statistical Science},
  year = {1986},
  volume = {1},
  pages = {359--378}
}

@INPROCEEDINGS{Stinchecombe:univ89,
  author = {M. Stinchecombe and H. White},
  title = {Universal approximation using feed-forward networks with non-sigmoid
	hidden layer activation functions},
  booktitle = ijcnn,
  year = {1989},
  volume = {1},
  pages = {613--618},
  address = {San Diego},
  publisher = {IEEE}
}

@TECHREPORT{Stitson:theorySVM96,
  author = {M. O. Stitson and Jason A. E. Weston and A. Gammerman and V. Vovk
	and Vladimir N. Vapnik},
  title = {Theory of Support Vector Machines},
  institution = {Royal Holloway University of London},
  year = {1996},
  note = {Available from \url{http://www.dcs.rhbnc.ac.uk/research/compint/areas/comp_learn/sv/}}
}

@ARTICLE{Stoecklin:posttranscriptional06,
  author = {Georg Stoecklin and Paul Anderson},
  title = {Posttranscriptional mechanisms regulating the inflammatory response.},
  journal = advimmunol,
  year = {2006},
  volume = {89},
  pages = {1--37},
  abstract = {The inflammatory response is a complex physiologic process that requires
	the coordinate induction of cytokines, chemokines, angiogenic factors,
	effector-enzymes, and proteases. Although transcriptional activation
	is required to turn on the inflammatory response, recent studies
	have revealed that posttranscriptional mechanisms play an important
	role by determining the rate at which mRNAs encoding inflammatory
	effector proteins are translated and degraded. Most posttranscriptional
	control mechanisms function to dampen the expression of pro-inflammatory
	proteins to ensure that potentially injurious proteins are not overexpressed
	during an inflammatory response. Here we discuss the factors that
	regulate the stability and translation of mRNAs encoding pro-inflammatory
	proteins.},
  doi = {10.1016/S0065-2776(05)89001-7},
  file = {sdarticle.pdf:http\://www.sciencedirect.com/science?_ob=MImg&_imagekey=B7CT8-4JWNHV9-1-1&_cdi=18044&_user=494590&_orig=search&_coverDate=12%2F31%2F2006&_sk=999109999&view=c&wchp=dGLbVzW-zSkzS&md5=0f1f1b74f2a15d9d27052f4ff03978ea&ie=/sdarticle.pdf:PDF},
  group = {cytokine, immune response},
  pmid = {16682271}
}

@ARTICLE{Stone:review78,
  author = {M. Stone},
  title = {Cross-validation: A Review},
  journal = {Math.\ Operationsforsch.\ Statist.\ Ser.\ Statistics},
  year = {1978},
  volume = {9},
  pages = {127--139},
  number = {1}
}

@ARTICLE{Stone:cv74,
  author = {M. Stone},
  title = {Cross-validatory choice and assessment of statistical predictions},
  journal = JRSSb,
  year = {1974},
  volume = {36},
  pages = {111--147},
  number = {1}
}

@ARTICLE{Su2004,
  author = {Ruey-Chyi Su and Karen E Brown and Sanam Saaber and Amanda G Fisher
	and Matthias Merkenschlager and Stephen T Smale},
  title = {Dynamic assembly of silent chromatin during thymocyte maturation.},
  journal = {Nat Genet},
  year = {2004},
  volume = {36},
  pages = {502--506},
  number = {5},
  month = {May},
  abstract = {Considerable knowledge has been gained from temporal analyses of molecular
	events culminating in gene activation, but technical hurdles have
	hindered comparable studies of gene silencing. Here we describe the
	temporal assembly of silent chromatin at the mouse terminal transferase
	gene (Dntt), which is silenced and repositioned to pericentromeric
	heterochromatin during thymocyte maturation. Silencing was nucleated
	at the Dntt promoter by the ordered deacetylation of histone H3 at
	Lys9 (H3-Lys9), loss of methylation at H3-Lys4 and acquisition of
	methylation at H3-Lys9, followed by bidirectional spreading of each
	event. Deacetylation at H3-Lys9 coincided with pericentromeric repositioning,
	and neither of these early events required de novo protein synthesis.
	CpG methylation increased primarily in mature T cells that had left
	the thymus. A transformed thymocyte line supported reversible inactivation
	of Dntt without repositioning. In these cells, histone modification
	changes were nucleated at the promoter but did not spread. These
	results provide a foundation for elucidating the mechanisms of silent
	chromatin assembly during development.},
  doi = {10.1038/ng1351},
  institution = {Howard Hughes Medical Institute and Department of Microbiology, Immunology,
	and Molecular Genetics, University of California, Los Angeles, California
	90095-1662, USA.},
  keywords = {Acetylation; Animals; Carcinogens, pharmacology; Chromatin, genetics;
	CpG Islands; Cycloheximide, pharmacology; DNA Methylation; DNA Nucleotidylexotransferase,
	genetics/metabolism; DNA-Binding Proteins, genetics/metabolism; Gene
	Silencing; Histone Deacetylases, metabolism; Histone-Lysine N-Methyltransferase,
	metabolism; Histones, genetics/metabolism; Homeodomain Proteins,
	genetics/metabolism; Ionomycin, pharmacology; Ionophores, pharmacology;
	Major Histocompatibility Complex, genetics/physiology; Mice; Mice,
	Knockout; Promoter Regions, Genetic, genetics; Protein Synthesis
	Inhibitors, pharmacology; RNA, Messenger, genetics; Reverse Transcriptase
	Polymerase Chain Reaction; T-Lymphocytes, cytology/metabolism; Tetradecanoylphorbol
	Acetate, pharmacology; Thymus Gland, growth /&/ development/physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pii = {ng1351},
  pmid = {15098035},
  timestamp = {2011.09.14},
  url = {http://dx.doi.org/10.1038/ng1351}
}

@INPROCEEDINGS{Sumner:deformation04,
  author = {Robert W. Sumner and Jovan Popovi\'c},
  title = {Deformation Transfer for Triangle Meshes},
  booktitle = {ACM Transactions on Graphics (SIGGRAPH 2004)},
  year = {2004}
}

@ARTICLE{Surkova:characterization08,
  author = {Svetlana Surkova and David Kosman and Konstantin Kozlov and Manu
	and Ekaterina Myasnikova and Anastasia A. Samsonova and Alexander
	Spirov and Carlos E. Vanario-Alonso and Maria Samsonova and John
	Reinitz},
  title = {Characterization of the Drosophila segment determination morphome},
  journal = {Dev Biol.},
  year = {2008},
  volume = {313},
  pages = {844--862},
  number = {2},
  abstract = {Here we characterize the expression of the full system of genes which
	control the segmentation morphogenetic field of \emph{Drosophila}
	at the protein level in one dimension. The data used for this characterization
	are quantitative with cellular resolution in space and about 6 min
	in time. We present the full quantitative profiles of all 14 segmentation
	genes which act before the onset of gastrulation. The expression
	patterns of these genes are first characterized in terms of their
	average or typical behavior. At this level, the expression of all
	of the genes has been integrated into a single atlas of gene expression
	in which the expression levels of all genes in each cell are specified.
	We show that expression domains do not arise synchronously, but rather
	each domain has its own specific dynamics of formation. Moreover,
	we show that the expression domains shift position in the direction
	of the cephalic furrow, such that domains in the anlage of the segmented
	germ band shift anteriorly while those in the presumptive head shift
	posteriorly. The expression atlas of integrated data is very close
	to the expression profiles of individual embryos during the latter
	part of the blastoderm stage. At earlier times gap gene domains show
	considerable variation in amplitude, and significant positional variability.
	Nevertheless, an average early gap domain is close to that of a median
	individual. In contrast, we show that there is a diversity of developmental
	trajectories among pair-rule genes at a variety of levels, including
	the order of domain formation and positional accuracy. We further
	show that this variation is dynamically reduced, or canalized, over
	time. As the first quantitatively characterized morphogenetic field,
	this system and its behavior constitute an extraordinarily rich set
	of materials for the study of canalization and embryonic regulation
	at the molecular level.},
  doi = {10.1016/j.ydbio.2007.10.037},
  group = {Drosophila segmentation},
  pmid = {18067886}
}

@ARTICLE{Sussman:unique92,
  author = {H. J. Sussmann},
  title = {Uniqueness of the weights for minimal feedforward nets with a given
	input-output map},
  journal = NN,
  year = {1992},
  volume = {5},
  pages = {589--593},
  number = {4}
}

@PHDTHESIS{Svensen:thesis98,
  author = {Marcus Svens\'{e}n},
  title = {{GTM}: {T}he {G}enerative {T}opographic {M}apping},
  school = {Aston University},
  year = {1998},
  address = {Birmingham, UK}
}

@ARTICLE{Symmons1994,
  author = {D. P. Symmons and E. M. Barrett and C. R. Bankhead and D. G. Scott
	and A. J. Silman},
  title = {The incidence of rheumatoid arthritis in the United Kingdom: results
	from the Norfolk Arthritis Register.},
  journal = {Br J Rheumatol},
  year = {1994},
  volume = {33},
  pages = {735--739},
  number = {8},
  month = {Aug},
  abstract = {This paper provides the first data on the incidence of RA based on
	a prospective population-based register. All new cases of inflammatory
	polyarthritis in the Norwich Health Authority are notified by general
	practitioners to the Norfolk Arthritis Register. The patients are
	then clinically evaluated by metrologists and blood taken for RF
	estimation. Cases of RA were defined as all those notified with an
	onset of symptoms in 1990; who presented by 31 December 1991; and
	who satisfied the 1987 ARA criteria for RA at the time of presentation.
	Two hundred and ten patients were notified in the defined time-frame,
	of whom 104 were classified as having RA. The annual incidence rate
	was 36/100,000 for women and 14/100,000 for men. RA was rare in men
	aged under 45 yr. The incidence in men rose steeply with age. The
	incidence in women rose up to age 45 yr, plateaued to age 75 yr,
	and fell in the very elderly.},
  institution = {ARC Epidemiology Research Unit, University of Manchester.},
  keywords = {Adolescent; Adult; Age Distribution; Aged; Aged, 80 and over; Arthritis,
	Rheumatoid, epidemiology; Female; Great Britain, epidemiology; Humans;
	Incidence; Male; Middle Aged; Primary Health Care; Prospective Studies;
	Registries; Sex Distribution},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {8055200},
  timestamp = {2011.09.14}
}

@ARTICLE{Tait:theorem80,
  author = {P. G. Tait},
  title = {Note on a Theorem in Geometry of Position},
  journal = {Transactions of the Royal Society of Edinburgh},
  year = {1880},
  volume = {29},
  pages = {657--660}
}

@ARTICLE{Takane:nonmetric77,
  author = {Yoshio Takane and Forrest W. Young and Jan {de Leeuw}},
  title = {Nonmetric Individual Difference Multidimensional Scaling: An Alternating
	Least Squares Method with Optimal Scaling Features},
  journal = {Psychometrika},
  year = {1977},
  volume = {42},
  pages = {7--67},
  file = {p007.pdf:http\://takane.brinkster.net/Yoshio/p007.pdf:PDF}
}

@ARTICLE{Tanaka:genome00,
  author = {T. S. Tanaka and S. A. Jaradat and M. K. Lim and G. J. Karguland
	X. Wang and M. J. Grahovac and S. Pantano and Y. Sano and Y. Piao
	and R. Nagaraja and H. Doi and W. H. Wood 3rd and K. G. Becker and
	M. S. H. Ko},
  title = {Genome-wide Expression Profiling of Mid-Gestation Placenta and Embryo
	Using a 15,000 Mouse Developmental {cDNA} Microarray},
  journal = pnasusa,
  year = {2000},
  volume = {97},
  pages = {9127--9132}
}

@INPROCEEDINGS{Tarassenko:nov95,
  author = {Lionel Tarassenko and P Hayton and N Cerneaz and M Brady},
  title = {Novelty detection for the identification of masses in mammograms},
  booktitle = {Proceedings Fourth IEE International Conference on Artificial Neural
	Networks},
  year = {1995},
  volume = {4},
  pages = {442--447},
  address = {London},
  publisher = {IEEE},
  label1 = {IEEE Xplore},
  link1 = {http://ieeexplore.ieee.org/xpl/abs_free.jsp?arNumber=497860}
}

@ARTICLE{Tarassenko:novelty00,
  author = {Lionel Tarassenko and A. Nairac and N. Townsend and I Buxton and
	P. Cowley},
  title = {Novelty detection for the identification of abnormalities},
  journal = {International Journal of Systems Science},
  year = {2000},
  volume = {31},
  pages = {1427--1439},
  number = {11},
  label1 = {Ingenta Select},
  link1 = {http://lysander.ingentaselect.com/vl=6308399/cl=104/nw=1/fm=docpdf/rpsv/cw/tandf/00207721/v31n11/s9/p1427}
}

@INPROCEEDINGS{Tarassenko:medical01,
  author = {Lionel Tarassenko and N. Townsend and G. Clifford and L Mason and
	J Burton and J Price},
  title = {Medical Signal Processing Using the Software Monitor},
  booktitle = {A DERA/IEE Workshop on Intelligent Sensor Processing},
  year = {2001},
  pages = {3/1--3/4},
  label1 = {IEEE Xplore},
  link1 = {http://ieeexplore.ieee.org/xpl/abs_free.jsp?arNumber=938219}
}

@ARTICLE{Teh:hdp06,
  author = {Yee Whye Teh and Michael I. Jordan and Matthew J. Beal and David
	M. Blei},
  title = {Hierarchical {D}irichlet Processes},
  journal = jasa,
  year = {2006},
  volume = {101},
  pages = {1566--1581},
  number = {476},
  abstract = {We consider problems involving groups of data, where each observation
	within a group is a draw from a mixture model, and where it is desirable
	to share mixture components between groups. We assume that the number
	of mixture components is unknown a priori and is to be inferred from
	the data. In this setting it is natural to consider sets of Dirichlet
	processes, one for each group, where the well-known clustering property
	of the Dirichlet process provides a nonparametric prior for the number
	of mixture componentswithin each group. Given our desire to tie the
	mixture models in the various groups, we consider a hierarchical
	model, specifically one in which the base measure for the child Dirichlet
	processes is itself distributed according to a Dirichlet process.
	Such a base measure being discrete, the child Dirichlet processes
	necessarily share atoms. Thus, as desired, the mixture models in
	the different groups necessarily share mixture components. We discuss
	representations of hierarchical Dirichlet processes in terms of a
	stick-breaking process, and a generalization of the Chinese restaurant
	process that we refer to as the âChinese restaurant franchise.â We
	present Markov chain Monte Carlo algorithms for posterior inference
	in hierarchical Dirichlet process mixtures, and describe applications
	to problems in information retrieval and text modelling.},
  file = {jasa2006.pdf:http\://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/jasa2006.pdf:PDF},
  group = {dp, hdp},
  label1 = {JASA},
  link1 = {http://www.amstat.org/publications/jasa/index.cfm?fuseaction=main}
}

@INPROCEEDINGS{Teh:collapsedLDA06,
  author = {Yee Whye Teh and David Newman and Max Welling},
  title = {A collapsed variational Bayesian inference algorithm for latent {D}irichlet
	allocation},
  abstract = {Latent Dirichlet allocation (LDA) is a Bayesian network that has recently
	gained much popularity in applications ranging from document modeling
	to computer vision. Due to the large scale nature of these applications,
	current inference procedures like variational Bayes and Gibb sampling
	have been found lacking. In this paper we propose the collapsed variational
	Bayesian inference algorithm for LDA, and show that it is computationally
	efficient, easy to implement and significantly more accurate than
	standard variational Bayesian inference for LDA.},
  group = {variational, topic models},
  optcrossref = {Schoelkopf:nips06}
}

@ARTICLE{Tenenbaum:isomap00,
  author = {Joshua B. Tenenbaum and Virginia {de Silva} and John C. Langford},
  title = {A Global Geometric Framework for Nonlinear Dimensionality Reduction},
  journal = {Science},
  year = {2000},
  volume = {290},
  pages = {2319--2323},
  number = {5500},
  abstract = {Scientists working with large volumes of high-dimensional data, such
	as global climate patterns, stellar spectra, or human gene distributions,
	regularly confront the problem of dimensionality reduction: finding
	meaningful low-dimensional structures hidden in their high-dimensional
	observations. The human brain confronts the same problem in everyday
	perception, extracting from its high-dimensional sensory inputs--30,000
	auditory nerve fibers or 106 optic nerve fibers--a manageably small
	number of perceptually relevant features. Here we describe an approach
	to solving dimensionality reduction problems that uses easily measured
	local metric information to learn the underlying global geometry
	of a data set. Unlike classical techniques such as principal component
	analysis (PCA) and multidimensional scaling (MDS), our approach is
	capable of discovering the nonlinear degrees of freedom that underlie
	complex natural observations, such as human handwriting or images
	of a face under different viewing conditions. In contrast to previous
	algorithms for nonlinear dimensionality reduction, ours efficiently
	computes a globally optimal solution, and, for an important class
	of data manifolds, is guaranteed to converge asymptotically to the
	true structure.},
  doi = {10.1126/science.290.5500.2319},
  group = {dimensional reduction},
  label1 = {Science Issue},
  link1 = {http://www.sciencemag.org/content/vol290/issue5500/}
}

@ARTICLE{Tenenbaum:style00,
  author = {Joshua B. Tenenbaum and William T. Freeman},
  title = {Separating Style and Content with Bilinear Models},
  journal = NC,
  year = {2000},
  volume = {12},
  pages = {1247--1283},
  file = {NC120601.pdf:http\://www-psych.stanford.edu/~jbt/NC120601.pdf:PDF}
}

@ARTICLE{Thodberg:review96,
  author = {Hans Henrik Thodberg},
  title = {A Review of {B}ayesian Neural Networks with an Application to Near
	Infrared Spectroscopy},
  journal = IEEE,
  year = {1996},
  volume = {7},
  pages = {56--72},
  number = {1}
}

@TECHREPORT{Thodberg:ace93,
  author = {Hans Henrik Thodberg},
  title = {Ace of {B}ayes: application of neural networks with pruning},
  institution = {The Danish Meat Research Institute},
  year = {1993},
  number = {1132E},
  address = {Maglegaardsvej 2, DK-4000 Roskilde, Denmark}
}

@ARTICLE{Thorburn:razor15,
  author = {W. M. Thorburn},
  title = {Occam's Razor},
  journal = {Mind},
  year = {1915},
  volume = {24},
  pages = {287--288}
}

@ARTICLE{Thorburn:razor15b,
  author = {W. M. Thorburn},
  title = {The Myth of {O}ccam's Razor},
  journal = {Mind},
  year = {1915},
  volume = {27},
  pages = {345--353}
}

@INPROCEEDINGS{Tian:articulated05,
  author = {Tai-Peng Tian and Rui Li and Stan Sclaroff},
  title = {Articulated Pose Estimation in a Learned Smooth Space of Feasible
	Solutions},
  booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer
	Vision and Pattern Recognition (CVPR'05) - Workshops},
  year = {2005},
  volume = {3},
  abstract = {A learning based framework is proposed for estimating human body pose
	from a single image. Given a differentiable function that maps from
	pose space to image feature space, the goal is to invert the process:
	estimate the pose given only image features. The inversion is an
	ill-posed problem as the inverse mapping is a one to many process,
	hence multiple solutions exist. It is desirable to restrict the solution
	space to a smaller subset of feasible solutions. The space of feasible
	solutions may not admit a closed form description. The proposed framework
	seeks to learn an approximation over such a space. Using Gaussian
	Process Latent Variable Modelling. The scaled conjugate gradient
	method is used to find the best matching pose in the learned space.
	The formulation allows easy incorporation of various constraints
	for more accurate pose estimation. The performance of the proposed
	approach is evaluated in the task of upper-body pose estimation from
	silhouettes and compared with the Specialized Mapping Architecture.
	The proposed approach performs better than the latter approach in
	terms of estimation accuracy with synthetic data and qualitatively
	better results with real video of humans performing gestures.},
  doi = {10.1109/CVPR.2005.414},
  file = {2005-025-learned-articulated-pose-estimation.pdf:http\://www.cs.bu.edu/techreports/pdf/2005-025-learned-articulated-pose-estimation.pdf:PDF},
  group = {gplvm},
  linkps = {http://www.cs.bu.edu/techreports/ps/2005-025-learned-articulated-pose-estimation.ps}
}

@ARTICLE{Tibshirani:pcurves92,
  author = {R. Tibshirani},
  title = {Principal curves revisited},
  journal = {Statistics and Computing},
  year = {1992},
  volume = {2},
  pages = {183--190},
  number = {4},
  abstract = {A principal curve (Hastie and Stuetzle, 1989) is a smooth curve passing
	through the lsquomiddlersquo of a distribution or data cloud, and
	is a generalization of linear principal components. We give an alternative
	definition of a principal curve, based on a mixture model. Estimation
	is carried out through an EM algorithm. Some comparisons are made
	to the Hastie-Stuetzle definition.},
  doi = {10.1007/BF01889678},
  group = {principal curve}
}

@ARTICLE{Tino:hierarchical02,
  author = {Peter Tino and Ian T. Nabney},
  title = {Hierarchical GTM: Constructing Localized Nonlinear Projection Manifolds
	in a Principled Way},
  journal = PAMI,
  year = {2002},
  volume = {24},
  pages = {639--656},
  number = {5},
  abstract = {It has been argued that a single two-dimensional visualization plot
	may not be sufficient to capture all of the interesting aspects of
	complex data sets and, therefore, a hierarchical visualization system
	is desirable. In this paper we extend an existing locally linear
	hierarchical visualization system PhiVis \cite{Bishop:hierarchy98}
	in several directions: 1) We allow for \emph{nonlinear} proection
	manifolds. The basic building block is the Generative Topographic
	Mapping (GTM). 2) We introduce a general formulation of hierarchical
	probabilistic models consisting of local probabilistic models organized
	in a hierarchical tree. General training equations are derived, regardless
	of the position of the model in the tree. 3) Using tools from differential
	geometry, we derive expressions for local directional curvatures
	of the projection manifold. Like PhiVis, our system is statistically
	principled and is built interactively in a top down fashioon using
	the EM algorithm. It enables the user to iteractively highlight those
	data in the ancestor visualization plots which are captured by a
	child model. We also incoporate into our system a hierarchical, locally
	selective representation of magnification factors and directional
	curvatures of the projection manifolds. Such information is important
	for further refinement of the hierarchical visualisation plot, as
	well as for controlling the amount of regularization imposed on the
	local models. We demonstrate the principle of the approach on a toy
	data set and apply our system to two more complex 12 and 18-dimensional
	data sets.},
  doi = {10.1109/34.1000238},
  group = {GTM}
}

@ARTICLE{Tipping:rvm01,
  author = {Michael E. Tipping},
  title = {Sparse {B}ayesian Learning and the Relevance Vector Machine},
  journal = jmlr,
  year = {2001},
  volume = {1},
  pages = {211--244},
  month = {June}
}

@PHDTHESIS{Tipping:thesis96,
  author = {Michael E. Tipping},
  title = {Topographic Mappings and Feed-Forward Neural Networks},
  school = {Aston University},
  year = {1996},
  address = {Aston Street, Birmingham B4 7ET, U.K.},
  label1 = {Web Page},
  limk1 = {http://research.microsoft.com/~mtipping/pages/thesis.htm},
  linkpsgz = {ftp://ftp.research.microsoft.com/users/mtipping/thesis.ps.gz}
}

@ARTICLE{Tipping:pca97,
  author = {Michael E. Tipping and Christopher M. Bishop},
  title = {Mixtures of Probabilistic Principal Component Analysers},
  journal = NC,
  year = {1999},
  volume = {11},
  pages = {443--482},
  number = {2},
  abstract = {Principal component analysis (PCA) is one of the most popular techniques
	for processing, compressing and visualising data, although its effectiveness
	is limited by its global linearity. While nonlinear variants of PCA
	have been proposed, an alternative paradigm is to capture data complexity
	by a combination of local linear PCA projections. However, conventional
	PCA does not correspond to a probability density, and so there is
	no unique way to combine PCA models. Previous attempts to formulate
	mixture models for PCA have therefore to some extent been ad hoc.
	In this paper, PCA is formulated within a maximum-likelihood framework,
	based on a specific form of Gaussian latent variable model. This
	leads to a well-defined mixture model for probabilistic principal
	component analysers, whose parameters can be determined using an
	EM algorithm. We discuss the advantages of this model in the context
	of clustering, density modelling and local dimensionality reduction,
	and we demonstrate its application to image compression and handwritten
	digit recognition.},
  file = {met-mppca.pdf:http\://www.miketipping.com/papers/met-mppca.pdf:PDF},
  group = {pca, ppca, mixtures},
  linkpsgz = {http://www.miketipping.com/papers/met-mppca.ps.gz}
}

@ARTICLE{Tipping:probpca99,
  author = {Michael E. Tipping and Christopher M. Bishop},
  title = {Probabilistic Principal Component Analysis},
  journal = JRSSb,
  year = {1999},
  volume = {6},
  pages = {611--622},
  number = {3},
  abstract = {Principal component analysis (PCA) is a ubiquitous technique for data
	analysis and processing, but one which is not based upon a probability
	model. In this paper we demonstrate how the principal axes of a set
	of observed data vectors may be determined through maximum-likelihood
	estimation of parameters in a latent variable model closely related
	to factor analysis. We consider the properties of the associated
	likelihood function, giving an EM algorithm for estimating the principal
	subspace iteratively, and discuss, with illustrative examples, the
	advantages conveyed by this probabilistic approach to PCA.},
  doi = {doi:10.1111/1467-9868.00196},
  file = {:http\://www.robots.ox.ac.uk/~cvrg/hilary2006/ppca.pdf:PDF},
  linkpdf = {http://www.robots.ox.ac.uk/~cvrg/hilary2006/ppca.pdf},
  linkps = {http://www.gatsby.ucl.ac.uk/~quaid/course/readings/ppca.ps}
}

@INPROCEEDINGS{Tipping:iee_hierarchy97,
  author = {Michael E. Tipping and Christopher M. Bishop},
  title = {Hierarchical models for data visualization},
  booktitle = {Proceedings IEE Fifth International Conference on Artificial Neural
	Networks, Cambridge, U.K.},
  year = {1997},
  pages = {70--75},
  group = {dimensional reduction, mixtures}
}

@INPROCEEDINGS{Tipping:iee_mixpca97,
  author = {Michael E. Tipping and Christopher M. Bishop},
  title = {Mixtures of Principal Component Analysers},
  booktitle = {Proceedings IEE Fifth International Conference on Artificial Neural
	Networks, Cambridge, U.K., July.},
  year = {1997},
  pages = {13--18}
}

@ARTICLE{Titsias:mixture02,
  author = {Michalis K. Titsias and A. Likas},
  title = {Mixture of Experts Classification Using a Hierarchical Mixture Model},
  journal = NC,
  year = {2002},
  volume = {14},
  pages = {2221-2244},
  number = {9}
}

@ARTICLE{Tomancak:systematic02,
  author = {P. Tomancak and A. Beaton and R. Weiszmann and E. Kwan and S. Shu
	and S. E. Lewis and S. Richards and M. Ashburner and V. Hartenstein
	and S. E. Celniker and G. M. Rubin},
  title = {{S}ystematic determination of patterns of gene expression during
	{D}rosophila embryogenesis},
  journal = {Genome Biology},
  year = {2002},
  volume = {3},
  pages = {RESEARCH0088},
  number = {12},
  abstract = {BACKGROUND: Cell-fate specification and tissue differentiation during
	development are largely achieved by the regulation of gene transcription.
	\\\\ 
	
	 RESULTS: As a first step to creating a comprehensive atlas of gene-expression
	patterns during Drosophila embryogenesis, we examined 2,179 genes
	by in situ hybridization to fixed Drosophila embryos. Of the genes
	assayed, 63.7\% displayed dynamic expression patterns that were documented
	with 25,690 digital photomicrographs of individual embryos. The photomicrographs
	were annotated using controlled vocabularies for anatomical structures
	that are organized into a developmental hierarchy. We also generated
	a detailed time course of gene expression during embryogenesis using
	microarrays to provide an independent corroboration of the in situ
	hybridization results. All image, annotation and microarray data
	are stored in publicly available database. We found that the RNA
	transcripts of about 1\% of genes show clear subcellular localization.
	Nearly all the annotated expression patterns are distinct. We present
	an approach for organizing the data by hierarchical clustering of
	annotation terms that allows us to group tissues that express similar
	sets of genes as well as genes displaying similar expression patterns.
	CONCLUSIONS: Analyzing gene-expression patterns by in situ hybridization
	to whole-mount embryos provides an extremely rich dataset that can
	be used to identify genes involved in developmental processes that
	have been missed by traditional genetic analysis. Systematic analysis
	of rigorously annotated patterns of gene expression will complement
	and extend the types of analyses carried out using expression microarrays.},
  group = {Drosophila},
  pmid = {12537577}
}

@UNPUBLISHED{Tong:active01,
  author = {Simon Tong and Edward Chang},
  title = {Support Vector Machine Active Learning for Image Retrieval},
  note = {To appear in \emph{ACM Multimedia}},
  year = {2001}
}

@ARTICLE{Torgerson:mds52,
  author = {Warren S. Torgerson},
  title = {Multidimensional Scaling: I. Theory and Method},
  journal = {Psychometrika},
  year = {1952},
  volume = {17},
  pages = {401--419}
}

@ARTICLE{Townsend:bayesian02,
  author = {J. Townsend and D. L. Hartyl},
  title = {Bayesian analysis of gene expression levels: statistical quantification
	of relative m{RNA} level across multiple strains or treatments},
  journal = {Genome Biology},
  year = {2002},
  volume = {3},
  pages = {research0071.1-0071.16},
  number = {12}
}

@Article{Gordon:novel93,
  author = 	 {Neil J. Gordon and David J. Salmond and Adrian F. M. Smith},
  title = 	 {Novel approach to nonlinear/non-{G}aussian {B}ayesian state estimation},
  journal = 	 {IEE Proceedings F Radar and Signal Processing},
  year = 	 {1993},
  OPTkey = 	 {},
  volume =	 {140},
  number =	 {2},
  OPTpages = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  abstract =	 {An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linearity or Gaussian noise: it may be applied to any state transition or measurement model. A simulation example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter},
  OPTgroup = 	 {}
}

@ARTICLE{Tresp:bcm00,
  author = {Volker Tresp},
  title = {A {B}ayesian Committee Machine},
  journal = NC,
  year = {2000},
  volume = {12},
  pages = {2719--2741},
  number = {11},
  abstract = {The Bayesian committee machine (BCM) is a novel approach to combining
	estimators that were trained on different data sets. Although the
	BCM can be applied to the combination of any kind of estimators,
	the main foci are Gaussian process regression and related systems
	such as regularization networks and smoothing splines for which the
	degrees of freedom increase with the number of training data. Somewhat
	surprisingly, we find that the performance of the BCM improves if
	several test points are queried at the same time and is optimal if
	the number of test points is at least as large as the degrees of
	freedom of the estimator. The BCM also provides a new solution for
	on-line learning with potential applications to data mining. We apply
	the BCM to systems with fixed basis functions and discuss its relationship
	to Gaussian process regression. Finally, we show how the ideas behind
	the BCM can be applied in a non-Bayesian setting to extend the input-dependent
	combination of estimators.},
  file = {bcm6.pdf:http\://tresp.org/papers/bcm6.pdf:PDF},
  group = {bcm,spgp}
}

@ARTICLE{Traven:91,
  author = {H. G. C. Tr{\aa}v\'{e}n},
  title = {A neural network approach to statistical pattern classification by
	`semiparametric' estimation of probability density functions},
  journal = IEEE,
  year = {1991},
  volume = {2},
  pages = {366--377},
  number = {3}
}

@ARTICLE{Tu:metaboliccycle05,
  author = {Benjamin P. Tu and Andrzej Kudlicki and Maga Rowicka and Steven L.
	{McKnight}},
  title = {Logic of the Yeast Metabolic Cycle: Temporal Compartmentalization
	of Cellular Processes},
  journal = {Science},
  year = {2005},
  volume = {310},
  pages = {1152--1158},
  number = {5715},
  abstract = {Budding yeast grown under continuous, nutrient-limited conditions
	exhibit robust, highly periodic cycles in the form of respiratory
	bursts. Microarray studies reveal that over half of the yeast genome
	is expressed periodically during these metabolic cycles. Genes encoding
	proteins having a common function exhibit similar temporal expression
	patterns, and genes specifying functions associated with energy and
	metabolism tend to be expressed with exceptionally robust periodicity.
	Essential cellular and metabolic events occur in synchrony with the
	metabolic cycle, demonstrating that key processes in a simple eukaryotic
	cell are compartmentalized in time.},
  doi = {10.1126/science.1120499},
  group = {yeast, gene networks, metabolic cycle},
  pmid = {16254148}
}

@ARTICLE{Turk:eigenfaces91,
  author = {M. Turk and A. Pentland},
  title = {Eigenfaces for Recognition},
  journal = {Journal of Cognitive Neuroscience},
  year = {1971},
  volume = {3},
  pages = {71--86},
  number = {1}
}

@INPROCEEDINGS{Ultsch:knowledge93,
  author = {A. Ultsch},
  title = {Knowledge extraction from self-organizing neural networks},
  booktitle = {Information and Classification},
  year = {1993},
  editor = {O. Opitz and B. Lausen and R. Klar},
  pages = {301--306},
  address = {Berlin},
  publisher = {Springer}
}

@INPROCEEDINGS{Ultsch:som93,
  author = {A. Ultsch},
  title = {Self-organizing networks for visualization and classification},
  booktitle = {Information and Classification},
  year = {1993},
  editor = {O. Opitz and B. Lausen and R. Klar},
  pages = {307--313},
  address = {Berlin},
  publisher = {Springer}
}

@InProceedings{Urtasun:local08,
  author = 	 {Raquel Urtasun and Trevor Darrell},
  title = 	 {Local Probabilistic Regression for Activity-Independent Human Pose Inference},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 pCVPR,
  OPTpages = 	 {},
  year =	 {2008},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {Anchorage, Alaska},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@INPROCEEDINGS{Urtasun:3dpeople06,
  author = {Raquel Urtasun and David J. Fleet and Pascal Fua},
  title = {3{D} People Tracking with {G}aussian Process Dynamical Models},
  booktitle = pCVPR,
  year = {2006},
  pages = {238--245},
  address = {New York, U.S.A.},
  month = {17--22 Jun.},
  publisher = ieeecomp,
  doi = {10.1109/CVPR.2006.15},
  group = {gplvm,tracking}
}

@INPROCEEDINGS{Urtasun:priors05,
  author = {Raquel Urtasun and David J. Fleet and Aaron Hertzmann and Pascal
	Fua},
  title = {Priors for People Tracking from Small Training Sets},
  booktitle = iccv,
  year = {2005},
  pages = {403--410},
  address = {Bejing, China},
  month = {17--21 Oct.},
  publisher = ieeecomp,
  abstract = {We advocate the use of Scaled Gaussian Process Latent Variable Models
	(SGPLVM) to learn prior models of 3D human pose for 3D people tracking.
	The SGPLVM simultaneously optimizes a low-dimensional embedding of
	the high dimensional pose data and a density function that both gives
	higher probability to points close to training data and provides
	a nonlinear probabilistic mapping from the low dimensional latent
	space to the full-dimensional pose space. The SGPLVM is a natural
	choice when only small amounts of training data are available. We
	demonstrate our approach with two distinct motions, golfing and walking.
	We show that the SGPLVM sufficiently constrains the problem such
	that tracking can be accomplished with straightforward deterministic
	optimization.},
  doi = {10.1109/ICCV.2005.193},
  group = {gplvm},
  label1 = {IEEE Xplore},
  label2 = {PDF},
  link1 = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=32910&arnumber=1541284&count=120&index=52},
  link2 = {http://cvlab.epfl.ch/~rurtasun/publications/urtasun_etal_iccv05.pdf}
}

@ARTICLE{Utsugi:bayes_som97,
  author = {A. Utsugi},
  title = {Hyperparameter selection for self-organizing maps},
  journal = NC,
  year = {1997},
  volume = {9},
  pages = {623--635},
  number = {3}
}

@TECHREPORT{Vanderbei:LOQO94,
  author = {R. J. Vanderbei},
  title = {LOQO: An Interior Point Code for Quadratic Programming},
  institution = {Princeton University},
  year = {1994},
  note = {Available from \url{http://www.princeton.edu/\~{ }rvdb}}
}

@ARTICLE{Vapnik:freq71,
  author = {V. N. Vapnik and A. Y. Chervonenkis},
  title = {On the uniform convergence of relative frequencies of events to their
	probabilities},
  journal = {Theory of Probability and its Applications},
  year = {1971},
  volume = {16},
  pages = {264--280},
  number = {2}
}

@ARTICLE{Tavazoie:genenet99,
  author = {D. S. Varnum and L. C. Stevens},
  title = {Systematic determination of genetic network architecture},
  journal = {Nature Genetics},
  year = {1999},
  volume = {22},
  pages = {281--285},
  number = {3}
}

@ARTICLE{Varnum:aphakia68,
  author = {D. S. Varnum and L. C. Stevens},
  title = {Aphakia, a new mutation in the mouse},
  journal = {Journal of Heredity},
  year = {1968},
  volume = {59},
  pages = {147--150},
  number = {2}
}

@ARTICLE{Vavouri:prediction05,
  author = {Tanya Vavouri and Greg Elgar},
  title = {Prediction of cis-regulatory elements using binding site matrices
	- the successes, the failures and the reasons for both},
  journal = {Current Opinion in Genetics \& Development},
  year = {2005},
  volume = {15},
  pages = {395--402},
  number = {4},
  abstract = {Protein-DNA interactions control many aspects of animal development
	and cellular responses to the environment. Although profiling of
	individual transcription factor binding sites is not a reliable guide
	for predicting the position of cis-regulatory elements in large genomes,
	modelling the evolution and the organization of regulatory elements
	has provided enough information to make some successful predictions.
	For vertebrate genomes, the field is limited by the lack of sufficient
	experimental data upon which to build reliable models. Nonetheless,
	a combination of experimental, computational and comparative data
	is likely to reveal aspects of complex regulatory networks in vertebrates,
	just as it has already done for simple eukaryotic genomes.},
  group = {gene networks}
}

@ARTICLE{Vazquez:multioutput03,
  author = {Emmanuel Vazquez and Eric Walter},
  title = {Multi-Output Support Vector Regression},
  journal = {13th IFAC Symposium on System Identification},
  year = {2003}
}

@ARTICLE{Veflingstad:delay05,
  author = {Siren R. Veflingstad and Erik Plahte and Nicholas A. M. Monk},
  title = {Effect of time delay on pattern formation: competition between homogenisation
	and patterning},
  journal = {Physica D},
  year = {2005},
  volume = {207},
  pages = {254--271},
  group = {gene networks, delays}
}

@ARTICLE{Veflingstad:effect05,
  author = {Siren R. Veflingstad and Erik Plahte and Nicholas A. M. Monk},
  title = {Effect of time delay on pattern formation: competition between homogenisation
	and patterning},
  journal = {Physica D},
  year = {2005},
  volume = {207},
  pages = {254--271},
  abstract = {We study a mathematical model for juxtacrine signalling in a discrete
	lattice of cells. As the signalling is assumed to be under transcriptional
	control, and transcription is a time-consuming process, we incorporate
	time delays in the equations and study the effect of this on the
	pattern forming potential of the model. Previous models without time
	delays have shown that the mechanism is able to generate spatial
	patterns. The analysis of the delay-model reveals a transient competition
	between patterning and homogeneous oscillations. A fine-grained pattern
	eventually appears over the whole lattice, but the duration of the
	oscillatory behaviour increases as the time delay increases. The
	results illustrate the importance of including the known delays in
	a model and of studying transients, as these may not be favourable
	to the system. In addition, the results may suggest that there are
	other mechanisms regulating the signalling than transcription, for
	example protein–protein interactions, which would render the patterning
	process much faster.},
  doi = {10.1016/j.physd.2005.06.006},
  group = {drosophila segmentation}
}

@ARTICLE{verHoef:convolution98,
  author = {Jay M. {Ver Hoef} and Ronald Paul Barry},
  title = {Constructing and fitting models for cokriging and multivariable spatial
	prediction},
  journal = {Journal of Statistical Plannig and Inference},
  year = {1998},
  volume = {69},
  pages = {275-294}
}

@ARTICLE{verHoelf:convolutionFFT04,
  author = {Jay M. {Ver Hoef} and Noel A. C. Cressie and Ronald Paul Barry},
  title = {Flexible Spatial Models for Kriging and Cokriging Using Moving Averages
	and the {F}ast {F}ourier {T}ransform ({F}{F}{T})},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2004},
  volume = {13},
  pages = {265-282},
  number = {2}
}

@ARTICLE{Vigario:extraction97,
  author = {Ricardo N. Vig\'ario},
  title = {Extraction of Ocular Artifacts from {EEG} using Independent Component
	Analysis},
  journal = {Electroencephalography and Clinical Neurophysiology},
  year = {1997},
  volume = {103},
  pages = {395--404}
}

@ARTICLE{Vignal2009,
  author = {Charlotte Vignal and Aruna T Bansal and David J Balding and Michael
	H Binks and Marion C Dickson and Doug S Montgomery and Anthony G
	Wilson},
  title = {Genetic association of the major histocompatibility complex with
	rheumatoid arthritis implicates two non-DRB1 loci.},
  journal = {Arthritis Rheum},
  year = {2009},
  volume = {60},
  pages = {53--62},
  number = {1},
  month = {Jan},
  __markedentry = {[neil]},
  abstract = {The HLA-DRB1 locus within the major histocompatibility complex (MHC)
	at 6p21.3 has been identified as a susceptibility gene for rheumatoid
	arthritis (RA); however, there is increasing evidence of additional
	susceptibility genes in the MHC region. The aim of this study was
	to estimate their number and location.A case-control study was performed
	involving 977 control subjects and 855 RA patients. The HLA-DRB1
	locus was genotyped together with 2,360 single-nucleotide polymorphisms
	in the MHC region. Logistic regression was used to detect DRB1-independent
	effects.After adjusting for the effect of HLA-DRB1, 18 markers in
	14 genes were strongly associated with RA (P<10(-4)). Multivariate
	logistic regression analysis of these markers and DRB1 led to a model
	containing DRB1 plus the following 3 markers: rs4678, a nonsynonymous
	change in the VARS2L locus, approximately 1.7 Mb telomeric of DRB1;
	rs2442728, upstream of HLA-B, approximately 1.2 Mb telomeric of DRB1;
	and rs17499655, located in the 5'-untranslated region of DQA2, only
	0.1 Mb centromeric of DRB1. In-depth investigation of the DQA2 association,
	however, suggested that it arose through cryptic linkage disequilibrium
	with an allele of DRB1. Two non-shared epitope alleles were also
	strongly associated with RA (P<10(-4)): *0301 with anti- cyclic citrullinated
	peptide-negative RA and *0701 independently of autoantibody status.These
	results confirm the polygenic contribution of the MHC to RA and implicate
	2 additional non-DRB1 susceptibility loci. The role of the HLA-DQ
	locus in RA has been a subject of controversy, but in our data, it
	appears to be spurious.},
  doi = {10.1002/art.24138},
  institution = {GlaxoSmithKline, Harlow, UK.},
  keywords = {Adolescent; Adult; Aged; Aged, 80 and over; Arthritis, Rheumatoid,
	genetics; Case-Control Studies; Female; Genetic Predisposition to
	Disease; Genotype; HLA-DR Antigens, genetics; Humans; Linkage Disequilibrium;
	Logistic Models; Male; Middle Aged; Polymorphism, Single Nucleotide;
	Young Adult},
  language = {eng},
  medline-pst = {ppublish},
  owner = {neil},
  pmid = {19116923},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1002/art.24138}
}

@ARTICLE{Devito:properties04,
  author = {Ernesto De Vito and Lorenzo Rosasco and Andrea Caponnetto and Michele
	Piana and Alessandro Verri},
  title = {Some Properties of Regularized Kernel Methods},
  journal = jmlr,
  year = {2004},
  volume = {5},
  pages = {1363--1390}
}

@ARTICLE{Vitushkin:54,
  author = {A. G. Vitushkin},
  title = {On {H}ilbert's thirteenth problem},
  journal = DOKLADY,
  year = {1954},
  volume = {95},
  pages = {701--704}
}

@INPROCEEDINGS{Vivarelli:iee97,
  author = {Francesco Vivarelli and Christopher K. I. Williams},
  title = {Using {B}ayesian Neural Networks to Classify Segmented Images},
  booktitle = {5th IEE International Conference on Artificial Neural Networks},
  year = {1997},
  pages = {268--273},
  publisher = {The Institute of Electrical Engineers}
}

@ARTICLE{Vogl:bp88,
  author = {T. P. Vogl and J. K. Mangis and A. K. Rigler and W. T. Zink and D.
	L. Alkon},
  title = {Accelerating the convergence of the back-propagation method},
  journal = {Biological Cybernetics},
  year = {1988},
  volume = {59},
  pages = {257--263}
}

@ARTICLE{Volterra:variationi26,
  author = {Vito Volterra},
  title = {Variazioni e fluttuazioni del numero d'individui in specie animali
	conviventi},
  journal = {Mem. R. Accad. Naz. dei Lincei Ser. VI},
  year = {1926},
  volume = {2}
}

@ARTICLE{Vyshemirsky:ranking08,
  author = {Vladislav Vyshemirsky and Mark A. Girolami},
  title = {Bayesian Ranking of Biochemical System Models},
  journal = bioinf,
  year = {2008},
  volume = {24},
  pages = {833--839},
  number = {6},
  abstract = {{\bf Motivation}: There often are many alternative 
	
	 models of a biochemical system. Distinguishing models and finding
	the most suitable ones is an important challenge in Systems Biology,
	as such model ranking, by experimental evidence, will help to judge
	the support of the working hypotheses forming each model. Bayes factors
	are employed as a measure of evidential preference for one model
	over another. Marginal likelihood is a key component of Bayes factors,
	however computing the marginal likelihood is a difficult problem,
	as it involves integration of nonlinear functions in multidimensional
	space. There are a number of methods available to compute the marginal
	likelihood approximately. A detailed investigation of such methods
	is required to find ones that perform appropriately for biochemical
	modelling.\\\\
	
	 {\bf Results}: We assess four methods for estimation of the marginal
	likelihoods required for computing Bayes factors. The Prior Arithmetic
	Mean estimator, the Posterior Harmonic Mean estimator, the Annealed
	Importance Sampling and the Annealing-Melting Integration methods
	are investigated and compared on a typical case study in Systems
	Biology. This allows us to understand the stability of the analysis
	results and make reliable judgements in uncertain context. We investigate
	the variance of Bayes factor estimates, and highlight the stability
	of the Annealed Importance Sampling and the Annealing- Melting Integration
	methods for the purposes of comparing nonlinear models.\\\\
	
	 {\bf Availability}: Models used in this study are available in SBML
	format as the supplementary material to this paper.\\\\
	
	 {\bf Contact}: vvv@dcs.gla.ac.uk},
  doi = {10.1093/bioinformatics/btm607},
  file = {833:http\://bioinformatics.oxfordjournals.org/cgi/reprint/24/6/833:PDF},
  group = {licsb, bayes, gene networks},
  pmid = {18057018}
}

@ARTICLE{Vyshemirsky:inferring08,
  author = {Vladislav Vyshemirsky and Terry Xu and Mark A. Girolami and Amelie
	Gormand and George Bailie and Mile Houslay and Walter Kolch},
  title = {Inferring {ERK} pathway structure via {B}ayes factors},
  journal = pnasusa,
  year = {2008},
  group = {systems biology, ERK}
}

@TECHREPORT{Vyshemirsky:erk06,
  author = {Vladislav Vyshermirsky and Mark Girolami and Amelie Gormand and Walter
	Koch},
  title = {A Bayesian Analysis of the ERK Signalling Pathway},
  institution = {University of Glasgow},
  year = {2006},
  group = {Bayesian ranking, systems biology},
  optmonth = {November}
}

@ARTICLE{Wahba:french75,
  author = {G. Wahba and S. Wold},
  title = {A completely automatic {F}rench curve: fitting spline functions by
	cross-validation},
  journal = {Communications in Statistics, Series A},
  year = {1975},
  volume = {4},
  pages = {1--17},
  number = {1}
}

@TECHREPORT{Wainwright:graphical03,
  author = {Martin J. Wainwright and Michael I. Jordan},
  title = {Graphical models, exponential families, and variational inference},
  institution = {UC Berkeley, Dept of Statistics},
  year = {2003},
  number = {649},
  linkps = {http://www.eecs.berkeley.edu/~wainwrig/Papers/WaiJorVariational03.ps},
  optmonth = {September}
}

@ARTICLE{Walker:post67,
  author = {A. M. Walker},
  title = {On the asymptotic behaviour of posterior distributions},
  journal = JRSSb,
  year = {1969},
  volume = {31},
  pages = {80--88},
  number = {1}
}

@ARTICLE{Wallace:code87,
  author = {C. S. Wallace and P. R. Freeman},
  title = {Estimation and inference by compact coding},
  journal = JRSSb,
  year = {1987},
  volume = {49},
  pages = {240--265},
  number = {3}
}

@ARTICLE{Wang:posttrans97,
  author = {Enhong Wang and Wei-Jun Ma and Carol Aghajanian and David R. Spriggs},
  title = {Posttranscriptional regulation of protein expression in human epithelial
	carcinoma cells by adenine-uridine-rich elements in the 3'-untranslated
	region of tumor necrosis factor-alpha messenger {RNA}.},
  journal = cancerres,
  year = {1997},
  volume = {57},
  pages = {5426--5433},
  number = {23},
  abstract = {Eukaryotic mRNAs contain 3'-untranslated regions (UTR) that are involved
	in posttranscriptional control of gene expression. AU-rich octanucleotide
	repeats, UUAUUUAU, present in the 3'-UTR of mature lymphokine and
	other cytokine transcripts, have been implicated in the regulation
	of mRNA stability and translational efficiency. For example, previous
	evidence suggests that the AU-rich element (ARE) present in the 3'-UTR
	of murine tumor necrosis factor-alpha (TNF-alpha) can affect the
	posttranscriptional regulation of murine TNF-alpha gene expression
	in hematopoietic cells. Although cytokines are produced in epithelial
	cells, little is known about the regulation of TNF-alpha and other
	cytokine gene expression by 3'-UTR elements in human malignant epithelial
	cells. To better understand the function of the 3'-UTR of the human
	TNF-alpha gene in the regulation of TNF-alpha protein production
	in human epithelial cancer cells, a series of luciferase reporter
	constructs with portions of the 3'-UTR of human TNF-alpha was transfected
	into human breast carcinoma cell lines ZR-75-1 and ZR-75-1R (which
	overexpresses TNF-alpha). The 3'-UTR of TNF-alpha markedly suppressed
	luciferase activity in both cell lines, and the suppression of activity
	was reversed by deletion of the AU-rich sequences. This suppression
	was quantitative, with six repeats causing more inhibition than two
	repeats. Increased levels of luciferase activity were observed 3
	h after TNF-alpha stimulation in ZR-75-1 cells transfected by constructs
	containing AU-rich repeats. In addition, cytoplasmic extracts from
	both cell lines were assayed for factors that bind to the 3'-UTR
	of human TNF-alpha mRNA. RNA-protein binding activities were found
	in both cell lines. Competition studies showed that these proteins
	specifically bound to AU-rich repeats present in the 3'-UTR of TNF-alpha.
	No binding activity was observed when the AU-rich repeats were deleted.
	TNF-alpha exposure markedly increased activity of several RNA-binding
	proteins, especially a novel Mr 50,000-55,000 RNA-binding protein.
	The binding activity in untreated ZR-75-1R was higher than that in
	untreated ZR-75-1 cells, suggesting that the level of RNA-protein
	binding correlates with the expression level of TNF-alpha in human
	epithelial cancer cells and that the RNA-binding proteins may control
	expression of TNF-alpha in ZR-75-1 cells. We conclude that the AU-rich
	repeats in the 3'-UTR of human TNF-alpha mRNA may regulate gene expression
	in human epithelial cancer cells by binding to AU sequence-specific
	proteins, including a previously undescribed Mr 50,000-55,000 protein
	not observed in hematopoietic cells.},
  file = {5426.pdf:http\://cancerres.aacrjournals.org/cgi/reprint/57/23/5426.pdf:PDF},
  group = {cytokine},
  pmid = {9393771}
}

@INPROCEEDINGS{Wang:multifactor07,
  author = {Jack M. Wang and David J. Fleet and Aaron Hertzmann},
  title = {Multifactor Gaussian Process Models for Style-Content Separation},
  crossref = {Ghahramani:icml07},
  pages = {975--982}
}

@ARTICLE{Wang:gpdm08,
  author = {Jack M. Wang and David J. Fleet and Aaron Hertzmann},
  title = {Gaussian Process Dynamical Models for Human Motion},
  journal = PAMI,
  year = {2008},
  volume = {30},
  pages = {283--298},
  number = {2},
  abstract = {We introduce Gaussian process dynamical models (GPDMs) for nonlinear
	time series analysis, with applications to learning models of human
	pose and motion from high-dimensional motion capture data. A GPDM
	is a latent variable model. It comprises a low-dimensional latent
	space with associated dynamics, as well as a map from the latent
	space to an observation space. We marginalize out the model parameters
	in closed form by using Gaussian process priors for both the dynamical
	and the observation mappings. This results in a nonparametric model
	for dynamical systems that accounts for uncertainty in the model.
	We demonstrate the approach and compare four learning algorithms
	on human motion capture data, in which each pose is 50-dimensional.
	Despite the use of small data sets, the GPDM learns an effective
	representation of the nonlinear dynamics in these spaces.},
  doi = {10.1109/TPAMI.2007.1167},
  issn = {0162-8828},
  keywords = {Gaussian processes, learning (artificial intelligence), motion estimation,
	time series, Gaussian process dynamical model, human motion capture
	data, learning model, low-dimensional latent space, nonlinear time
	series analysis, animation, machine learning, motion, stochastic
	processes, time series analysis, tracking},
  owner = {neil},
  timestamp = {2009.11.13}
}

@ARTICLE{Wang:precision02,
  author = {Y. Wang and C. Liu and J. D. Storey and R. J. Tibshirani and D. Herschlag
	and P. O Brown},
  title = {Precision and functional specificity in {mRNA} decay},
  journal = pnasusa,
  year = {2002},
  volume = {99},
  pages = {5860--5865},
  group = {gene networks}
}

@ARTICLE{Watkin:statmech93,
  author = {T. L. H. Watkin and Albrecht Rau},
  title = {The Statistical Mechanics of Learning a Rule},
  journal = RMP,
  year = {1993},
  volume = {65},
  pages = {499--556},
  number = {2}
}

@INPROCEEDINGS{Watrous:grad87,
  author = {R. L. Watrous},
  title = {Learning algorithms for connectionist networks: applied gradient
	methods of nonlinear optimization},
  booktitle = {Proceedings IEEE First International Conference on Neural Networks},
  year = {1987},
  volume = {2},
  pages = {619--627},
  address = {San Diego},
  publisher = {IEEE}
}

@ARTICLE{Watson:kernel64,
  author = {G. S. Watson},
  title = {Smooth regression analysis},
  journal = {Sankhy{\={a}}: The Indian Journal of Statistics. Series A},
  year = {1964},
  volume = {26},
  pages = {359--372}
}

@ARTICLE{Waugh:fixed90,
  author = {F. R. Waugh and C. M. Marcus and R. M. Westervelt},
  title = {Fixed-point Attractors in Analog Neural Computation},
  journal = PRL,
  year = {1990},
  volume = {64},
  pages = {1986--1989},
  number = {16}
}

@ARTICLE{Webb:lms93,
  author = {A. R. Webb},
  title = {Functional approximation by feed-forward networks: a least-squares
	approach to generalisation},
  journal = IEEE,
  year = {1994},
  volume = {5},
  pages = {363--371},
  number = {3}
}

@ARTICLE{Webb:disc90,
  author = {A. R. Webb and David Lowe},
  title = {The optimised internal representation of multilayer classifier networks
	performs nonlinear discriminant analysis},
  journal = NN,
  year = {1990},
  volume = {3},
  pages = {367--375},
  number = {4}
}

@TECHREPORT{Webb:hybrid88,
  author = {A. R. Webb and David Lowe},
  title = {A hybrid optimisation strategy for adaptive feed-forward layered
	networks},
  institution = {Royal Signals and Radar Establishment},
  year = {1988},
  type = {RSRE Memorandum},
  number = {4193},
  address = {St Andrews Road, Malvern, UK}
}

@TECHREPORT{Webb:optimiz88,
  author = {A. R. Webb and David Lowe and M. D. Bedworth},
  title = {A comparison of non-linear optimisation strategies for feed-forward
	adaptive layered networks},
  institution = {Royal Signals and Radar Establishment},
  year = {1988},
  type = {RSRE Memorandum},
  number = {4157},
  address = {St Andrew's Road, Malvern, UK}
}

@INPROCEEDINGS{Weigend:sunspot90,
  author = {A S Weigend and B A Huberman and David E Rumelhart},
  title = {Predicting sunspots and Exchange Rates with Connectionist Networks},
  booktitle = {Proceedings of the 1990 NATO Workshop on Nonlinear Modeling and Forcasting,
	Santa Fe, New Mexico},
  year = {1990},
  editor = {S Eubank and M Casdagli},
  publisher = addison
}

@ARTICLE{Weigend:future90,
  author = {A. S. Weigend and B. A. Huberman and David E. Rumelhart},
  title = {Predicting the future: a connectionist approach},
  journal = IJNS,
  year = {1990},
  volume = {1},
  pages = {193--209},
  number = {3}
}

@INPROCEEDINGS{Weiss:segment99,
  author = {Yair Weiss},
  title = {Segmentation Using Eigenvectors: A Unifying View},
  booktitle = iccv,
  year = {1999},
  pages = {975--982},
  publisher = ieeecomp,
  file = {iccv99.pdf:http\://www.cs.huji.ac.il/~yweiss/iccv99.pdf:PDF},
  linkpsgz = {http://www.cs.huji.ac.il/~yweiss/iccv99.ps.gz}
}

@PHDTHESIS{Werbos:phd74,
  author = {P. J. Werbos},
  title = {Beyond regression: new tools for prediction and analysis in the behavioral
	sciences},
  school = {Harvard University},
  year = {1974},
  address = {Boston, MA}
}

@TECHREPORT{Weston:densityestim98,
  author = {Jason Weston and Alex Gammerman and M. Stitson and Vladmir N. Vapnik
	and V. Vovk and C. Watkins},
  title = {Density Estimation using Support Vector Machines},
  institution = {Royal Holloway Univeristy of London},
  year = {1998},
  note = {Available from \url{http://www.dcs.rhbnc.ac.uk/research/compint/areas/comp_learn/sv/}}
}

@TECHREPORT{Weston:multiclass98,
  author = {Jason Weston and C. Watkins},
  title = {Multi-class Support Vector Machines},
  institution = {Royal Holloway University of London},
  year = {1998},
  address = {Department of Computer Science},
  month = Apr,
  note = {Available from \url{http://www.dcs.rhbnc.ac.uk/research/compint/areas/comp_learn/sv/}}
}

@ARTICLE{White:univ90,
  author = {H. White},
  title = {Connectionist nonparametric regression: multilayer feedforward networks
	can learn arbitrary mappings},
  journal = NN,
  year = {1990},
  volume = {3},
  pages = {535--549},
  number = {5}
}

@ARTICLE{White:review89,
  author = {H. White},
  title = {Learning in artificial neural networks: a statistical perspective},
  journal = NC,
  year = {1989},
  volume = {1},
  pages = {425--464},
  number = {4}
}

@INPROCEEDINGS{Widrow:adapt60,
  author = {B. Widrow and M. E. Hoff},
  title = {Adaptive Switching Circuits},
  booktitle = {IRE WESCON Convention Record},
  year = {1960},
  volume = {4},
  pages = {96--104},
  address = {New York},
  note = {Reprinted in \cite{Anderson:collect88}}
}

@ARTICLE{Widrow:review90,
  author = {B. Widrow and M. A. Lehr},
  title = {30 years of adaptive neural networks: perceptron, madeline, and backpropagation},
  journal = {Proceedings of the IEEE},
  year = {1990},
  volume = {78},
  pages = {1415--1442},
  number = {9}
}

@INPROCEEDINGS{Wieland:geom87,
  author = {A. Wieland and R. Leighton},
  title = {Geometric Analysis of Neural Network Capabilities},
  booktitle = {Proceedings of the First IEEE International Conference on Neural
	Networks},
  year = {1987},
  volume = {3},
  pages = {385--392},
  address = {San Diego, CA},
  publisher = {IEEE}
}

@ARTICLE{Wikle:hierarchicalEcologicalProcesses03,
  author = {Christopher K. Wikle},
  title = {Hierarchical {B}ayesian Models for Predicting the Spread of Ecological
	Processes},
  journal = {Ecology},
  year = {2003},
  volume = {84},
  pages = {1382-1394},
  number = {6}
}

@ARTICLE{Wikle:kernelBasedSpectralModel02,
  author = {Christopher K. Wikle},
  title = {A kernel-based spectral model for non-{G}Aussian spatio-temporal
	processes},
  journal = statmod,
  year = {2002},
  volume = {2},
  pages = {299-314}
}

@ARTICLE{Wikle:hierarchicalBayesSpaceTimeModels98,
  author = {Christopher K. Wikle and L. Mark Berliner and Noel A. C. Cressie},
  title = {Hierarchical {B}ayesian space-time models},
  journal = {Environmental and Ecological Statistics},
  year = {1998},
  volume = {5},
  pages = {117-154}
}

@inproceedings{Barber:bayesianrbf98,
title = {Radial Basis Functions: A Bayesian Treatment},
author = {David Barber and Bernhard Schottky},
crossref = {Jordan:nips97},
pages = {402--408},
linkpdf = {http://papers.nips.cc/paper/1452-radial-basis-functions-a-bayesian-treatment.pdf}
}

@ARTICLE{Williams:multiclass98,
  author = {Christopher K.I. Williams and David Barber},
  title = {Bayesian {C}lassification with {G}aussian Processes},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1998},
  volume = {20},
  pages = {1342-1351},
  number = {12}
}

@ARTICLE{Williams:computation98,
  author = {Christopher K. I. Williams},
  title = {Computation with Infinite Neural Networks},
  journal = nc,
  year = {1998},
  volume = {10},
  pages = {1203--1216},
  number = {5},
  abstract = {For neural networks with a wide class of weight priors, it can be
	shown that in the limit of an infinite number of hidden units the
	prior over functions tends to a Gaussian process. In this paper analytic
	forms are derived for the covariance function of the Gaussian processes
	corresponding to networks with sigmoidal and Gaussian hidden units.
	This allows predictions to be made efficiently using networks with
	an infinite number of hidden units, and shows that, somewhat paradoxically,
	it may be easier to carry out Bayesian prediction with infinite networks
	rather than finite ones. },
  linkpsz = {http://www.ncrg.aston.ac.uk/Papers/postscript/NCRG_97_025.ps.zip}
}

@MISC{Williams:gauss95,
  author = {Christopher K. I. Williams},
  title = {Regression with {G}aussian Processes},
  year = {1995},
  note = {Paper presented at the Mathematics of Neural Networks and Applications
	Conference, Oxford, UK, June 1995. To appear in {\em Annals of Mathematics
	and Artificial Intelligence}.}
}

@INPROCEEDINGS{Williams:tree98,
  author = {Christopher K. I. Williams and Xiaojuan Feng},
  title = {Tree-structured Belief Networks as Models of Images},
  booktitle = {Proceedings Ninth International Conference on Artificial Neural Networks,
	ICANN'99},
  year = {1999},
  abstract = {In this paper we are concerned with using a tree-structured belief
	network (TSBN) as a prior model in segmenting a natural image into
	a number of predefined classes. The TSBN was trained by the EM algorithm
	based on a set of training label images. The average log likelihood
	(or bit rate) of a test set of images shows that the learned TSBN
	is a better model for images than models based upon independent blocks
	of varying sizes. We also analyze the relative advanteges obtained
	by modelling correlations at different length scales in the tree.},
  group = {tree},
  linkpsgz = {http://www.dai.ed.ac.uk/homes/ckiw/postscript/coding6.ps.gz}
}

@INPROCEEDINGS{Williams:segmentation98,
  author = {Christopher K. I. Williams and Xiaojuan Feng},
  title = {Combining neural networks and belief networks for image segmentation},
  booktitle = {Proceedings of the IEEE Signal Processing Society Workshop on Neural
	Networks for Signal Processing},
  year = {1998},
  publisher = {IEEE}
}

@INPROCEEDINGS{Bishop:error_bars95,
  author = {Christopher K. I. Williams and Cazhaow Qazaz and Christopher M. Bishop
	and H. Zhu},
  title = {On the relationship between {B}ayesian error bars and the input data
	density},
  booktitle = {Proceedings Fourth IEE International Conference on Artificial Neural
	Networks},
  year = {1995},
  pages = {160--165},
  address = {Cambridge, U.K.},
  publisher = {IEE}
}

@TECHREPORT{Williams:observations02,
  author = {Christopher K. I. Williams and Carl Edward Rasmussen and Anton Schwaighofer
	and Volker Tresp},
  title = {Observations of the {N}ystr\"om Method for {G}aussian Process Prediction},
  institution = {University of Edinburgh},
  year = {2002},
  abstract = {A number of methods for speeding up Gaussian Process (GP) prediction
	have been proposed, including the \emph{Nystr\"om method} of Williams
	and Seeger \cite{Williams:nystrom00}. In this paper we focus on two
	issues (1) the relationship of the Nystr\"om method to the Subset
	of Regressors method Poggio and Girosi, 1990 \cite{Poggio:approx90};
	Luo and Wahba, 1997 \cite{Luo:hybrid97}) and (2) understanding in
	what circumstances the Nystr\"om approximation would be expected
	to provide a good approximation to exact GP regression.},
  group = {spgp},
  linkpsgz = {http://wwwbrauer.informatik.tu-muenchen.de/~trespvol/papers/obsnys3.ps.gz}
}

@INCOLLECTION{Williams:digit93,
  author = {Christopher K. I. Williams and M. D. Revow and Geoffrey E. Hinton},
  title = {Hand-printed Digit Recogntion Using Deformable Models},
  booktitle = {Spatial Vision in Humans and Robots},
  publisher = cup,
  year = {1993},
  editor = {L. Harris and M. Jenkin}
}

@ARTICLE{Williams:greedy04,
  author = {Christopher K. I. Williams and Michalis K. Titsias},
  title = {Greedy Learning of Multiple Objects in Images using Robust Statistics
	and Factorial Learning},
  journal = NC,
  year = {2004},
  volume = {16},
  pages = {1039--1062},
  number = {5}
}

@ARTICLE{Williams:conditional96,
  author = {P. M. Williams},
  title = {Using Neural Networks to Model Conditional Multivariate Densities},
  journal = NC,
  year = {1996},
  volume = {8},
  pages = {843--854},
  number = {4}
}

@ARTICLE{Williams:prune95,
  author = {P. M. Williams},
  title = {{B}ayesian Regularization and Pruning Using a {L}aplace Prior},
  journal = NC,
  year = {1995},
  volume = {7},
  pages = {117--143},
  number = {1}
}

@TECHREPORT{Williams:scg91,
  author = {P. M. Williams},
  title = {A {M}arquardt algorithm for Choosing the Step-size in Backpropagation
	Learning with Conjugate gradients},
  institution = {University of Sussex},
  year = {1991},
  number = {CSRP 299},
  address = {Brighton, UK}
}

@INPROCEEDINGS{Willis:towards99,
  author = {Craig E. Willis and Mikhail Mikhailov},
  title = {Towards a better understanding of web resources and server responses
	for improved caching},
  booktitle = {Proceedings of the 8th International World Wide Web Conference},
  year = {1999},
  pages = {153--165}
}

@MISC{Winn:personal02,
  author = {John Winn},
  howpublished = {Personal communication.},
  year = {2002},
  note = {Cavendish Laboratory, Cambridge.}
}

@ARTICLE{Winn:vmp05,
  author = {John Winn and Christopher M. Bishop},
  title = {Variational Message Passing},
  journal = jmlr,
  year = {2005},
  volume = {6},
  pages = {661--694},
  linkpdf = {http://johnwinn.org/Publications/papers/VMP2005.pdf}
}

@INPROCEEDINGS{Wolman:scale99,
  author = {Alec Wolman and Geoffrey M. Voelker and Nitin Sharma and Neal Cardwell
	and Anna Karlin and Henry M. Levy},
  title = {On the scale and performance of co-operative web proxy caching},
  booktitle = {17th ACM Symposium Operating System Principles (SOSP'99)},
  year = {1999},
  pages = {16--31}
}

@ARTICLE{Wolpert:stack92,
  author = {D. H. Wolpert},
  title = {Stacked Generalization},
  journal = NN,
  year = {1992},
  volume = {5},
  pages = {241--259},
  number = {2}
}

@ARTICLE{Woodward:vegetation98,
  author = {Ian Woodward and Mark R. Lomas and Richard A. Betts},
  title = {Vegetation-Climate Feedbacks in a Greenhouse World},
  journal = {Philosophical Transactions: Biological Sciences},
  year = {1998},
  volume = {353},
  pages = {29-39},
  number = {1365}
}

@ARTICLE{Xie:regulatorymotifs04,
  author = {Xiaohui Xie and Jun Lu and Edward J. Kulbokas and Todd R. Golub and
	Vamsi Mootha and Kerstin {Lindblad-Toh} and Eric S. Lander and Manolis
	Kellis},
  title = {Systematic Discovery of Regulatory Motifs in Human Promoters and
	3' {UTR}s by Comparison of Several Mammals},
  journal = {Nature},
  year = {2005},
  volume = {434},
  pages = {338--345},
  group = {gene networks}
}

@ARTICLE{Xu:rbf94,
  author = {L. Xu and A. Krzy{\.{z}}ak and A. Yuille},
  title = {On radial basis function nets and kernel regression: statistical
	consistency, convergence rates, and receptive fields},
  journal = NN,
  year = {1994},
  volume = {7},
  pages = {609--628},
  number = {4}
}

@ARTICLE{Xue:multitask07,
  author = {Ya Xue and Xuejun Liao and Lawrence Carin},
  title = {Multi-task Learning for Classification with {D}irichlet process priors},
  journal = jmlr,
  year = {2007},
  volume = {8},
  pages = {35-63}
}

@TECHREPORT{Yang:comparison00,
  author = {Yee Hwa Yang and Michael J. Buckley and Sandrine Dudoit and Terence
	P. Speed},
  title = {Comparison of methods for image analysis on {cDNA} microarray data},
  institution = {Department of Statistics, University of California, Berkeley},
  year = {2000},
  note = {Available from \url{http://www.stat.Berkeley.edu/$\sim$terry}},
  optnumber = {584}
}

@TECHREPORT{Yang:normalization00,
  author = {Yee Hwa Yang and Sandrine Dudoit and Percy Luu and Terence P. Speed},
  title = {Normalization for {cDNA} Microarray Data},
  institution = {Department of Statistics, University of California, Berkeley},
  year = {2001},
  note = {Available from \url{http://www.stat.Berkeley.edu/$\sim$terry}}
}

@ARTICLE{Yeang:physical04,
  author = {Chen-Hsiang Yeang and Trey Ideker and Tommi Jaakkola},
  title = {Physical Network Models},
  journal = {Journal of Computational Biology},
  year = {2004},
  volume = {11},
  pages = {243--262},
  number = {2--3},
  abstract = {We develop a new framework for inferring models of transcriptional
	regulation. The models, which we call \emph{physical network models},
	are annotated molecular interaction graphs. The atributes in the
	model correspond to verifiable properties of the underlying biological
	system such as the existence of protein-protein and protein-DNA interactions,
	the directionality of signal transduction in protein-protein interactions,
	as well as signs of the immediate effects of these interactions.
	Possible configures of these variables are constrained by the available
	data sources. Some of the data sources such as factor-binding data
	involve measurements that are directly tied to the variables in the
	model. Other sources such as gene knock-outs are \emph{functional}
	in nature and provide only indirect evidence about the variables.
	We associated each observed knock-out effect in the deletion mutant
	data with a set of causal paths (molecular cascades) that could in
	principle explain the effect, resulting in aggregate constraints
	about the physical variables in the model. The most likely settings
	of all the variables, specifying the most likely graph annotations,
	are found by a recursive application of the max-product algorithm.
	By testing our approach on datasets related to the pheromone response
	pathway in \emph{S. cerevisiae}, we demonstrate that the resulting
	model is consistent with previous studies about the pathway. Moreover,
	we successfully predict gene knock-out effects with high degree of
	accuracy in a cross-validation setting. When applying this approach
	to genome-wide, we extract submodels consistent with previous studies.
	The apporach can be readily extended to other data sources, or to
	facilitate automated experimental design.},
  group = {gene networks}
}

@INPROCEEDINGS{Yeang:time03,
  author = {Chen-Hsiang Yeang and Tommi Jaakkola},
  title = {Time Series Analysis of Gene Expression and Location Data},
  booktitle = {Proceedings of the Third IEEE Symposium on BioInformatics and BioEngineering
	(BIBE'03)},
  year = {2003},
  group = {gene networks}
}

@ARTICLE{Yeang:validation05,
  author = {Chen-Hsiang Yeang and H. Craig Mak and Scott McCuine and Christopher
	Workman and Tommi Jaakkola and Trey Ideker},
  title = {Validation and refinement of gene-regulatory pathways on a network
	of physical interactions},
  journal = {Genome Biology},
  year = {2005},
  volume = {6},
  number = {R62},
  note = {gene networks},
  abstract = {As genome-scale measurements lead to increasingly complex models of
	gene regulation, systematic approaches are needed to validate and
	refine these models. Towards this goal, we describe an automated
	procedure for prioritizing genetic pertubations in order to discriminate
	optimally between alternative models of a gene-regulatory network.
	Using this procedure, we evaluate 38 candidate regulatory networks
	in yeast and perform four high-priority gene knockout experiments.
	The refined networks support previously unknown regulatory mechanisms
	downstream of \emph{SOK2} and \emph{SWI14}.}
}

@ARTICLE{Yeung:model01,
  author = {K. Y. Yeung and C. Fraley and A. Murua and Adrian E. Raftery and
	W. L. Ruzzo},
  title = {Model-based clustering and data transformations for gene expression
	data},
  journal = bioinf,
  year = {2001},
  volume = {17},
  pages = {977--87},
  number = {10}
}

@INPROCEEDINGS{Yu:design,
  author = {Haifeng Yu and Amin Vahdat},
  title = {Design and Evaluation of a Continuous Consistency Model for Replicated
	Services},
  booktitle = {4th Symposium on Operating System Design and Implementation (OSDI)},
  year = {2000}
}

@INPROCEEDINGS{Kai:multitask05,
  author = {Kai Yu and Volker Tresp and Anton Schwaighofer},
  title = {Learning {G}aussian processes from multiple tasks},
  booktitle = {Proceedings of the 22nd International Conference on Machine Learning
	(ICML 2005)},
  year = {2005},
  pages = {1012-1019}
}

@ARTICLE{Yuille:cccp02,
  author = {Alan L. Yuille and Anand Rangarajan},
  title = {The Concave-Convex Procedure ({CCCP})},
  journal = NC,
  year = {2003},
  volume = {14},
  number = {4},
  linkpsgz = {http://www.cise.ufl.edu/~anand/ps/cccp_nc_final.ps.gz}
}

@ARTICLE{Zadeh:fuzzy65,
  author = {Lotfi A. Zadeh},
  title = {Fuzzy Sets},
  journal = {Information and Control},
  year = {1965},
  volume = {8},
  pages = {338--353}
}

@INPROCEEDINGS{Zak:local02,
  author = {Daniel E. Zak and Francis J. {Doyle III} and James S. Schwaber},
  title = {Local Identifiability: When can Genetic Networks be Identified from
	Microarray Data?},
  booktitle = {Third International Conference on Systems Biology},
  year = {2002},
  pages = {236--237},
  address = {Stockholm, Sweden},
  month = {December},
  file = {zaketal_icsb2002.pdf:http\://www.che.udel.edu/systems/people/zak/conferences/abstracts/zaketal_icsb2002.pdf:PDF},
  group = {gene networks}
}

@PHDTHESIS{Zemel:phd93,
  author = {R. Zemel},
  title = {A minimum description length framework for unsupervised learning},
  school = {Department of Computer Science, University of Toronto},
  year = {1993},
  address = {Canada}
}

@ARTICLE{Zhang:EMLMC07,
  author = {Hao Zhang},
  title = {Maximum-likelihood estimation for multivariate spatial linear coregionalization
	models},
  journal = {Environmetrics},
  year = {2007},
  volume = {18},
  pages = {125-139}
}

@ARTICLE{Zhang:geneexpcancer97,
  author = {L. Zhang and W. Zhou and V. E. Velculescu and S. E. Kern and R. H.
	Hruban and S. R. Hamilton and B. Volgestein and W. Kinzler},
  title = {Gene expression in normal and cancer cells},
  journal = {Science},
  year = {1997},
  volume = {276},
  pages = {1268--1272}
}

@ARTICLE{Zhang:genecore98,
  author = {M. Q. Zhang},
  title = {Identification of human gene core in silico},
  journal = {Genome Research},
  year = {1998},
  volume = {8},
  pages = {319--326}
}

@ARTICLE{Zhu:lbfgsb97,
  author = {Ciyou Zhu and Richard H. Byrd and Jorge Nocedal},
  title = {{L-BFGS-B}: Algorithm 778: {L-BFGS-B}, {FORTRAN} routines for large
	scale bound constrained optimization},
  journal = {ACM Transactions on Mathematical Software},
  year = {1997},
  volume = {23},
  pages = {550--560},
  number = {4},
  abstract = {L-BFGS-B is a limited memory algorithm for solving large nonlinear
	optimization problems subject to simple bounds on the variables.
	It is intended for problems in which information on the Hessian matrix
	is difficult to obtain, or for large dense problems. L-BFGS-B can
	also be used for unconstrained problems, and in this case performs
	smilarly to its predecessor, algorithm L-BFGS (Harwell routine VA15).
	The algorithm is implemented in Fortran 77.},
  linkpsgz = {http://www.ece.northwestern.edu/~nocedal/PSfiles/lbfgsb.ps.gz},
  linksoftware = {http://www.ece.northwestern.edu/~nocedal/lbfgsb.html}
}

@TECHREPORT{Zhu:graphsemi03,
  author = {Xiaojin Zhu and John Lafferty and Zoubin Ghahramani},
  title = {Semi-supervised Learning: From {G}aussian Fields to {G}aussian Processes},
  institution = {Carnegie Mellon University},
  year = {2003},
  number = {CMU-CS-03-175},
  linkpdf = {http://www.cs.cmu.edu/~zhuxj/pub/gf2gp.pdf},
  pdf = {http://www.cs.cmu.edu/~zhuxj/pub/gf2gp.pdf}
}

@INPROCEEDINGS{Zien:largemargin05,
  author = {Alexander Zien and Joaquin {Qui\~nonero Candela}},
  title = {Large Margin Non-Linear Embedding},
  note = {To appear at ICML 2005},
  linkps = {http://www.kyb.mpg.de/publications/pss/ps3375.ps}
}

@ARTICLE{Zinzen2009,
  author = {Robert P Zinzen and Charles Girardot and Julien Gagneur and Martina
	Braun and Eileen E M Furlong},
  title = {Combinatorial binding predicts spatio-temporal cis-regulatory activity},
  journal = {Nature},
  year = {2009},
  volume = {462},
  pages = {65--70},
  number = {7269},
  month = {Nov},
  abstract = {Development requires the establishment of precise patterns of gene
	expression, which are primarily controlled by transcription factors
	binding to cis-regulatory modules. Although transcription factor
	occupancy can now be identified at genome-wide scales, decoding this
	regulatory landscape remains a daunting challenge. Here we used a
	novel approach to predict spatio-temporal cis-regulatory activity
	based only on in vivo transcription factor binding and enhancer activity
	data. We generated a high-resolution atlas of cis-regulatory modules
	describing their temporal and combinatorial occupancy during Drosophila
	mesoderm development. The binding profiles of cis-regulatory modules
	with characterized expression were used to train support vector machines
	to predict five spatio-temporal expression patterns. In vivo transgenic
	reporter assays demonstrate the high accuracy of these predictions
	and reveal an unanticipated plasticity in transcription factor binding
	leading to similar expression. This data-driven approach does not
	require previous knowledge of transcription factor sequence affinity,
	function or expression, making it widely applicable.},
  doi = {10.1038/nature08531},
  institution = {European Molecular Biology Laboratory, D-69117 Heidelberg, Germany.},
  keywords = {Animals; Animals, Genetically Modified; Artificial Intelligence; Chromatin
	Immunoprecipitation; Conserved Sequence, genetics; Databases, Genetic;
	Drosophila melanogaster, embryology/genetics; Enhancer Elements,
	Genetic, genetics; Gene Expression Regulation, Developmental, genetics;
	Genes, Reporter, genetics; Mesoderm, embryology/metabolism; Models,
	Genetic; Protein Binding; Time Factors; Transcription Factors, metabolism},
  language = {eng},
  medline-pst = {ppublish},
  owner = {ahonkela},
  pii = {nature08531},
  pmid = {19890324},
  timestamp = {2010.09.09},
  url = {http://dx.doi.org/10.1038/nature08531}
}

@INPROCEEDINGS{Zoeter:quadrature05,
  author = {Onno Zoeter and Tom Heskes},
  title = {Gaussian quadrature based Expectation Propagation},
  booktitle = {Proceedings of the Tenth International Workshop on Artificial Intelligence
	and Statistics},
  year = {2005},
  pages = {445--452}
}

@MANUAL{Affymetrix:mas01,
  title = {Microarray Suite User Guide version 5.0},
  organization = {Affymetrix Inc.},
  address = {Santa Clara, CA},
  optyear = {2001}
}


@INBOOK{Lappalainen:ensemble00,
  title = {Ensemble Learning},
  booktitle = {Advances in Independent Component Analysis},
  publisher = {Springer},
  year = {2000},
  author =	 {Harri Lappalainen and James W. Miskin},
  editor =	 {Mark Girolami}
}

@MISC{lectric:law99,
  title = {The Legal Lexicon's Lyceum},
  howpublished = {Available from \url{http://www.lectlaw.com/def.htm}.},
  year = {1999},
  key = {Legal Lexicon's Lyceum},
  organization = {The 'Lectric Law Library}
}

@MISC{UN:rights48,
  title = {Universal Declaration of Human Rights},
  howpublished = {Available from \url{http://www.un.org/Overview/rights.html}.},
  year = {1948},
  key = {General Assembly of United Nations},
  organization = {General Assembly of the United Nations}
}

@INCOLLECTION{Naish:epfitc08,
  author = {Andrew Naish-Guzman and Sean Holden},
  title = {The Generalized {FITC} Approximation},
  pages = {1057--1064},
  crossref = {Platt:nips07}
}

@ARTICLE{Seeger:gps04,
  author = {Matthias Seeger},
  title = {{G}aussian processes for {M}achine {L}earning},
  journal = IJNS,
  year = {2004},
  volume = {14},
  pages = {69--106},
  number = {2}
}

@TechReport{Calandra:manifold,
  title={Manifold {G}aussian Processes for Regression},
  author={Roberto Calandra and Jan Peters and Carl Edward Rasmussen and Marc Peter Deisenroth},
  journal={arXiv preprint arXiv:1402.5876},
  year={2014}

}

@INPROCEEDINGS{Snelson:warped04,
  author = {Edward Snelson and  Carl Edward Rasmussen and  Zoubin Ghahramani},
  title = {Warped {G}aussian Processes},
  crossref = {Thrun:nips03}
}

@INPROCEEDINGS{Lazaro:warped12,
  title={{B}ayesian Warped {G}aussian Processes},
  author={Miguel L{\'a}zaro-Gredilla},
  crossref={Bartlett:nips12},
}

@TechReport{Kingma:auto13,
  title={Auto-encoding Variational {B}ayes},
  author={Diederik P. Kingma and Max Welling},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@TechReport{Rezende:stochastic14,
  title={Stochastic Back-propagation and Variational Inference in Deep Latent {G}aussian Models},
  author={Danilo Jimenez Rezende and Shakir Mohamed and Daan Wierstra},
  journal={arXiv preprint arXiv:1401.4082},
  year={2014}
}
@TechReport{Durrande:additive11,
 author = {Durrande, N and Ginsbourger, D and Roustant, O},
 title = {Additive Kernels for {G}aussian Process Modeling},
 journal = {ArXiv e-prints 1103.4023},
 year = {2011}
}
@TechReport{Bengio:review12,
  author    = {Yoshua Bengio and
               Aaron C. Courville and
               Pascal Vincent},
  title     = {Unsupervised Feature Learning and Deep Learning: A Review
               and New Perspectives},
  journal   = {CoRR},
  volume    = {abs/1206.5538},
  year      = {2012},
  ee        = {http://arxiv.org/abs/1206.5538}
}

@inproceedings{Turner:problems08,
  title={Two problems with variational expectation maximisation for time-series models},
  author={Turner, Richard E and Berkes, Pietro and Sahani, Maneesh},
  booktitle={Workshop on Inference and Estimation in Probabilistic Time-Series Models},
  volume={2},
  year={2008}
}

@inproceedings{Kusner:stochastic14,
  title={Stochastic Neighbor Compression},
  author={Kusner, Matt and Tyree, Stephen and Weinberger, Kilian Q and Agrawal, Kunal},
  crossref={icml14},
  pages={622--630},
  year={2014}
}

@InProceedings{Gal:distributed14,
  title = {Distributed Variational Inference in Sparse {G}aussian Process Regression and Latent Variable Models},
author = {Yarin Gal and Mark van der Wilk and Carl E. Rasmussen},
  crossref={Ghahramani:nips14},
}

@inproceedings{Frey:mixtures98,
  title={Mixtures of local linear subspaces for face recognition},
  author={Frey, Brendan J and Colmenarez, Antonio and Huang, Thomas S},
  booktitle={Computer Vision and Pattern Recognition, 1998. Proceedings. 1998 IEEE Computer Society Conference on},
  pages={32--37},
  year={1998},
  organization={IEEE}
}


@article{Sporns-connectome05,
    author = {Sporns, Olaf and Tononi, Giulio and Kötter, Rolf},
    journal = {PLOS Computational Biology},
    publisher = {Public Library of Science},
    title = {The Human Connectome: A Structural Description of the Human Brain},
    year = {2005},
    month = {09},
    volume = {1},
    url = {https://doi.org/10.1371/journal.pcbi.0010042},
    pages = {},
    abstract = {The connection matrix of the human brain (the human âconnectomeâ) represents an indispensable foundation for basic and applied neurobiological research. However, the network of anatomical connections linking the neuronal elements of the human brain is still largely unknown. While some databases or collations of large-scale anatomical connection patterns exist for other mammalian species, there is currently no connection matrix of the human brain, nor is there a coordinated research effort to collect, archive, and disseminate this important information. We propose a research strategy to achieve this goal, and discuss its potential impact.},
    number = {4},
    doi = {10.1371/journal.pcbi.0010042}
}

@article{Tenenbaum-mind11,
	author = {Tenenbaum, Joshua B. and Kemp, Charles and Griffiths, Thomas L. and Goodman, Noah D.},
	title = {How to Grow a Mind: Statistics, Structure, and Abstraction},
	volume = {331},
	number = {6022},
	pages = {1279--1285},
	year = {2011},
	doi = {10.1126/science.1192788},
	publisher = {American Association for the Advancement of Science},
	abstract = {In coming to understand the world{\textemdash}in learning concepts, acquiring language, and grasping causal relations{\textemdash}our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/331/6022/1279},
	eprint = {http://science.sciencemag.org/content/331/6022/1279.full.pdf},
	journal = {Science}
}

@article{Kosinski-private13,
author = {Kosinski, Michal and Stillwell, David and Graepel, Thore}, 
title = {Private traits and attributes are predictable from digital records of human behavior},
volume = {110}, 
number = {15}, 
pages = {5802-5805}, 
year = {2013}, 
doi = {10.1073/pnas.1218772110}, 
abstract ={We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. The analysis presented is based on a dataset of over 58,000 volunteers who provided their Facebook Likes, detailed demographic profiles, and the results of several psychometric tests. The proposed model uses dimensionality reduction for preprocessing the Likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from Likes. The model correctly discriminates between homosexual and heterosexual men in 88\% of cases, African Americans and Caucasian Americans in 95\% of cases, and between Democrat and Republican in 85\% of cases. For the personality trait “Openness,” prediction accuracy is close to the test–retest accuracy of a standard personality test. We give examples of associations between attributes and Likes and discuss implications for online personalization and privacy.}, 
URL = {http://www.pnas.org/content/110/15/5802.abstract}, 
eprint = {http://www.pnas.org/content/110/15/5802.full.pdf}, 
journal = {Proceedings of the National Academy of Sciences} 
}

@article{Youyou-computer15,
author = {Youyou, Wu and Kosinski, Michal and Stillwell, David}, 
title = {Computer-based personality judgments are more accurate than those made by humans},
volume = {112}, 
number = {4}, 
pages = {1036-1040}, 
year = {2015}, 
doi = {10.1073/pnas.1418680112}, 
abstract ={Judging others’ personalities is an essential skill in successful social living, as personality is a key driver behind people’s interactions, behaviors, and emotions. Although accurate personality judgments stem from social-cognitive skills, developments in machine learning show that computer models can also make valid judgments. This study compares the accuracy of human and computer-based personality judgments, using a sample of 86,220 volunteers who completed a 100-item personality questionnaire. We show that (i) computer predictions based on a generic digital footprint (Facebook Likes) are more accurate (r = 0.56) than those made by the participants’ Facebook friends using a personality questionnaire (r = 0.49); (ii) computer models show higher interjudge agreement; and (iii) computer personality judgments have higher external validity when predicting life outcomes such as substance use, political attitudes, and physical health; for some outcomes, they even outperform the self-rated personality scores. Computers outpacing humans in personality judgment presents significant opportunities and challenges in the areas of psychological assessment, marketing, and privacy.}, 
URL = {http://www.pnas.org/content/112/4/1036.abstract}, 
eprint = {http://www.pnas.org/content/112/4/1036.full.pdf}, 
journal = {Proceedings of the National Academy of Sciences} 
}
  
@Article{Reed-information98,
  author = 	 {Charlotte Reed and Nathaniel I. Durlach},
  title = 	 {Note on Information Transfer Rates in Human Communication},
  journal = 	 {Presence Teleoperators \& Virtual Environments},
  year = 	 {1998},
  OPTkey = 	 {},
  volume =	 {7},
  number =	 {5},
  pages =	 {509--518},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1162/105474698565893},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}


@PhdThesis{Hagmann-connectome05,
  author = {Patric Hagmann},
  title = {From diffusion {MRI} to brain connectomics},
  institute = {Lausanne: EPFL},
  doi = {10.5075/epfl-thesis-3230}
  }

@BOOK{Laplace-essai14,
  title = {Essai philosophique sur les probabilit\'es},
  publisher = {Courcier},
  year = {1814},
  author = {Pierre Simon Laplace},
  address = {Paris},
  edition = {2nd},
  note = {Sixth edition of 1840 translated and repreinted (1951) as \emph{A
	Philosophical Essay on Probabilities}, New York: Dover; fifth edition
	of 1825 reprinted 1986 with notes by Bernard Bru, Paris: Christian
	Bourgois \'Editeur, translated by Andrew Dale (1995) as \emph{Philosophical
	Essay on Probabilities}, New York: Springer}
}


@InProceedings{Ananthanarayanan-cat09,
  author = 	 {Rajagopal Ananthanarayanan and Steven K. Esser and Horst D. Simon and Dharmendra S. Modha},
  title = 	 {The Cat is Out of the Bag: Cortical Simulations with $10^9$ Neurons, $10^{13}$ Synapses},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis - SC ’09},
  OPTpages = 	 {},
  year =	 {2009},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1145/1654059.1654124},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Camerer-neuroeconomics04,
  author = 	 {Colin F. Camerer and George Loewenstein and Drazen Prelec},
  title = 	 {Neuroeconomics: Why Economics Needs Brains},
  journal = 	 {Scandinavian Journal of Economics},
  year = 	 {2004},
  OPTkey = 	 {},
  volume =	 {106},
  number =	 {3},
  pages =	 {555--579},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1111/j.1467-9442.2004.00378.x},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{Bakker-crashspace15,
  author = 	 {R. Scott Bakker},
  title = 	 {Crash Space},
  journal = 	 {Midwest Studies in Philosophy},
  year = 	 {2015},
  OPTkey = 	 {},
  volume =	 {39},
  OPTnumber = 	 {},
  pages =	 {186--204},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1111/misp.12034},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@InBook{Frankish-duality09,
  author =	 {Keith Frankish and Jonathan Evans},
  editor =	 {Jonathan Evans and Keith Frankish},
  title = 	 {The Duality of Mind: An Historical Perspective},
  booktitle =    {In Two Minds: Dual Processes and Beyond},
  chapter = 	 {1},
  publisher = 	 {},
  year = 	 {2009},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTtype = 	 {},
  OPTaddress = 	 {},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  ISBN = {9780199230167},
  pages =	 {1--29},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}
@Article{Presser-caredata15,
  author = 	 {Lizzie Presser and Maia Hruskova and Helen Rowbottom and Jesse Kancir},
  title = 	 {Care.data and Access to UK Health Records: Patient Privacy and
    Public Trust},
  journal = 	 {Technology Science},
  year = 	 {2015},
  OPTkey = 	 {},
  OPTvolume = 	 {03},
  OPTnumber = 	 {},
  OPTpages = 	 {},
  OPTmonth = 	 {11 August},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  url =	 {http://techscience.org/a/2015081103/}
}

@INPROCEEDINGS{Taigman-deepface14, 
author={Y. Taigman and M. Yang and M. Ranzato and L. Wolf}, 
booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
title={DeepFace: Closing the Gap to Human-Level Performance in Face Verification}, 
year={2014}, 
pages={1701-1708}, 
abstract={In modern face recognition, the conventional pipeline consists of four stages: detect => align => represent => classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4, 000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.35% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27%, closely approaching human-level performance.}, 
keywords={face recognition;image representation;neural nets;3D face modeling;DeepFace;LFW dataset;alignment step;deep neural network;face recognition;face representation;face verification;human-level performance;labeled faces in the wild;piecewise affine transformation;representation step;Agriculture;Face;Face recognition;Shape;Solid modeling;Three-dimensional displays;Training}, 
doi={10.1109/CVPR.2014.220}, 
ISSN={1063-6919}, 
month={June}
}

@inproceedings{McMahan-adclick13,
title = {Ad Click Prediction: a View from the Trenches},
author  = {H. Brendan McMahan and Gary Holt and D. Sculley and Michael Young and Dietmar Ebner and Julian Grady and Lan Nie and Todd Phillips and Eugene Davydov and Daniel Golovin and Sharat Chikkerur and Dan Liu and Martin Wattenberg and Arnar Mar Hrafnkelsson and Tom Boulos and Jeremy Kubica},
year  = 2013,
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)}
}

@article{Russakovsky-imagenet15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}
@article{Silver-alphago16,
	Abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses `value networks'to evaluate board positions and `policy networks'to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8{\%} winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	Author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	Date = {2016/01/28/print},
	Date-Added = {2017-05-12 14:44:20 +0000},
	Date-Modified = {2017-05-12 14:44:20 +0000},
	Day = {28},
	Isbn = {0028-0836},
	Journal = {Nature},
	L3 = {10.1038/nature16961; http://www.nature.com/nature/journal/v529/n7587/abs/nature16961.html#supplementary-information},
	M3 = {Article},
	Month = {01},
	Number = {7587},
	Pages = {484--489},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Title = {Mastering the game of {Go} with deep neural networks and tree search},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature16961},
	Volume = {529},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature16961}
}

@comment{jabref-entrytype: Html: req[url] opt[]}


@InProceedings{Cho:deep09,
title = {Kernel Methods for Deep Learning},
author = {Youngmin Cho and Lawrence K. Saul},
booktitle = {Advances in Neural Information Processing Systems 22},
editor = {Y. Bengio and D. Schuurmans and J. D. Lafferty and C. K. I. Williams and A. Culotta},
pages = {342--350},
year = {2009},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf}
}

@InProceedings{Ioffe:batch15,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Sergey Ioffe and Christian Szegedy},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {448--456},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/ioffe15.pdf},
  url = 	 {http://proceedings.mlr.press/v37/ioffe15.html},
  abstract = 	 {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.}
}

@InProceedings{Ranganath-survival16,
  title = 	 {Deep Survival Analysis},
  author = 	 {Rajesh Ranganath and Adler Perotte and Noémie Elhadad and David Blei},
  booktitle = 	 {Proceedings of the 1st Machine Learning for Healthcare Conference},
  pages = 	 {101--114},
  year = 	 {2016},
  editor = 	 {Finale Doshi-Velez and Jim Fackler and David Kale and Byron Wallace and Jenna Wiens},
  volume = 	 {56},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Children's Hospital LA, Los Angeles, CA, USA},
  month = 	 {18--19 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v56/Ranganath16.pdf},
  url = 	 {http://proceedings.mlr.press/v56/Ranganath16.html},
  abstract = 	 {The electronic health record (EHR) provides an unprecedented opportunity to build actionable tools to support physicians at the point of care. In this paper, we introduce deep survival analysis, a hierarchical generative  approach to survival analysis in the context of the EHR. It departs from previous approaches in two main ways: (1) all observations, including covariates, are modeled jointly conditioned on a rich latent structure; and (2) the observations are aligned by their failure time, rather than by an arbitrary time zero as in traditional survival analysis. Further, it handles heterogeneous data types that occur in the EHR. We validate deep survival analysis by stratifying patients according to risk of developing coronary heart disease (CHD) on 313,000 patients corresponding to 5.5 million months of observations. When compared to the clinically validated Framingham CHD risk score, deep survival analysis is superior in stratifying patients according to their risk.}
}

@PhDThesis{MacKay:bayesian92,
author = {David J. C. MacKay},
year = {1992},
title = {Bayesian Methods for Adaptive Models}, 
school = {California Institute of Technology},
pdf = {http://www.inference.org.uk/mackay/thesis.pdf},
abstract = {The Bayesian framework for model comparison and regularisation is demonstrated by studying
interpolation and classification problems modelled with both linear and non–linear models.
This framework quantitatively embodies `Occam's razor'. Over–complex and under–
regularised models are automatically inferred to be less probable, even though their flexibility
allows them to fit the data better.
When applied to `neural networks', the Bayesian framework makes possible (1) objective
comparison of solutions using alternative network architectures; (2) objective stopping rules
for network pruning or growing procedures; (3) objective choice of type of weight decay
terms (or regularisers); (4) on–line techniques for optimising weight decay (or regularisation
constant) magnitude; (5) a measure of the effective number of well–determined parameters
in a model; (6) quantified estimates of the error bars on network parameters and on network
output. In the case of classification models, it is shown that the careful incorporation of
error bar information into a classifier’s predictions yields improved performance.
Comparisons of the inferences of the Bayesian framework with more traditional cross–
validation methods help detect poor underlying assumptions in learning models.
The relationship of the Bayesian learning framework to `active learning' is examined.
Objective functions are discussed which measure the expected informativeness of candidate
data measurements, in the context of both interpolation and classification problems.
The concepts and methods described in this thesis are quite general and will be applicable
to other data modelling problems whether they involve regression, classification or
density estimation.}
}
@PhDThesis{Neal:bayesian94,
author = {Radford M. Neal},
year = {1994},
title = {Bayesian Learning for Neural Networks}, 
school = {Dept. of Computer Science, University of Toronto},
pdf = {http://www.cs.toronto.edu/~radford/ftp/thesis.pdf},
softwarelink = {http://www.cs.toronto.edu/~radford/fbm.software.html},
abstract = {Two features distinguish the Bayesian approach to learning models from data. First, beliefs derived from background knowledge are used to select a prior probability distribution for the model parameters. Second, predictions of future observations are made by integrating the model's predictions with respect to the posterior parameter distribution obtained by updating this prior to take account of the data. For neural network models, both these aspects present difficulties - the prior over network parameters has no obvious relation to our prior knowledge, and integration over the posterior is computationally very demanding.

I address the first problem by defining classes of prior distributions for network parameters that reach sensible limits as the size of the network goes to infinity. In this limit, the properties of these priors can be elucidated. Some priors converge to Gaussian processes, in which functions computed by the network may be smooth, Brownian, or fractionally Brownian. Other priors converge to non-Gaussian stable processes. Interesting effects are obtained by combining priors of both sorts in networks with more than one hidden layer.

The problem of integrating over the posterior can be solved using Markov chain Monte Carlo methods. I demonstrate that the hybrid Monte Carlo algorithm, which is based on dynamical simulation, is superior to methods based on simple random walks.

I use a hybrid Monte Carlo implementation to test the performance of Bayesian neural network models on several synthetic and real data sets. Good results are obtained on small data sets when large networks are used in conjunction with priors designed to reach limits as network size increases, confirming that with Bayesian learning one need not restrict the complexity of the network based on the size of the data set. A Bayesian approach is also found to be effective in automatically determining the relevance of inputs.

Ph.D. Thesis, Dept. of Computer Science, University of Toronto, 195 pages}
}
@article{Thang:unifying17,
  author  = {Thang D. Bui and Josiah Yan and Richard E. Turner},
  title   = {A Unifying Framework for {G}aussian Process Pseudo-Point Approximations using Power Expectation Propagation},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {104},
  pages   = {1-72},
  url     = {http://jmlr.org/papers/v18/16-603.html}
}
@PhdThesis{Damianou:thesis2015,
  author = 	 {Andreas Damianou},
  title = 	 {Deep {G}aussian Processes and Variational Propagation of Uncertainty},
  school = 	 {University of Sheffield},
  year = 	 {2015},
  OPTkey = 	 {},
  OPTtype = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@article{Mattos:recurrent15,
  author    = {C{\'{e}}sar Lincoln C. Mattos and
               Zhenwen Dai and
               Andreas C. Damianou and
               Jeremy Forth and
               Guilherme A. Barreto and
               Neil D. Lawrence},
  title     = {Recurrent Gaussian Processes},
  journal   = {CoRR},
  volume    = {abs/1511.06644},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06644},
  archivePrefix = {arXiv},
  eprint    = {1511.06644},
  timestamp = {Wed, 07 Jun 2017 14:42:48 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/MattosDDFBL15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@incollection{Salimbeni:doubly2017,
title = {Doubly Stochastic Variational Inference for Deep Gaussian Processes},
author = {Salimbeni, Hugh and Deisenroth, Marc},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4591--4602},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7045-doubly-stochastic-variational-inference-for-deep-gaussian-processes.pdf}
}
@ARTICLE{Dunlop:deep2017,
   author = {Matthew M. Dunlop and Mark A. Girolami and Andrew M. Stuart and Aretha L. Teckentrup},
   title = {How Deep Are Deep {G}aussian Processes?},
   journal = jmlr,
   volume = 19,
   number = 54,
   pages = {1--46},
   url   = {http://jmlr.org/papers/v19/18-015.html}
}
@incollection{Alaa:deep2017,
title = {Deep Multi-task {G}aussian Processes for Survival Analysis with Competing Risks},
author = {Ahmed M. Alaa and Mihaela {van der Schaar}},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {2326--2334},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6827-deep-multi-task-gaussian-processes-for-survival-analysis-with-competing-risks.pdf}
}
@PhdThesis{Saul:thesis2016,
  author = 	 {Alan Daniel Saul},
  title = 	 {Gaussian Process Based Approaches for Survival Analysis},
  school = 	 {University of Sheffield},
  year = 	 {2016},
  OPTkey = 	 {},
  OPTtype = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@article {Perdikaris:multifidelity17,
	author = {Perdikaris, P. and Raissi, M. and Damianou, A. and Lawrence, N. D. and Karniadakis, G. E.},
	title = {Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling},
	volume = {473},
	number = {2198},
	year = {2017},
	doi = {10.1098/rspa.2016.0751},
	publisher = {The Royal Society},
	abstract = {Multi-fidelity modelling enables accurate inference of quantities of interest by synergistically combining realizations of low-cost/low-fidelity models with a small set of high-fidelity observations. This is particularly effective when the low- and high-fidelity models exhibit strong correlations, and can lead to significant computational gains over approaches that solely rely on high-fidelity models. However, in many cases of practical interest, low-fidelity models can only be well correlated to their high-fidelity counterparts for a specific range of input parameters, and potentially return wrong trends and erroneous predictions if probed outside of their validity regime. Here we put forth a probabilistic framework based on Gaussian process regression and nonlinear autoregressive schemes that is capable of learning complex nonlinear and space-dependent cross-correlations between models of variable fidelity, and can effectively safeguard against low-fidelity models that provide wrong trends. This introduces a new class of multi-fidelity information fusion algorithms that provide a fundamental extension to the existing linear autoregressive methodologies, while still maintaining the same algorithmic complexity and overall computational cost. The performance of the proposed methods is tested in several benchmark problems involving both synthetic and real multi-fidelity datasets from computational fluid dynamics simulations.},
	issn = {1364-5021},
	URL = {http://rspa.royalsocietypublishing.org/content/473/2198/20160751},
	eprint = {http://rspa.royalsocietypublishing.org/content/473/2198/20160751.full.pdf},
	journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences}
}
@Article{Steele:predictive12,
  author = 	 {Steele, S and Bilchik, A and Eberhardt, J and Kalina, P and Nissan, A and Johnson, E and Avital, I and Stojadinovic, A},
  title = 	 {Using Machine-Learned {B}ayesian Belief Networks to Predict Perioperative Risk of Clostridium Difficile Infection Following Colon Surgery},
  journal = 	 {Interact J Med Res},
  year = 	 {2012},
  OPTkey = 	 {},
  volume =	 {1},
  number =	 {2},
  pages =	 {e6},
  doi = 	 {10.2196/ijmr.2131},
  url = 	 {https://www.i-jmr.org/2012/2/e6},
  OPTannote = 	 {}
}

@incollection{Anqi:gpspike2017,
title = {Gaussian process based nonlinear latent structure discovery in multivariate spike train data},
author = {Wu, Anqi and Roy, Nicholas G and Keeley, Stephen and Pillow, Jonathan W},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {3499--3508},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6941-gaussian-process-based-nonlinear-latent-structure-discovery-in-multivariate-spike-train-data.pdf}
}

@incollection{Schulam:counterfactual17,
title = {Counterfactual Gaussian Processes for Reliable Decision-making and What-if Reasoning},
author = {Schulam, Peter and Saria, Suchi},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {1696--1706},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6767-counterfactual-gaussian-processes-for-reliable-decision-making-and-what-if-reasoning.pdf}
}




@Article{Freund:risk56,
  author = 	 {Rudolf J. Freund},
  title = 	 {The Introduction of Risk into a Programming Model},
  journal = 	 {Econometrica},
  year = 	 {1956},
  OPTkey = 	 {},
  volume =	 {24},
  number =	 {3},
  pages =	 {253--263},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.2307/1911630},
  jstor = {1911630},
  url =          {https://www.jstor.org/stable/1911630},
  pdf =          {https://www.jstor.org/stable/pdf/1911630.pdf},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@InCollection{Ramsey:truth26,
  author = 	 {Frank P. Ramsey},
  title = 	 {Truth and Probability},
  booktitle = 	 {Foundations of Mathematics
and other Logical Essays},
  OPTcrossref =  {},
  OPTkey = 	 {},
  pages =	 {156--198},
  publisher =	 {Kegan, Paul, Trench, Trubner & Co},
  year =	 {1926},
  OPTeditor = 	 {R. B Braithwaite},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTtype = 	 {},
  chapter =	 {VII},
  address =	 {London},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@Article{,
  author = 	 {Frank P. Ramsey},
  title = 	 {Truth and Probability},
  journal = 	 {},
  year = 	 {},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTpages = 	 {},
  OPTmonth = 	 {},
  note =	 {Published 1931},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@article{Berhold:distribution73,
 title = {The Use of Distribution Functions to Represent Utility Functions},
 author = {Marvin H. Berhold},
 ISSN = {00251909, 15265501},
 URL = {http://www.jstor.org/stable/2629422},
 jstor = {2629422},
 abstract = {This paper considers the decision maker whose evaluation and consequent choice of actions is accomplished through the use of the expected utility hypothesis. In cases where the utility function is increasing with upper and lower bounds then the utility function can be characterized by a distribution function, and we can take advantage of the various properties of such functions as well as existing results with respect to such functions. Using these properties and results we can determine the certainty equivalents as a function of the parameters of the distribution function (utility function) and the parameters of the probability distribution on the uncertain payoff. The following cases are considered: (1) Gaussian distribution function and Gaussian probability distribution, (2) Exponential distribution function and exponential distribution and (3) Exponential distribution function and Gaussian probability distribution.},
 doi = {10.2307/2629422},
 journal = {Management Science},
 number = {7},
 pages = {825--829},
 publisher = {INFORMS},
 volume = {19},
 year = {1973}
}

@article{Thaler:gambling90,
author = {Thaler, Richard H. and Johnson, Eric J.},
title = {Gambling with the House Money and Trying to Break Even: The Effects of Prior Outcomes on Risky Choice},
journal = {Management Science},
volume = {36},
number = {6},
pages = {643-660},
year = {1990},
doi = {10.1287/mnsc.36.6.643},
url = {https://doi.org/10.1287/mnsc.36.6.643},
abstract = { How is risk-taking affected by prior gains and losses? While normative theory implores decision makers to only consider incremental outcomes, real decision makers are influenced by prior outcomes. We first consider how prior outcomes are combined with the potential payoffs offered by current choices. We propose an editing rule to describe how decision makers frame such problems. We also present data from real money experiments supporting a house money effect (increased risk seeking in the presence of a prior gain) and break-even effects (in the presence of prior losses, outcomes which offer a chance to break even are especially attractive).}
}



@TechReport{Vasilaki-epicurius17,
  author={Eleni Vasilaki},
  title = "{Is Epicurus the Father of Reinforcement Learning?}",
  journal = {ArXiv e-prints},
  archivePrefix = "arXiv",
  eprint = {1710.04582},
  primaryClass = "cs.LG",
  year = 2017,
  month = oct,
  url = {https://arxiv.org/abs/1710.04582}
}
@Article{Breiman-bagging96,
author="Breiman, Leo",
title="Bagging predictors",
journal="Machine Learning",
year="1996",
volume="24",
number="2",
pages="123--140",
abstract="Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.",
issn="1573-0565",
doi="10.1007/BF00058655",
url="http://dx.doi.org/10.1007/BF00058655"
}
@TechReport{DoT-casualities16,
  author = 	 {},
  title = 	 {Reported road casualties in
Great Britain: main results 2015},
  institution =  {UK Department for Transport},
  year = 	 {2016},
  OPTkey = 	 {Reported road casualties in
Great Britain: main results 2015},
  OPTtype = 	 {},
  OPTnumber = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  linkpdf = 	 {https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/556396/rrcgb2015-01.pdf},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}


@Article{Foot-problem67,
  author = 	 {Philippa Foot},
  title = 	 {The Problem of Abortion and the Doctrine of the Double Effect in Virtues and Vices},
  journal = 	 {Oxford Review},
  year = 	 {1967},
  OPTkey = 	 {},
  volume =	 {5},
  OPTnumber = 	 {},
  pages =	 {5--15},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  doi =		 {10.1093/0199252866.003.0002},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}



@Article{Thomson-trolley76,
  author = 	 {Judith Jarvis Thomson},
  title = 	 {Killing, Letting Die, and the Trolley Problem},
  journal = 	 {The Monist},
  year = 	 {1976},
  OPTkey = 	 {},
  volume =	 {59},
  number =	 {2},
  pages =	 {204--217},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {10.5840/monist197659224},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}




@Article{Box-science76,
  author = 	 {George E. P. Box},
  title = 	 {Science and Statistics},
  journal = 	 {Journal of the American Statistical Association},
  year = 	 {1976},
  OPTkey = 	 {},
  volume =	 {71},
  number =	 {356},
  pages =	 {791--799},
  month = 	 {12},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  url =	 {http://www.jstor.org/stable/2286841}
}

@Article{Box-robustness79,
  author = 	 {George E. P. Box},
  title = 	 {Robustness in the strategy of scientific model building},
  booktitle = 	 {Robustness in Statistics},
  OPTcrossref =  {},
  OPTkey = 	 {},
  pages =	 {201--236},
  publisher =	 {Academic Press},
  editor =	 {R. L. Launer and G. N. Wilkinson},
  year = 	 {1979},
  url = 	 {http://www.dtic.mil/docs/citations/ADA070213},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTpages = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTdoi = 	 {},
  OPTlinkpdf = 	 {},
  OPTlinkps = 	 {},
  OPTlinkpsgz =  {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  OPTgroup = 	 {}
}

@article{Geman-biasvariance92,
author = { Stuart Geman  and  Elie Bienenstock  and  René Doursat },
title = {Neural Networks and the Bias/Variance Dilemma},
journal = {Neural Computation},
volume = {4},
number = {1},
pages = {1-58},
year = {1992},
doi = {10.1162/neco.1992.4.1.1},

URL = { 
        http://dx.doi.org/10.1162/neco.1992.4.1.1
    
},
eprint = { 
        http://dx.doi.org/10.1162/neco.1992.4.1.1
    
}
,
    abstract = { Feedforward neural networks trained by error backpropagation are examples of nonparametric regression estimators. We present a tutorial on nonparametric inference and its relation to neural networks, and we use the statistical viewpoint to highlight strengths and weaknesses of neural models. We illustrate the main points with some recognition experiments involving artificial data as well as handwritten numerals. In way of conclusion, we suggest that current-generation feedforward neural networks are largely inadequate for difficult problems in machine perception and machine learning, regardless of parallel-versus-serial hardware or other implementation issues. Furthermore, we suggest that the fundamental challenges in neural modeling are about representation rather than learning per se. This last point is supported by additional experiments with handwritten numerals. }
}


