{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 12: Gaussian Processes\n",
    "\n",
    "### Neil D. Lawrence\n",
    "\n",
    "### 15th December 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pods\n",
    "import matplotlib.pyplot as plt\n",
    "import mlai\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review\n",
    "\n",
    "* Last week: Logistic Regression and Generalised Linear Models\n",
    "* Introduced link functions and different transformations.\n",
    "* Showed examples in classification and mentioned possibilities for disease rate models (Come to tonight's Data Hide for more!).\n",
    "* This week: \n",
    "    * Gaussian Processes: non parametric Bayesian modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes\n",
    "\n",
    "* Basis function models give non-linear predictions.\n",
    "* Need to choose number and location of basis functions. \n",
    "* Gaussian processes is a general framework (basis functions special case)\n",
    "* Within the framework you can consider models with infinite basis functions.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling a Function\n",
    "\n",
    "**Multi-variate Gaussians**\n",
    "\n",
    "* We will consider a Gaussian with a particular structure of covariance\n",
    "    matrix.\n",
    "* Generate a single sample from this 25 dimensional Gaussian distribution, $\\mathbf{f}=\\left[f_{1},f_{2}\\dots f_{25}\\right]$.\n",
    "\n",
    "* We will plot these points against their index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s compute_kernel mlai.py\n",
    "def compute_kernel(X, X2, kernel, **kwargs):\n",
    "    K = np.zeros((X.shape[0], X2.shape[0]))\n",
    "    for i in np.arange(X.shape[0]):\n",
    "        for j in np.arange(X2.shape[0]):\n",
    "            K[i, j] = kernel(X[i, :], X2[j, :], **kwargs)\n",
    "        \n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s exponentiated_quadratic mlai.py\n",
    "def exponentiated_quadratic(x, x_prime, variance=1., lengthscale=1.):\n",
    "    \"Exponentiated quadratic covariance function.\"\n",
    "    squared_distance = ((x-x_prime)**2).sum()\n",
    "    return variance*np.exp((-0.5*squared_distance)/lengthscale**2)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x109684080>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFHCAYAAAAodW7lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEgASCEsASPh/qNqCzt5mNDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10971be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=((5,5)))\n",
    "x = np.linspace(-1, 1, 25)[:, None]\n",
    "K = compute_kernel(x, x, exponentiated_quadratic, lengthscale=0.3)\n",
    "ax.matshow(K)\n",
    "ax.set_xlabel('$i$',fontsize=16)\n",
    "ax.set_ylabel('$j$',fontsize=16)\n",
    "ax.set_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "close all\n",
    "K = kernCompute(kern, x);\n",
    "ax = axes('position', [0 0 1 1])\n",
    "plotMatrix(K, ax, 'none', 'imagesc')\n",
    "colorbar\n",
    "\n",
    "t = [];\n",
    "t = [t xlabel('$\\dataIndex$')];\n",
    "t = [t ylabel('$\\dataIndexTwo$')];\n",
    "printLatexPlot('gpSampleCovariance', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "\n",
    "clf\n",
    "% need to take the real part of the sample as the kernel is numerically less than full rank \n",
    "f = real(gsamp(zeros(1, size(x, 1)), K, 1))';\n",
    "\n",
    "a = plot(f, 'x', 'color', blackColor);\n",
    "t = [t xlabel('$\\dataIndex$')];\n",
    "t = [t ylabel('$\\mappingFunction_\\dataIndex$')];\n",
    "set(gca, 'ylim', [-2 2])\n",
    "set(gca, 'xlim', [0 26])\n",
    "set(gca, 'ytick', [-2 -1 0 1 2])\n",
    "set(a,'markersize', 5)\n",
    "set(a, 'linewidth', 6)\n",
    "box off\n",
    "xlim = get(gca, 'xlim');\n",
    "ylim = get(gca, 'ylim');\n",
    "line([xlim(1) xlim(1)], ylim, 'color', blackColor)\n",
    "line(xlim, [ylim(1) ylim(1)], 'color', blackColor)\n",
    "\n",
    "printLatexPlot('gpSampleValue', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "yLim = get(gca, 'ylim');\n",
    "xLim = get(gca, 'xlim');\n",
    "ySpan = yLim(2) - yLim(1);\n",
    "xSpan = xLim(2) - xLim(1);\n",
    "chand = oval([1 f(1)], 0.025*xSpan, 0.025*ySpan);\n",
    "chand = [chand oval([2 f(2)], 0.025*xSpan, 0.025*ySpan)];\n",
    "set(chand, 'color', magentaColor, 'linewidth', 3)\n",
    "printLatexPlot('gpSampleValue12', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "\n",
    "clf\n",
    "options = plotMatrixOptions;\n",
    "options.color = blackColor;\n",
    "options.highlight.on = true;\n",
    "options.highlight.row = [1 2];\n",
    "options.highlight.col= [1 2];\n",
    "options.highlight.color = magentaColor;\n",
    "options.highlight.width = 10;\n",
    "ax = axes('position', [0 0 1 1])      \n",
    "plotMatrix(K, ax, 'none', 'imagesc', options)\n",
    "colorbar\n",
    "printLatexPlot('gpSampleCovariance12a', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "\n",
    "options.zoom.on = true;\n",
    "options.zoom.row = [1 10];\n",
    "options.zoom.col = [1 10];\n",
    "\n",
    "cla(ax)\n",
    "plotMatrix(K, ax, 'none', 'imagesc', options)\n",
    "colorbar\n",
    "printLatexPlot('gpSampleCovariance12b', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "\n",
    "options.zoom.on = true;\n",
    "options.zoom.row = [1 5];\n",
    "options.zoom.col = [1 5];\n",
    "\n",
    "cla(ax)\n",
    "plotMatrix(K, ax, 'none', 'imagesc', options)\n",
    "colorbar\n",
    "printLatexPlot('gpSampleCovariance12c', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "\n",
    "options.zoom.on = true;\n",
    "options.zoom.row = [1 3];\n",
    "options.zoom.col = [1 3];\n",
    "\n",
    "plotMatrix(K, ax, 'none', 'imagesc', options)\n",
    "colorbar \n",
    "printLatexPlot('gpSampleCovariance12d', '../../../gp/tex/diagrams/', 0.4*\n",
    "textWidth);\n",
    "\n",
    "options.zoom.on = true;\n",
    "options.zoom.row = [1 2];\n",
    "options.zoom.col = [1 2];\n",
    "\n",
    "plotMatrix(K, ax, 'none', 'imagesc', options)\n",
    "colorbar \n",
    "printLatexPlot('gpSampleCovariance12e', '../../../gp/tex/diagrams/', 0.4*\n",
    "textWidth);\n",
    "\n",
    "clf\n",
    "options.highlight.on = false;\n",
    "options.zoom.on = false;\n",
    "options.bracketWidth = 10;\n",
    "ax = axes('position', [0 0 1 1])      \n",
    "plotMatrix(K([1 2], [1 2]), ax, 'square', 'values', options)\n",
    "printLatexPlot('gpSampleCovariance12f', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "\n",
    "\n",
    "clf\n",
    "options.highlight.on = false;\n",
    "options.zoom.on = false;\n",
    "options.bracketWidth = 10;\n",
    "ax = axes('position', [0 0 1 1])      \n",
    "plotMatrix(K([1 5], [1 5]), ax, 'square', 'values', options)\n",
    "printLatexPlot('gpSampleCovariance15f', '../../../gp/tex/diagrams/', 0.4*textWidth);\n",
    "\n",
    "save gpdistfunc K x f\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Distribution Sample\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Log Odds\n",
    "\n",
    "* model the *log-odds* with the basis functions.\n",
    "* [odds](http://en.wikipedia.org/wiki/Odds) are defined as the ratio of the probability of a positive outcome, to the probability of a negative outcome. \n",
    "* Probability is between zero and one, odds are:\n",
    "    $$ \\frac{\\pi}{1-\\pi} $$\n",
    "* Odds are between $0$ and $\\infty$. \n",
    "* Logarithm of odds maps them to $-\\infty$ to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logit Link Function\n",
    "\n",
    "* The [Logit function](http://en.wikipedia.org/wiki/Logit), $$g^{-1}(\\pi_i) = \\log\\frac{\\pi_i}{1-\\pi_i}.$$ This function is known as a *link function*.\n",
    "\n",
    "* For a standard regression we take,\n",
    "    $$f(\\mathbf{x}_i) = \\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x}_i),$$\n",
    "* For classification we perform a logistic regression. \n",
    "    $$\\log \\frac{\\pi_i}{1-\\pi_i} = \\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse Link Function\n",
    "\n",
    "We have defined the link function as taking the form $g^{-1}(\\cdot)$ implying that the inverse link function is given by $g(\\cdot)$. Since we have defined,\n",
    "$$\n",
    "g^{-1}(\\pi(\\mathbf{x})) = \\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})\n",
    "$$\n",
    "we can write $\\pi$ in terms of the *inverse link* function, $g(\\cdot)$ as \n",
    "$$\n",
    "\\pi(\\mathbf{x}) = g(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "f = np.linspace(-8, 8, 100)\n",
    "g = 1/(1+np.exp(-f))\n",
    "\n",
    "ax.plot(f, g, 'r-')\n",
    "ax.set_title('Logistic Function', fontsize=20)\n",
    "ax.set_xlabel('$f_i$', fontsize=20)\n",
    "ax.set_ylabel('$g_i$', fontsize=20)\n",
    "plt.savefig('./diagrams/logistic.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic function\n",
    "\n",
    "* [Logistic](http://en.wikipedia.org/wiki/Logistic_function) (or sigmoid) squashes real line to between 0   & 1. Sometimes also called a 'squashing function'. \n",
    "![](./diagrams/logistic.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Prediction Function\n",
    "* Can now write $\\pi$ as a function of the input and the parameter vector as, $$\\pi(\\mathbf{x},\\mathbf{w}) = \\frac{1}{1+ \\exp\\left(-\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})\\right)}.$$\n",
    "\n",
    "* Compute the output of a standard linear basis function composition ($\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})$, as we did for linear regression)\n",
    "\n",
    "* Apply the inverse link function, $g(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x}))$. \n",
    "\n",
    "* Use this value in a Bernoulli distribution to form the likelihood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bernoulli Reminder\n",
    "\n",
    "* From last time $$P(y_i|\\mathbf{w}, \\mathbf{x}) = \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}$$\n",
    "\n",
    "* Trick for switching betwen probabilities\n",
    "```python\n",
    "def bernoulli(y, pi):\n",
    "    if y == 1:\n",
    "        return pi\n",
    "    else:\n",
    "        return 1-pi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximum Likelihood\n",
    "\n",
    "\n",
    "* Conditional independence of data:$$P(\\mathbf{y}|\\mathbf{w}, \\mathbf{X}) = \\prod_{i=1}^n P(y_i|\\mathbf{w}, \\mathbf{x}_i). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log Likelihood\n",
    "\n",
    "\\begin{align*}\n",
    "\\log P(\\mathbf{y}|\\mathbf{w}, \\mathbf{X}) = & \\sum_{i=1}^n \\log P(y_i|\\mathbf{w}, \\mathbf{x}_i) \\\\ = &\\sum_{i=1}^n y_i \\log \\pi_i \\\\ & + \\sum_{i=1}^n (1-y_i)\\log (1-\\pi_i)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objective Function\n",
    "\n",
    "* Probability of positive outcome for the $i$th data point $$\\pi_i = g\\left(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x}_i)\\right),$$ where $g(\\cdot)$ is the *inverse* link function\n",
    "\n",
    "* Objective function of the form \\begin{align*}\n",
    "E(\\mathbf{w}) = & -  \\sum_{i=1}^n y_i \\log g\\left(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x}_i)\\right) \\\\& - \\sum_{i=1}^n(1-y_i)\\log \\left(1-g\\left(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x}_i)\\right)\\right).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimize Objective\n",
    "\n",
    "* Grdient wrt  $\\pi(\\mathbf{x};\\mathbf{w})$ \n",
    "\\begin{align*}\n",
    "\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}} = & -\\sum_{i=1}^n \\frac{y_i}{g\\left(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})\\right)}\\frac{\\text{d}g(f_i)}{\\text{d}f_i} \\boldsymbol{\\phi(\\mathbf{x}_i)} \\\\ & +  \\sum_{i=1}^n \\frac{1-y_i}{1-g\\left(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})\\right)}\\frac{\\text{d}g(f_i)}{\\text{d}f_i} \\boldsymbol{\\phi(\\mathbf{x}_i)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Link Function Gradient\n",
    "\n",
    "* Also need gradient of inverse link function wrt parameters.\n",
    "\\begin{align*}\n",
    "g(f_i) &= \\frac{1}{1+\\exp(-f_i)}\\\\\n",
    "&=(1+\\exp(-f_i))^{-1}\n",
    "\\end{align*}\n",
    "and the gradient can be computed as\n",
    "\\begin{align*}\n",
    "\\frac{\\text{d}g(f_i)}{\\text{d} f_i} & = \\exp(-f_i)(1+\\exp(-f_i))^{-2}\\\\\n",
    "& = \\frac{1}{1+\\exp(-f_i)} \\frac{\\exp(-f_i)}{1+\\exp(-f_i)} \\\\\n",
    "& = g(f_i) (1-g(f_i))\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objective Gradient\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}} = & -\\sum_{i=1}^n y_i\\left(1-g\\left(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})\\right)\\right) \\boldsymbol{\\phi(\\mathbf{x}_i)} \\\\ & + \\sum_{i=1}^n (1-y_i)\\left(g\\left(\\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x})\\right)\\right) \\boldsymbol{\\phi(\\mathbf{x}_i)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization of the Function\n",
    "\n",
    "* Can't find a stationary point of the objective function analytically.\n",
    "\n",
    "* Optimization has to proceed by *numerical methods*. \n",
    "    * [Newton's method](http://en.wikipedia.org/wiki/Newton%27s_method) or \n",
    "    * [gradient based optimization methods](http://en.wikipedia.org/wiki/Gradient_method) \n",
    "    \n",
    "* Similarly to matrix factorization, for large data *stochastic gradient descent*  (Robbins Munroe optimization procedure) works well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ad Matching for Facebook\n",
    "\n",
    "* This approach used in many internet companies.\n",
    "\n",
    "* Example: ad matching for Facebook.\n",
    "    * Millions of advertisers\n",
    "    * Billions of users\n",
    "    * How do you choose who to show what?\n",
    "    \n",
    "* Logistic regression used in combination with [decision trees]()\n",
    "\n",
    "* [Paper available here](http://www.herbrich.me/papers/adclicksfacebook.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other GLMs\n",
    "\n",
    "* Logistic regression is part of a family known as *generalized linear models*\n",
    "\n",
    "* They all take the form $$g^{-1}(f_i(x)) = \\mathbf{w}^\\top \\boldsymbol{\\phi}(\\mathbf{x}_i)$$\n",
    "\n",
    "* As another example let's look at *Poisson regression*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Poisson Distribution\n",
    "\n",
    "* Poisson distribution is used for 'count data'. For non-negative integers, $y$, $$P(y) = \\frac{\\lambda^y}{y!}\\exp(-y)$$\n",
    "\n",
    "* Here $\\lambda$ is a *rate* parameter that can be thought of as the number of arrivals per unit time.\n",
    "\n",
    "* Poisson distributions can be used for disease count data. E.g. number of incidence of malaria in a district.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "y = np.asarray(range(0, 16))\n",
    "p1 = poisson.pmf(y, mu=1.)\n",
    "p3 = poisson.pmf(y, mu=3.)\n",
    "p10 = poisson.pmf(y, mu=10.)\n",
    "\n",
    "ax.plot(y, p1, 'r.-', markersize=20, label='$\\lambda=1$')\n",
    "ax.plot(y, p3, 'g.-', markersize=20, label='$\\lambda=3$')\n",
    "ax.plot(y, p10, 'b.-', markersize=20, label='$\\lambda=10$')\n",
    "ax.set_title('Poisson Distribution', fontsize=20)\n",
    "ax.set_xlabel('$y_i$', fontsize=20)\n",
    "ax.set_ylabel('$p(y_i)$', fontsize=20)\n",
    "ax.legend(fontsize=20)\n",
    "plt.savefig('./diagrams/poisson.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Poisson Distribution\n",
    "\n",
    "![](./diagrams/poisson.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Poisson Regression\n",
    "\n",
    "* In a Poisson regression make rate a function of space/time.$$\\log \\lambda(\\mathbf{x}, t) = \\mathbf{w}_x^\\top \\boldsymbol{\\phi_x(\\mathbf{x})} + \\mathbf{w}_t^\\top \\boldsymbol(\\phi_t(t))$$\n",
    "\n",
    "* This is known as a *log linear* or *log additive* model. \n",
    "\n",
    "* The link function is a logarithm.\n",
    "\n",
    "* We can rewrite such a function as \n",
    "$$\\log \\lambda(\\mathbf{x}, t) = f_x(\\mathbf{x}) + f_t(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiplicative Model\n",
    "\n",
    "* Be careful though ... a log additive model is really multiplicative.\n",
    "$$\\log \\lambda(\\mathbf{x}, t) = f_x(\\mathbf{x}) + f_t(t)$$\n",
    "\n",
    "* Becomes $$\\lambda(\\mathbf{x}, t) = \\exp(f_x(\\mathbf{x}) + f_t(t))$$\n",
    "\n",
    "* Which is equivalent to  $$\\lambda(\\mathbf{x}, t) = \\exp(f_x(\\mathbf{x}))\\exp(f_t(t))$$\n",
    "\n",
    "* Link functions can be deceptive in this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reading\n",
    "\n",
    "- Section 5.2.2 of @Rogers:book11 up to pg 182.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
