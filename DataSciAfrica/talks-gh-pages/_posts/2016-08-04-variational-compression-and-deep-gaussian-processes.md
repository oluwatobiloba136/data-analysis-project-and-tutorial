---
abstract: In this fourth sesssion we describe how deep neural networks can be modified
  to produce deep Gaussian process models. The framework of deep Gaussian processes
  allow for unsupervised learning, transfer learning, semi-supervised learning, multi-task
  learning and principled handling of different data types (count data, binary data,
  heavy tailed noise distributions). The main challenge is to handle the intractabilities.
  In this talk we review the variational bounds that are used under the framework
  of variational compression and give some initial results of deep Gaussian process
  models.
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: University of Sheffield
  twitter: lawrennd
  url: http://inverseprobability.com
categories:
- Lawrence-mlss16bIV
day: '4'
demo: demo_2016_08_04_mlss16.m
errata: []
extras: []
key: Lawrence-mlss16bIV
layout: talk
month: 8
pdf: gp_mlss16b.pdf
published: 2016-08-04
section: pre
title: Variational Compression and Deep <span>G</span>aussian Processes
venue: MLSS, Arequipa
year: '2016'
---