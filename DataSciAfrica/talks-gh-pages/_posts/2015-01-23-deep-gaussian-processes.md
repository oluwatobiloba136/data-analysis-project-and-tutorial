---
title: Deep Gaussian Processes
venue: Instituto Italiano de Tecnologia, Genova, Italy
year: 2015
published: 2015-01-23
abstract: In this talk we describe how deep neural networks can be modified to produce
  deep Gaussian process models. The framework of deep Gaussian processes allow for
  unsupervised learning, transfer learning, semi-supervised learning, multi-task learning
  and principled handling of different data types (count data, binary data, heavy
  tailed noise distributions). The main challenge is to solve these models efficiently
  for massive data sets. That challenge is in reach through a new class of variational
  approximations known as variational compression. The underlying variational bounds
  are very similar to the objective functions for deep neural networks, giving the
  promise of efficient approaches to deep learning that are constructed from components
  with very well understood analytical properties.
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: University of Sheffield
  twitter: lawrennd
  url: http://inverseprobability.com
categories:
- Lawrence-iit15
day: '23'
errata: []
extras: []
key: Lawrence-iit15
layout: talk
linkpdf: http://staffwww.dcs.shef.ac.uk/people/N.Lawrence/talks/deepgp_iit15.pdf
month: 1
---