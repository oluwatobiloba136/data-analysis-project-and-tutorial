---
abstract: Spectral approaches to dimensionality reduction typically reduce the dimensionality
  of a data set through taking the eigenvectors of a Laplacian or a similarity matrix.
  Classical multidimensional scaling also makes use of the eigenvectors of a similarity
  matrix. In this talk we introduce a maximum entropy approach to designing this similarity
  matrix. The approach is closely related to maximum variance unfolding. Other spectral
  approaches, e.g. locally linear embeddings, turn out to also be closely related.
  These methods can be seen as a sparse Gaussian graphical model where correlations
  between data points (rather than across data features) are specified in the graph.
  The hope is that this unifying perspective will allow the relationships between
  these methods to be better understood and will also provide the groundwork for further
  research.
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: University of Sheffield
  twitter: lawrennd
  url: http://inverseprobability.com
categories:
- Lawrence-cambridge11
day: '16'
errata: []
extras: []
key: Lawrence-cambridge11
layout: talk
linkpdf: ftp://ftp.dcs.shef.ac.uk/home/neil/spectral_cambridge11.pdf
month: 11
mp3: ftp://ftp.dcs.shef.ac.uk/home/neil/111116_ode_cambridge11.mp3
published: 2011-11-16
section: pre
title: A Maximum Entropy Perspective on Spectral Dimensionality Reduction
venue: Machine Learning @ CUED, University of Cambridge, U.K.
year: '2011'
youtube: 2XM2tS6TKhA
---