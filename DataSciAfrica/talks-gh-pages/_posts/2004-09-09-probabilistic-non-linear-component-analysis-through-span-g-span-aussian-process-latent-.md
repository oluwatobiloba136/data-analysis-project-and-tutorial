---
abstract: It is known that Principal Component Analysis has an underlying probabilistic
  representation based on a latent variable model. Principal component analysis (PCA)
  is recovered when the latent variables are integrated out and the parameters of
  the model are optimised by maximum likelihood. It is less well known that the dual
  approach of integrating out the parameters and optimising with respect to the latent
  variables also leads to PCA. The marginalised likelihood in this case takes the
  form of Gaussian process mappings, with linear Covariance functions, from a latent
  space to an observed space, which we refer to as a Gaussian Process Latent Variable
  Model (GPLVM). This dual probabilistic PCA is still a linear latent variable model,
  but by looking beyond the inner product kernel as a for a covariance function we
  can develop a non-linear probabilistic PCA.
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: University of Sheffield
  twitter: lawrennd
  url: http://inverseprobability.com
categories:
- Lawrence-smlwgplvm03
day: '9'
errata: []
extras: []
key: Lawrence-smlwgplvm03
layout: talk
linkpptgz: ftp://ftp.dcs.shef.ac.uk/home/neil/gplvm_smlw.ppt.gz
linkvideo: mms://velblod2.ijs.si/pascal/2004/sheffield_04/lawrence_neil/lawrence_neil_00.wmv
month: 9
published: 2004-09-09
section: pre
title: Probabilistic Non-linear Component Analysis through <span>G</span>aussian Process
  Latent Variable Models
venue: Sheffield Machine Learning Workshop, Sheffield, U.K.
year: '2004'
---